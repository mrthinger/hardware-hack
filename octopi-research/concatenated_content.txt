# set QT_API environment variable
import os 
import glob
import argparse
os.environ["QT_API"] = "pyqt5"
import qtpy

import sys

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_malaria as gui

from configparser import ConfigParser
from control.widgets import ConfigEditorBackwardsCompatible, ConfigEditorForAcquisitions

from control._def import CACHED_CONFIG_FILE_PATH

parser = argparse.ArgumentParser()
parser.add_argument("--simulation", help="Run the GUI with simulated hardware.", action = 'store_true')
args = parser.parse_args()

def show_config(cfp, configpath, main_gui):
    config_widget = ConfigEditorBackwardsCompatible(cfp, configpath, main_gui)
    config_widget.exec_()

def show_acq_config(cfm):
    acq_config_widget = ConfigEditorForAcquisitions(cfm)
    acq_config_widget.exec_()

if __name__ == "__main__":
    legacy_config = False
    cf_editor_parser = ConfigParser()
    config_files = glob.glob('.' + '/' + 'configuration*.ini')
    if config_files:
        cf_editor_parser.read(CACHED_CONFIG_FILE_PATH)
    else:
        print('configuration*.ini file not found, defaulting to legacy configuration')
        legacy_config = True
    app = QApplication([])
    app.setStyle('Fusion')
    if(args.simulation):
        win = gui.OctopiGUI(is_simulation = True)
    else:
        win = gui.OctopiGUI()
       
    acq_config_action = QAction("Acquisition Settings", win)
    acq_config_action.triggered.connect(lambda : show_acq_config(win.configurationManager))

    file_menu = QMenu("File", win)
    file_menu.addAction(acq_config_action)

    if not legacy_config:
        config_action = QAction("Microscope Settings", win)
        config_action.triggered.connect(lambda : show_config(cf_editor_parser, config_files[0], win))
        file_menu.addAction(config_action)
    
    menu_bar = win.menuBar()
    menu_bar.addMenu(file_menu)
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
import argparse
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_displacement_measurement as gui

parser = argparse.ArgumentParser()
parser.add_argument("--simulation", help="Run the GUI with simulated hardware.", action = 'store_true')
args = parser.parse_args()

if __name__ == "__main__":

    app = QApplication([])
    app.setStyle('Fusion')
    if(args.simulation):
        win = gui.OctopiGUI(is_simulation = True)
    else:
        win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
import argparse
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_platereader as gui

parser = argparse.ArgumentParser()
parser.add_argument("--simulation", help="Run the GUI with simulated hardware.", action = 'store_true')
args = parser.parse_args()

if __name__ == "__main__":

    app = QApplication([])
    if(args.simulation):
    	win = gui.OctopiGUI(is_simulation = True)
    else:
    	win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import glob
import argparse
os.environ["QT_API"] = "pyqt5"
import qtpy

import sys

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_hcs as gui

from configparser import ConfigParser
from control.widgets import ConfigEditorBackwardsCompatible, ConfigEditorForAcquisitions

from control._def import CACHED_CONFIG_FILE_PATH

import glob

parser = argparse.ArgumentParser()
parser.add_argument("--simulation", help="Run the GUI with simulated hardware.", action = 'store_true')
args = parser.parse_args()

def show_config(cfp, configpath, main_gui):
    config_widget = ConfigEditorBackwardsCompatible(cfp, configpath, main_gui)
    config_widget.exec_()

def show_acq_config(cfm):
    acq_config_widget = ConfigEditorForAcquisitions(cfm)
    acq_config_widget.exec_()

if __name__ == "__main__":
    legacy_config = False
    cf_editor_parser = ConfigParser()
    config_files = glob.glob('.' + '/' + 'configuration*.ini')
    if config_files:
        cf_editor_parser.read(CACHED_CONFIG_FILE_PATH)
    else:
        print('configuration*.ini file not found, defaulting to legacy configuration')
        legacy_config = True
    app = QApplication([])
    app.setStyle('Fusion')
    if(args.simulation):
        win = gui.OctopiGUI(is_simulation = True)
    else:
        win = gui.OctopiGUI()
       
    acq_config_action = QAction("Acquisition Settings", win)
    acq_config_action.triggered.connect(lambda : show_acq_config(win.configurationManager))

    file_menu = QMenu("File", win)
    file_menu.addAction(acq_config_action)

    if not legacy_config:
        config_action = QAction("Microscope Settings", win)
        config_action.triggered.connect(lambda : show_config(cf_editor_parser, config_files[0], win))
        file_menu.addAction(config_action)
    
    try:
        csw = win.cswWindow
        if csw is not None:
            csw_action = QAction("Camera Settings",win)
            csw_action.triggered.connect(csw.show)
            file_menu.addAction(csw_action)
    except AttributeError:
        pass

    try:
        csw_fc = win.cswfcWindow
        if csw_fc is not None:
            csw_fc_action = QAction("Camera Settings (Focus Camera)", win)
            csw_fc_action.triggered.connect(csw_fc.show)
            file_menu.addAction(csw_fc_action)
    except AttributeError:
        pass
    
    menu_bar = win.menuBar()
    menu_bar.addMenu(file_menu)
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
import argparse
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_2cameras_sync as gui
#import control.gui_2cameras_async as gui
#import control.gui_tiscamera as gui

parser = argparse.ArgumentParser()
parser.add_argument("--simulation", help="Run the GUI with simulated hardware.", action = 'store_true')
args = parser.parse_args()

if __name__ == "__main__":

    app = QApplication([])
    app.setStyle('Fusion')
    if(args.simulation):
        win = gui.OctopiGUI(is_simulation = True)
    else:
        win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_simulation as gui
#import control.gui_2cameras_async as gui
#import control.gui_tiscamera as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_tiscamera_DZK250 as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
#import control.gui_camera_only as gui
#import control.gui_2cameras_async as gui
#import control.gui_tiscamera as gui
import control.gui_2cameras_async_focus_tracking as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
import glob
import argparse
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_6060 as gui

from configparser import ConfigParser
from control.widgets import ConfigEditorBackwardsCompatible, ConfigEditorForAcquisitions

from control._def import CACHED_CONFIG_FILE_PATH

parser = argparse.ArgumentParser()
parser.add_argument("--simulation", help="Run the GUI with simulated hardware.", action = 'store_true')
args = parser.parse_args()

def show_config(cfp, configpath, main_gui):
    config_widget = ConfigEditorBackwardsCompatible(cfp, configpath, main_gui)
    config_widget.exec_()

def show_acq_config(cfm):
    acq_config_widget = ConfigEditorForAcquisitions(cfm)
    acq_config_widget.exec_()

if __name__ == "__main__":
    legacy_config = False
    cf_editor_parser = ConfigParser()
    config_files = glob.glob('.' + '/' + 'configuration*.ini')
    if config_files:
        cf_editor_parser.read(CACHED_CONFIG_FILE_PATH)
    else:
        print('configuration*.ini file not found, defaulting to legacy configuration')
        legacy_config = True
    app = QApplication([])
    app.setStyle('Fusion')
    if(args.simulation):
        win = gui.OctopiGUI(is_simulation = True)
    else:
        win = gui.OctopiGUI()
       
    acq_config_action = QAction("Acquisition Settings", win)
    acq_config_action.triggered.connect(lambda : show_acq_config(win.configurationManager))

    file_menu = QMenu("File", win)
    file_menu.addAction(acq_config_action)

    if not legacy_config:
        config_action = QAction("Microscope Settings", win)
        config_action.triggered.connect(lambda : show_config(cf_editor_parser, config_files[0], win))
        file_menu.addAction(config_action)
    
    menu_bar = win.menuBar()
    menu_bar.addMenu(file_menu)
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
#import control.gui_camera_only as gui
#import control.gui_2cameras_async as gui
#import control.gui_tiscamera as gui
import control.gui_2cameras_daheng_tis as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_motion_only as gui
#import control.gui_2cameras_async as gui
#import control.gui_tiscamera as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

import serial
import serial.tools.list_ports

print('\n')

for p in serial.tools.list_ports.comports():
	print(p.__dict__)
	print('\n')
# set QT_API environment variable
import os 
import sys
import argparse
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_usbspectrometer as gui

parser = argparse.ArgumentParser()
parser.add_argument("--simulation", help="Run the GUI with simulated hardware.", action = 'store_true')
args = parser.parse_args()

if __name__ == "__main__":

    app = QApplication([])
    app.setStyle('Fusion')
    if(args.simulation):
        win = gui.OctopiGUI(is_simulation = True)
    else:
        win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

import control.toupcam as toupcam
from control.camera_toupcam import Camera, get_sn_by_model
from control._def import *
import time

model = "ITR3CMOS26000KMA"

sn = get_sn_by_model(model)

camera = Camera(sn =sn,rotate_image_angle = ROTATE_IMAGE_ANGLE, flip_image=FLIP_IMAGE)

camera.open()

camera.set_gain_mode('HCG')

camera.set_resolution(2000,2000)

camera.set_continuous_acquisition()

camera.start_streaming()

time.sleep(0.5)


camera.set_resolution(camera.res_list[1][0], camera.res_list[1][1])

time.sleep(0.5)

camera.set_pixel_format('MONO16')

time.sleep(0.5)

print(camera.get_awb_ratios())

time.sleep(0.5)

camera.set_ROI(10,10,32,32)

time.sleep(0.5)

myframe = camera.read_frame()
print(myframe)
print(myframe.shape)
print(myframe.dtype)
camera.set_pixel_format('MONO8')
time.sleep(0.5)

myframe2 = camera.read_frame()
print(myframe2)
print(myframe2.shape)
print(myframe2.dtype)

time.sleep(1.0)


myframe2 = camera.read_frame()
print(myframe2)
print(myframe2.shape)
print(myframe2.dtype)



camera.set_ROI(0,0,0,0)

time.sleep(0.5)

camera.set_ROI(2500,2500,3000,3000)

time.sleep(1.0)

myframe2 = camera.read_frame()
print(myframe2)
print(myframe2.shape)
print(myframe2.dtype)


camera.close()

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
#import control.gui_simulation as gui
import control.gui_2cameras_async as gui
#import control.gui_tiscamera as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_volumetric_imaging as gui
#import control.gui_2cameras_async as gui
#import control.gui_tiscamera as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_PDAF_calibration as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI(is_simulation=True)
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_PDAF_demo as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI(is_simulation=True)
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
import argparse
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui as gui
#import control.gui_2cameras_async as gui
#import control.gui_tiscamera as gui

parser = argparse.ArgumentParser()
parser.add_argument("--simulation", help="Run the GUI with simulated hardware.", action = 'store_true')
args = parser.parse_args()

if __name__ == "__main__":

    app = QApplication([])
    app.setStyle('Fusion')
    if(args.simulation):
        win = gui.OctopiGUI(is_simulation = True)
    else:
        win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_camera_only_tiscamera as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_tiscamera_simulation as gui
#import control.gui_2cameras_async as gui
#import control.gui_tiscamera as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_camera_only as gui
#import control.gui_2cameras_async as gui
#import control.gui_tiscamera as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

# version:1.0.1808.9101
import control.gxipy as gx

def main():
    
    # create a device manager
    device_manager = gx.DeviceManager()
    dev_num, dev_info_list = device_manager.update_device_list()
    if dev_num is 0:
        print("Number of enumerated devices is 0")
        return
    for i in range(dev_num):
        print(dev_info_list[i])

if __name__ == "__main__":
    main()

# version:1.0.1905.9051
import gxipy as gx
from PIL import Image


def main():
    # print the demo information
    print("")
    print("-------------------------------------------------------------")
    print("Sample to show how to acquire color image continuously and show acquired image.")
    print("-------------------------------------------------------------")
    print("")
    print("Initializing......")
    print("")

    # create a device manager
    device_manager = gx.DeviceManager()
    dev_num, dev_info_list = device_manager.update_device_list()
    if dev_num is 0:
        print("Number of enumerated devices is 0")
        return

    # open the first device
    cam = device_manager.open_device_by_index(1)

    # exit when the camera is a mono camera
    if cam.PixelColorFilter.is_implemented() is False:
        print("This sample does not support mono camera.")
        cam.close_device()
        return

    # set continuous acquisition
    cam.TriggerMode.set(gx.GxSwitchEntry.OFF)

    # set exposure
    cam.ExposureTime.set(10000.0)

    # set gain
    cam.Gain.set(10.0)

    # get param of improving image quality
    if cam.GammaParam.is_readable():
        gamma_value = cam.GammaParam.get()
        gamma_lut = gx.Utility.get_gamma_lut(gamma_value)
    else:
        gamma_lut = None
    if cam.ContrastParam.is_readable():
        contrast_value = cam.ContrastParam.get()
        contrast_lut = gx.Utility.get_contrast_lut(contrast_value)
    else:
        contrast_lut = None
    if cam.ColorCorrectionParam.is_readable():
        color_correction_param = cam.ColorCorrectionParam.get()
    else:
        color_correction_param = 0

    # start data acquisition
    cam.stream_on()

    # acquisition image: num is the image number
    num = 1
    for i in range(num):
        # get raw image
        raw_image = cam.data_stream[0].get_image()
        if raw_image is None:
            print("Getting image failed.")
            continue

        # get RGB image from raw image
        rgb_image = raw_image.convert("RGB")
        if rgb_image is None:
            continue

        # improve image quality
        rgb_image.image_improvement(color_correction_param, contrast_lut, gamma_lut)

        # create numpy array with data from raw image
        numpy_image = rgb_image.get_numpy_array()
        if numpy_image is None:
            continue

        # show acquired image
        img = Image.fromarray(numpy_image, 'RGB')
        img.show()

        # print height, width, and frame ID of the acquisition image
        print("Frame ID: %d   Height: %d   Width: %d"
              % (raw_image.get_frame_id(), raw_image.get_height(), raw_image.get_width()))

    # stop data acquisition
    cam.stream_off()

    # close device
    cam.close_device()

if __name__ == "__main__":
    main()

#!/usr/bin/env python
# -*- coding:utf-8 -*-
from __future__ import print_function
from setuptools import setup, find_packages
import sys

setup(
    name='gxipy',
    version='1.0.1905.9051',
    description='',
    license='MIT',
    packages=['gxipy'],
)

# version:1.0.1905.9051
import gxipy as gx
from PIL import Image


def main():
    # print the demo information
    print("")
    print("-------------------------------------------------------------")
    print("Sample to show how to acquire mono image continuously and show acquired image.")
    print("-------------------------------------------------------------")
    print("")
    print("Initializing......")
    print("")

    # create a device manager
    device_manager = gx.DeviceManager()
    dev_num, dev_info_list = device_manager.update_device_list()
    if dev_num is 0:
        print("Number of enumerated devices is 0")
        return

    # open the first device
    cam = device_manager.open_device_by_index(1)

    # exit when the camera is a color camera
    if cam.PixelColorFilter.is_implemented() is True:
        print("This sample does not support color camera.")
        cam.close_device()
        return

    # set continuous acquisition
    cam.TriggerMode.set(gx.GxSwitchEntry.OFF)

    # set exposure
    cam.ExposureTime.set(10000)

    # set gain
    cam.Gain.set(10.0)

    # start data acquisition
    cam.stream_on()

    # acquire image: num is the image number
    num = 1
    for i in range(num):
        # get raw image
        raw_image = cam.data_stream[0].get_image()
        if raw_image is None:
            print("Getting image failed.")
            continue

        # create numpy array with data from raw image
        numpy_image = raw_image.get_numpy_array()
        if numpy_image is None:
            continue

        # show acquired image
        img = Image.fromarray(numpy_image, 'L')
        img.show()

        # print height, width, and frame ID of the acquisition image
        print("Frame ID: %d   Height: %d   Width: %d"
              % (raw_image.get_frame_id(), raw_image.get_height(), raw_image.get_width()))

    # stop data acquisition
    cam.stream_off()

    # close device
    cam.close_device()

if __name__ == "__main__":
    main()

# set QT_API environment variable
import os 
import sys
import argparse
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_toupcam_IMX571 as gui
#import control.gui_2cameras_async as gui
#import control.gui_tiscamera as gui

parser = argparse.ArgumentParser()
parser.add_argument("--simulation", help="Run the GUI with simulated hardware.", action = 'store_true')
args = parser.parse_args()

if __name__ == "__main__":

    app = QApplication([])
    app.setStyle('Fusion')
    if(args.simulation):
        win = gui.OctopiGUI(is_simulation = True)
    else:
        win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

import os
from glob import glob
from script_stitch_slide import get_channels, get_time_indices
import json
import sys
import pandas as pd

def get_ny(slide_path):
    parameter_path = os.path.join(slide_path, "acquisition parameters.json")
    parameters = {}
    with open(parameter_path, "r") as f:
        parameters = json.load(f)

    Ny = int(parameters['Ny'])
    return Ny

def get_inverted_y_filepath(filepath, channel_name, Ny):
    """Given a channel name to strip and a number of y indices, returns
    a version of the slide name with its y-index inverted."""
    channel_name = channel_name.replace(" ", "_")
    filename = filepath.split("/")[-1]
    extension = filename.split(".")[-1]
    coord_list = filename.replace(channel_name, "").replace("."+extension,"").strip("_").split("_")
    if len(coord_list) > 3:
        coord_list[1] = str(Ny-1-int(coord_list[1]))
    else:
        coord_list[0] = str(Ny-1-int(coord_list[0]))

    inverted_y_filename = "_".join([*coord_list, channel_name])+"."+extension
    inverted_y_filepath = filepath.replace(filename, inverted_y_filename)
    return inverted_y_filepath


def invert_y_in_folder(fovs_path, channel_names, Ny):
    """Given a folder with FOVs, channel names, and Ny, inverts the y-indices of all of them"""
    
    for channel in channel_names:
        channel = channel.replace(" ", "_")
        filepaths = list(glob(os.path.join(fovs_path, "*_*_*_"+channel+".*")))
        for path in filepaths:
            inv_y_filepath = get_inverted_y_filepath(path, channel, Ny)
            os.rename(path, inv_y_filepath+"._inverted")
        for path in filepaths:
            os.rename(path+"._inverted", path)

def invert_y_in_slide(slide_path):
    Ny = get_ny(slide_path)
    time_indices = get_time_indices(slide_path)
    channels = get_channels(slide_path)
    for t in time_indices:
        fovs_path = os.path.join(slide_path, str(t))
        invert_y_in_folder(fovs_path, channels, Ny)

        # invert the y-index in the CSV too
        coord_csv_path = os.path.join(fovs_path, "coordinates.csv")
        coord_df = pd.read_csv(coord_csv_path)
        coord_df["i"] = (Ny-1)-coord_df["i"]
        coord_df.to_csv(coord_csv_path, index=False)

if __name__ == "__main__":
    if len(sys.argv) <= 1:
        print("Must provide a path to a slide folder.")
        exit()
    invert_y_in_slide(sys.argv[1])
    print("Inverted all i/y-indices in "+sys.argv[1])

from lxml import etree as ET
top = ET.Element('modes')

mode_1 = ET.SubElement(top,'mode')
# ID = ET.SubElement(mode_1,'ID')
# ID.text = '123'
mode_1.set('ID','1')
mode_1.set('Name','BF LED matrix full')
mode_1.set('ExposureTime','100')
mode_1.set('AnalogGain','10')
mode_1.set('IlluminationSource','0')
mode_1.set('IlluminationIntensity','100')
mode_1.set('CameraSN','')
mode_1.set('ZOffset','0.0')
mode_1.set('PixelFormat','default')
mode_1.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')


mode_2 = ET.SubElement(top,'mode')
mode_2.set('ID','2')
mode_2.set('Name','BF LED matrix left half')
mode_2.set('ExposureTime','100')
mode_2.set('AnalogGain','10')
mode_2.set('IlluminationSource','1')
mode_2.set('IlluminationIntensity','100')
mode_2.set('CameraSN','')
mode_2.set('ZOffset','0.0')
mode_2.set('PixelFormat','default')
mode_2.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')


mode_3 = ET.SubElement(top,'mode')
mode_3.set('ID','3')
mode_3.set('Name','BF LED matrix right half')
mode_3.set('ExposureTime','100')
mode_3.set('AnalogGain','10')
mode_3.set('IlluminationSource','2')
mode_3.set('IlluminationIntensity','100')
mode_3.set('CameraSN','')
mode_3.set('ZOffset','0.0')
mode_3.set('PixelFormat','default')
mode_3.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')


mode_4 = ET.SubElement(top,'mode')
mode_4.set('ID','4')
mode_4.set('Name','BF LED matrix color PDAF')
mode_4.set('ExposureTime','100')
mode_4.set('AnalogGain','10')
mode_4.set('IlluminationSource','3')
mode_4.set('IlluminationIntensity','100')
mode_4.set('CameraSN','')
mode_4.set('ZOffset','0.0')
mode_4.set('PixelFormat','default')
mode_4.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')



mode_5 = ET.SubElement(top,'mode')
mode_5.set('ID','5')
mode_5.set('Name','Fluorescence 405 nm Ex')
mode_5.set('ExposureTime','100')
mode_5.set('AnalogGain','10')
mode_5.set('IlluminationSource','11')
mode_5.set('IlluminationIntensity','100')
mode_5.set('CameraSN','')
mode_5.set('ZOffset','0.0')
mode_5.set('PixelFormat','default')
mode_5.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')


mode_6 = ET.SubElement(top,'mode')
mode_6.set('ID','6')
mode_6.set('Name','Fluorescence 488 nm Ex')
mode_6.set('ExposureTime','100')
mode_6.set('AnalogGain','10')
mode_6.set('IlluminationSource','12')
mode_6.set('IlluminationIntensity','100')
mode_6.set('CameraSN','')
mode_6.set('ZOffset','0.0')
mode_6.set('PixelFormat','default')
mode_6.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')


mode_7 = ET.SubElement(top,'mode')
mode_7.set('ID','7')
mode_7.set('Name','Fluorescence 638 nm Ex')
mode_7.set('ExposureTime','100')
mode_7.set('AnalogGain','10')
mode_7.set('IlluminationSource','13')
mode_7.set('IlluminationIntensity','100')
mode_7.set('CameraSN','')
mode_7.set('ZOffset','0.0')
mode_7.set('PixelFormat','default')
mode_7.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')


# print(ET.tostring(top, encoding="UTF-8", pretty_print=True).decode())
tree = ET.ElementTree(top)
tree.write('configurations.xml',encoding="utf-8", xml_declaration=True, pretty_print=True)

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.gui_camera_only as gui
#import control.gui_2cameras_async as gui
#import control.gui_tiscamera as gui

if __name__ == "__main__":

    app = QApplication([])
    win = gui.OctopiGUI()
    win.show()
    sys.exit(app.exec_())

#!/usr/bin/python
# -*- coding:utf-8 -*-
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-

from gxipy.gxiapi import *
from gxipy.gxidef import *


__all__ = ["gxwrapper", "dxwrapper", "gxiapi", "gxidef"]

__version__ = '1.0.1905.9051'

# version:1.0.1905.9071
import gxipy as gx
import time
from PIL import Image


def acq_color(device, num):
    """
           :brief      acquisition function of color device
           :param      device:     device object[Device]
           :param      num:        number of acquisition images[int]
    """
    for i in range(num):
        time.sleep(0.1)

        # send software trigger command
        device.TriggerSoftware.send_command()

        # get raw image
        raw_image = device.data_stream[0].get_image()
        if raw_image is None:
            print("Getting image failed.")
            continue

        # get RGB image from raw image
        rgb_image = raw_image.convert("RGB")
        if rgb_image is None:
            continue

        # create numpy array with data from raw image
        numpy_image = rgb_image.get_numpy_array()
        if numpy_image is None:
            continue

        # show acquired image
        img = Image.fromarray(numpy_image, 'RGB')
        img.show()

        # print height, width, and frame ID of the acquisition image
        print("Frame ID: %d   Height: %d   Width: %d"
              % (raw_image.get_frame_id(), raw_image.get_height(), raw_image.get_width()))


def acq_mono(device, num):
    """
           :brief      acquisition function of mono device
           :param      device:     device object[Device]
           :param      num:        number of acquisition images[int]
    """
    for i in range(num):
        time.sleep(0.1)

        # send software trigger command
        device.TriggerSoftware.send_command()

        # get raw image
        raw_image = device.data_stream[0].get_image()
        if raw_image is None:
            print("Getting image failed.")
            continue

        # create numpy array with data from raw image
        numpy_image = raw_image.get_numpy_array()
        if numpy_image is None:
            continue

        # show acquired image
        img = Image.fromarray(numpy_image, 'L')
        img.show()

        # print height, width, and frame ID of the acquisition image
        print("Frame ID: %d   Height: %d   Width: %d"
              % (raw_image.get_frame_id(), raw_image.get_height(), raw_image.get_width()))


def main():
    # print the demo information
    print("")
    print("-------------------------------------------------------------")
    print("Sample to show how to acquire mono or color image by soft trigger "
          "and show acquired image.")
    print("-------------------------------------------------------------")
    print("")
    print("Initializing......")
    print("")

    # create a device manager
    device_manager = gx.DeviceManager()
    dev_num, dev_info_list = device_manager.update_device_list()
    if dev_num is 0:
        print("Number of enumerated devices is 0")
        return

    # open the first device
    cam = device_manager.open_device_by_index(1)

    # set exposure
    cam.ExposureTime.set(10000)

    # set gain
    cam.Gain.set(10.0)

    if dev_info_list[0].get("device_class") == gx.GxDeviceClassList.USB2:
        # set trigger mode
        cam.TriggerMode.set(gx.GxSwitchEntry.ON)
    else:
        # set trigger mode and trigger source
        cam.TriggerMode.set(gx.GxSwitchEntry.ON)
        cam.TriggerSource.set(gx.GxTriggerSourceEntry.SOFTWARE)

    # start data acquisition
    cam.stream_on()

    # camera is color camera
    if cam.PixelColorFilter.is_implemented() is True:
        acq_color(cam, 1)
    # camera is mono camera
    else:
        acq_mono(cam, 1)

    # stop acquisition
    cam.stream_off()

    # close device
    cam.close_device()


if __name__ == "__main__":
    main()

import json
import os
from glob import glob
from lxml import etree as ET
import cv2
from stitcher import stitch_slide, compute_overlap_percent
import sys

def get_pixel_size(slide_path, default_pixel_size=1.85, default_tube_lens_mm=50.0, default_objective_tube_lens_mm=180.0, default_magnification=20.0):
    parameter_path = os.path.join(slide_path, "acquisition parameters.json")
    parameters = {}
    with open(parameter_path, "r") as f:
        parameters = json.load(f)
    try:
        tube_lens_mm = float(parameters['tube_lens_mm'])
    except KeyError:
        tube_lens_mm = default_tube_lens_mm
    try:
        pixel_size_um = float(parameters['sensor_pixel_size_um'])
    except KeyError:
        pixel_size_um = default_pixel_size
    try:
        objective_tube_lens_mm = float(parameters['objective']['tube_lens_f_mm'])
    except KeyError:
        objective_tube_lens_mm = default_objective_tube_lens_mm
    try:
        magnification = float(parameters['objective']['magnification'])
    except KeyError:
        magnification = default_magnification

    pixel_size_xy = pixel_size_um/(magnification/(objective_tube_lens_mm/tube_lens_mm))

    return pixel_size_xy

def get_overlap(slide_path, **kwargs):
    sample_fov_path = os.path.join(slide_path, "0/*0_0_0_*.*")
    sample_fov_path = glob(sample_fov_path)[0]
    sample_fov_shape = cv2.imread(sample_fov_path).shape
    fov_width = sample_fov_shape[1]
    fov_height = sample_fov_shape[0]

    pixel_size_xy = get_pixel_size(slide_path, **kwargs)
    
    parameter_path = os.path.join(slide_path, "acquisition parameters.json")
    parameters = {}
    with open(parameter_path, "r") as f:
        parameters = json.load(f)

    dx = float(parameters['dx(mm)'])*1000.0
    dy = float(parameters['dy(mm)'])*1000.0

    overlap_percent = compute_overlap_percent(dx, dy, fov_width, fov_height, pixel_size_xy)

    return overlap_percent

def get_time_indices(slide_path):
    
    parameter_path = os.path.join(slide_path, "acquisition parameters.json")
    parameters = {}
    with open(parameter_path, "r") as f:
        parameters = json.load(f)

    time_indices = list(range(int(parameters['Nt'])))
    return time_indices

def get_channels(slide_path):
    config_xml_tree_root = ET.parse(os.path.join(slide_path, "configurations.xml")).getroot()
    channel_names = []
    for mode in config_xml_tree_root.iter('mode'):
        if mode.get("Selected") == "1":
            channel_names.append(mode.get('Name').replace(" ","_"))
    return channel_names

def get_z_indices(slide_path):
    parameter_path = os.path.join(slide_path, "acquisition parameters.json")
    parameters = {}
    with open(parameter_path, "r") as f:
        parameters = json.load(f)

    z_indices = list(range(int(parameters['Nz'])))
    return z_indices


def get_coord_names(slide_path):
    sample_fovs_path=os.path.join(slide_path, "0/*_0_0_0_*.*")
    sample_fovs = glob(sample_fovs_path)
    coord_names = []
    for fov in sample_fovs:
        filename = fov.split("/")[-1]
        coord_name = filename.split("_0_")[0]
        coord_names.append(coord_name+"_")
    coord_names = list(set(coord_names))
    if len(coord_names) == 0:
        coord_names = ['']
    return coord_names

def stitch_slide_from_path(slide_path, **kwargs):
    time_indices = get_time_indices(slide_path)
    z_indices = get_z_indices(slide_path)
    channels = get_channels(slide_path)
    coord_names = get_coord_names(slide_path)
    overlap_percent = get_overlap(slide_path, **kwargs)

    recompute_overlap = (overlap_percent > 10)

    stitch_slide(slide_path, time_indices, channels, z_indices, coord_names, overlap_percent = overlap_percent, reg_threshold=0.30, avg_displacement_threshold=2.50, abs_displacement_threshold=3.50, tile_downsampling=1.0, recompute_overlap=recompute_overlap)

def print_usage():
    usage_str = """
    Stitches images using Fiji. NOTE: the y-indexing of images must go from bottom to top, which is only the case for the most recent patch of Squid.

    Usage (to be run from software directory in your Squid install):

    python tools/script_stitch_slide.py PATH_TO_SLIDE_FOLDER [--sensor-size SENSOR_PIXEL_SIZE_UM] [--tube-lens TUBE_LENS_MM] [--objective-tube-lens OBJECTIVE_TUBE_LENS_MM] [--magnification MAGNIFICATION] [--help]

    OPTIONAL PARAMETERS:
    --help/-h : Prints this and exits.

    --sensor-size : Sensor pixel size in um
    --tube-lens : Your tube lens's length in mm (separate from the objective's
        tube lens focal length)
    --objective-tube-lens : Your objective's tube lens focal length in mm
    --magnification : Your objective's listed magnification

    The script will first try to read this parameters from acquisition parameters.json, but will default to your provided values if it can't.
    """

    print(usage_str)

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("No slide path name provided!")
        print_usage()
        exit()
        
    parameter_names = {
            "--sensor-size":"default_pixel_size",
            "--tube-lens":"default_tube_lens_mm",
            "--objective-tube-lens":"default_objective_tube_lens_mm",
            "--magnification":"default_magnification"
            }

    param_list = list(parameter_names.keys())

    user_kwargs = {}

    if "--help" in sys.argv or "-h" in sys.argv:
        print_usage()
        exit()

    for i in range(len(sys.argv)):
        if sys.argv[i] in param_list:
            try:
                arg_value = float(sys.argv[i+1])
                user_kwargs[parameter_names[sys.argv[i]]] = arg_value
            except (IndexError, ValueError):
                print("Malformed argument, exiting.")
                exit()

    

    stitch_slide_from_path(sys.argv[1], **user_kwargs)

from lxml import etree as ET
import json
import sys
import os
import re

import zarr
from skimage.io import imread
from skimage.io.collection import alphanumeric_key
from dask import delayed
import dask.array as da
from glob import glob

from ome_zarr.writer import write_image
from ome_zarr.io import parse_url

lazy_imread = delayed(imread)

def read_configurations_used(filepath):
    xml_tree = ET.parse(filepath)
    xml_tree_root = xml_tree.getroot()
    conf_list = []
    for mode in xml_tree_root.iter('mode'):
        selected = int(mode.get("Selected"))
        if selected != 0:
            mode_id = int(mode.get("ID"))
            mode_name = mode.get('Name')
            conf_list.append((mode_id,mode_name))
    conf_list = sorted(conf_list,key= lambda tup: tup[0])
    conf_list = [tup[1] for tup in conf_list]
    return conf_list

def get_dimensions_for_dataset(dataset_folder_path, sensor_pixel_size_um_default = 1.0, objective_magnification_default=1.0, Nz_override = None, Nt_override = None):
    """Returns dict of dimensions and then step sizes in
    mm for dx/dy, um for dz, and s in dt.

    :return: dict in format {
        'Nx':Nx,
        'Ny':Ny,
        'Nz':Nz,
        'Nt':Nt,
        'dt':dt,
        'dx': dx (in mm),
        'dy': dy (in mm),
        'dz': dz (in um),
        'Nc': number of channels,
        'channels': list of channel names,
        'pixel_size_um': pixel side length (in um),
        'FOV_shape': int 2-tuple that is the shape of a single channel's FOV,
        'FOV_dtype': numpy dtype representing a single FOV image's dtype
    }"""
    acq_param_path = os.path.join(dataset_folder_path,"acquisition parameters.json")
    config_xml_path = os.path.join(dataset_folder_path,"configurations.xml")
    acq_params = None
    with open(acq_param_path,'r') as file:
        acq_params = json.load(file)
    Nt = int(acq_params.get('Nt'))
    if Nt_override is not None:
        if Nt_override < Nt:
            Nt = Nt_override
    Nz = int(acq_params.get('Nz'))
    if Nz_override is not None:
        if Nz_override < Nz:
            Nz = Nz_override
    dt = float(acq_params.get('dt(s)'))
    dz = float(acq_params.get('dz(um)'))
    
    Nx = int(acq_params.get('Nx'))
    Ny = int(acq_params.get('Ny'))
    dx = float(acq_params.get('dx(mm)'))
    dy = float(acq_params.get('dy(mm)'))

    try:
        objective = acq_params.get('objective')
        objective_magnification = float(objective['magnification'])
    except (KeyError, ValueError, AttributeError, TypeError):
        objective_magnification = objective_magnification_default

    try:
        sensor = acq_params.get('sensor')
        sensor_pixel_size = float(sensor['pixel_size_um'])
    except (KeyError, ValueError, AttributeError, TypeError):
        sensor_pixel_size = sensor_pixel_size_um_default

    pixel_size_um = sensor_pixel_size/objective_magnification

    imagespath = os.path.join(dataset_folder_path, '0/0_*.*')
    first_file  = sorted(glob(imagespath), key=alphanumeric_key)[0]
    sample = imread(first_file)
    
    FOV_shape = sample.shape
    FOV_dtype = sample.dtype

    channels = read_configurations_used(config_xml_path)
    Nc = len(channels)

    return {'Nx':Nx,
            'Ny':Ny,
            'Nz':Nz,
            'dx':dx,
            'dy':dy,
            'dz':dz,
            'Nt':Nt,
            'dt':dt,
            'Nc':Nc,
            'channels':channels,
            'pixel_size_um':pixel_size_um,
            'FOV_shape':FOV_shape,
            'FOV_dtype':FOV_dtype
            }


def create_dask_array_for_single_fov(dataset_folder_path, x=0,y=0, sensor_pixel_size_um_default = 1.0, objective_magnification_default=1.0, z_to_use=None, t_to_use=None, well=0):
    Nt_override = None
    if t_to_use is not None:
        Nt_override = len(t_to_use)
    Nz_override = None
    if z_to_use is not None:
        Nz_override = len(z_to_use)
    dimension_data = get_dimensions_for_dataset(dataset_folder_path, sensor_pixel_size_um_default, objective_magnification_default, Nz_override, Nt_override)
    if t_to_use is not None:
        if max(t_to_use) >= dimension_data['Nt'] or min(t_to_use) < 0:
            raise IndexError("t index given in list out of bounds")
    if z_to_use is not None:
        if max(z_to_use) >= dimension_data['Nz'] or min(z_to_use) < 0:
            raise IndexError("z index given in list out of bounds")
    if t_to_use is None:
        t_to_use = list(range(dimension_data['Nt']))
    if z_to_use is None:
        z_to_use = list(range(dimension_data['Nz']))
    if x >= dimension_data['Nx'] or x<0 or y>= dimension_data['Ny'] or y < 0:
        raise IndexError("FOV indices out of range.")
    dask_arrays_time = []
    for t in t_to_use:
        dask_arrays_channel = []
        for channel in dimension_data['channels']:
            filenames = []
            for z in z_to_use:
                image_path = str(t)+"/"+str(y)+"_"+str(x)+"_"+str(z)+"_"+channel.strip().replace(" ","_")+".*"
                image_path = os.path.join(dataset_folder_path, image_path)
                file_matches = glob(image_path)
                if len(file_matches) > 0:
                    filenames.append(file_matches[0])
                else:
                    image_path = str(t)+"/"+str(well)+"_"+str(y)+"_"+str(x)+"_"+str(z)+"_"+channel.strip().replace(" ","_")+".*"
                    image_path = os.path.join(dataset_folder_path, image_path)
                    file_matches = glob(image_path)
                    if len(file_matches) > 0:
                        filenames.append(file_matches[0])
            filenames = sorted(filenames,key=alphanumeric_key)
            lazy_arrays = [lazy_imread(fn) for fn in filenames]
            dask_arrays = [
                    da.from_delayed(delayed_reader, shape = dimension_data['FOV_shape'], dtype=dimension_data['FOV_dtype'])
                    for delayed_reader in lazy_arrays
                    ]
            stack = da.stack(dask_arrays, axis=0)
            dask_arrays_channel.append(stack)
        channel_stack = da.stack(dask_arrays_channel, axis=0)
        dask_arrays_time.append(channel_stack)
    time_stack = da.stack(dask_arrays_time,axis=0)
    return time_stack

def create_zarr_for_single_fov(dataset_folder_path, saving_path, x=0,y=0,sensor_pixel_size_um=1.0, objective_magnification=1.0, z_to_use=None, t_to_use = None, well=0):
    try:
        os.mkdir(saving_path)
    except FileExistsError:
        pass
    dimension_data = get_dimensions_for_dataset(dataset_folder_path, sensor_pixel_size_um, objective_magnification)
    scale_xy = dimension_data["pixel_size_um"]
    scale_z = dimension_data["dz"]
    if scale_z == 0.0:
        scale_z = 1.0
    scale_t = dimension_data["dt"]
    if scale_t == 0.0:
        scale_t = 1.0
    coord_transform=[{"type":"scale","scale":[scale_t,1.0,scale_z,scale_xy,scale_xy]}]

    fov_dask_array = create_dask_array_for_single_fov(dataset_folder_path, x,y, sensor_pixel_size_um, objective_magnification, z_to_use, t_to_use, well)
    xy_only_dims = fov_dask_array.shape[3:]
    store = parse_url(saving_path, mode="w").store
    root = zarr.group(store=store)
    write_image(image=fov_dask_array, group=root,
            scaler = None, axes=["t","c","z","y","x"],
            coordinate_transformations=[coord_transform],
            storage_options=dict(chunks=(1,1,1,*xy_only_dims)))

if __name__ == "__main__":
    if len(sys.argv) != 5 and len(sys.argv) != 3 and len(sys.argv) != 7 and len(sys.argv) != 8 and len(sys.argv) != 9:
        raise RuntimeError("2 positional arguments required: path to slide data folder, and path to zarr to write. The following 2 positional arguments, if they exist, must be the x-index and the y-index of the FOV to convert (default 0). The last two positional arguments should be the pixel_size_um parameter of the sensor, and the magnification of the objective used. The last two positional arguments are an override on the number of z steps to use and an override on the number of t steps to use.")
    folderpath = sys.argv[1]
    saving_path = sys.argv[2]
    try:
        x = int(sys.argv[3])
        y = int(sys.argv[4])
    except IndexError:
        x = 0
        y = 0

    try:
        sensor_pixel_size = float(sys.argv[5])
        objective_magnification = float(sys.argv[6])
    except IndexError:
        sensor_pixel_size=1.85
        objective_magnification=20.0

    try:
        Nz_override = int(sys.argv[7])
        z_to_use = list(range(Nz_override))
    except IndexError:
        z_to_use = None

    try:
        Nt_override = int(sys.argv[8])
        t_to_use = list(range(Nt_overide))
    except IndexError:
        t_to_use = None

    create_zarr_for_single_fov(folderpath, saving_path,x,y, sensor_pixel_size, objective_magnification, z_to_use, t_to_use)
    print("OME-Zarr written to "+saving_path)
    print("Use the command\n    $> napari --plugin napari-ome-zarr "+saving_path+"\nto view.")

import os
import stat
def create_desktop_shortcut_simulation(directory_path, script_name):
    squid_suffix = script_name.replace("main_","")
    icon_path = os.path.join(directory_path, "icon/cephla_logo.svg")
    if squid_suffix != "main" and squid_suffix != "":
        shortcut_content = f'''\
[Desktop Entry]
Name=Squid_{squid_suffix}_simulation
Icon={icon_path}
Exec=gnome-terminal --working-directory="{directory_path}" -e "/usr/bin/env python3 {directory_path}/{script_name}.py --simulation"
Type=Application
Terminal=true
'''
    else:
         shortcut_content = f'''\
[Desktop Entry]
Name=Squid_simulation
Icon={icon_path}
Exec=gnome-terminal --working-directory="{directory_path}" -e "/usr/bin/env python3 {directory_path}/{script_name}.py --simulation"
Type=Application
Terminal=true
'''

    if squid_suffix != "main" and squid_suffix != "":
        desktop_path_base = f'~/Desktop/Squid_{squid_suffix}_simulation.desktop'
    else:
        desktop_path_base = f'~/Desktop/Squid_simulation.desktop'
    desktop_path = os.path.expanduser(desktop_path_base)
    with open(desktop_path, 'w') as shortcut_file:
        shortcut_file.write(shortcut_content)
    os.chmod(desktop_path, stat.S_IRWXU)
    return desktop_path



def create_desktop_shortcut(directory_path, script_name):
    squid_suffix = script_name.replace("main_","")
    icon_path = os.path.join(directory_path, "icon/cephla_logo.svg")
    if squid_suffix != "main" and squid_suffix != "":
        shortcut_content = f'''\
[Desktop Entry]
Name=Squid_{squid_suffix}
Icon={icon_path}
Exec=gnome-terminal --working-directory="{directory_path}" -e "/usr/bin/env python3 {directory_path}/{script_name}.py"
Type=Application
Terminal=true
'''
    else:
         shortcut_content = f'''\
[Desktop Entry]
Name=Squid
Icon={icon_path}
Exec=gnome-terminal --working-directory="{directory_path}" -e "/usr/bin/env python3 {directory_path}/{script_name}.py"
Type=Application
Terminal=true
'''

    if squid_suffix != "main" and squid_suffix != "":
        desktop_path_base = f'~/Desktop/Squid_{squid_suffix}.desktop'
    else:
        desktop_path_base = f'~/Desktop/Squid.desktop'
    desktop_path = os.path.expanduser(desktop_path_base)
    with open(desktop_path, 'w') as shortcut_file:
        shortcut_file.write(shortcut_content)
    os.chmod(desktop_path, stat.S_IRWXU)
    return desktop_path

def main():
    # Prompt for directory path and script name
    directory_path = input('Enter the directory path to octopi-research/software (default: current directory): ') or os.getcwd()
    script_name = input('Enter the main script name under octopi-research/software (without .py extension): ')

    simulation = input('Is this for launching in simulation mode? [NO/yes]: ') or False
    if str(simulation).lower() == 'yes':
        simulation = True
    else:
        simulation = False

    # Create desktop shortcut
    if not simulation:
        desktop_path = create_desktop_shortcut(directory_path, script_name)
    else:
        desktop_path = create_desktop_shortcut_simulation(directory_path, script_name)
    print(f'Desktop shortcut created at: {desktop_path}')

if __name__ == '__main__':
    main()


# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

from control._def import *

class TrackingControllerWidget(QFrame):
    def __init__(self, multipointController, navigationController, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.multipointController = multipointController
        self.navigationController = navigationController
        self.base_path_is_set = False
        # self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)


# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.core_PDAF as core_PDAF
import control.microcontroller as microcontroller

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		self.camera_1 = camera.Camera_Simulation(sn='FW0190110139')
		self.camera_2 = camera.Camera_Simulation(sn='FU0190090030')
		self.microcontroller = microcontroller.Microcontroller_Simulation()

		self.PDAFController = core_PDAF.PDAFController()
		
		self.streamHandler_1 = core.StreamHandler()
		self.streamHandler_2 = core.StreamHandler()
		self.liveController_1 = core.LiveController(self.camera_1,self.microcontroller)
		self.liveController_2 = core.LiveController(self.camera_2,self.microcontroller)
		self.navigationController = core.NavigationController(self.microcontroller)
		self.autofocusController = core.AutoFocusController(self.camera_1,self.navigationController,self.liveController_1)
		self.trackingController = core.TrackingController(self.microcontroller,self.navigationController)
		self.imageSaver_1 = core.ImageSaver()
		self.imageSaver_2 = core.ImageSaver()
		self.imageDisplay_1 = core.ImageDisplay()
		self.imageDisplay_2 = core.ImageDisplay()

		# open the cameras
		self.camera_1.open()
		self.camera_1.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera_1.set_callback(self.streamHandler_1.on_new_frame)
		self.camera_1.enable_callback()

		self.camera_2.open()
		self.camera_2.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera_2.set_callback(self.streamHandler_2.on_new_frame)
		self.camera_2.enable_callback()

		# load widgets
		self.cameraSettingWidget_1 = widgets.CameraSettingsWidget(self.camera_1,self.liveController_1)
		self.liveControlWidget_1 = widgets.LiveControlWidget(self.streamHandler_1,self.liveController_1)
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
		self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
		self.recordingControlWidget_1 = widgets.RecordingWidget(self.streamHandler_1,self.imageSaver_1)
		self.trackingControlWidget = widgets.TrackingControllerWidget(self.streamHandler_1,self.trackingController)

		self.cameraSettingWidget_2 = widgets.CameraSettingsWidget(self.camera_2,self.liveController_2)
		self.liveControlWidget_2 = widgets.LiveControlWidget(self.streamHandler_2,self.liveController_2)
		self.recordingControlWidget_2 = widgets.RecordingWidget(self.streamHandler_2,self.imageSaver_2)
		
		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		# layout.addWidget(self.cameraSettingWidget_1,0,0)
		layout.addWidget(self.liveControlWidget_1,1,0)
		# layout.addWidget(self.navigationWidget,2,0)
		# layout.addWidget(self.autofocusWidget,3,0)
		# layout.addWidget(self.recordingControlWidget_1,4,0)
		
		# layout.addWidget(self.cameraSettingWidget_2,5,0)
		layout.addWidget(self.liveControlWidget_2,6,0)
		# layout.addWidget(self.recordingControlWidget_2,7,0)

		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# load window
		self.imageDisplayWindow_1 = core.ImageDisplayWindow()
		self.imageDisplayWindow_1.show()
		self.imageDisplayWindow_2 = core.ImageDisplayWindow()
		self.imageDisplayWindow_2.show()

		# make connections
		self.streamHandler_1.signal_new_frame_received.connect(self.liveController_1.on_new_frame)
		self.streamHandler_1.image_to_display.connect(self.imageDisplay_1.enqueue)
		self.streamHandler_1.packet_image_to_write.connect(self.imageSaver_1.enqueue)
		self.streamHandler_1.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
		self.imageDisplay_1.image_to_display.connect(self.imageDisplayWindow_1.display_image) # may connect streamHandler directly to imageDisplayWindow

		self.streamHandler_2.signal_new_frame_received.connect(self.liveController_2.on_new_frame)
		self.streamHandler_2.image_to_display.connect(self.imageDisplay_2.enqueue)
		self.streamHandler_2.packet_image_to_write.connect(self.imageSaver_2.enqueue)
		self.imageDisplay_2.image_to_display.connect(self.imageDisplayWindow_2.display_image) # may connect streamHandler directly to imageDisplayWindow
		
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)
		self.autofocusController.image_to_display.connect(self.imageDisplayWindow_1.display_image)

		self.streamHandler_1.image_to_display.connect(self.PDAFController.register_image_from_camera_1)
		self.streamHandler_2.image_to_display.connect(self.PDAFController.register_image_from_camera_2)


	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.liveController_1.stop_live()
		self.camera_1.close()
		self.imageSaver_1.close()
		self.imageDisplay_1.close()
		self.imageDisplayWindow_1.close()
		self.liveController_2.stop_live()
		self.camera_2.close()
		self.imageSaver_2.close()
		self.imageDisplay_2.close()
		self.imageDisplayWindow_2.close()

#!/usr/bin/python
# -*- coding:utf-8 -*-
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-
#

from ctypes import *
import sys
import os

if sys.platform == 'linux2' or sys.platform == 'linux':
    if os.path.exists('/usr/lib/libdximageproc.so') : 
        filepath = '/usr/lib/libdximageproc.so'
    else:
        filepath = '/usr/lib/libgxiapi.so'
    try:
        dll = CDLL(filepath)
    except OSError:
        print('Cannot find libdximageproc.so or libgxiapi.so.')
else:
    try:
        dll = WinDLL('DxImageProc.dll')
    except OSError:
        print('Cannot find DxImageProc.dll.')


# status  definition
class DxStatus:
    OK = 0                               # Operation is successful
    PARAMETER_INVALID = -101             # Invalid input parameter
    PARAMETER_OUT_OF_BOUND = -102        # The input parameter is out of bounds
    NOT_ENOUGH_SYSTEM_MEMORY = -103      # System out of memory
    NOT_FIND_DEVICE = -104               # not find device
    STATUS_NOT_SUPPORTED = -105          # operation is not supported
    CPU_NOT_SUPPORT_ACCELERATE = -106    # CPU does not support acceleration
  
    def __init__(self):
        pass


if sys.platform == 'linux2' or sys.platform == 'linux':
    # Bayer layout
    class DxPixelColorFilter:
        NONE = 0                                # Isn't bayer format
        RG = 1                                  # The first row starts with RG
        GB = 2                                  # The first line starts with GB
        GR = 3                                  # The first line starts with GR
        BG = 4                                  # The first line starts with BG

        def __init__(self):
            pass
else:
    # Bayer layout
    class DxPixelColorFilter:
        NONE = 0                                # Isn't bayer format
        BG = 1                                  # The first row starts with BG
        GR = 2                                  # The first line starts with GR
        GB = 3                                  # The first line starts with GB
        RG = 4                                  # The first line starts with RG

        def __init__(self):
            pass


# image actual bits
class DxActualBits:
    BITS_10 = 10             # 10bit
    BITS_12 = 12             # 12bit
    BITS_14 = 14             # 14bit
    BITS_16 = 16             # 16bit

    def __init__(self):
        pass


'''
# mono8 image process structure
class MonoImgProcess(Structure):
    _fields_ = [
        ('defective_pixel_correct',     c_bool),        # Pixel correct switch
        ('sharpness',                   c_bool),        # Sharpness switch
        ('accelerate',                  c_bool),        # Accelerate switch
        ('sharp_factor',                c_float),       # Sharpen the intensity factor
        ('pro_lut',                     c_char_p),      # Lookup table
        ('lut_length',                  c_ushort),      # Lut Buffer length
        ('array_reserved',              c_ubyte * 32),  # Reserved
    ]

    def __str__(self):
        return "MonoImgProcess\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


# Raw8 Image process structure
class ColorImgProcess(Structure):
    _fields_ = [
        ('defective_pixel_correct',     c_bool),        # Pixel correct switch
        ('denoise',                     c_bool),        # Noise reduction switch
        ('sharpness',                   c_bool),        # Sharpness switch
        ('accelerate',                  c_bool),        # Accelerate switch
        ('arr_cc',                      c_void_p),      # Color processing parameters
        ('cc_buf_length',               c_ubyte),       # Color processing parameters length(sizeof(VxInt16)*9)
        ('sharp_factor',                c_float),       # Sharpen the intensity factor
        ('pro_lut',                     c_char_p),      # Lookup table
        ('lut_length',                  c_ushort),      # The length of the lookup table
        ('cv_type',                     c_uint),        # Interpolation algorithm
        ('layout',                      c_uint),        # Bayer format
        ('flip',                        c_bool),        # Image flip flag
        ('array_reserved',              c_ubyte*32),    # Reserved
    ]

    def __str__(self):
        return "ColorImgProcess\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


if hasattr(dll, 'DxGetLut'):
    def gx_get_lut(contrast_param, gamma, lightness):
        """
        :brief calculating lookup table of 8bit image
        :param contrast_param:  contrast param,range(-50~100)
        :param gamma:           gamma param,range(0.1~10)
        :param lightness:       lightness param,range(-150~150)
        :return: status         State return value, See detail in DxStatus
                 lut            lookup table
                 lut_length     lookup table length(unit:byte)
        """
        contrast_param_c = c_int()
        contrast_param_c.value = contrast_param

        gamma_c = c_double()
        gamma_c.value = gamma

        lightness_c = c_int()
        lightness_c.value = lightness

        lut_length_c = c_int()
        lut_length_c.value = 0

        # Get length of the lookup table
        dll.DxGetLut(contrast_param_c, gamma_c, lightness_c, None, byref(lut_length_c))

        # Create buff to get LUT data
        lut_c = (c_ubyte * lut_length_c.value)()
        status = dll.DxGetLut(contrast_param_c, gamma_c, lightness_c,  byref(lut_c), byref(lut_length_c))

        return status, lut_c, lut_length_c.value
'''

if hasattr(dll, "DxGetGammatLut"):
    def dx_get_gamma_lut(gamma_param):
        """
        :brief  calculating gamma lookup table (RGB24)
        :param  gamma_param:    gamma param,range(0.1 ~ 10)
        :return: status:        State return value, See detail in DxStatus
                gamma_lut:      gamma lookup table
                lut_length:     gamma lookup table length(unit:byte)
        """
        gamma_param_c = c_double()
        gamma_param_c.value = gamma_param

        lut_length_c = c_int()
        status = dll.DxGetGammatLut(gamma_param_c, None, byref(lut_length_c))

        gamma_lut = (c_ubyte * lut_length_c.value)()
        status = dll.DxGetGammatLut(gamma_param_c, byref(gamma_lut), byref(lut_length_c))

        return status, gamma_lut, lut_length_c.value


if hasattr(dll, "DxGetContrastLut"):
    def dx_get_contrast_lut(contrast_param):
        """
        :brief  ccalculating contrast lookup table (RGB24)
        :param  contrast_param: contrast param,range(-50 ~ 100)
        :return: status:       State return value, See detail in DxStatus
                 contrast_lut: contrast lookup table
                 lut_length:   contrast lookup table length(unit:byte)
        """
        contrast_param_c = c_int()
        contrast_param_c.value = contrast_param

        lut_length_c = c_int()
        status = dll.DxGetContrastLut(contrast_param_c, None, byref(lut_length_c))

        contrast_lut = (c_ubyte * lut_length_c.value)()
        status = dll.DxGetContrastLut(contrast_param_c, byref(contrast_lut), byref(lut_length_c))

        return status, contrast_lut, lut_length_c.value


if hasattr(dll, 'DxRaw8toRGB24'):
    def dx_raw8_to_rgb24(input_address, output_address, width, height, convert_type, bayer_type, flip):
        """
        :brief  Convert Raw8 to Rgb24
        :param input_address:      The input raw image buff address, buff size = width * height
        :param output_address:     The output rgb image buff address, buff size = width * height * 3
        :param width:           Image width
        :param height:          Image height
        :param convert_type:    Bayer convert type, See detail in DxBayerConvertType
        :param bayer_type:      pixel color filter, See detail in DxPixelColorFilter
        :param flip:            Output image flip flag
                                True: turn the image upside down
                                False: do not flip
        :return: status         State return value, See detail in DxStatus
                 data_array     Array of output images, buff size = width * height * 3
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        convert_type_c = c_uint()
        convert_type_c.value = convert_type

        bayer_type_c = c_uint()
        bayer_type_c.value = bayer_type

        flip_c = c_bool()
        flip_c.value = flip

        input_address_p = c_void_p()
        input_address_p.value = input_address

        output_address_p = c_void_p()
        output_address_p.value = output_address

        status = dll.DxRaw8toRGB24(input_address_p, output_address_p,
                                   width_c, height_c, convert_type_c, bayer_type_c, flip_c)
        return status


if hasattr(dll, 'DxRaw16toRaw8'):
    def dx_raw16_to_raw8(input_address, out_address, width, height, valid_bits):
        """
        :biref  Raw16 converted to Raw8
        :param  input_address:     The input image buff address, buff size = width * height * 2
        :param  out_address:       The output image buff address, buff size = width * height
        :param  width:          Image width
        :param  height:         Image height
        :param  valid_bits:     Data valid digit, See detail in DxValidBit
        :return: status         State return value, See detail in DxStatus
                 data_array     Array of output images, buff size = width * height
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        valid_bits_c = c_uint()
        valid_bits_c.value = valid_bits

        input_address_p = c_void_p()
        input_address_p.value = input_address

        out_address_p = c_void_p()
        out_address_p.value = out_address

        status = dll.DxRaw16toRaw8(input_address_p, out_address_p,
                                   width_c, height_c, valid_bits_c)
        return status


if hasattr(dll, "DxImageImprovment"):
    def dx_image_improvement(input_address, output_address, width, height,
                             color_correction_param, contrast_lut, gamma_lut):
        """
        :brief      image quality improvement
        :param      input_address:              input buffer address, buff size = width * height *3
        :param      output_address:             input buffer address, buff size = width * height *3
        :param      width:                      image width
        :param      height:                     image height
        :param      color_correction_param:     color correction param(get from camera)
        :param      contrast_lut:               contrast lookup table
        :param      gamma_lut:                  gamma lookup table
        :return:    status                      State return value, See detail in DxStatus
                    data_array                  Array of output images, buff size = width * height * 3
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        input_address_p = c_void_p()
        input_address_p.value = input_address

        output_address_p = c_void_p()
        output_address_p.value = output_address

        color_correction_param_p = c_int64()
        color_correction_param_p.value = color_correction_param

        status = dll.DxImageImprovment(input_address_p, output_address_p, width_c, height_c,
                                       color_correction_param_p, contrast_lut, gamma_lut)
        return status

if hasattr(dll, "DxSaturation"):
    def dx_saturation(input_address, output_address, image_size, factor):
        """
        :brief      Saturation adjustment (RGB24)
        :param      input_address:          input buffer address, buff size = width * height * 3
        :param      output_address:         output buffer address, buff size = width * height * 3        
        :param      image_size:             image size (width * height)
        :param      factor:                 saturation factor,range(0 ~ 128)
        :return:    status:                 State return value, See detail in DxStatus
        """
        image_size_c = c_uint()
        image_size_c.value = image_size

        factor_c = c_int()
        factor_c.value = factor

        input_address_p = c_void_p()
        input_address_p.value = input_address

        output_address_p = c_void_p()
        output_address_p.value = output_address

        status = dll.DxSaturation(input_address_p, output_address_p, image_size_c, factor_c)
        return status

if hasattr(dll, "DxAutoRawDefectivePixelCorrect"):
    def dx_auto_raw_defective_pixel_correct(inout_address, width, height, bit_num):
        """
        :brief      Auto raw defective pixel correct,Support image from Raw8 to Raw16, the bit number is actual
                    bit number, when it is more than 8, the actual bit can be every number between 9 to 16.
                    And if image format is packed, you need convert it to Raw16.
                    This function should be used in each frame.
        :param      inout_address:          input & output buffer address
        :param      width:                  image width
        :param      height:                 image height
        :param      bit_num:                image bit number (for example:if image 10bit, nBitNum = 10,
                                                                          if image 12bit, nBitNum = 12,
                                                                          range:8 ~ 16)
        :return:    status:                 State return value, See detail in DxStatus
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        bit_num_c = c_int()
        bit_num_c.value = bit_num

        inout_address_p = c_void_p()
        inout_address_p.value = inout_address

        status = dll.DxAutoRawDefectivePixelCorrect(inout_address_p, width_c, height_c, bit_num_c)
        return status

if hasattr(dll, "DxSharpen24B"):
    def dx_sharpen_24b(input_address, output_address, width, height, factor):
        """
        :brief      Sharpen adjustment (RGB24)
        :param      input_address:          input buffer address, buff size = width * height * 3
        :param      output_address:         output buffer address, buff size = width * height * 3
        :param      width:                  image width
        :param      height:                 image height
        :param      factor:                 sharpen factor, range(0.1~5.0)
        :return:    status:                 State return value, See detail in DxStatus
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        input_address_p = c_void_p()
        input_address_p.value = input_address

        output_address_p = c_void_p()
        output_address_p.value = output_address

        factor_c = c_float()
        factor_c.value = factor

        status = dll.DxSharpen24B(input_address_p, output_address_p, width_c, height_c, factor_c)
        return status

#!/usr/bin/python
# -*- coding:utf-8 -*-
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-
#

from ctypes import *
import sys
import os

if sys.platform == 'linux2' or sys.platform == 'linux':
    if os.path.exists('/usr/lib/libdximageproc.so') : 
        filepath = '/usr/lib/libdximageproc.so'
    else:
        filepath = '/usr/lib/libgxiapi.so'
    try:
        dll = CDLL(filepath)
    except OSError:
        print('Cannot find libdximageproc.so or libgxiapi.so.')
else:
    try:
        dll = WinDLL('DxImageProc.dll')
    except OSError:
        print('Cannot find DxImageProc.dll.')


# status  definition
class DxStatus:
    OK = 0                               # Operation is successful
    PARAMETER_INVALID = -101             # Invalid input parameter
    PARAMETER_OUT_OF_BOUND = -102        # The input parameter is out of bounds
    NOT_ENOUGH_SYSTEM_MEMORY = -103      # System out of memory
    NOT_FIND_DEVICE = -104               # not find device
    STATUS_NOT_SUPPORTED = -105          # operation is not supported
    CPU_NOT_SUPPORT_ACCELERATE = -106    # CPU does not support acceleration
  
    def __init__(self):
        pass


if sys.platform == 'linux2' or sys.platform == 'linux':
    # Bayer layout
    class DxPixelColorFilter:
        NONE = 0                                # Isn't bayer format
        RG = 1                                  # The first row starts with RG
        GB = 2                                  # The first line starts with GB
        GR = 3                                  # The first line starts with GR
        BG = 4                                  # The first line starts with BG

        def __init__(self):
            pass
else:
    # Bayer layout
    class DxPixelColorFilter:
        NONE = 0                                # Isn't bayer format
        BG = 1                                  # The first row starts with BG
        GR = 2                                  # The first line starts with GR
        GB = 3                                  # The first line starts with GB
        RG = 4                                  # The first line starts with RG

        def __init__(self):
            pass


# image actual bits
class DxActualBits:
    BITS_10 = 10             # 10bit
    BITS_12 = 12             # 12bit
    BITS_14 = 14             # 14bit
    BITS_16 = 16             # 16bit

    def __init__(self):
        pass


'''
# mono8 image process structure
class MonoImgProcess(Structure):
    _fields_ = [
        ('defective_pixel_correct',     c_bool),        # Pixel correct switch
        ('sharpness',                   c_bool),        # Sharpness switch
        ('accelerate',                  c_bool),        # Accelerate switch
        ('sharp_factor',                c_float),       # Sharpen the intensity factor
        ('pro_lut',                     c_char_p),      # Lookup table
        ('lut_length',                  c_ushort),      # Lut Buffer length
        ('array_reserved',              c_ubyte * 32),  # Reserved
    ]

    def __str__(self):
        return "MonoImgProcess\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


# Raw8 Image process structure
class ColorImgProcess(Structure):
    _fields_ = [
        ('defective_pixel_correct',     c_bool),        # Pixel correct switch
        ('denoise',                     c_bool),        # Noise reduction switch
        ('sharpness',                   c_bool),        # Sharpness switch
        ('accelerate',                  c_bool),        # Accelerate switch
        ('arr_cc',                      c_void_p),      # Color processing parameters
        ('cc_buf_length',               c_ubyte),       # Color processing parameters length(sizeof(VxInt16)*9)
        ('sharp_factor',                c_float),       # Sharpen the intensity factor
        ('pro_lut',                     c_char_p),      # Lookup table
        ('lut_length',                  c_ushort),      # The length of the lookup table
        ('cv_type',                     c_uint),        # Interpolation algorithm
        ('layout',                      c_uint),        # Bayer format
        ('flip',                        c_bool),        # Image flip flag
        ('array_reserved',              c_ubyte*32),    # Reserved
    ]

    def __str__(self):
        return "ColorImgProcess\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


if hasattr(dll, 'DxGetLut'):
    def gx_get_lut(contrast_param, gamma, lightness):
        """
        :brief calculating lookup table of 8bit image
        :param contrast_param:  contrast param,range(-50~100)
        :param gamma:           gamma param,range(0.1~10)
        :param lightness:       lightness param,range(-150~150)
        :return: status         State return value, See detail in DxStatus
                 lut            lookup table
                 lut_length     lookup table length(unit:byte)
        """
        contrast_param_c = c_int()
        contrast_param_c.value = contrast_param

        gamma_c = c_double()
        gamma_c.value = gamma

        lightness_c = c_int()
        lightness_c.value = lightness

        lut_length_c = c_int()
        lut_length_c.value = 0

        # Get length of the lookup table
        dll.DxGetLut(contrast_param_c, gamma_c, lightness_c, None, byref(lut_length_c))

        # Create buff to get LUT data
        lut_c = (c_ubyte * lut_length_c.value)()
        status = dll.DxGetLut(contrast_param_c, gamma_c, lightness_c,  byref(lut_c), byref(lut_length_c))

        return status, lut_c, lut_length_c.value
'''

if hasattr(dll, "DxGetGammatLut"):
    def dx_get_gamma_lut(gamma_param):
        """
        :brief  calculating gamma lookup table (RGB24)
        :param  gamma_param:    gamma param,range(0.1 ~ 10)
        :return: status:        State return value, See detail in DxStatus
                gamma_lut:      gamma lookup table
                lut_length:     gamma lookup table length(unit:byte)
        """
        gamma_param_c = c_double()
        gamma_param_c.value = gamma_param

        lut_length_c = c_int()
        status = dll.DxGetGammatLut(gamma_param_c, None, byref(lut_length_c))

        gamma_lut = (c_ubyte * lut_length_c.value)()
        status = dll.DxGetGammatLut(gamma_param_c, byref(gamma_lut), byref(lut_length_c))

        return status, gamma_lut, lut_length_c.value


if hasattr(dll, "DxGetContrastLut"):
    def dx_get_contrast_lut(contrast_param):
        """
        :brief  ccalculating contrast lookup table (RGB24)
        :param  contrast_param: contrast param,range(-50 ~ 100)
        :return: status:       State return value, See detail in DxStatus
                 contrast_lut: contrast lookup table
                 lut_length:   contrast lookup table length(unit:byte)
        """
        contrast_param_c = c_int()
        contrast_param_c.value = contrast_param

        lut_length_c = c_int()
        status = dll.DxGetContrastLut(contrast_param_c, None, byref(lut_length_c))

        contrast_lut = (c_ubyte * lut_length_c.value)()
        status = dll.DxGetContrastLut(contrast_param_c, byref(contrast_lut), byref(lut_length_c))

        return status, contrast_lut, lut_length_c.value


if hasattr(dll, 'DxRaw8toRGB24'):
    def dx_raw8_to_rgb24(input_address, output_address, width, height, convert_type, bayer_type, flip):
        """
        :brief  Convert Raw8 to Rgb24
        :param input_address:      The input raw image buff address, buff size = width * height
        :param output_address:     The output rgb image buff address, buff size = width * height * 3
        :param width:           Image width
        :param height:          Image height
        :param convert_type:    Bayer convert type, See detail in DxBayerConvertType
        :param bayer_type:      pixel color filter, See detail in DxPixelColorFilter
        :param flip:            Output image flip flag
                                True: turn the image upside down
                                False: do not flip
        :return: status         State return value, See detail in DxStatus
                 data_array     Array of output images, buff size = width * height * 3
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        convert_type_c = c_uint()
        convert_type_c.value = convert_type

        bayer_type_c = c_uint()
        bayer_type_c.value = bayer_type

        flip_c = c_bool()
        flip_c.value = flip

        input_address_p = c_void_p()
        input_address_p.value = input_address

        output_address_p = c_void_p()
        output_address_p.value = output_address

        status = dll.DxRaw8toRGB24(input_address_p, output_address_p,
                                   width_c, height_c, convert_type_c, bayer_type_c, flip_c)
        return status


if hasattr(dll, 'DxRaw16toRaw8'):
    def dx_raw16_to_raw8(input_address, out_address, width, height, valid_bits):
        """
        :biref  Raw16 converted to Raw8
        :param  input_address:     The input image buff address, buff size = width * height * 2
        :param  out_address:       The output image buff address, buff size = width * height
        :param  width:          Image width
        :param  height:         Image height
        :param  valid_bits:     Data valid digit, See detail in DxValidBit
        :return: status         State return value, See detail in DxStatus
                 data_array     Array of output images, buff size = width * height
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        valid_bits_c = c_uint()
        valid_bits_c.value = valid_bits

        input_address_p = c_void_p()
        input_address_p.value = input_address

        out_address_p = c_void_p()
        out_address_p.value = out_address

        status = dll.DxRaw16toRaw8(input_address_p, out_address_p,
                                   width_c, height_c, valid_bits_c)
        return status


if hasattr(dll, "DxImageImprovment"):
    def dx_image_improvement(input_address, output_address, width, height,
                             color_correction_param, contrast_lut, gamma_lut):
        """
        :brief      image quality improvement
        :param      input_address:              input buffer address, buff size = width * height *3
        :param      output_address:             input buffer address, buff size = width * height *3
        :param      width:                      image width
        :param      height:                     image height
        :param      color_correction_param:     color correction param(get from camera)
        :param      contrast_lut:               contrast lookup table
        :param      gamma_lut:                  gamma lookup table
        :return:    status                      State return value, See detail in DxStatus
                    data_array                  Array of output images, buff size = width * height * 3
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        input_address_p = c_void_p()
        input_address_p.value = input_address

        output_address_p = c_void_p()
        output_address_p.value = output_address

        color_correction_param_p = c_int64()
        color_correction_param_p.value = color_correction_param

        status = dll.DxImageImprovment(input_address_p, output_address_p, width_c, height_c,
                                       color_correction_param_p, contrast_lut, gamma_lut)
        return status

if hasattr(dll, "DxSaturation"):
    def dx_saturation(input_address, output_address, image_size, factor):
        """
        :brief      Saturation adjustment (RGB24)
        :param      input_address:          input buffer address, buff size = width * height * 3
        :param      output_address:         output buffer address, buff size = width * height * 3        
        :param      image_size:             image size (width * height)
        :param      factor:                 saturation factor,range(0 ~ 128)
        :return:    status:                 State return value, See detail in DxStatus
        """
        image_size_c = c_uint()
        image_size_c.value = image_size

        factor_c = c_int()
        factor_c.value = factor

        input_address_p = c_void_p()
        input_address_p.value = input_address

        output_address_p = c_void_p()
        output_address_p.value = output_address

        status = dll.DxSaturation(input_address_p, output_address_p, image_size_c, factor_c)
        return status

if hasattr(dll, "DxAutoRawDefectivePixelCorrect"):
    def dx_auto_raw_defective_pixel_correct(inout_address, width, height, bit_num):
        """
        :brief      Auto raw defective pixel correct,Support image from Raw8 to Raw16, the bit number is actual
                    bit number, when it is more than 8, the actual bit can be every number between 9 to 16.
                    And if image format is packed, you need convert it to Raw16.
                    This function should be used in each frame.
        :param      inout_address:          input & output buffer address
        :param      width:                  image width
        :param      height:                 image height
        :param      bit_num:                image bit number (for example:if image 10bit, nBitNum = 10,
                                                                          if image 12bit, nBitNum = 12,
                                                                          range:8 ~ 16)
        :return:    status:                 State return value, See detail in DxStatus
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        bit_num_c = c_int()
        bit_num_c.value = bit_num

        inout_address_p = c_void_p()
        inout_address_p.value = inout_address

        status = dll.DxAutoRawDefectivePixelCorrect(inout_address_p, width_c, height_c, bit_num_c)
        return status

if hasattr(dll, "DxSharpen24B"):
    def dx_sharpen_24b(input_address, output_address, width, height, factor):
        """
        :brief      Sharpen adjustment (RGB24)
        :param      input_address:          input buffer address, buff size = width * height * 3
        :param      output_address:         output buffer address, buff size = width * height * 3
        :param      width:                  image width
        :param      height:                 image height
        :param      factor:                 sharpen factor, range(0.1~5.0)
        :return:    status:                 State return value, See detail in DxStatus
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        input_address_p = c_void_p()
        input_address_p.value = input_address

        output_address_p = c_void_p()
        output_address_p.value = output_address

        factor_c = c_float()
        factor_c.value = factor

        status = dll.DxSharpen24B(input_address_p, output_address_p, width_c, height_c, factor_c)
        return status

import cv2
import imagej, scyjava
import os
import shutil
import tifffile
from glob import glob
import numpy as np
import multiprocessing as mp

JVM_MAX_MEMORY_GB = 4.0

def compute_overlap_percent(deltaX, deltaY, image_width, image_height, pixel_size_xy, min_overlap=0):
    """Helper function to calculate percent overlap between images in
    a grid"""
    shift_x = deltaX/pixel_size_xy
    shift_y = deltaY/pixel_size_xy
    overlap_x = max(0,image_width-shift_x)
    overlap_y = max(0,image_height-shift_y)
    overlap_x = overlap_x*100.0/image_width
    overlap_y = overlap_y*100.0/image_height
    overlap = max(min_overlap, overlap_x, overlap_y)
    return overlap

def stitch_slide_mp(*args, **kwargs):
    ctx = mp.get_context('spawn')
    stitch_process = ctx.Process(target=stitch_slide, args=args, kwargs=kwargs)
    stitch_process.start()
    return stitch_process
    
def migrate_tile_config(fovs_path, coord_name, channel_name_source, z_index_source, channel_name_target, z_index_target):
    channel_name_source = channel_name_source.replace(" ", "_")
    channel_name_target = channel_name_target.replace(" ","_")
    
    if z_index_source == z_index_target and channel_name_source == channel_name_target:
        raise RuntimeError("Source and target for channel/z-index migration are the same!")

    tile_conf_name_source = "TileConfiguration_COORD_"+coord_name+"_Z_"+str(z_index_source)+"_"+channel_name_source+".registered.txt"
    tile_conf_name_target = "TileConfiguration_COORD_"+coord_name+"_Z_"+str(z_index_target)+"_"+channel_name_target+".registered.txt"
    tile_config_source_path = os.path.join(fovs_path, tile_conf_name_source)
        
    if not os.path.isfile(tile_config_source_path):
        tile_config_source_path = tile_config_source_path.replace(".registered.txt", ".txt")

    assert os.path.isfile(tile_config_source_path)

    tile_config_target_path = os.path.join(fovs_path, tile_conf_name_target)

    tile_conf_target = open(tile_config_target_path, 'w')

    with open(tile_config_source_path, 'r') as tile_conf_source:
        for line in tile_conf_source:
            if line.startswith("#") or line.startswith("dim") or len(line) <= 1:
                tile_conf_target.write(line)
                continue
            line_to_write = line.replace("_"+str(z_index_source)+"_"+channel_name_source, "_"+str(z_index_target)+"_"+channel_name_target)
            tile_conf_target.write(line_to_write)

    tile_conf_target.close()

    return tile_conf_name_target

def stitch_slide(slide_path, time_indices, channels, z_indices, coord_names=[''], overlap_percent=10, reg_threshold=0.30, avg_displacement_threshold=2.50, abs_displacement_threshold=3.50, tile_downsampling=0.5, recompute_overlap=False, **kwargs):
    st = Stitcher()
    st.stitch_slide(slide_path, time_indices, channels, z_indices, coord_names, overlap_percent, reg_threshold, avg_displacement_threshold, abs_displacement_threshold, tile_downsampling, recompute_overlap, **kwargs)

class Stitcher:
    def __init__(self):
        scyjava.config.add_option('-Xmx'+str(int(JVM_MAX_MEMORY_GB))+'g')
        self.ij = imagej.init('sc.fiji:fiji', mode='headless')

    def stitch_slide(self, slide_path, time_indices, channels, z_indices, coord_names=[''], overlap_percent = 10, reg_threshold=0.30, avg_displacement_threshold=2.50, abs_displacement_threshold=3.50, tile_downsampling=0.5, recompute_overlap=False, **kwargs):
        for time_index in time_indices:
            self.stitch_single_time_point(slide_path, time_index, channels, z_indices, coord_names, overlap_percent, reg_threshold, avg_displacement_threshold, abs_displacement_threshold, tile_downsampling, recompute_overlap, **kwargs)

    def stitch_single_time_point(self, slide_path, time_index, channels, z_indices, coord_names = [''], overlap_percent=10, reg_threshold=0.30, avg_displacement_threshold=2.50, abs_displacement_threshold=3.50, tile_downsampling=0.5, recompute_overlap=False, **kwargs):
        fovs_path = os.path.join(slide_path, str(time_index))
        for coord_name in coord_names:
            already_registered = False
            registered_z_index = None
            registered_channel_name = None
            for channel_name in channels:
                for z_index in z_indices:
                    if already_registered:
                        migrate_tile_config(fovs_path, coord_name, registered_channel_name, registered_z_index, channel_name.replace(" ", "_"), z_index)
                        output_dir = self.stitch_single_channel_from_tile_config(fovs_path, channel_name, z_index, coord_name)
                        combine_stitched_channels(output_dir, **kwargs)
                    else:
                        output_dir = self.stitch_single_channel(fovs_path, channel_name, z_index, coord_name, overlap_percent, reg_threshold, avg_displacement_threshold, abs_displacement_threshold, tile_downsampling, recompute_overlap)
                        combine_stitched_channels(output_dir, **kwargs)
                    if not already_registered:
                        already_registered = True
                        registered_z_index = z_index
                        registered_channel_name = channel_name.replace(" ", "_")


    def stitch_single_channel_from_tile_config(self, fovs_path, channel_name, z_index, coord_name):
        """
        Stitches images using grid/collection stitching, reading registered
        positions from a tile configuration path that has been migrated from an
        already-registered channel/z-level at the same coordinate name
        """
        channel_name = channel_name.replace(" ", "_")
        tile_conf_name = "TileConfiguration_COORD_"+coord_name+"_Z_"+str(z_index)+"_"+channel_name+".registered.txt"
        assert os.path.isfile(os.path.join(fovs_path, tile_conf_name))

        stitching_output_dir = 'COORD_'+coord_name+"_Z_"+str(z_index)+"_"+channel_name+"_stitched/"

        stitching_output_dir = os.path.join(fovs_path,stitching_output_dir)

        os.makedirs(stitching_output_dir, exist_ok=True)

        stitching_params = {'type':'Positions from file',
                'order':'Defined by TileConfiguration',
                'fusion_mode':'Linear Blending',
                'ignore_z_stage':True,
                'downsample_tiles':False,
                'directory':fovs_path,
                'layout_file':tile_conf_name,
                'fusion_method':'Linear Blending',
                'regression_threshold':"0.30",
                'max/avg_displacement_threshold':"2.50",
                'absolute_displacement_threshold':"3.50",
                'compute_overlap':False,
                'computation_parameters':'Save computation time (but use more RAM)',
                'image_output':'Write to disk',
                'output_directory':stitching_output_dir 
                }

        plugin = "Grid/Collection stitching"

        self.ij.py.run_plugin(plugin, stitching_params)

        return stitching_output_dir


    def stitch_single_channel(self, fovs_path, channel_name, z_index, coord_name='', overlap_percent=10, reg_threshold = 0.30, avg_displacement_threshold=2.50, abs_displacement_threshold=3.50, tile_downsampling=0.5, recompute_overlap=False):
        """
        Stitches images using grid/collection stitching with filename-defined
        positions following the format that squid saves multipoint acquisitions
        in. Requires that the filename-indicated grid positions go top-to-bottom
        on the y axis and left-to-right on the x axis (this is handled by
        the MultiPointController code in control/core.py). Must be passed
        the folder containing the image files.
        """
        channel_name = channel_name.replace(" ", "_")

        file_search_name = coord_name+"0_0_"+str(z_index)+"_"+channel_name+".*"

        ext_glob = list(glob(os.path.join(fovs_path,file_search_name)))

        file_ext = ext_glob[0].split(".")[-1]

        y_length_pattern = coord_name+"*_0_"+str(z_index)+"_"+channel_name+"."+file_ext

        x_length_pattern = coord_name+"0_*_"+str(z_index)+"_"+channel_name+"."+file_ext

        grid_size_y = len(list(glob(os.path.join(fovs_path,y_length_pattern))))

        grid_size_x = len(list(glob(os.path.join(fovs_path,x_length_pattern))))

        stitching_filename_pattern = coord_name+"{y}_{x}_"+str(z_index)+"_"+channel_name+"."+file_ext

        stitching_output_dir = 'COORD_'+coord_name+"_Z_"+str(z_index)+"_"+channel_name+"_stitched/"

        tile_conf_name = "TileConfiguration_COORD_"+coord_name+"_Z_"+str(z_index)+"_"+channel_name+".txt"

        stitching_output_dir = os.path.join(fovs_path,stitching_output_dir)

        os.makedirs(stitching_output_dir, exist_ok=True)


        sample_tile_name = coord_name+"0_0_"+str(z_index)+"_"+channel_name+"."+file_ext
        sample_tile_shape = cv2.imread(os.path.join(fovs_path, sample_tile_name)).shape

        tile_downsampled_width=int(sample_tile_shape[1]*tile_downsampling)
        tile_downsampled_height=int(sample_tile_shape[0]*tile_downsampling)
        stitching_params = {'type':'Filename defined position',
                'order':'Defined by filename',
                'fusion_mode':'Linear Blending',
                'grid_size_x':grid_size_x,
                'grid_size_y':grid_size_y,
                'first_file_index_x':str(0),
                'first_file_index_y':str(0),
                'ignore_z_stage':True,
                'downsample_tiles':False,
                'tile_overlap':overlap_percent,
                'directory':fovs_path,
                'file_names':stitching_filename_pattern,
                'output_textfile_name':tile_conf_name,
                'fusion_method':'Linear Blending',
                'regression_threshold':str(reg_threshold),
                'max/avg_displacement_threshold':str(avg_displacement_threshold),
                'absolute_displacement_threshold':str(abs_displacement_threshold),
                'compute_overlap':recompute_overlap,
                'computation_parameters':'Save computation time (but use more RAM)',
                'image_output':'Write to disk',
                'output_directory':stitching_output_dir #,
                #'x':str(tile_downsampling),
                #'y':str(tile_downsampling),
                #'width':str(tile_downsampled_width),
                #'height':str(tile_downsampled_height),
                #'interpolation':'Bicubic average'
                }

        plugin = "Grid/Collection stitching"

        self.ij.py.run_plugin(plugin, stitching_params)

        return stitching_output_dir

def images_identical(im_1, im_2):
    """Return True if two opencv arrays are exactly the same"""
    return im_1.shape == im_2.shape and not (np.bitwise_xor(im_1,im_2).any())

def combine_stitched_channels(stitched_image_folder_path, write_multiscale_tiff = False, pixel_size_um=1.0, tile_side_length=1024, subresolutions=3):
    """Combines the three channel images created into one TIFF. Currently
    not recommended to run this with multiscale TIFF enabled, combining
    all channels/z-levels in one region of the acquisition into one OME-TIFF
    to be done later."""

    c1 = cv2.imread(os.path.join(stitched_image_folder_path, "img_t1_z1_c1"))

    c2 = cv2.imread(os.path.join(stitched_image_folder_path, "img_t1_z1_c2"))

    c3 = cv2.imread(os.path.join(stitched_image_folder_path, "img_t1_z1_c3"))

    combine_to_mono = False

    if c2 is None or c3 is None:
        combine_to_mono = True

    if write_multiscale_tiff:
        output_path = os.path.join(stitched_image_folder_path,"stitched_img.ome.tif")
    else:
        output_path = os.path.join(stitched_image_folder_path,"stitched_img.tif")

    if not combine_to_mono:
        if images_identical(c1,c2) and images_identical(c2,c3):
            combine_to_mono = True

    if not combine_to_mono:
        c1 = c1[:,:,0]
        c2 = c2[:,:,1]
        c3 = c3[:,:,2]
        if write_multiscale_tiff:
            data = np.stack((c1,c2,c3), axis=0)
        else:
            data = np.stack((c1,c2,c3),axis=-1)
        axes = 'CYX'
        channels = {'Name':['Channel 1', 'Channel 2', 'Channel 3']}
    else:
        data = c1[:,:,0]
        axes = 'YX'
        channels = None

    metadata = {
            'axes':axes,
            'SignificantBits':16 if data.dtype==np.uint8 else 8,
            'PhysicalSizeX':pixel_size_um,
            'PhysicalSizeY':pixel_size_um,
            'PhysicalSizeXUnit':'um',
            'PhysicalSizeYUnit':'um',
            }
    if channels is not None:
        metadata['Channel'] = channels

    options = dict(
            photometric = 'rgb' if not combine_to_mono else 'minisblack',
            tile = (tile_side_length, tile_side_length),
            compression = 'jpeg',
            resolutionunit='CENTIMETER',
            maxworkers = 2
            )

    if write_multiscale_tiff:
        with tifffile.TiffWriter(output_path, bigtiff=True) as tif:
                tif.write(data, subifds=subresolutions,
                    resolution=(1e4/pixel_size_um, 1e4/pixel_size_um),
                    metadata = metadata,
                    **options)
                for level in range(subresolutions):
                    mag = 2**(level+1)
                    if combine_to_mono:
                        subdata = data[::mag,::mag]
                    else:
                        subdata = data[:,::mag,::mag]
                    tif.write(
                        subdata,
                        subfiletype=1,
                        resolution=(1e4/mag/pixel_size_um, 1e3/mag/pixel_size_um),
                        **options
                        )

                if combine_to_mono:
                    thumbnail = (data[::8,::8] >> 2).astype('uint8')
                else:
                    thumbnail = (data[0,::8,::8] >> 2).astype('uint8')
                tif.write(thumbnail,metadata={'Name':'thumbnail'})
    else:
        cv2.imwrite(output_path, data)

    channel_files = [os.path.join(stitched_image_folder_path,'img_t1_z1_c')+str(i+1) for i in range(3)]

    for filename in channel_files:
        try:
            os.remove(filename)
        except FileNotFoundError:
            pass

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

import pandas as pd
import numpy as np
import time
import cv2
from control._def import *
import control.utils as utils

def multipoint_custom_script_entry(multiPointWorker,time_point,current_path,coordinate_id,coordiante_name,i,j):
    
    print( 'in custom script; t ' + str(multiPointWorker.time_point) + ', location ' + coordiante_name + ': ' +  str(i) + '_' + str(j) )

    # autofocus

    # if z location is included in the scan coordinates
    if multiPointWorker.use_scan_coordinates and multiPointWorker.scan_coordinates_mm.shape[1] == 3 :

        if multiPointWorker.do_autofocus:
            
            # autofocus for every FOV in the first scan and update the coordinates
            if multiPointWorker.time_point == 0:

                configuration_name_AF = MULTIPOINT_AUTOFOCUS_CHANNEL
                config_AF = next((config for config in multiPointWorker.configurationManager.configurations if config.name == configuration_name_AF))
                multiPointWorker.signal_current_configuration.emit(config_AF)
                multiPointWorker.autofocusController.autofocus()
                multiPointWorker.autofocusController.wait_till_autofocus_has_completed()
                multiPointWorker.scan_coordinates_mm[coordinate_id,2] = multiPointWorker.navigationController.z_pos_mm

            # in subsequent scans, autofocus at the first FOV and offset the rest
            else:

                if coordinate_id == 0:

                    z0 = multiPointWorker.scan_coordinates_mm[0,2]
                    configuration_name_AF = MULTIPOINT_AUTOFOCUS_CHANNEL
                    config_AF = next((config for config in multiPointWorker.configurationManager.configurations if config.name == configuration_name_AF))
                    multiPointWorker.signal_current_configuration.emit(config_AF)
                    multiPointWorker.autofocusController.autofocus()
                    multiPointWorker.autofocusController.wait_till_autofocus_has_completed()
                    multiPointWorker.scan_coordinates_mm[0,2] = multiPointWorker.navigationController.z_pos_mm
                    offset = multiPointWorker.scan_coordinates_mm[0,2] - z0
                    print('offset is ' + str(offset))
                    multiPointWorker.scan_coordinates_mm[1:,2] = multiPointWorker.scan_coordinates_mm[1:,2] + offset

                else:

                    pass


    # if z location is not included in the scan coordinates
    else:
        if multiPointWorker.do_reflection_af == False:
            # perform AF only if when not taking z stack or doing z stack from center
            if ( (multiPointWorker.NZ == 1) or Z_STACKING_CONFIG == 'FROM CENTER' ) and (multiPointWorker.do_autofocus) and (multiPointWorker.FOV_counter%Acquisition.NUMBER_OF_FOVS_PER_AF==0):
            # temporary: replace the above line with the line below to AF every FOV
            # if (multiPointWorker.NZ == 1) and (multiPointWorker.do_autofocus):
                configuration_name_AF = MULTIPOINT_AUTOFOCUS_CHANNEL
                config_AF = next((config for config in multiPointWorker.configurationManager.configurations if config.name == configuration_name_AF))
                multiPointWorker.signal_current_configuration.emit(config_AF)
                multiPointWorker.autofocusController.autofocus()
                multiPointWorker.autofocusController.wait_till_autofocus_has_completed()
        else:
           # initialize laser autofocus
            if multiPointWorker.reflection_af_initialized==False:
                # initialize the reflection AF
                multiPointWorker.microscope.laserAutofocusController.initialize_auto()
                multiPointWorker.reflection_af_initialized = True
                # do contrast AF for the first FOV
                if multiPointWorker.do_autofocus and ( (multiPointWorker.NZ == 1) or Z_STACKING_CONFIG == 'FROM CENTER' ) :
                    configuration_name_AF = MULTIPOINT_AUTOFOCUS_CHANNEL
                    config_AF = next((config for config in multiPointWorker.configurationManager.configurations if config.name == configuration_name_AF))
                    multiPointWorker.signal_current_configuration.emit(config_AF)
                    multiPointWorker.autofocusController.autofocus()
                    multiPointWorker.autofocusController.wait_till_autofocus_has_completed()
                # set the current plane as reference
                multiPointWorker.microscope.laserAutofocusController.set_reference()
            else:
                multiPointWorker.microscope.laserAutofocusController.move_to_target(0)
                multiPointWorker.microscope.laserAutofocusController.move_to_target(0) # for stepper in open loop mode, repeat the operation to counter backlash 

    if (multiPointWorker.NZ > 1):
        # move to bottom of the z stack
        if Z_STACKING_CONFIG == 'FROM CENTER':
            multiPointWorker.navigationController.move_z_usteps(-multiPointWorker.deltaZ_usteps*round((multiPointWorker.NZ-1)/2))
            multiPointWorker.wait_till_operation_is_completed()
            time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)
        # maneuver for achiving uniform step size and repeatability when using open-loop control
        multiPointWorker.navigationController.move_z_usteps(-160)
        multiPointWorker.wait_till_operation_is_completed()
        multiPointWorker.navigationController.move_z_usteps(160)
        multiPointWorker.wait_till_operation_is_completed()
        time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)

    # z-stack
    for k in range(multiPointWorker.NZ):
        
        file_ID = coordiante_name + str(i) + '_' + str(j if multiPointWorker.x_scan_direction==1 else multiPointWorker.NX-1-j) + '_' + str(k)
        # metadata = dict(x = multiPointWorker.navigationController.x_pos_mm, y = multiPointWorker.navigationController.y_pos_mm, z = multiPointWorker.navigationController.z_pos_mm)
        # metadata = json.dumps(metadata)

        # iterate through selected modes
        for config in multiPointWorker.selected_configurations:

            if 'USB Spectrometer' not in config.name:

                if time_point%10 != 0:

                    if 'Fluorescence' in config.name:
                        # only do fluorescence every 10th timepoint
                        continue

                # update the current configuration
                multiPointWorker.signal_current_configuration.emit(config)
                multiPointWorker.wait_till_operation_is_completed()
                # trigger acquisition (including turning on the illumination)
                if multiPointWorker.liveController.trigger_mode == TriggerMode.SOFTWARE:
                    multiPointWorker.liveController.turn_on_illumination()
                    multiPointWorker.wait_till_operation_is_completed()
                    multiPointWorker.camera.send_trigger()
                elif multiPointWorker.liveController.trigger_mode == TriggerMode.HARDWARE:
                    multiPointWorker.microcontroller.send_hardware_trigger(control_illumination=True,illumination_on_time_us=multiPointWorker.camera.exposure_time*1000)
                # read camera frame
                image = multiPointWorker.camera.read_frame()
                if image is None:
                    print('multiPointWorker.camera.read_frame() returned None')
                    continue
                # tunr of the illumination if using software trigger
                if multiPointWorker.liveController.trigger_mode == TriggerMode.SOFTWARE:
                    multiPointWorker.liveController.turn_off_illumination()
                # process the image -  @@@ to move to camera
                image = utils.crop_image(image,multiPointWorker.crop_width,multiPointWorker.crop_height)
                image = utils.rotate_and_flip_image(image,rotate_image_angle=multiPointWorker.camera.rotate_image_angle,flip_image=multiPointWorker.camera.flip_image)
                # multiPointWorker.image_to_display.emit(cv2.resize(image,(round(multiPointWorker.crop_width*multiPointWorker.display_resolution_scaling), round(multiPointWorker.crop_height*multiPointWorker.display_resolution_scaling)),cv2.INTER_LINEAR))
                image_to_display = utils.crop_image(image,round(multiPointWorker.crop_width*multiPointWorker.display_resolution_scaling), round(multiPointWorker.crop_height*multiPointWorker.display_resolution_scaling))
                multiPointWorker.image_to_display.emit(image_to_display)
                multiPointWorker.image_to_display_multi.emit(image_to_display,config.illumination_source)
                if image.dtype == np.uint16:
                    saving_path = os.path.join(current_path, file_ID + '_' + str(config.name).replace(' ','_') + '.tiff')
                    if multiPointWorker.camera.is_color:
                        if 'BF LED matrix' in config.name:
                            if MULTIPOINT_BF_SAVING_OPTION == 'RGB2GRAY':
                                image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)
                            elif MULTIPOINT_BF_SAVING_OPTION == 'Green Channel Only':
                                image = image[:,:,1]
                    iio.imwrite(saving_path,image)
                else:
                    saving_path = os.path.join(current_path, file_ID + '_' + str(config.name).replace(' ','_') + '.' + Acquisition.IMAGE_FORMAT)
                    if multiPointWorker.camera.is_color:
                        if 'BF LED matrix' in config.name:
                            if MULTIPOINT_BF_SAVING_OPTION == 'Raw':
                                image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)
                            elif MULTIPOINT_BF_SAVING_OPTION == 'RGB2GRAY':
                                image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)
                            elif MULTIPOINT_BF_SAVING_OPTION == 'Green Channel Only':
                                image = image[:,:,1]
                        else:
                            image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)
                    cv2.imwrite(saving_path,image)
                QApplication.processEvents()
            
            else:

                if multiPointWorker.usb_spectrometer != None:
                    for l in range(N_SPECTRUM_PER_POINT):
                        data = multiPointWorker.usb_spectrometer.read_spectrum()
                        multiPointWorker.spectrum_to_display.emit(data)
                        saving_path = os.path.join(current_path, file_ID + '_' + str(config.name).replace(' ','_') + '_' + str(l) + '.csv')
                        np.savetxt(saving_path,data,delimiter=',')

        # add the coordinate of the current location
        new_row = pd.DataFrame({'i':[i],'j':[multiPointWorker.NX-1-j],'k':[k],
                                'x (mm)':[multiPointWorker.navigationController.x_pos_mm],
                                'y (mm)':[multiPointWorker.navigationController.y_pos_mm],
                                'z (um)':[multiPointWorker.navigationController.z_pos_mm*1000]},
                                )
        multiPointWorker.coordinates_pd = pd.concat([multiPointWorker.coordinates_pd, new_row], ignore_index=True)

        # register the current fov in the navigationViewer 
        multiPointWorker.signal_register_current_fov.emit(multiPointWorker.navigationController.x_pos_mm,multiPointWorker.navigationController.y_pos_mm)

        # check if the acquisition should be aborted
        if multiPointWorker.multiPointController.abort_acqusition_requested:
            multiPointWorker.liveController.turn_off_illumination()
            multiPointWorker.navigationController.move_x_usteps(-multiPointWorker.dx_usteps)
            multiPointWorker.wait_till_operation_is_completed()
            multiPointWorker.navigationController.move_y_usteps(-multiPointWorker.dy_usteps)
            multiPointWorker.wait_till_operation_is_completed()
            if multiPointWorker.navigationController.get_pid_control_flag(2) is False:
                _usteps_to_clear_backlash = max(160,20*multiPointWorker.navigationController.z_microstepping)
                multiPointWorker.navigationController.move_z_usteps(-multiPointWorker.dz_usteps-_usteps_to_clear_backlash)
                multiPointWorker.wait_till_operation_is_completed()
                multiPointWorker.navigationController.move_z_usteps(_usteps_to_clear_backlash)
                multiPointWorker.wait_till_operation_is_completed()
            else:
                multiPointWorker.navigationController.move_z_usteps(-multiPointWorker.dz_usteps)
                multiPointWorker.wait_till_operation_is_completed()
            multiPointWorker.coordinates_pd.to_csv(os.path.join(current_path,'coordinates.csv'),index=False,header=True)
            multiPointWorker.navigationController.enable_joystick_button_action = True
            return

        if multiPointWorker.NZ > 1:
            # move z
            if k < multiPointWorker.NZ - 1:
                multiPointWorker.navigationController.move_z_usteps(multiPointWorker.deltaZ_usteps)
                multiPointWorker.wait_till_operation_is_completed()
                time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)
                multiPointWorker.dz_usteps = multiPointWorker.dz_usteps + multiPointWorker.deltaZ_usteps
    
    if multiPointWorker.NZ > 1:
        # move z back
        if Z_STACKING_CONFIG == 'FROM CENTER':
            if multiPointWorker.navigationController.get_pid_control_flag(2) is False:
                _usteps_to_clear_backlash = max(160,20*multiPointWorker.navigationController.z_microstepping)
                multiPointWorker.navigationController.move_z_usteps( -multiPointWorker.deltaZ_usteps*(multiPointWorker.NZ-1) + multiPointWorker.deltaZ_usteps*round((multiPointWorker.NZ-1)/2) - _usteps_to_clear_backlash)
                multiPointWorker.wait_till_operation_is_completed()
                multiPointWorker.navigationController.move_z_usteps(_usteps_to_clear_backlash)
                multiPointWorker.wait_till_operation_is_completed()
            else:
                multiPointWorker.navigationController.move_z_usteps( -multiPointWorker.deltaZ_usteps*(multiPointWorker.NZ-1) + multiPointWorker.deltaZ_usteps*round((multiPointWorker.NZ-1)/2))
                multiPointWorker.wait_till_operation_is_completed()

            multiPointWorker.dz_usteps = multiPointWorker.dz_usteps - multiPointWorker.deltaZ_usteps*(multiPointWorker.NZ-1) + multiPointWorker.deltaZ_usteps*round((multiPointWorker.NZ-1)/2)
        else:
            if multiPointWorker.navigationController.get_pid_control_flag(2) is False:
                _usteps_to_clear_backlash = max(160,20*multiPointWorker.navigationController.z_microstepping)
                multiPointWorker.navigationController.move_z_usteps(-multiPointWorker.deltaZ_usteps*(multiPointWorker.NZ-1) - _usteps_to_clear_backlash)
                multiPointWorker.wait_till_operation_is_completed()
                multiPointWorker.navigationController.move_z_usteps(_usteps_to_clear_backlash)
                multiPointWorker.wait_till_operation_is_completed()
            else:
                multiPointWorker.navigationController.move_z_usteps(-multiPointWorker.deltaZ_usteps*(multiPointWorker.NZ-1))
                multiPointWorker.wait_till_operation_is_completed()

            multiPointWorker.dz_usteps = multiPointWorker.dz_usteps - multiPointWorker.deltaZ_usteps*(multiPointWorker.NZ-1)

    # update FOV counter
    multiPointWorker.FOV_counter = multiPointWorker.FOV_counter + 1

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.microcontroller as microcontroller
from control._def import *

import pyqtgraph.dockarea as dock
import time

SINGLE_WINDOW = True # set to False if use separate windows for display and control

class OctopiGUI(QMainWindow):

    # variables
    fps_software_trigger = 100

    def __init__(self, is_simulation = False, *args, **kwargs):
        super().__init__(*args, **kwargs)

        # load objects
        if is_simulation:
            self.camera = camera.Camera_Simulation(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
            self.microcontroller = microcontroller.Microcontroller_Simulation()
        else:
            try:
                self.camera = camera.Camera(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
                self.camera.open()
            except:
                self.camera = camera.Camera_Simulation(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
                self.camera.open()
                print('! camera not detected, using simulated camera !')
            try:
                self.microcontroller = microcontroller.Microcontroller(version=CONTROLLER_VERSION)
            except:
                print('! Microcontroller not detected, using simulated microcontroller !')
                self.microcontroller = microcontroller.Microcontroller_Simulation()

        # reset the MCU
        self.microcontroller.reset()

        # reinitialize motor drivers and DAC (in particular for V2.1 driver board where PG is not functional)
        self.microcontroller.initialize_drivers()

        # configure the actuators
        self.microcontroller.configure_actuators()

        self.configurationManager = core.ConfigurationManager()
        self.streamHandler = core.StreamHandler(display_resolution_scaling=DEFAULT_DISPLAY_CROP/100)
        self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
        self.navigationController = core.NavigationController(self.microcontroller, parent=self)
        self.slidePositionController = core.SlidePositionController(self.navigationController,self.liveController)
        self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
        self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController,self.configurationManager)
        if ENABLE_TRACKING:
            self.trackingController = core.TrackingController(self.camera,self.microcontroller,self.navigationController,self.configurationManager,self.liveController,self.autofocusController,self.imageDisplayWindow)
        self.imageSaver = core.ImageSaver()
        self.imageDisplay = core.ImageDisplay()
        self.navigationViewer = core.NavigationViewer()

        # retract the objective
        self.navigationController.home_z()
        # wait for the operation to finish
        t0 = time.time()
        while self.microcontroller.is_busy():
            time.sleep(0.005)
            if time.time() - t0 > 10:
                print('z homing timeout, the program will exit')
                sys.exit(1)
        print('objective retracted')

        # set encoder arguments
        # set axis pid control enable
        # only ENABLE_PID_X and HAS_ENCODER_X are both enable, can be enable to PID
        if HAS_ENCODER_X == True:
            self.navigationController.set_axis_PID_arguments(0, PID_P_X, PID_I_X, PID_D_X)
            self.navigationController.configure_encoder(0, (SCREW_PITCH_X_MM * 1000) / ENCODER_RESOLUTION_UM_X, ENCODER_FLIP_DIR_X)
            self.navigationController.set_pid_control_enable(0, ENABLE_PID_X)
        if HAS_ENCODER_Y == True:
            self.navigationController.set_axis_PID_arguments(1, PID_P_Y, PID_I_Y, PID_D_Y)
            self.navigationController.configure_encoder(1, (SCREW_PITCH_Y_MM * 1000) / ENCODER_RESOLUTION_UM_Y, ENCODER_FLIP_DIR_Y)
            self.navigationController.set_pid_control_enable(1, ENABLE_PID_Y)
        if HAS_ENCODER_Z == True:
            self.navigationController.set_axis_PID_arguments(2, PID_P_Z, PID_I_Z, PID_D_Z)
            self.navigationController.configure_encoder(2, (SCREW_PITCH_Z_MM * 1000) / ENCODER_RESOLUTION_UM_Z, ENCODER_FLIP_DIR_Z)
            self.navigationController.set_pid_control_enable(2, ENABLE_PID_Z)

        time.sleep(0.5)

        # homing, set zero and set software limit
        self.navigationController.set_x_limit_pos_mm(100)
        self.navigationController.set_x_limit_neg_mm(-100)
        self.navigationController.set_y_limit_pos_mm(100)
        self.navigationController.set_y_limit_neg_mm(-100)
        print('start homing')
        self.slidePositionController.move_to_slide_scanning_position()
        while self.slidePositionController.slide_scanning_position_reached == False:
            time.sleep(0.005)
        print('homing finished')
        self.navigationController.set_x_limit_pos_mm(SOFTWARE_POS_LIMIT.X_POSITIVE)
        self.navigationController.set_x_limit_neg_mm(SOFTWARE_POS_LIMIT.X_NEGATIVE)
        self.navigationController.set_y_limit_pos_mm(SOFTWARE_POS_LIMIT.Y_POSITIVE)
        self.navigationController.set_y_limit_neg_mm(SOFTWARE_POS_LIMIT.Y_NEGATIVE)

        # set piezo arguments
        if ENABLE_OBJECTIVE_PIEZO is True:
            if OBJECTIVE_PIEZO_CONTROL_VOLTAGE_RANGE == 5:
                OUTPUT_GAINS.CHANNEL7_GAIN = True
            else:
                OUTPUT_GAINS.CHANNEL7_GAIN = False

        # set output's gains
        div = 1 if OUTPUT_GAINS.REFDIV is True else 0
        gains  = OUTPUT_GAINS.CHANNEL0_GAIN << 0 
        gains += OUTPUT_GAINS.CHANNEL1_GAIN << 1 
        gains += OUTPUT_GAINS.CHANNEL2_GAIN << 2 
        gains += OUTPUT_GAINS.CHANNEL3_GAIN << 3 
        gains += OUTPUT_GAINS.CHANNEL4_GAIN << 4 
        gains += OUTPUT_GAINS.CHANNEL5_GAIN << 5 
        gains += OUTPUT_GAINS.CHANNEL6_GAIN << 6 
        gains += OUTPUT_GAINS.CHANNEL7_GAIN << 7 
        self.microcontroller.configure_dac80508_refdiv_and_gain(div, gains)

        # set illumination intensity factor
        global ILLUMINATION_INTENSITY_FACTOR
        self.microcontroller.set_dac80508_scaling_factor_for_illumination(ILLUMINATION_INTENSITY_FACTOR)

        # set software limit
        self.navigationController.set_x_limit_pos_mm(SOFTWARE_POS_LIMIT.X_POSITIVE)
        self.navigationController.set_x_limit_neg_mm(SOFTWARE_POS_LIMIT.X_NEGATIVE)
        self.navigationController.set_y_limit_pos_mm(SOFTWARE_POS_LIMIT.Y_POSITIVE)
        self.navigationController.set_y_limit_neg_mm(SOFTWARE_POS_LIMIT.Y_NEGATIVE)
        self.navigationController.set_z_limit_pos_mm(SOFTWARE_POS_LIMIT.Z_POSITIVE)

        # open the camera
        # camera start streaming
        # self.camera.set_reverse_x(CAMERA_REVERSE_X) # these are not implemented for the cameras in use
        # self.camera.set_reverse_y(CAMERA_REVERSE_Y) # these are not implemented for the cameras in use
        self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
        self.camera.set_callback(self.streamHandler.on_new_frame)
        self.camera.enable_callback()

        # load widgets
        self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,include_gain_exposure_time=False)
        self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager,show_display_options=True)
        self.navigationWidget = widgets.NavigationWidget(self.navigationController,self.slidePositionController,widget_configuration='malaria')
        self.dacControlWidget = widgets.DACControWidget(self.microcontroller)
        self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
        self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)
        self.focusMapWidget = widgets.FocusMapWidget(self.autofocusController)
        if ENABLE_TRACKING:
            self.trackingControlWidget = widgets.TrackingControllerWidget(self.trackingController,self.configurationManager,show_configurations=TRACKING_SHOW_MICROSCOPE_CONFIGURATIONS)
        self.multiPointWidget = widgets.MultiPointWidget(self.multipointController,self.configurationManager)

        self.recordTabWidget = QTabWidget()
        if ENABLE_TRACKING:
            self.recordTabWidget.addTab(self.trackingControlWidget, "Tracking")
        #self.recordTabWidget.addTab(self.recordingControlWidget, "Simple Recording")
        self.recordTabWidget.addTab(self.multiPointWidget, "Multipoint Acquisition")
        self.recordTabWidget.addTab(self.focusMapWidget, "Contrast Focus Map")

        self.imageDisplayTabs = QTabWidget()
        if USE_NAPARI_FOR_LIVE_VIEW:
            self.napariLiveWidget = widgets.NapariLiveWidget(self.configurationManager, self.liveControlWidget)
            self.imageDisplayTabs.addTab(self.napariLiveWidget, "Live View")
        else:
            if ENABLE_TRACKING:
                self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True)
                self.imageDisplayWindow.show_ROI_selector()
            else:
                self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True)
            self.imageDisplayTabs.addTab(self.imageDisplayWindow.widget, "Live View")

        if USE_NAPARI_FOR_MULTIPOINT:
            self.napariMultiChannelWidget = widgets.NapariMultiChannelWidget(self.configurationManager)
            self.imageDisplayTabs.addTab(self.napariMultiChannelWidget, "Multichannel Acquisition")
        else:
            self.imageArrayDisplayWindow = core.ImageArrayDisplayWindow()
            self.imageDisplayTabs.addTab(self.imageArrayDisplayWindow.widget, "Multichannel Acquisition")

        if SHOW_TILED_PREVIEW:
            if USE_NAPARI_FOR_TILED_DISPLAY:
                self.napariTiledDisplayWidget = widgets.NapariTiledDisplayWidget(self.configurationManager)
                self.imageDisplayTabs.addTab(self.napariTiledDisplayWidget, "Tiled Preview")
            else:
                self.imageDisplayWindow_scan_preview = core.ImageDisplayWindow(draw_crosshairs=True)
                self.imageDisplayTabs.addTab(self.imageDisplayWindow_scan_preview.widget, "Tiled Preview")

        # layout widgets
        layout = QVBoxLayout() #layout = QStackedLayout()
        #layout.addWidget(self.cameraSettingWidget)
        layout.addWidget(self.liveControlWidget)
        layout.addWidget(self.navigationWidget)
        if SHOW_DAC_CONTROL:
            layout.addWidget(self.dacControlWidget)
        layout.addWidget(self.autofocusWidget)
        layout.addWidget(self.recordTabWidget)
        layout.addWidget(self.navigationViewer)
        layout.addStretch()

        # transfer the layout to the central widget
        self.centralWidget = QWidget()
        self.centralWidget.setLayout(layout)
        # self.centralWidget.setFixedSize(self.centralWidget.minimumSize())
        # self.centralWidget.setFixedWidth(self.centralWidget.minimumWidth())
        # self.centralWidget.setMaximumWidth(self.centralWidget.minimumWidth())
        self.centralWidget.setFixedWidth(self.centralWidget.minimumSizeHint().width())

        if SINGLE_WINDOW:
            dock_display = dock.Dock('Image Display', autoOrientation = False)
            dock_display.showTitleBar()
            dock_display.addWidget(self.imageDisplayTabs)
            dock_display.setStretch(x=100,y=None)
            dock_controlPanel = dock.Dock('Controls', autoOrientation = False)
            # dock_controlPanel.showTitleBar()
            dock_controlPanel.addWidget(self.centralWidget)
            dock_controlPanel.setStretch(x=1,y=None)
            dock_controlPanel.setFixedWidth(dock_controlPanel.minimumSizeHint().width())
            main_dockArea = dock.DockArea()
            main_dockArea.addDock(dock_display)
            main_dockArea.addDock(dock_controlPanel,'right')
            self.setCentralWidget(main_dockArea)
            desktopWidget = QDesktopWidget()
            height_min = 0.9*desktopWidget.height()
            width_min = 0.96*desktopWidget.width()
            self.setMinimumSize(int(width_min),int(height_min))
        else:
            self.setCentralWidget(self.centralWidget)
            self.tabbedImageDisplayWindow = QMainWindow()
            self.tabbedImageDisplayWindow.setCentralWidget(self.imageDisplayTabs)
            self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() | Qt.CustomizeWindowHint)
            self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() & ~Qt.WindowCloseButtonHint)
            desktopWidget = QDesktopWidget()
            width = 0.96*desktopWidget.height()
            height = width
            self.tabbedImageDisplayWindow.setFixedSize(width,height)
            self.tabbedImageDisplayWindow.show()

        # make connections
        self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
        self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
        # self.streamHandler.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
        self.navigationController.xPos.connect(lambda x:self.navigationWidget.label_Xpos.setText("{:.2f}".format(x)))
        self.navigationController.yPos.connect(lambda x:self.navigationWidget.label_Ypos.setText("{:.2f}".format(x)))
        self.navigationController.zPos.connect(lambda x:self.navigationWidget.label_Zpos.setText("{:.2f}".format(x)))
        if ENABLE_TRACKING:
            self.navigationController.signal_joystick_button_pressed.connect(self.trackingControlWidget.slot_joystick_button_pressed)
        else:
            self.navigationController.signal_joystick_button_pressed.connect(self.autofocusController.autofocus)
        self.multipointController.signal_current_configuration.connect(self.liveControlWidget.set_microscope_mode)
        self.multiPointWidget.signal_acquisition_started.connect(self.navigationWidget.toggle_navigation_controls)

        if USE_NAPARI_FOR_LIVE_VIEW:
            self.autofocusController.image_to_display.connect(lambda image: self.napariLiveWidget.updateLiveLayer(image, from_autofocus=True))
            self.streamHandler.image_to_display.connect(lambda image: self.napariLiveWidget.updateLiveLayer(image, from_autofocus=False))
            self.multipointController.image_to_display.connect(lambda image: self.napariLiveWidget.updateLiveLayer(image, from_autofocus=False))
            self.napariLiveWidget.signal_coordinates_clicked.connect(self.navigationController.move_from_click)
        else:
            self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
            self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
            self.multipointController.image_to_display.connect(self.imageDisplayWindow.display_image)
            self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image)
            self.imageDisplayWindow.image_click_coordinates.connect(self.navigationController.move_from_click)

        if USE_NAPARI_FOR_MULTIPOINT:
            self.multiPointWidget.signal_acquisition_channels.connect(self.napariMultiChannelWidget.initChannels)
            self.multiPointWidget.signal_acquisition_shape.connect(self.napariMultiChannelWidget.initLayersShape)
            self.multipointController.napari_layers_init.connect(self.napariMultiChannelWidget.initLayers)
            self.multipointController.napari_layers_update.connect(self.napariMultiChannelWidget.updateLayers)
            if USE_NAPARI_FOR_LIVE_VIEW:
                self.napariMultiChannelWidget.signal_layer_contrast_limits.connect(self.napariLiveWidget.saveContrastLimits)
                self.napariLiveWidget.signal_layer_contrast_limits.connect(self.napariMultiChannelWidget.saveContrastLimits)
        else:
            self.multipointController.image_to_display_multi.connect(self.imageArrayDisplayWindow.display_image)

        if SHOW_TILED_PREVIEW:
            if USE_NAPARI_FOR_TILED_DISPLAY:
                self.multiPointWidget.signal_acquisition_channels.connect(self.napariTiledDisplayWidget.initChannels)
                self.multiPointWidget.signal_acquisition_shape.connect(self.napariTiledDisplayWidget.initLayersShape)
                self.multipointController.napari_layers_init.connect(self.napariTiledDisplayWidget.initLayers)
                self.multipointController.napari_layers_update.connect(self.napariTiledDisplayWidget.updateLayers)
                self.napariTiledDisplayWidget.signal_coordinates_clicked.connect(self.navigationController.scan_preview_move_from_click)
                if USE_NAPARI_FOR_LIVE_VIEW:
                    self.napariTiledDisplayWidget.signal_layer_contrast_limits.connect(self.napariLiveWidget.saveContrastLimits)
                    self.napariLiveWidget.signal_layer_contrast_limits.connect(self.napariTiledDisplayWidget.saveContrastLimits)
                if USE_NAPARI_FOR_MULTIPOINT:
                    self.napariTiledDisplayWidget.signal_layer_contrast_limits.connect(self.napariMultiChannelWidget.saveContrastLimits)
                    self.napariMultiChannelWidget.signal_layer_contrast_limits.connect(self.napariTiledDisplayWidget.saveContrastLimits)
            else:
                self.multipointController.image_to_display_tiled_preview.connect(self.imageDisplayWindow_scan_preview.display_image)
                self.imageDisplayWindow_scan_preview.image_click_coordinates.connect(self.navigationController.scan_preview_move_from_click)

        self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
        self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
        self.liveControlWidget.update_camera_settings()

        self.slidePositionController.signal_slide_loading_position_reached.connect(self.navigationWidget.slot_slide_loading_position_reached)
        self.slidePositionController.signal_slide_loading_position_reached.connect(self.multiPointWidget.disable_the_start_aquisition_button)
        self.slidePositionController.signal_slide_scanning_position_reached.connect(self.navigationWidget.slot_slide_scanning_position_reached)
        self.slidePositionController.signal_slide_scanning_position_reached.connect(self.multiPointWidget.enable_the_start_aquisition_button)
        self.slidePositionController.signal_clear_slide.connect(self.navigationViewer.clear_slide)

        self.navigationController.xyPos.connect(self.navigationViewer.update_current_location)
        self.multipointController.signal_register_current_fov.connect(self.navigationViewer.register_fov)

        self.navigationController.move_to_cached_position()

    def closeEvent(self, event):
        self.navigationController.cache_current_position()
        event.accept()
        # self.softwareTriggerGenerator.stop() @@@ => 
        self.navigationController.home()
        self.navigationController.turnoff_axis_pid_control()

        self.liveController.stop_live()
        self.camera.close()
        self.imageSaver.close()
        self.imageDisplay.close()
        if not SINGLE_WINDOW:
            self.imageDisplayWindow.close()
            self.imageArrayDisplayWindow.close()
            self.tabbedImageDisplayWindow.close()
        self.microcontroller.close()

#!/usr/bin/python
# -*- coding:utf-8 -*-
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-
#

GAMMA_MIN = 0.1
GAMMA_MAX = 10.0
CONTRAST_MIN = -50
CONTRAST_MAX = 100
UNSIGNED_INT_MAX = 0xFFFFFFFF
UNSIGNED_LONG_LONG_MAX = 0xFFFFFFFFFFFFFFFF


# frame state code
class GxFrameStatusList:
    SUCCESS = 0                 # Normal frame
    INCOMPLETE = -1             # Residual frame
    INVALID_IMAGE_INFO = -2     # invalid image info

    def __init__(self):
        pass


# Device type code
class GxDeviceClassList:
    UNKNOWN = 0                 # Unknown device type
    USB2 = 1                    # USB2.0 vision device
    GEV = 2                     # Gige vision device
    U3V = 3                     # USB3.0 vision device
    SMART = 4                   # Smart device

    def __init__(self):
        pass


class GxAccessMode:
    READONLY = 2                # Open the device in read-only mode
    CONTROL = 3                 # Open the device in controlled mode
    EXCLUSIVE = 4               # Open the device in exclusive mode

    def __init__(self):
        pass


class GxAccessStatus:
    UNKNOWN = 0                # The device's current status is unknown
    READWRITE = 1              # The device currently supports reading and writing
    READONLY = 2               # The device currently only supports reading
    NOACCESS = 3               # The device currently does neither support reading nor support writing

    def __init__(self):
        pass


class GxIPConfigureModeList:
    DHCP = 0x6                 # Enable the DHCP mode to allocate the IP address by the DHCP server
    LLA = 0x4                  # Enable the LLA mode to allocate the IP addresses
    STATIC_IP = 0x5            # Enable the static IP mode to configure the IP address
    DEFAULT = 0x7              # Enable the default mode to configure the IP address

    def __init__(self):
        pass


class GxPixelSizeEntry:
    BPP8 = 8
    BPP10 = 10
    BPP12 = 12
    BPP14 = 14
    BPP16 = 16
    BPP24 = 24
    BPP30 = 30
    BPP32 = 32
    BPP36 = 36
    BPP48 = 48
    BPP64 = 64

    def __init__(self):
        pass


class GxPixelColorFilterEntry:
    NONE = 0
    BAYER_RG = 1
    BAYER_GB = 2
    BAYER_GR = 3
    BAYER_BG = 4

    def __init__(self):
        pass


GX_PIXEL_MONO = 0x01000000
GX_PIXEL_COLOR = 0x02000000
GX_PIXEL_8BIT = 0x00080000
GX_PIXEL_10BIT = 0x000A0000
GX_PIXEL_12BIT = 0x000C0000
GX_PIXEL_16BIT = 0x00100000
GX_PIXEL_24BIT = 0x00180000
GX_PIXEL_30BIT = 0x001E0000
GX_PIXEL_32BIT = 0x00200000
GX_PIXEL_36BIT = 0x00240000
GX_PIXEL_48BIT = 0x00300000
GX_PIXEL_64BIT = 0x00400000


class GxPixelFormatEntry:
    UNDEFINED = 0
    MONO8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x0001)  # 0x1080001
    MONO8_SIGNED = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x0002)  # 0x1080002
    MONO10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0003)  # 0x1100003
    MONO12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0005)  # 0x1100005
    MONO14 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0025)  # 0x1100025
    MONO16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0007)  # 0x1100007
    BAYER_GR8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x0008)  # 0x1080008
    BAYER_RG8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x0009)  # 0x1080009
    BAYER_GB8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x000A)  # 0x108000A
    BAYER_BG8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x000B)  # 0x108000B
    BAYER_GR10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x000C)  # 0x110000C
    BAYER_RG10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x000D)  # 0x110000D
    BAYER_GB10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x000E)  # 0x110000E
    BAYER_BG10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x000F)  # 0x110000F
    BAYER_GR12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0010)  # 0x1100010
    BAYER_RG12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0011)  # 0x1100011
    BAYER_GB12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0012)  # 0x1100012
    BAYER_BG12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0013)  # 0x1100013
    BAYER_GR16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x002E)  # 0x110002E
    BAYER_RG16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x002F)  # 0x110002F
    BAYER_GB16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0030)  # 0x1100030
    BAYER_BG16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0031)  # 0x1100031
    RGB8_PLANAR = (GX_PIXEL_COLOR | GX_PIXEL_24BIT | 0x0021)  # 0x2180021
    RGB10_PLANAR = (GX_PIXEL_COLOR | GX_PIXEL_48BIT | 0x0022)  # 0x2300022
    RGB12_PLANAR = (GX_PIXEL_COLOR | GX_PIXEL_48BIT | 0x0023)  # 0x2300023
    RGB16_PLANAR = (GX_PIXEL_COLOR | GX_PIXEL_48BIT | 0x0024)  # 0x2300024

    def __init__(self):
        pass


class GxAcquisitionModeEntry:
    SINGLE_FRAME = 0
    MULITI_FRAME = 1
    CONTINUOUS = 2

    def __init__(self):
        pass


class GxTriggerSourceEntry:
    SOFTWARE = 0
    LINE0 = 1
    LINE1 = 2
    LINE2 = 3
    LINE3 = 4


    def __init__(self):
        pass


class GxTriggerActivationEntry:
    FALLING_EDGE = 0
    RISING_EDGE = 1

    def __init__(self):
        pass


class GxExposureModeEntry:
    TIMED = 1
    TRIGGER_WIDTH = 2

    def __init__(self):
        pass


class GxUserOutputSelectorEntry:
    OUTPUT0 = 1
    OUTPUT1 = 2
    OUTPUT2 = 4

    def __init__(self):
        pass


class GxUserOutputModeEntry:
    STROBE = 0
    USER_DEFINED = 1

    def __init__(self):
        pass


class GxGainSelectorEntry:
    ALL = 0
    RED = 1
    GREEN = 2
    BLUE = 3

    def __init__(self):
        pass


class GxBlackLevelSelectEntry:
    ALL = 0
    RED = 1
    GREEN = 2
    BLUE = 3

    def __init__(self):
        pass


class GxBalanceRatioSelectorEntry:
    RED = 0
    GREEN = 1
    BLUE = 2

    def __init__(self):
        pass


class GxAALightEnvironmentEntry:
    NATURE_LIGHT = 0
    AC50HZ = 1
    AC60HZ = 2

    def __init__(self):
        pass


class GxUserSetEntry:
    DEFAULT = 0
    USER_SET0 = 1

    def __init__(self):
        pass


class GxAWBLampHouseEntry:
    ADAPTIVE = 0
    D65 = 1
    FLUORESCENCE = 2
    INCANDESCENT = 3
    D75 = 4
    D50 = 5
    U30 = 6

    def __init__(self):
        pass


class GxTestPatternEntry:
    OFF = 0
    GRAY_FRAME_RAMP_MOVING = 1
    SLANT_LINE_MOVING = 2
    VERTICAL_LINE_MOVING = 3
    SLANT_LINE = 6

    def __init__(self):
        pass


class GxTriggerSelectorEntry:
    FRAME_START = 1
    FRAME_BURST_START = 2

    def __init__(self):
        pass


class GxLineSelectorEntry:
    LINE0 = 0
    LINE1 = 1
    LINE2 = 2
    LINE3 = 3

    def __init__(self):
        pass


class GxLineModeEntry:
    INPUT = 0
    OUTPUT = 1

    def __init__(self):
        pass


class GxLineSourceEntry:
    OFF = 0
    STROBE = 1
    USER_OUTPUT0 = 2
    USER_OUTPUT1 = 3
    USER_OUTPUT2 = 4
    EXPOSURE_ACTIVE = 5
    FRAME_TRIGGER_WAIT = 6
    ACQUISITION_TRIGGER_WAIT = 7
    TIMER1_ACTIVE = 8

    def __init__(self):
        pass


class GxEventSelectorEntry:
    EXPOSURE_END = 0x0004
    BLOCK_DISCARD = 0x9000
    EVENT_OVERRUN = 0x9001
    FRAME_START_OVER_TRIGGER = 0x9002
    BLOCK_NOT_EMPTY = 0x9003
    INTERNAL_ERROR = 0x9004

    def __init__(self):
        pass


class GxLutSelectorEntry:
    LUMINANCE = 0

    def __init__(self):
        pass


class GxTransferControlModeEntry:
    BASIC = 0
    USER_CONTROLED = 1

    def __init__(self):
        pass


class GxTransferOperationModeEntry:
    MULTI_BLOCK = 0

    def __init__(self):
        pass


class GxTestPatternGeneratorSelectorEntry:
    SENSOR = 0          # Sensor test pattern
    REGION0 = 1         # FPGA test pattern

    def __init__(self):
        pass


class GxChunkSelectorEntry:
    FRAME_ID = 1
    TIME_STAMP = 2
    COUNTER_VALUE = 3

    def __init__(self):
        pass

class GxTimerSelectorEntry:
    TIMER1 = 1         

    def __init__(self):
        pass

class GxTimerTriggerSourceEntry:
    EXPOSURE_START = 1

    def __init__(self):
        pass

class GxCounterSelectorEntry:
    COUNTER1 = 1

    def __init__(self):
        pass

class GxCounterEventSourceEntry:
    FRAME_START = 1

    def __init__(self):
        pass

class GxCounterResetSourceEntry:
    OFF = 0
    SOFTWARE = 1
    LINE0 = 2
    LINE1 = 3
    LINE2 = 4
    LINE3 = 5

    def __init__(self):
        pass

class GxCounterResetActivationEntry:
    RISING_EDGE = 1

    def __init__(self):
        pass               

class GxBinningHorizontalModeEntry:
    SUM = 0
    AVERAGE = 1

    def __init__(self):
        pass


class GxBinningVerticalModeEntry:
    SUM = 0
    AVERAGE = 1

    def __init__(self):
        pass


class GxAcquisitionStatusSelectorEntry:
    ACQUISITION_TRIGGER_WAIT = 0
    FRAME_TRIGGER_WAIT = 1

    def __init__(self):
        pass


class GxGammaModeEntry:
    SRGB = 0
    USER = 1

    def __init__(self):
        pass


class GxColorTransformationModeEntry:
    RGB_TO_RGB = 0
    USER = 1

    def __init__(self):
        pass


class GxColorTransformationValueSelectorEntry:
    GAIN00 = 0
    GAIN01 = 1
    GAIN02 = 2
    GAIN10 = 3
    GAIN11 = 4
    GAIN12 = 5
    GAIN20 = 6
    GAIN21 = 7
    GAIN22 = 8

    def __init__(self):
        pass


class GxAutoEntry:
    OFF = 0
    CONTINUOUS = 1
    ONCE = 2

    def __init__(self):
        pass


class GxSwitchEntry:
    OFF = 0
    ON = 1

    def __init__(self):
        pass


class GxRegionSendModeEntry:
    SINGLE_ROI = 0
    MULTI_ROI = 1

    def __init__(self):
        pass


class GxRegionSelectorEntry:
    REGION0 = 0
    REGION1 = 1
    REGION2 = 2
    REGION3 = 3
    REGION4 = 4
    REGION5 = 5
    REGION6 = 6
    REGION7 = 7

    def __init__(self):
        pass


# image interpolation method
class DxBayerConvertType:
    NEIGHBOUR = 0                           # Neighborhood average interpolation algorithm
    ADAPTIVE = 1                            # Edge adaptive interpolation algorithm
    NEIGHBOUR3 = 2                          # The neighborhood average interpolation algorithm for a larger region

    def __init__(self):
        pass


# image valid bit
class DxValidBit:
    BIT0_7 = 0              # bit 0~7
    BIT1_8 = 1              # bit 1~8
    BIT2_9 = 2              # bit 2~9
    BIT3_10 = 3             # bit 3~10
    BIT4_11 = 4             # bit 4~11

    def __init__(self):
        pass


# image mirror method
class DxImageMirrorMode:
    HORIZONTAL_MIRROR = 0                               # Horizontal mirror
    VERTICAL_MIRROR = 1                                 # Vertical mirror

    def __init__(self):
        pass

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.core_displacement_measurement as core_displacement_measurement
import control.microcontroller as microcontroller
from control._def import *

import pyqtgraph.dockarea as dock
SINGLE_WINDOW = True # set to False if use separate windows for display and control

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, is_simulation = False, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load window
		if ENABLE_TRACKING:
			self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True)
			self.imageDisplayWindow.show_ROI_selector()
		else:
			self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True)
		self.imageArrayDisplayWindow = core.ImageArrayDisplayWindow() 
		# self.imageDisplayWindow.show()
		# self.imageArrayDisplayWindow.show()

		# image display windows
		self.imageDisplayTabs = QTabWidget()
		self.imageDisplayTabs.addTab(self.imageDisplayWindow.widget, "Live View")
		self.imageDisplayTabs.addTab(self.imageArrayDisplayWindow.widget, "Multichannel Acquisition")

		# load objects
		if is_simulation:
			self.camera = camera.Camera_Simulation(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
			self.microcontroller = microcontroller.Microcontroller_Simulation()
		else:
			self.camera = camera.Camera(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
			try:
				self.microcontroller = microcontroller.Microcontroller()
			except:
				print('! Microcontroller not detected, using simulated microcontroller !')
				self.microcontroller = microcontroller.Microcontroller_Simulation()

		# configure the actuators
		self.microcontroller.configure_actuators()
			
		self.configurationManager = core.ConfigurationManager()
		self.streamHandler = core.StreamHandler(display_resolution_scaling=DEFAULT_DISPLAY_CROP/100)
		self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
		self.navigationController = core.NavigationController(self.microcontroller)
		self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
		self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController,self.configurationManager)
		if ENABLE_TRACKING:
			self.trackingController = core.TrackingController(self.camera,self.microcontroller,self.navigationController,self.configurationManager,self.liveController,self.autofocusController,self.imageDisplayWindow)
		self.imageSaver = core.ImageSaver(image_format=Acquisition.IMAGE_FORMAT)
		self.imageDisplay = core.ImageDisplay()
		self.displacementMeasurementController = core_displacement_measurement.DisplacementMeasurementController()

		# open the camera
		# camera start streaming
		self.camera.open()
		# self.camera.set_reverse_x(CAMERA_REVERSE_X) # these are not implemented for the cameras in use
		# self.camera.set_reverse_y(CAMERA_REVERSE_Y) # these are not implemented for the cameras in use
		self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera.set_callback(self.streamHandler.on_new_frame)
		self.camera.enable_callback()
		if ENABLE_STROBE_OUTPUT:
			self.camera.set_line3_to_exposure_active()

		# load widgets
		self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,include_gain_exposure_time=False)
		self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager)
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
		self.dacControlWidget = widgets.DACControWidget(self.microcontroller)
		self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
		self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)
		if ENABLE_TRACKING:
			self.trackingControlWidget = widgets.TrackingControllerWidget(self.trackingController,self.configurationManager,show_configurations=TRACKING_SHOW_MICROSCOPE_CONFIGURATIONS)
		self.multiPointWidget = widgets.MultiPointWidget(self.multipointController,self.configurationManager)

		self.recordTabWidget = QTabWidget()
		if ENABLE_TRACKING:
			self.recordTabWidget.addTab(self.trackingControlWidget, "Tracking")
		self.recordTabWidget.addTab(self.recordingControlWidget, "Simple Recording")
		self.recordTabWidget.addTab(self.multiPointWidget, "Multipoint Acquisition")

		self.waveformDisplay = widgets.WaveformDisplay(N=1000)
		self.displacementMeasurementWidget = widgets.DisplacementMeasurementWidget(self.displacementMeasurementController,self.waveformDisplay)

		# layout widgets
		layout = QVBoxLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget)
		layout.addWidget(self.liveControlWidget)
		layout.addWidget(self.navigationWidget)
		if SHOW_DAC_CONTROL:
			layout.addWidget(self.dacControlWidget)
		layout.addWidget(self.autofocusWidget)
		layout.addWidget(self.recordTabWidget)
		layout.addStretch()
		layout.addWidget(self.displacementMeasurementWidget)
		
		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		# self.centralWidget.setFixedSize(self.centralWidget.minimumSize())
		# self.centralWidget.setFixedWidth(self.centralWidget.minimumWidth())
		# self.centralWidget.setMaximumWidth(self.centralWidget.minimumWidth())
		self.centralWidget.setFixedWidth(self.centralWidget.minimumSizeHint().width())
		
		if SINGLE_WINDOW:
			dock_display = dock.Dock('Image Display', autoOrientation = False)
			dock_display.showTitleBar()
			dock_display.addWidget(self.imageDisplayTabs)
			dock_display.setStretch(x=100,y=60)
			dock_waveform = dock.Dock('Displacement Measurement', autoOrientation = False)
			dock_waveform.showTitleBar()
			dock_waveform.addWidget(self.waveformDisplay)
			dock_waveform.setStretch(x=100,y=40)
			dock_controlPanel = dock.Dock('Controls', autoOrientation = False)
			# dock_controlPanel.showTitleBar()
			dock_controlPanel.addWidget(self.centralWidget)
			dock_controlPanel.setStretch(x=1,y=None)
			dock_controlPanel.setFixedWidth(dock_controlPanel.minimumSizeHint().width())
			main_dockArea = dock.DockArea()
			main_dockArea.addDock(dock_display)
			main_dockArea.addDock(dock_waveform,'bottom')
			main_dockArea.addDock(dock_controlPanel,'right')
			self.setCentralWidget(main_dockArea)
			desktopWidget = QDesktopWidget()
			height_min = 0.9*desktopWidget.height()
			width_min = 0.96*desktopWidget.width()
			self.setMinimumSize(int(width_min),int(height_min))
		else:
			self.setCentralWidget(self.centralWidget)
			self.tabbedImageDisplayWindow = QMainWindow()
			self.tabbedImageDisplayWindow.setCentralWidget(self.imageDisplayTabs)
			self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() | Qt.CustomizeWindowHint)
			self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() & ~Qt.WindowCloseButtonHint)
			desktopWidget = QDesktopWidget()
			width = 0.96*desktopWidget.height()
			height = width
			self.tabbedImageDisplayWindow.setFixedSize(width,height)
			self.tabbedImageDisplayWindow.show()

		# make connections
		self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
		self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
		self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
		# self.streamHandler.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
		self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)
		if ENABLE_TRACKING:
			self.navigationController.signal_joystick_button_pressed.connect(self.trackingControlWidget.slot_joystick_button_pressed)
		else:
			self.navigationController.signal_joystick_button_pressed.connect(self.autofocusController.autofocus)
		self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
		self.multipointController.image_to_display.connect(self.imageDisplayWindow.display_image)
		self.multipointController.signal_current_configuration.connect(self.liveControlWidget.set_microscope_mode)
		self.multipointController.image_to_display_multi.connect(self.imageArrayDisplayWindow.display_image)
		self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
		self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
		self.liveControlWidget.update_camera_settings()

		# displacement measurement
		self.streamHandler.image_to_display.connect(self.displacementMeasurementController.update_measurement)
		self.displacementMeasurementController.signal_plots.connect(self.waveformDisplay.plot)
		self.displacementMeasurementController.signal_readings.connect(self.displacementMeasurementWidget.display_readings)

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.navigationController.home()
		self.liveController.stop_live()
		self.camera.close()
		self.imageSaver.close()
		self.imageDisplay.close()
		if not SINGLE_WINDOW:
			self.imageDisplayWindow.close()
			self.imageArrayDisplayWindow.close()
			self.tabbedImageDisplayWindow.close()
		self.microcontroller.close()

﻿#!/usr/bin/python
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-
# -*- coding:utf-8 -*-

from ctypes import *
import sys


if sys.platform == 'linux2' or sys.platform == 'linux':
    try:
        dll = CDLL('/usr/lib/libgxiapi.so')
    except OSError:
        print("Cannot find libgxiapi.so.")
else:
    try:
        dll = WinDLL('GxIAPI.dll')
    except OSError:
        print('Cannot find GxIAPI.dll.')


# Error code
class GxStatusList:
    SUCCESS = 0	                # Success
    ERROR = -1                  # There is a unspecified internal error that is not expected to occur
    NOT_FOUND_TL = -2           # The TL library cannot be found
    NOT_FOUND_DEVICE = -3       # The device is not found
    OFFLINE = -4                # The current device is in a offline state
    INVALID_PARAMETER = -5      # Invalid parameter, Generally the pointer is NULL or the input IP and
                                # Other parameter formats are invalid
    INVALID_HANDLE = -6         # Invalid handle
    INVALID_CALL = -7           # The interface is invalid, which refers to software interface logic error
    INVALID_ACCESS = -8         # The function is currently inaccessible or the device access mode is incorrect
    NEED_MORE_BUFFER = -9       # The user request buffer is insufficient: the user input buffersize during
                                # the read operation is less than the actual need
    ERROR_TYPE = -10            # The type of FeatureID used by the user is incorrect,
                                # such as an integer interface using a floating-point function code
    OUT_OF_RANGE = -11          # The value written by the user is crossed
    NOT_IMPLEMENTED = -12       # This function is not currently supported
    NOT_INIT_API = -13          # There is no call to initialize the interface
    TIMEOUT = -14               # Timeout error
    REPEAT_OPENED = -1004       # The device has been opened

    def __init__(self):
        pass


class GxOpenMode:
    SN = 0	                   # Opens the device via a serial number
    IP = 1                     # Opens the device via an IP address
    MAC = 2                    # Opens the device via a MAC address
    INDEX = 3                  # Opens the device via a serial number(Start from 1)
    USER_ID = 4                # Opens the device via user defined ID

    def __init__(self):
        pass


class GxFrameMask:
    TYPE_MASK = 0xF0000000
    LEVEL_MASK = 0x0F000000
    
    def __init__(self):
        pass
    

class GxFeatureType:
    INT = 0x10000000            # Integer type
    FLOAT = 0X20000000          # Floating point type
    ENUM = 0x30000000           # Enum type
    BOOL = 0x40000000           # Boolean type
    STRING = 0x50000000         # String type
    BUFFER = 0x60000000         # Block data type
    COMMAND = 0x70000000        # Command type

    def __init__(self):
        pass


class GxFeatureLevel:
    REMOTE_DEV = 0x00000000     # RemoteDevice Layer
    TL = 0x01000000             # TL Layer
    IF = 0x02000000             # Interface Layer
    DEV = 0x03000000            # Device Layer
    DS = 0x04000000             # DataStream Layer

    def __init__(self):
        pass


class GxFeatureID:
    # ---------------Device Information Section---------------------------
    STRING_DEVICE_VENDOR_NAME = 0x50000000                 # The name of the device's vendor
    STRING_DEVICE_MODEL_NAME = 0x50000001                  # The model name of the device
    STRING_DEVICE_FIRMWARE_VERSION = 0x50000002            # The version of the device's firmware and software
    STRING_DEVICE_VERSION = 0x50000003                     # The version of the device
    STRING_DEVICE_SERIAL_NUMBER = 0x50000004               # A serial number for device
    STRING_FACTORY_SETTING_VERSION = 0x50000006            # The version of the device's Factory Setting
    STRING_DEVICE_USER_ID = 0x50000007                     # A user programmable string
    INT_DEVICE_LINK_SELECTOR = 0x10000008                  # Selects which Link of the device to control
    ENUM_DEVICE_LINK_THROUGHPUT_LIMIT_MODE = 0x30000009    # DeviceLinkThroughputLimit switch
    INT_DEVICE_LINK_THROUGHPUT_LIMIT = 0x1000000a          # Limits the maximum bandwidth of the data
    INT_DEVICE_LINK_CURRENT_THROUGHPUT = 0x1000000b        # Current bandwidth of the data
    COMMAND_DEVICE_RESET = 0x7000000c                      # Device reset
    INT_TIMESTAMP_TICK_FREQUENCY = 0x1000000d              # Timestamp tick frequency
    COMMAND_TIMESTAMP_LATCH = 0x7000000e                   # Timestamp latch
    COMMAND_TIMESTAMP_RESET = 0x7000000f                   # Timestamp reset
    COMMAND_TIMESTAMP_LATCH_RESET = 0x70000010             # Timestamp latch reset
    INT_TIMESTAMP_LATCH_VALUE = 0x10000011                 # The value of timestamp latch

    # ---------------ImageFormat Section----------------------------------
    INT_SENSOR_WIDTH = 0x100003e8                           # The actual width of the camera's sensor in pixels
    INT_SENSOR_HEIGHT = 0x100003e9                          # The actual height of the camera's sensor in pixels
    INT_WIDTH_MAX = 0x100003ea                              # Width max[read_only]
    INT_HEIGHT_MAX = 0x100003eb                             # Height max[read_only]
    INT_OFFSET_X = 0x100003ec                               # The X offset for the area of interest
    INT_OFFSET_Y = 0x100003ed                               # The Y offset for the area of interest
    INT_WIDTH = 0x100003ee                                  # the width of the area of interest in pixels
    INT_HEIGHT = 0x100003ef                                 # the height of the area of interest in pixels
    INT_BINNING_HORIZONTAL = 0x100003f0                     # Horizontal pixel Binning
    INT_BINNING_VERTICAL = 0x100003f1                       # Vertical pixel Binning
    INT_DECIMATION_HORIZONTAL = 0x100003f2                  # Horizontal pixel sampling
    INT_DECIMATION_VERTICAL = 0x100003f3                    # Vertical pixel sampling
    ENUM_PIXEL_SIZE = 0x300003f4                            # Pixel depth, Reference GxPixelSizeEntry
    ENUM_PIXEL_COLOR_FILTER = 0x300003f5                    # Bayer format, Reference GxPixelColorFilterEntry
    ENUM_PIXEL_FORMAT = 0x300003f6                          # Pixel format, Reference GxPixelFormatEntry
    BOOL_REVERSE_X = 0x400003f7                             # Horizontal flipping
    BOOL_REVERSE_Y = 0x400003f8                             # Vertical flipping
    ENUM_TEST_PATTERN = 0x300003f9                          # Test pattern, Reference GxTestPatternEntry
    ENUM_TEST_PATTERN_GENERATOR_SELECTOR = 0x300003fa       # The source of test pattern, reference GxTestPatternGeneratorSelectorEntry
    ENUM_REGION_SEND_MODE = 0x300003fb                      # ROI region output mode, reference GxRegionSendModeEntry
    ENUM_REGION_MODE = 0x300003fc                           # ROI region output switch
    ENUM_REGION_SELECTOR = 0x300003fd                       # ROI region select, reference GxRegionSelectorEntry
    INT_CENTER_WIDTH = 0x100003fe                           # Window width
    INT_CENTER_HEIGHT = 0x100003ff                          # Window height
    ENUM_BINNING_HORIZONTAL_MODE = 0x30000400               # Binning horizontal mode
    ENUM_BINNING_VERTICAL_MODE = 0x30000401                 # Binning vertical mode

    # ---------------TransportLayer Section-------------------------------
    INT_PAYLOAD_SIZE = 0x100007d0                           # Size of images in byte
    BOOL_GEV_CURRENT_IP_CONFIGURATION_LLA = 0x400007d1      # IP configuration by LLA.
    BOOL_GEV_CURRENT_IP_CONFIGURATION_DHCP = 0x400007d2     # IP configuration by DHCP
    BOOL_GEV_CURRENT_IP_CONFIGURATION_PERSISTENT_IP = 0x400007d3   # IP configuration by PersistentIP
    INT_ESTIMATED_BANDWIDTH = 0x100007d4                    # Estimated Bandwidth in Bps
    INT_GEV_HEARTBEAT_TIMEOUT = 0x100007d5                  # The heartbeat timeout in milliseconds
    INT_GEV_PACKET_SIZE = 0x100007d6                        # The packet size in bytes for each packet
    INT_GEV_PACKET_DELAY = 0x100007d7                       # A delay between the transmission of each packet
    INT_GEV_LINK_SPEED = 0x100007d8                         # The connection speed in Mbps

    # ---------------AcquisitionTrigger Section---------------------------
    ENUM_ACQUISITION_MODE = 0x30000bb8                      # The mode of acquisition, Reference: GxAcquisitionModeEntry
    COMMAND_ACQUISITION_START = 0x70000bb9                  # The command for starts the acquisition of images
    COMMAND_ACQUISITION_STOP = 0x70000bba                   # The command for stop the acquisition of images
    INT_ACQUISITION_SPEED_LEVEL = 0x10000bbb                # The level for acquisition speed
    INT_ACQUISITION_FRAME_COUNT = 0x10000bbc
    ENUM_TRIGGER_MODE = 0x30000bbd                          # Trigger mode, Reference:GxTriggerModeEntry
    COMMAND_TRIGGER_SOFTWARE = 0x70000bbe                   # The command for generates a software trigger signal
    ENUM_TRIGGER_ACTIVATION = 0x30000bbf                    # Trigger polarity, Reference GxTriggerActivationEntry
    ENUM_TRIGGER_SWITCH = 0x30000bc0                        # The switch of External trigger
    FLOAT_EXPOSURE_TIME = 0x20000bc1                        # Exposure time
    ENUM_EXPOSURE_AUTO = 0x30000bc2                         # Exposure auto
    FLOAT_TRIGGER_FILTER_RAISING = 0x20000bc3               # The Value of rising edge triggered filter
    FLOAT_TRIGGER_FILTER_FALLING = 0x20000bc4               # The Value of falling edge triggered filter
    ENUM_TRIGGER_SOURCE = 0x30000bc5                        # Trigger source, Reference GxTriggerSourceEntry
    ENUM_EXPOSURE_MODE = 0x30000bc6                         # Exposure mode, Reference GxExposureModeEntry
    ENUM_TRIGGER_SELECTOR = 0x30000bc7                      # Trigger type, Reference GxTriggerSelectorEntry
    FLOAT_TRIGGER_DELAY = 0x20000bc8                        # The trigger delay in microsecond
    ENUM_TRANSFER_CONTROL_MODE = 0x30000bc9                 # The control method for the transfers, Reference GxTransferControlModeEntry
    ENUM_TRANSFER_OPERATION_MODE = 0x30000bca               # The operation method for the transfers, Reference GxTransferOperationModeEntry
    COMMAND_TRANSFER_START = 0x70000bcb                     # Starts the streaming of data blocks out of the device
    INT_TRANSFER_BLOCK_COUNT = 0x10000bcc                   # The number of data Blocks that the device should stream before stopping
    BOOL_FRAME_STORE_COVER_ACTIVE = 0x40000bcd              # The switch for frame cover
    ENUM_ACQUISITION_FRAME_RATE_MODE = 0x30000bce           # The switch for Control frame rate
    FLOAT_ACQUISITION_FRAME_RATE = 0x20000bcf               # The value for Control frame rate
    FLOAT_CURRENT_ACQUISITION_FRAME_RATE = 0x20000bd0       # The maximum allowed frame acquisition rate
    ENUM_FIXED_PATTERN_NOISE_CORRECT_MODE = 0x30000bd1      # The switch of fixed pattern noise correct
    INT_ACQUISITION_BURST_FRAME_COUNT = 0x10000bd6          # The acquisition burst frame count
    ENUM_ACQUISITION_STATUS_SELECTOR = 0x30000bd7           # The selector of acquisition status
    BOOL_ACQUISITION_STATUS = 0x40000bd8                    # The acquisition status
    FLOAT_EXPOSURE_DELAY = 0x2000765c                       # The exposure delay

    # ----------------DigitalIO Section-----------------------------------
    ENUM_USER_OUTPUT_SELECTOR = 0x30000fa0                  # selects user settable output signal, Reference GxUserOutputSelectorEntry
    BOOL_USER_OUTPUT_VALUE = 0x40000fa1                     # The state of the output signal
    ENUM_USER_OUTPUT_MODE = 0x30000fa2                      # UserIO output mode, Reference GxUserOutputModeEntry
    ENUM_STROBE_SWITCH = 0x30000fa3                         # Strobe switch
    ENUM_LINE_SELECTOR = 0x30000fa4                         # Line selector, Reference GxLineSelectorEntry
    ENUM_LINE_MODE = 0x30000fa5                             # Line mode, Reference GxLineModeEntry
    BOOL_LINE_INVERTER = 0x40000fa6                         # Pin level reversal
    ENUM_LINE_SOURCE = 0x30000fa7                           # line source, Reference GxLineSourceEntry
    BOOL_LINE_STATUS = 0x40000fa8                           # line status
    INT_LINE_STATUS_ALL = 0x10000fa9                        # all line status
    FLOAT_PULSE_WIDTH = 0x20000faa                          #

    # ----------------AnalogControls Section------------------------------
    ENUM_GAIN_AUTO = 0x30001388                             # gain auto, Reference GxGainAutoEntry
    ENUM_GAIN_SELECTOR = 0x30001389                         # selects gain channel, Reference GxGainSelectorEntry
    ENUM_BLACK_LEVEL_AUTO = 0x3000138b                      # Black level auto, Reference GxBlackLevelAutoEntry
    ENUM_BLACK_LEVEL_SELECTOR = 0x3000138c                  # Black level channel, Reference GxBlackLevelSelectEntry
    ENUM_BALANCE_WHITE_AUTO = 0x3000138e                    # Balance white auto, Reference GxBalanceWhiteAutoEntry
    ENUM_BALANCE_RATIO_SELECTOR = 0x3000138f                # selects Balance white channel, Reference GxBalanceRatioSelectorEntry
    FLOAT_BALANCE_RATIO = 0x20001390                        # Balance white channel ratio
    ENUM_COLOR_CORRECT = 0x30001391                         # Color correct, Reference GxColorCorrectEntry
    ENUM_DEAD_PIXEL_CORRECT = 0x30001392                    # Pixel correct, Reference GxDeadPixelCorrectEntry
    FLOAT_GAIN = 0x20001393                                 # gain
    FLOAT_BLACK_LEVEL = 0x20001394                          # Black level
    BOOL_GAMMA_ENABLE = 0x40001395                          # Gamma enable bit
    ENUM_GAMMA_MODE = 0x30001396                            # Gamma mode
    FLOAT_GAMMA = 0x20001397                                # The value of Gamma
    INT_DIGITAL_SHIFT = 0x10001398                          #

    # ---------------CustomFeature Section--------------------------------
    INT_ADC_LEVEL = 0x10001770                              # AD conversion level
    INT_H_BLANKING = 0x10001771                             # Horizontal blanking
    INT_V_BLANKING = 0x10001772                             # Vertical blanking
    STRING_USER_PASSWORD = 0x50001773                       # User encrypted zone cipher
    STRING_VERIFY_PASSWORD = 0x50001774                     # User encrypted zone check cipher
    BUFFER_USER_DATA = 0x60001775                           # User encrypted area content
    INT_GRAY_VALUE = 0x10001776                             # Expected gray value
    ENUM_AA_LIGHT_ENVIRONMENT = 0x30001777                  # Gain auto, Exposure auto, Light environment type,
                                                            # Reference GxAALightEnvironmentEntry
    INT_AAROI_OFFSETX = 0x10001778                          # The X offset for the rect of interest in pixels for 2A
    INT_AAROI_OFFSETY = 0x10001779                          # The Y offset for the rect of interest in pixels for 2A
    INT_AAROI_WIDTH = 0x1000177a                            # The width offset for the rect of interest in pixels for 2A
    INT_AAROI_HEIGHT = 0x1000177b                           # The height offset for the rect of interest in pixels for 2A
    FLOAT_AUTO_GAIN_MIN = 0x2000177c                        # Automatic gain minimum
    FLOAT_AUTO_GAIN_MAX = 0x2000177d                        # Automatic gain maximum
    FLOAT_AUTO_EXPOSURE_TIME_MIN = 0x2000177e               # Automatic exposure minimum
    FLOAT_AUTO_EXPOSURE_TIME_MAX = 0x2000177f               # Automatic exposure maximum
    BUFFER_FRAME_INFORMATION = 0x60001780                   # Image frame information
    INT_CONTRAST_PARAM = 0x10001781                         # Contrast parameter
    FLOAT_GAMMA_PARAM = 0x20001782                          # Gamma parameter
    INT_COLOR_CORRECTION_PARAM = 0x10001783                 # Color correction param
    ENUM_IMAGE_GRAY_RAISE_SWITCH = 0x30001784               # Image gray raise, Reference GxImageGrayRaiseSwitchEntry
    ENUM_AWB_LAMP_HOUSE = 0x30001785                        # Automatic white balance light source
                                                            # Reference GxAWBLampHouseEntry
    INT_AWBROI_OFFSETX = 0x10001786                         # Offset_X of automatic white balance region
    INT_AWBROI_OFFSETY = 0x10001787                         # Offset_Y of automatic white balance region
    INT_AWBROI_WIDTH = 0x10001788                           # Width of automatic white balance region
    INT_AWBROI_HEIGHT = 0x10001789                          # Height of automatic white balance region
    ENUM_SHARPNESS_MODE = 0x3000178a                        # Sharpness mode, Reference GxSharpnessModeEntry
    FLOAT_SHARPNESS = 0x2000178b                            # Sharpness

    # ---------------UserSetControl Section-------------------------------
    ENUM_USER_SET_SELECTOR = 0x30001b58                     # Parameter group selection, Reference GxUserSetSelectorEntry
    COMMAND_USER_SET_LOAD = 0x70001b59                      # Load parameter group
    COMMAND_USER_SET_SAVE = 0x70001b5a                      # Save parameter group
    ENUM_USER_SET_DEFAULT = 0x30001b5b                      # Startup parameter group, Reference GxUserSetDefaultEntry

    # ---------------Event Section----------------------------------------
    ENUM_EVENT_SELECTOR = 0x30001f40                        # Event source select, Reference GxEventSelectorEntry
    ENUM_EVENT_NOTIFICATION = 0x30001f41                    # Event enabled, Reference GxEventNotificationEntry
    INT_EVENT_EXPOSURE_END = 0x10001f42                     # Exposure end event
    INT_EVENT_EXPOSURE_END_TIMESTAMP = 0x10001f43           # The timestamp of Exposure end event
    INT_EVENT_EXPOSURE_END_FRAME_ID = 0x10001f44            # The frame id of Exposure end event
    INT_EVENT_BLOCK_DISCARD = 0x10001f45                    # Block discard event
    INT_EVENT_BLOCK_DISCARD_TIMESTAMP = 0x10001f46          # The timestamp of Block discard event
    INT_EVENT_OVERRUN = 0x10001f47                          # Event queue overflow event
    INT_EVENT_OVERRUN_TIMESTAMP = 0x10001f48                # The timestamp of event queue overflow event
    INT_EVENT_FRAME_START_OVER_TRIGGER = 0x10001f49         # Trigger signal shield event
    INT_EVENT_FRAME_START_OVER_TRIGGER_TIMESTAMP = 0x10001f4a   # The timestamp of trigger signal shield event
    INT_EVENT_BLOCK_NOT_EMPTY = 0x10001f4b                  # Frame memory not empty event
    INT_EVENT_BLOCK_NOT_EMPTY_TIMESTAMP = 0x10001f4c        # The timestamp of frame memory not empty event
    INT_EVENT_INTERNAL_ERROR = 0x10001f4d                   # Internal erroneous event
    INT_EVENT_INTERNAL_ERROR_TIMESTAMP = 0x10001f4e         # The timestamp of internal erroneous event

    # ---------------LUT Section------------------------------------------
    ENUM_LUT_SELECTOR = 0x30002328                          # Select lut, Reference GxLutSelectorEntry
    BUFFER_LUT_VALUE_ALL = 0x60002329                       # Lut data
    BOOL_LUT_ENABLE = 0x4000232a                            # Lut enable bit
    INT_LUT_INDEX = 0x1000232b                              # Lut index
    INT_LUT_VALUE = 0x1000232c                              # Lut value

    # ---------------Color Transformation Control-------------------------
    ENUM_COLOR_TRANSFORMATION_MODE = 0x30002af8             # Color transformation mode
    BOOL_COLOR_TRANSFORMATION_ENABLE = 0x40002af9           # Color transformation enable bit
    ENUM_COLOR_TRANSFORMATION_VALUE_SELECTOR = 0x30002afa   # The selector of color transformation value
    FLOAT_COLOR_TRANSFORMATION_VALUE = 0x20002afb           # The value of color transformation

    # ---------------ChunkData Section------------------------------------
    BOOL_CHUNK_MODE_ACTIVE = 0x40002711                     # Enable frame information
    ENUM_CHUNK_SELECTOR = 0x30002712                        # Select frame information channel, Reference GxChunkSelectorEntry
    BOOL_CHUNK_ENABLE = 0x40002713                          # Enable single frame information channel

    # ---------------CounterAndTimerControl Section-----------------------
    ENUM_TIMER_SELECTOR = 0x30002ee0                        # Selects which Counter to configure, Refer to GxTimerSelectorEntry
    FLOAT_TIMER_DURATION = 0x20002ee1                       # Sets the duration (in microseconds) of the Timer pulse.
    FLOAT_TIMER_DELAY = 0x20002ee2                          # Sets the duration (in microseconds) of the delay to apply at the reception of a trigger before starting the Timer.
    ENUM_TIMER_TRIGGER_SOURCE = 0x30002ee3                  # Selects the source of the trigger to start the Timer, Refer to GxTimerTriggerSourceEntry
    ENUM_COUNTER_SELECTOR = 0x30002ee4                      # Selects which Counter to configure, Refer to GxCounterSelectorEntry
    ENUM_COUNTER_EVENT_SOURCE = 0x30002ee5                  # Select the events that will be the source to increment the Counter, Refer to GxCounterEventSourceEntry
    ENUM_COUNTER_RESET_SOURCE = 0x30002ee6                  # Selects the signals that will be the source to reset the Counter, Refer to GxCounterResetSourceEntry
    ENUM_COUNTER_RESET_ACTIVATION = 0x30002ee7              # Selects the Activation mode of the Counter Reset Source signal, Refer to GxCounterResetActivationEntry
    COMMAND_COUNTER_RESET = 0x70002ee8                      # Does a software reset of the selected Counter and starts it.

    # ---------------Device Feature---------------------------------------
    INT_COMMAND_TIMEOUT = 0x13000000                        # The time of command timeout
    INT_COMMAND_RETRY_COUNT = 0x13000001                    # Command retry times

    # ---------------DataStream Feature-----------------------------------
    INT_ANNOUNCED_BUFFER_COUNT = 0x14000000                 # The number of Buffer declarations
    INT_DELIVERED_FRAME_COUNT = 0x14000001                  # Number of received frames (including remnant frames)
    INT_LOST_FRAME_COUNT = 0x14000002                       # Number of lost frames caused by buffer deficiency
    INT_INCOMPLETE_FRAME_COUNT = 0x14000003                 # Number of residual frames received
    INT_DELIVERED_PACKET_COUNT = 0x14000004                 # The number of packets received
    INT_RESEND_PACKET_COUNT = 0x14000005                    # Number of retransmission packages
    INT_RESCUED_PACKED_COUNT = 0x14000006                   # Retransmission success package number
    INT_RESEND_COMMAND_COUNT = 0x14000007                   # Retransmission command times
    INT_UNEXPECTED_PACKED_COUNT = 0x14000008                # Exception packet number
    INT_MAX_PACKET_COUNT_IN_ONE_BLOCK = 0x14000009          # Data block maximum retransmission number
    INT_MAX_PACKET_COUNT_IN_ONE_COMMAND = 0x1400000a        # The maximum number of packets contained in one command
    INT_RESEND_TIMEOUT = 0x1400000b                         # Retransmission timeout time
    INT_MAX_WAIT_PACKET_COUNT = 0x1400000c                  # Maximum waiting packet number
    ENUM_RESEND_MODE = 0x3400000d                           # Retransmission mode, Reference GxDSResendModeEntry
    INT_MISSING_BLOCK_ID_COUNT = 0x1400000e                 # BlockID lost number
    INT_BLOCK_TIMEOUT = 0x1400000f                          # Data block timeout time
    INT_STREAM_TRANSFER_SIZE = 0x14000010                   # Data block size
    INT_STREAM_TRANSFER_NUMBER_URB = 0x14000011             # Number of data blocks
    INT_MAX_NUM_QUEUE_BUFFER = 0x14000012                   # The maximum Buffer number of the collection queue
    INT_PACKET_TIMEOUT = 0x14000013                         # Packet timeout time

    def __init__(self):
        pass


class GxDeviceIPInfo(Structure):
    _fields_ = [
        ('device_id', c_char * 68),         # The unique identifier of the device.
        ('mac', c_char * 32),               # MAC address
        ('ip', c_char * 32),                # IP address
        ('subnet_mask', c_char * 32),       # Subnet mask
        ('gateway', c_char * 32),           # Gateway
        ('nic_mac', c_char * 32),           # The MAC address of the corresponding NIC(Network Interface Card).
        ('nic_ip', c_char * 32),            # The IP of the corresponding NIC
        ('nic_subnet_mask', c_char * 32),   # The subnet mask of the corresponding NIC
        ('nic_gateWay', c_char * 32),       # The Gateway of the corresponding NIC
        ('nic_description', c_char * 132),  # The description of the corresponding NIC
        ('reserved', c_char * 512),         # Reserved 512 bytes
    ]

    def __str__(self):
        return "GxDeviceIPInfo\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxDeviceBaseInfo(Structure):
    _fields_ = [
        ('vendor_name', c_char*32),         # Vendor name
        ('model_name', c_char*32),          # TModel name
        ('serial_number', c_char*32),       # Serial number
        ('display_name', c_char*132),       # Display name
        ('device_id', c_char*68),           # The unique identifier of the device.
        ('user_id', c_char*68),             # User's custom name
        ('access_status', c_int),           # Access status that is currently supported by the device
                                            # Refer to GxAccessStatus
        ('device_class', c_int),            # Device type. Such as USB2.0, GEV.
        ('reserved', c_char*300),           # Reserved 300 bytes
    ]

    def __str__(self):
        return "GxDeviceBaseInfo\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxOpenParam(Structure):
    _fields_ = [
        ('content',             c_char_p),
        ('open_mode',           c_uint),
        ('access_mode',         c_uint),
    ]

    def __str__(self):
        return "GxOpenParam\n%s" % "\n".join( "%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxFrameCallbackParam(Structure):
    _fields_ = [
        ('user_param_index',    c_void_p),      # User private data
        ('status',              c_int),         # The return state of the image
        ('image_buf',           c_void_p),      # Image buff address
        ('image_size',          c_int),         # Image data size, Including frame information
        ('width',               c_int),         # Image width
        ('height',              c_int),         # Image height
        ('pixel_format',        c_int),         # Image PixFormat
        ('frame_id',            c_ulonglong),   # The frame id of the image
        ('timestamp',           c_ulonglong),   # Time stamp of image
        ('reserved',            c_int),         # Reserved
    ]

    def __str__(self):
        return "GxFrameCallbackParam\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxFrameData(Structure):
    _fields_ = [
        ('status', c_int),                      # The return state of the image
        ('image_buf', c_void_p),                # Image buff address
        ('width', c_int),                       # Image width
        ('height', c_int),                      # Image height
        ('pixel_format', c_int),                # Image PixFormat
        ('image_size', c_int),                  # Image data size, Including frame information
        ('frame_id', c_ulonglong),              # The frame id of the image
        ('timestamp', c_ulonglong),             # Time stamp of image
        ('buf_id', c_ulonglong),                # Image buff ID
        ('reserved',  c_int),                   # Reserved
    ]

    def __str__(self):
        return "GxFrameData\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxIntRange(Structure):
    _fields_ = [
        ('min',                 c_ulonglong),
        ('max',                 c_ulonglong),
        ('inc',                 c_ulonglong),
        ('reserved',            c_int * 8),
    ]

    def __str__(self):
        return "GxIntRange\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxFloatRange(Structure):
    _fields_ = [
        ('min',                 c_double),
        ('max',                 c_double),
        ('inc',                 c_double),
        ('unit',                c_char * 8),
        ('inc_is_valid',        c_bool),
        ('reserved',            c_char * 31),
    ]

    def __str__(self):
        return "GxFloatRange\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxEnumDescription(Structure):
    _fields_ = [
        ('value',               c_longlong),    # Enum value
        ('symbolic',            c_char * 64),   # Character description
        ('reserved',            c_int * 8),
    ]

    def __str__(self):
        return "GxEnumDescription\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


if hasattr(dll, 'GXInitLib'):
    def gx_init_lib():
        """
        :brief      Initialize the device library for some resource application operations
        :return:    None
        """
        return dll.GXInitLib()


if hasattr(dll, 'GXCloseLib'):
    def gx_close_lib():
        """
        :brief      Close the device library to release resources.
        :return:    None
        """
        return dll.GXCloseLib()


if hasattr(dll, 'GXGetLastError'):
    def gx_get_last_error(size=1024):
        """
        :brief      To get the latest error descriptions information of the program
        :param      size:           string buff length(size=1024)
                                    Type: Int, Minnum: 0
        :return:    status:         State return value, See detail in GxStatusList
                    err_code:       Return the last error code
                    err_content:    the latest error descriptions information of the program
        """
        err_code = c_int()
        err_content_buff = create_string_buffer(size)

        content_size = c_size_t()
        content_size.value = size

        status = dll.GXGetLastError(byref(err_code), byref(err_content_buff), byref(content_size))
        err_content = string_at(err_content_buff, content_size.value-1)

        return status, err_code.value, string_decoding(err_content)


if hasattr(dll, 'GXUpdateDeviceList'):
    def gx_update_device_list(time_out=200):
        """
        :brief      Enumerating currently all available devices in subnet and gets the number of devices.
        :param      time_out:           The timeout time of enumeration (unit: ms).
                                        Type: Int, Minimum:0
        :return:    status:             State return value, See detail in GxStatusList
                    device_num:         The number of devices
        """
        time_out_c = c_uint()
        time_out_c.value = time_out

        device_num = c_uint()
        status = dll.GXUpdateDeviceList(byref(device_num), time_out_c)
        return status, device_num.value


if hasattr(dll, 'GXUpdateAllDeviceList'):
    def gx_update_all_device_list(time_out=200):
        """
        :brief      Enumerating currently all available devices in entire network and gets the number of devices
        :param      time_out:           The timeout time of enumeration (unit: ms).
                                        Type: Int, Minimum: 0
        :return:    status:             State return value, See detail in GxStatusList
                    device_num:         The number of devices
        """
        time_out_c = c_uint()
        time_out_c.value = time_out

        device_num = c_uint()
        status = dll.GXUpdateAllDeviceList(byref(device_num), time_out_c)
        return status, device_num.value


if hasattr(dll, 'GXGetAllDeviceBaseInfo'):
    def gx_get_all_device_base_info(devices_num):
        """
        :brief      To get the basic information of all the devices
        :param      devices_num:        The number of devices
                                        Type: Int, Minimum: 0
        :return:    status:             State return value, See detail in GxStatusList
                    device_ip_info:     The structure pointer of the device information(GxDeviceIPInfo)
        """
        devices_info = (GxDeviceBaseInfo * devices_num)()

        buf_size_c = c_size_t()
        buf_size_c.value = sizeof(GxDeviceBaseInfo) * devices_num

        status = dll.GXGetAllDeviceBaseInfo(byref(devices_info), byref(buf_size_c))
        return status, devices_info
        

if hasattr(dll, 'GXGetDeviceIPInfo'):
    def gx_get_device_ip_info(index):
        """
        :brief      To get the network information of the device.
        :param      index:              Device index
                                        Type: Int, Minimum: 1
        :return:    status:             State return value, See detail in GxStatusList
                    device_ip_info:     The structure pointer of the device information(GxDeviceIPInfo)
        """
        index_c = c_uint()
        index_c.value = index

        device_ip_info = GxDeviceIPInfo()
        status = dll.GXGetDeviceIPInfo(index_c, byref(device_ip_info))

        return status, device_ip_info


if hasattr(dll, 'GXOpenDeviceByIndex'):
    def gx_open_device_by_index(index):
        """
        :brief      Open the device by a specific Index(1, 2, 3, ...)
        :param      index:          Device index
                                    Type: Int, Minimum: 1
        :return:    status:         State return value, See detail in GxStatusList
                    handle:         The device handle returned by the interface
        """
        index_c = c_uint()
        index_c.value = index

        handle_c = c_void_p()
        status = dll.GXOpenDeviceByIndex(index_c, byref(handle_c))
        return status, handle_c.value


if hasattr(dll, 'GXOpenDevice'):
    def gx_open_device(open_param):
        """
        :brief      Open the device by a specific unique identification, such as: SN, IP, MAC, Index etc.
        :param      open_param:     The open device parameter which is configurated by the user.
                                    Type: GxOpenParam
        :return:    status:         State return value, See detail in GxStatusList
                    handle:         The device handle returned by the interface
        """
        handle = c_void_p()
        status = dll.GXOpenDevice(byref(open_param), byref(handle))
        return status, handle.value


if hasattr(dll, 'GXCloseDevice'):
    def gx_close_device(handle):
        """
        :brief      Specify the device handle to close the device
        :param      handle:     The device handle that the user specified to close.
                                Type: Long, Greater than 0
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXCloseDevice(handle_c)
        return status

'''
if hasattr(dll, 'GXGetDevicePersistentIpAddress'):
    def gx_get_device_persistent_ip_address(handle, ip_length=16, subnet_mask_length=16, default_gateway_length=16):
        """
        :brief      Get the persistent IP information of the device
        :param      handle:                 The handle of the device
        :param      ip_length:              The character string length of the device persistent IP address.
        :param      subnet_mask_length:     The character string length of the device persistent subnet mask.
        :param      default_gateway_length: The character string length of the device persistent gateway
        :return:    status:                 State return value, See detail in GxStatusList
                    ip:                     The device persistent IP address(str)
                    subnet_mask:            The device persistent subnet mask(str)
                    default_gateway:        The device persistent gateway
        """
        handle_c = c_void_p()
        handle_c.value = handle

        ip_length_c = c_uint()
        ip_length_c.value = ip_length
        ip_c = create_string_buffer(ip_length)

        subnet_mask_length_c = c_uint()
        subnet_mask_length_c.value = subnet_mask_length
        subnet_mask_c = create_string_buffer(subnet_mask_length)

        default_gateway_length_c = c_uint()
        default_gateway_length_c.value = default_gateway_length
        default_gateway_c = create_string_buffer(default_gateway_length)

        status = dll.GXGetDevicePersistentIpAddress(handle_c, byref(ip_c), byref(ip_length_c),
                                                    byref(subnet_mask_c), byref(subnet_mask_length_c),
                                                    byref(default_gateway_c), byref(default_gateway_length_c))

        ip = string_at(ip_c, ip_length_c.value-1)
        subnet_mask = string_at(subnet_mask_c, subnet_mask_length_c.value-1)
        default_gateway = string_at(default_gateway_c, default_gateway_length_c.value-1)

        return status, string_decoding(ip), string_decoding(subnet_mask), string_decoding(default_gateway)

if hasattr(dll, 'GXSetDevicePersistentIpAddress'):
    def gx_set_device_persistent_ip_address(handle, ip, subnet_mask, default_gate_way):
        """
        :brief      Set the persistent IP information of the device
        :param      handle:             The handle of the device
        :param      ip:                 The persistent IP character string of the device(str)
        :param      subnet_mask:        The persistent subnet mask character string of the device(str)
        :param      default_gate_way:   The persistent gateway character string of the device(str)
        :return:    status:             State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        ip_c = create_string_buffer(string_encoding(ip))
        subnet_mask_c = create_string_buffer(string_encoding(subnet_mask))
        default_gate_way_c = create_string_buffer(string_encoding(default_gate_way))

        status = dll.GXSetDevicePersistentIpAddress(handle_c, byref(ip_c), byref(subnet_mask_c),
                                                    byref(default_gate_way_c))
        return status
'''

if hasattr(dll, 'GXGetFeatureName'):
    def gx_get_feature_name(handle, feature_id):
        """
        :brief      Get the string description for the feature code
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: Int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    name:           The string description for the feature code
        """
        handle_c = c_void_p()
        handle_c.value = handle
        feature_id_c = c_int()
        feature_id_c.value = feature_id

        size_c = c_size_t()
        status = dll.GXGetFeatureName(handle_c, feature_id_c, None, byref(size_c))

        name_buff = create_string_buffer(size_c.value)
        status = dll.GXGetFeatureName(handle_c, feature_id_c, byref(name_buff), byref(size_c))

        name = string_at(name_buff, size_c.value-1)
        return status, string_decoding(name)


if hasattr(dll, 'GXIsImplemented'):
    def gx_is_implemented(handle, feature_id):
        """
        :brief      Inquire the current camera whether support a special feature.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    is_implemented: To return the result whether is support this feature
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        is_implemented = c_bool()
        status = dll.GXIsImplemented(handle_c, feature_id_c, byref(is_implemented))
        return status, is_implemented.value


if hasattr(dll, 'GXIsReadable'):
    def gx_is_readable(handle, feature_id):
        """
        :brief      Inquire if a feature code is currently readable
        :param      handle:             The handle of the device
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    is_readable:        To return the result whether the feature code ID is readable
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        is_readable = c_bool()
        status = dll.GXIsReadable(handle_c, feature_id_c, byref(is_readable))
        return status, is_readable.value


if hasattr(dll, 'GXIsWritable'):
    def gx_is_writable(handle, feature_id):
        """
        :brief      Inquire if a feature code is currently writable
        :param      handle:             The handle of the device.
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    is_writeable:       To return the result whether the feature code ID is writable(Bool)
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        is_writeable = c_bool()
        status = dll.GXIsWritable(handle_c, feature_id_c, byref(is_writeable))
        return status, is_writeable.value


if hasattr(dll, 'GXGetIntRange'):
    def gx_get_int_range(handle, feature_id):
        """
        :brief      To get the minimum value, maximum value and steps of the int type
        :param      handle:         The handle of the device.
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    int_range:      The structure of range description(GxIntRange)
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        int_range = GxIntRange()
        status = dll.GXGetIntRange(handle_c, feature_id_c, byref(int_range))
        return status, int_range


if hasattr(dll, 'GXGetInt'):
    def gx_get_int(handle, feature_id):
        """
        :brief      Get the current value of the int type.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    int_value:      Get the current value of the int type
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        int_value = c_int64()
        status = dll.GXGetInt(handle_c, feature_id_c, byref(int_value))
        return status, int_value.value


if hasattr(dll, 'GXSetInt'):
    def gx_set_int(handle, feature_id, int_value):
        """
        :brief      Set the value of int type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID.
                                    Type: int, Greater than 0
        :param      int_value:      The value that the user will set
                                    Type: long, minnum:0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        value_c = c_int64()
        value_c.value = int_value

        status = dll.GXSetInt(handle_c, feature_id_c, value_c)
        return status


if hasattr(dll, 'GXGetFloatRange'):
    def gx_get_float_range(handle, feature_id):
        """
        :brief      To get the minimum value, maximum value, stepsand unit of the float type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    float_range:    The description structure(GxFloatRange)
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        float_range = GxFloatRange()
        status = dll.GXGetFloatRange(handle_c, feature_id_c, byref(float_range))
        return status, float_range


if hasattr(dll, 'GXSetFloat'):
    def gx_set_float(handle, feature_id, float_value):
        """
        :brief      Set the value of float type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :param      float_value:    The float value that the user will set
                                    Type: double
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        value_c = c_double()
        value_c.value = float_value

        status = dll.GXSetFloat(handle_c, feature_id_c, value_c)
        return status


if hasattr(dll, 'GXGetFloat'):
    def gx_get_float(handle, feature_id):
        """
        :brief      Get the value of float type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        float_value = c_double()
        status = dll.GXGetFloat(handle_c, feature_id_c, byref(float_value))

        return status, float_value.value


if hasattr(dll, 'GXGetEnumEntryNums'):
    def gx_get_enum_entry_nums(handle, feature_id):
        """
        :brief      Get the number of the options for the enumeration item
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    enum_num:       The number of the options for the enumeration item
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        enum_nums = c_uint()
        status = dll.GXGetEnumEntryNums(handle_c, feature_id_c, byref(enum_nums))
        return status, enum_nums.value


if hasattr(dll, 'GXGetEnumDescription'):
    def gx_get_enum_description(handle, feature_id, enum_num):
        """
        :brief      To get the description information of the enumerated type values
                    the number of enumerated items and the value and descriptions of each item
                    please reference GxEnumDescription.
        :param      handle:             The handle of the device
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :param      enum_num:           The number of enumerated information
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    enum_description:   Enumerated information array(GxEnumDescription)
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        buf_size_c = c_size_t()
        buf_size_c.value = sizeof(GxEnumDescription) * enum_num

        enum_description = (GxEnumDescription * enum_num)()
        status = dll.GXGetEnumDescription(handle_c, feature_id_c, byref(enum_description), byref(buf_size_c))
        return status, enum_description


if hasattr(dll, 'GXGetEnum'):
    def gx_get_enum(handle, feature_id):
        """
        :brief      To get the current enumeration value
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    enum_value:     Get the current enumeration value
        """
        handle_c = c_void_p()
        handle_c.value = handle
        feature_id_c = c_int()
        feature_id_c.value = feature_id

        enum_value = c_int64()
        status = dll.GXGetEnum(handle_c, feature_id_c, byref(enum_value))

        return status, enum_value.value


if hasattr(dll, 'GXSetEnum'):
    def gx_set_enum(handle, feature_id, enum_value):
        """
        :brief      Set the enumeration value
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :param      enum_value:     Set the enumeration value
                                    Type: int
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        value_c = c_int64()
        value_c.value = enum_value

        status = dll.GXSetEnum(handle_c, feature_id_c, value_c)
        return status


if hasattr(dll, 'GXGetBool'):
    def gx_get_bool(handle, feature_id):
        """
        :brief      Get the value of bool type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    boot_value:     the value of bool type
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        boot_value = c_bool()
        status = dll.GXGetBool(handle_c, feature_id_c, byref(boot_value))
        return status, boot_value.value


if hasattr(dll, 'GXSetBool'):
    def gx_set_bool(handle, feature_id, bool_value):
        """
        :brief      Set the value of bool type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :param      bool_value:     The bool value that the user will set
                                    Type: Bool
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        value_c = c_bool()
        value_c.value = bool_value

        status = dll.GXSetBool(handle_c, feature_id_c, value_c)
        return status


if hasattr(dll, 'GXGetStringLength'):
    def gx_get_string_length(handle, feature_id):
        """
        :brief      Get the current value length of the character string type. Unit: byte
        :param      handle:             The handle of the device
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    string_length:      the current value length of the character string type
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        string_length = c_size_t()
        status = dll.GXGetStringLength(handle_c, feature_id_c, byref(string_length))

        return status, string_length.value - 1


if hasattr(dll, 'GXGetStringMaxLength'):
    def gx_get_string_max_length(handle, feature_id):
        """
        :brief      Get the maximum length of the string type value,  Unit: byte
        :param      handle:             The handle of the device
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    string_max_length:  the maximum length of the string type value
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        string_max_length = c_size_t()
        status = dll.GXGetStringMaxLength(handle_c, feature_id, byref(string_max_length))

        return status, string_max_length.value - 1


if hasattr(dll, 'GXGetString'):
    def gx_get_string(handle, feature_id):
        """
        :brief      Get the content of the string type value
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        size_c = c_size_t()
        status = dll.GXGetString(handle_c, feature_id_c, None, byref(size_c))

        content_c = create_string_buffer(size_c.value)
        status = dll.GXGetString(handle_c, feature_id_c, byref(content_c), byref(size_c))

        content = string_at(content_c, size_c.value-1)
        return status, string_decoding(content)


if hasattr(dll, 'GXSetString'):
    def gx_set_string(handle, feature_id, content):
        """
        :brief      Set the content of the string value
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :param      content:        The string will be setting(str)
                                    Type: str
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        content_c = create_string_buffer(string_encoding(content))

        status = dll.GXSetString(handle_c, feature_id_c, byref(content_c))
        return status


if hasattr(dll, 'GXGetBufferLength'):
    def gx_get_buffer_length(handle, feature_id):
        """
        :brief      Get the length of the chunk data and the unit is byte,
                    the user can apply the buffer based on the length obtained,
                    and then call the gx_get_buffer to get the chunk data.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    buff_length:    Buff length, Unit: byte
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        buff_length = c_size_t()
        status = dll.GXGetBufferLength(handle_c, feature_id_c, byref(buff_length))
        return status, buff_length.value


if hasattr(dll, 'GXGetBuffer'):
    def gx_get_buffer(handle, feature_id):
        """
        :brief      Get the chunk data
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    buff:           chunk data
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        buff_length_c = c_size_t()
        status = dll.GXGetBuffer(handle_c, feature_id_c, None, byref(buff_length_c))

        buff_c = (c_ubyte * buff_length_c.value)()
        status = dll.GXGetBuffer(handle_c, feature_id_c, byref(buff_c), byref(buff_length_c))
        return status, buff_c


if hasattr(dll, 'GXSetBuffer'):
    def gx_set_buffer(handle, feature_id, buff, buff_size):
        """
        :brief      Set the chunk data
        :param      handle:         The handle of the device
        :param      feature_id:     The feature code ID
                                    Type: long, Greater than 0
        :param      buff:           chunk data buff
                                    Type: Ctype array
        :param      buff_size:      chunk data buff size
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """

        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        buff_size_c = c_size_t()
        buff_size_c.value = buff_size

        status = dll.GXSetBuffer(handle_c, feature_id_c, buff, buff_size_c)
        return status


if hasattr(dll, 'GXSendCommand'):
    def gx_send_command(handle, feature_id):
        """
        :brief      Send the command
        :param      handle:         The handle of the device
                                    Type: long, Greater than 0
        :param      feature_id:     The feature code ID.
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        status = dll.GXSendCommand(handle_c, feature_id_c)
        return status

'''
CAP_CALL = CFUNCTYPE(None, POINTER(GxFrameCallbackParam))
if hasattr(dll, 'GXRegisterCaptureCallback'):
    def gx_register_capture_callback(handle, cap_call):
        """
        :brief      Register the capture callback function
        :param      handle:         The handle of the device
        :param      cap_call:       The callback function that the user will register(@ CAP_CALL)
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXRegisterCaptureCallback(handle_c, None, cap_call)
        return status


if hasattr(dll, 'GXUnregisterCaptureCallback'):
    def gx_unregister_capture_callback(handle):
        """
        :brief      Unregister the capture callback function
        :param      handle:         The handle of the device
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXUnregisterCaptureCallback(handle_c)
        return status
'''

if hasattr(dll, 'GXGetImage'):
    def gx_get_image(handle, frame_data, time_out=200):
        """
        :brief      After starting acquisition, you can call this function to get images directly.
                    Noting that the interface can not be mixed with the callback capture mode.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      frame_data:     [out]User introduced to receive the image data
                                    Type: GxFrameData
        :param      time_out:       The timeout time of capture image.(unit: ms)
                                    Type: int, minnum: 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        time_out_c = c_uint()
        time_out_c.value = time_out

        status = dll.GXGetImage(handle_c, byref(frame_data), time_out_c)
        return status


if hasattr(dll, 'GXFlushQueue'):
    def gx_flush_queue(handle):
        """
        :brief      Empty the cache image in the image output queue.
        :param      handle:     The handle of the device
                                Type: Long, Greater than 0
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXFlushQueue(handle_c)
        return status


'''
OFF_LINE_CALL = CFUNCTYPE(None, c_void_p)
if hasattr(dll, 'GXRegisterDeviceOfflineCallback'):
    def gx_register_device_offline_callback(handle, call_back):
        """
        :brief      At present, the mercury GIGE camera provides the device offline notification event mechanism,
                    the user can call this interface to register the event handle callback function
        :param      handle:             The handle of the device
        :param      call_back:          The user event handle callback function(@ OFF_LINE_CALL)
        :return:    status:             State return value, See detail in GxStatusList
                    call_back_handle:   The handle of offline callback function
                                        the handle is used for unregistering the callback function
        """
        handle_c = c_void_p()
        handle_c.value = handle

        call_back_handle = c_void_p()

        status = dll.GXRegisterDeviceOfflineCallback(handle_c, None, call_back, byref(call_back_handle))
        return status, call_back_handle.value


if hasattr(dll, 'GXUnregisterDeviceOfflineCallback'):
    def gx_unregister_device_offline_callback(handle, call_back_handle):
        """
        :brief      Unregister event handle callback function
        :param      handle:             The handle of the device
        :param      call_back_handle:   The handle of device offline callback function
        :return:    status:             State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        call_back_handle_c = c_void_p()
        call_back_handle_c.value = call_back_handle

        status = dll.GXUnregisterDeviceOfflineCallback(handle, call_back_handle_c)
        return status


if hasattr(dll, 'GXFlushEvent'):
    def gx_flush_event(handle):
        """
        :brief      Empty the device event, such as the frame exposure to end the event data queue
        :param      handle:    The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXFlushEvent(handle_c)
        return status


if hasattr(dll, 'GXGetEventNumInQueue'):
    def gx_get_event_num_in_queue(handle):
        """
        :brief      Get the number of the events in the current remote device event queue cache.
        :param      handle:     The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
                    event_num:  event number.
        """
        handle_c = c_void_p()
        handle_c.value = handle

        event_num = c_uint()

        status = dll.GXGetEventNumInQueue(handle_c, byref(event_num))
        return status, event_num.value


FEATURE_CALL = CFUNCTYPE(None, c_uint, c_void_p)
if hasattr(dll, 'GXRegisterFeatureCallback'):
    def gx_register_feature_callback(handle, call_back, feature_id):
        """
        :brief      Register device attribute update callback function.
                    When the current value of the device property has updated, or the accessible property is changed,
                    call this callback function.
        :param      handle:             The handle of the device
        :param      call_back:          The user event handle callback function(@ FEATURE_CALL)
        :param      feature_id:         The feature code ID
        :return:    status:             State return value, See detail in GxStatusList
                    call_back_handle:   The handle of property update callback function,
                                        to unregister the callback function.
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        call_back_handle = c_void_p()
        status = dll.GXRegisterFeatureCallback(handle_c, None, call_back, feature_id_c, byref(call_back_handle))

        return status, call_back_handle.value


if hasattr(dll, 'GXUnregisterFeatureCallback'):
    """
    """
    def gx_unregister_feature_callback(handle, feature_id, call_back_handle):
        """
        :brief      Unregister device attribute update callback function
        :param      handle:             The handle of the device
        :param      feature_id:         The feature code ID
        :param      call_back_handle:   Handle of property update callback function
        :return:    status:             State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        call_back_handle_c = c_void_p()
        call_back_handle_c.value = call_back_handle

        status = dll.GXUnregisterFeatureCallback(handle_c, feature_id_c, call_back_handle_c)
        return status
'''

if hasattr(dll, 'GXExportConfigFile'):
    def gx_export_config_file(handle, file_path):
        """
        :brief      Export the current parameter of the camera to the configuration file.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      file_path:      The path of the configuration file that to be generated
                                    Type: str
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        file_path_c = create_string_buffer(string_encoding(file_path))
        status = dll.GXExportConfigFile(handle_c, byref(file_path_c))

        return status


if hasattr(dll, 'GXImportConfigFile'):
    def gx_import_config_file(handle, file_path, verify):
        """
        :brief      Import the configuration file for the camera
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      file_path:      The path of the configuration file(str)
                                    Type: str
        :param      verify:         If this value is true, all imported values will be read out
                                    to check whether they are consistent.
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        verify_c = c_bool()
        verify_c.value = verify

        file_path_c = create_string_buffer(string_encoding(file_path))
        status = dll.GXImportConfigFile(handle_c, byref(file_path_c), verify_c)
        return status

'''
if hasattr(dll, 'GXReadRemoteDevicePort'):
    def gx_read_remote_device_port(handle, address, buff, size):
        """
        :brief      Read data for user specified register.
        :param      handle:     The handle of the device
        :param      address:    Register address
        :param      buff:       Output data buff
        :param      size:       Buff size
        :return:    status:     State return value, See detail in GxStatusList
                    size:       Returns the length of the actual read register
        """
        handle_c = c_void_p()
        handle_c.value = handle

        address_c = c_ulonglong()
        address_c.value = address

        size_c = c_uint()
        size_c.value = size

        status = dll.GXReadRemoteDevicePort(handle_c, address_c, byref(buff), byref(size_c))
        return status, size_c.value


if hasattr(dll, 'GXWriteRemoteDevicePort'):
    def gx_write_remote_device_port(handle, address, buff, size):
        """
        :brief      Writes user specified data to a user specified register.
        :param      handle:     The handle of the device
        :param      address:    Register address
        :param      buff:       User data
        :param      size:       User data size
        :return:    status:     State return value, See detail in GxStatusList
                    size:       Returns the length of the actual write register
        """
        handle_c = c_void_p()
        handle_c.value = handle

        address_c = c_ulonglong()
        address_c.value = address

        size_c = c_uint()
        size_c.value = size

        status = dll.GXWriteRemoteDevicePort(handle_c, address_c, byref(buff), byref(size_c))
        return status, size_c.value


if hasattr(dll, 'GXGigEIpConfiguration'):
    def gx_gige_ip_configuration(mac_address, ipconfig_flag, ip_address, subnet_mask, default_gateway, user_id):
        """
        "brief      Configure the static IP address of the camera
        :param      mac_address:        The MAC address of the device(str)
        :param      ipconfig_flag:      IP Configuration mode(GxIPConfigureModeList)
        :param      ip_address:         The IP address to be set(str)
        :param      subnet_mask:        The subnet mask to be set(str)
        :param      default_gateway:    The default gateway to be set(str)
        :param      user_id:            The user-defined name to be set(str)
        :return:    status:             State return value, See detail in GxStatusList
        """
        mac_address_c = create_string_buffer(string_encoding(mac_address))
        ip_address_c = create_string_buffer(string_encoding(ip_address))
        subnet_mask_c = create_string_buffer(string_encoding(subnet_mask))
        default_gateway_c = create_string_buffer(string_encoding(default_gateway))
        user_id_c = create_string_buffer(string_encoding(user_id))

        status = dll.GXGigEIpConfiguration(mac_address_c, ipconfig_flag,
                                           ip_address_c, subnet_mask_c,
                                           default_gateway_c, user_id_c)
        return status


if hasattr(dll, 'GXGigEForceIp'):
    def gx_gige_force_ip(mac_address, ip_address, subnet_mask, default_gate_way):
        """
        :brief      Execute the Force IP
        :param      mac_address:        The MAC address of the device(str)
        :param      ip_address:         The IP address to be set(str)
        :param      subnet_mask:        The subnet mask to be set(str)
        :param      default_gate_way:   The default gateway to be set(str)
        :return:    status:             State return value, See detail in GxStatusList
        """
        mac_address_c = create_string_buffer(string_encoding(mac_address))
        ip_address_c = create_string_buffer(string_encoding(ip_address))
        subnet_mask_c = create_string_buffer(string_encoding(subnet_mask))
        default_gate_way_c = create_string_buffer(string_encoding(default_gate_way))

        status = dll.GXGigEForceIp(mac_address_c, ip_address_c, subnet_mask_c, default_gate_way_c)
        return status
'''

if hasattr(dll, 'GXSetAcqusitionBufferNumber'):
    def gx_set_acquisition_buffer_number(handle, buffer_num):
        """
        :brief      Users Set Acquisition buffer Number
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      buffer_num:     Acquisition buffer Number
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        buffer_num_c = c_uint64()
        buffer_num_c.value = buffer_num

        status = dll.GXSetAcqusitionBufferNumber(handle_c, buffer_num_c)
        return status

'''
if hasattr(dll, 'GXStreamOn'):
    def gx_stream_on(handle):
        """
        :brief      Start acquisition
        :param      handle:     The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXStreamOn(handle_c)
        return status


if hasattr(dll, 'GXDQBuf'):
    def gx_dequeue_buf(handle, time_out):
        """
        :brief      Get a image
                    After the image processing is completed, the gx_queue_buf interface needs to be called
                    otherwise the collection will not be able to continue.
        :param      handle:             The handle of the device
        :param      time_out:           The timeout time of capture image.(unit: ms)
        :return:    status:             State return value, See detail in GxStatusList
                    frame_data:         Image data
                    frame_data_p:       Image buff address
        """
        handle_c = c_void_p()
        handle_c.value = handle

        time_out_c = c_uint()
        time_out_c.value = time_out

        frame_data_p = c_void_p()
        status = dll.GXDQBuf(handle_c, byref(frame_data_p), time_out_c)

        frame_data = GxFrameData()
        memmove(addressof(frame_data), frame_data_p.value, sizeof(frame_data))
        return status, frame_data, frame_data_p.value


if hasattr(dll, 'GXQBuf'):
    def gx_queue_buf(handle, frame_data_p):
        """
        :brief      Put an image Buff back to the GxIAPI library and continue to be used for collection.
        :param      handle:         The handle of the device
        :param      frame_data_p:   Image buff address
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        frame_data_p_p = c_void_p()
        frame_data_p_p.value = frame_data_p

        status = dll.GXQBuf(handle_c, frame_data_p_p)
        return status
        

if hasattr(dll, 'GXDQAllBufs'):
    def gx_dequeue_all_bufs(handle, buff_num, time_out):
        """
        :brief      Get images
                    After the image processing is completed, the gx_queue_all_bufs interface needs to be called
                    otherwise the collection will not be able to continue.
        :param      handle:         The handle of the device
        :param      buff_num:       The number of images expected to be obtained
        :param      time_out:       The timeout time of capture image.(unit: ms)
        :return:    status:         State return value, See detail in GxStatusList
                    frame_data:     Image data arrays
                    frame_count:    The number of images that are actually returned
        """
        handle_c = c_void_p()
        handle_c.value = handle

        time_out_c = c_uint()
        time_out_c.value = time_out

        frame_data_p = (c_void_p * buff_num)()
        frame_count_c = c_uint()

        status = dll.GXDQAllBufs(handle_c, frame_data_p, buff_num, byref(frame_count_c), time_out_c)
        frame_data = (GxFrameData * buff_num)()

        for i in range(buff_num):
            memmove(addressof(frame_data[i]), frame_data_p[i], sizeof(GxFrameData))

        return status, frame_data, frame_count_c.value


if hasattr(dll, 'GXQAllBufs'):
    def gx_queue_all_bufs(handle):
        """
        :brief      The image data Buf is returned to the GxIAPI library and used for collection.
        :param      handle:     The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXQAllBufs(handle_c)
        return status


if hasattr(dll, 'GXStreamOff'):
    def gx_stream_off(handle):
        """
        :brief      Stop acquisition
        :param      handle:     The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXStreamOff(handle_c)
        return status
'''


def string_encoding(string):
    """
    :breif      Python3.X: String encoded as bytes
    :param      string
    :return:
    """
    if sys.version_info.major == 3:
        string = string.encode()
    return string


def string_decoding(string):
    """
    :brief      Python3.X: bytes decoded as string
    :param      string
    :return:
    """
    if sys.version_info.major == 3:
        string = string.decode()
    return string


def range_check(value, min_value, max_value, inc_value=0):
    """
    :brief      Determine if the input parameter is within range
    :param      value:       input value
    :param      min_value:   max value
    :param      max_value:   min value
    :param      inc_value:   step size, default=0
    :return:    True/False
    """
    if value < min_value:
        return False
    elif value > max_value:
        return False
    elif (inc_value != 0) and (value != int(value / inc_value) * inc_value):
        return False
    return True

﻿#!/usr/bin/python
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-
# -*- coding:utf-8 -*-

from ctypes import *
import sys


if sys.platform == 'linux2' or sys.platform == 'linux':
    try:
        dll = CDLL('/usr/lib/libgxiapi.so')
    except OSError:
        print("Cannot find libgxiapi.so.")
else:
    try:
        dll = WinDLL('GxIAPI.dll')
    except OSError:
        print('Cannot find GxIAPI.dll.')


# Error code
class GxStatusList:
    SUCCESS = 0	                # Success
    ERROR = -1                  # There is a unspecified internal error that is not expected to occur
    NOT_FOUND_TL = -2           # The TL library cannot be found
    NOT_FOUND_DEVICE = -3       # The device is not found
    OFFLINE = -4                # The current device is in a offline state
    INVALID_PARAMETER = -5      # Invalid parameter, Generally the pointer is NULL or the input IP and
                                # Other parameter formats are invalid
    INVALID_HANDLE = -6         # Invalid handle
    INVALID_CALL = -7           # The interface is invalid, which refers to software interface logic error
    INVALID_ACCESS = -8         # The function is currently inaccessible or the device access mode is incorrect
    NEED_MORE_BUFFER = -9       # The user request buffer is insufficient: the user input buffersize during
                                # the read operation is less than the actual need
    ERROR_TYPE = -10            # The type of FeatureID used by the user is incorrect,
                                # such as an integer interface using a floating-point function code
    OUT_OF_RANGE = -11          # The value written by the user is crossed
    NOT_IMPLEMENTED = -12       # This function is not currently supported
    NOT_INIT_API = -13          # There is no call to initialize the interface
    TIMEOUT = -14               # Timeout error
    REPEAT_OPENED = -1004       # The device has been opened

    def __init__(self):
        pass


class GxOpenMode:
    SN = 0	                   # Opens the device via a serial number
    IP = 1                     # Opens the device via an IP address
    MAC = 2                    # Opens the device via a MAC address
    INDEX = 3                  # Opens the device via a serial number(Start from 1)
    USER_ID = 4                # Opens the device via user defined ID

    def __init__(self):
        pass


class GxFrameMask:
    TYPE_MASK = 0xF0000000
    LEVEL_MASK = 0x0F000000
    
    def __init__(self):
        pass
    

class GxFeatureType:
    INT = 0x10000000            # Integer type
    FLOAT = 0X20000000          # Floating point type
    ENUM = 0x30000000           # Enum type
    BOOL = 0x40000000           # Boolean type
    STRING = 0x50000000         # String type
    BUFFER = 0x60000000         # Block data type
    COMMAND = 0x70000000        # Command type

    def __init__(self):
        pass


class GxFeatureLevel:
    REMOTE_DEV = 0x00000000     # RemoteDevice Layer
    TL = 0x01000000             # TL Layer
    IF = 0x02000000             # Interface Layer
    DEV = 0x03000000            # Device Layer
    DS = 0x04000000             # DataStream Layer

    def __init__(self):
        pass


class GxFeatureID:
    # ---------------Device Information Section---------------------------
    STRING_DEVICE_VENDOR_NAME = 0x50000000                 # The name of the device's vendor
    STRING_DEVICE_MODEL_NAME = 0x50000001                  # The model name of the device
    STRING_DEVICE_FIRMWARE_VERSION = 0x50000002            # The version of the device's firmware and software
    STRING_DEVICE_VERSION = 0x50000003                     # The version of the device
    STRING_DEVICE_SERIAL_NUMBER = 0x50000004               # A serial number for device
    STRING_FACTORY_SETTING_VERSION = 0x50000006            # The version of the device's Factory Setting
    STRING_DEVICE_USER_ID = 0x50000007                     # A user programmable string
    INT_DEVICE_LINK_SELECTOR = 0x10000008                  # Selects which Link of the device to control
    ENUM_DEVICE_LINK_THROUGHPUT_LIMIT_MODE = 0x30000009    # DeviceLinkThroughputLimit switch
    INT_DEVICE_LINK_THROUGHPUT_LIMIT = 0x1000000a          # Limits the maximum bandwidth of the data
    INT_DEVICE_LINK_CURRENT_THROUGHPUT = 0x1000000b        # Current bandwidth of the data
    COMMAND_DEVICE_RESET = 0x7000000c                      # Device reset
    INT_TIMESTAMP_TICK_FREQUENCY = 0x1000000d              # Timestamp tick frequency
    COMMAND_TIMESTAMP_LATCH = 0x7000000e                   # Timestamp latch
    COMMAND_TIMESTAMP_RESET = 0x7000000f                   # Timestamp reset
    COMMAND_TIMESTAMP_LATCH_RESET = 0x70000010             # Timestamp latch reset
    INT_TIMESTAMP_LATCH_VALUE = 0x10000011                 # The value of timestamp latch

    # ---------------ImageFormat Section----------------------------------
    INT_SENSOR_WIDTH = 0x100003e8                           # The actual width of the camera's sensor in pixels
    INT_SENSOR_HEIGHT = 0x100003e9                          # The actual height of the camera's sensor in pixels
    INT_WIDTH_MAX = 0x100003ea                              # Width max[read_only]
    INT_HEIGHT_MAX = 0x100003eb                             # Height max[read_only]
    INT_OFFSET_X = 0x100003ec                               # The X offset for the area of interest
    INT_OFFSET_Y = 0x100003ed                               # The Y offset for the area of interest
    INT_WIDTH = 0x100003ee                                  # the width of the area of interest in pixels
    INT_HEIGHT = 0x100003ef                                 # the height of the area of interest in pixels
    INT_BINNING_HORIZONTAL = 0x100003f0                     # Horizontal pixel Binning
    INT_BINNING_VERTICAL = 0x100003f1                       # Vertical pixel Binning
    INT_DECIMATION_HORIZONTAL = 0x100003f2                  # Horizontal pixel sampling
    INT_DECIMATION_VERTICAL = 0x100003f3                    # Vertical pixel sampling
    ENUM_PIXEL_SIZE = 0x300003f4                            # Pixel depth, Reference GxPixelSizeEntry
    ENUM_PIXEL_COLOR_FILTER = 0x300003f5                    # Bayer format, Reference GxPixelColorFilterEntry
    ENUM_PIXEL_FORMAT = 0x300003f6                          # Pixel format, Reference GxPixelFormatEntry
    BOOL_REVERSE_X = 0x400003f7                             # Horizontal flipping
    BOOL_REVERSE_Y = 0x400003f8                             # Vertical flipping
    ENUM_TEST_PATTERN = 0x300003f9                          # Test pattern, Reference GxTestPatternEntry
    ENUM_TEST_PATTERN_GENERATOR_SELECTOR = 0x300003fa       # The source of test pattern, reference GxTestPatternGeneratorSelectorEntry
    ENUM_REGION_SEND_MODE = 0x300003fb                      # ROI region output mode, reference GxRegionSendModeEntry
    ENUM_REGION_MODE = 0x300003fc                           # ROI region output switch
    ENUM_REGION_SELECTOR = 0x300003fd                       # ROI region select, reference GxRegionSelectorEntry
    INT_CENTER_WIDTH = 0x100003fe                           # Window width
    INT_CENTER_HEIGHT = 0x100003ff                          # Window height
    ENUM_BINNING_HORIZONTAL_MODE = 0x30000400               # Binning horizontal mode
    ENUM_BINNING_VERTICAL_MODE = 0x30000401                 # Binning vertical mode

    # ---------------TransportLayer Section-------------------------------
    INT_PAYLOAD_SIZE = 0x100007d0                           # Size of images in byte
    BOOL_GEV_CURRENT_IP_CONFIGURATION_LLA = 0x400007d1      # IP configuration by LLA.
    BOOL_GEV_CURRENT_IP_CONFIGURATION_DHCP = 0x400007d2     # IP configuration by DHCP
    BOOL_GEV_CURRENT_IP_CONFIGURATION_PERSISTENT_IP = 0x400007d3   # IP configuration by PersistentIP
    INT_ESTIMATED_BANDWIDTH = 0x100007d4                    # Estimated Bandwidth in Bps
    INT_GEV_HEARTBEAT_TIMEOUT = 0x100007d5                  # The heartbeat timeout in milliseconds
    INT_GEV_PACKET_SIZE = 0x100007d6                        # The packet size in bytes for each packet
    INT_GEV_PACKET_DELAY = 0x100007d7                       # A delay between the transmission of each packet
    INT_GEV_LINK_SPEED = 0x100007d8                         # The connection speed in Mbps

    # ---------------AcquisitionTrigger Section---------------------------
    ENUM_ACQUISITION_MODE = 0x30000bb8                      # The mode of acquisition, Reference: GxAcquisitionModeEntry
    COMMAND_ACQUISITION_START = 0x70000bb9                  # The command for starts the acquisition of images
    COMMAND_ACQUISITION_STOP = 0x70000bba                   # The command for stop the acquisition of images
    INT_ACQUISITION_SPEED_LEVEL = 0x10000bbb                # The level for acquisition speed
    INT_ACQUISITION_FRAME_COUNT = 0x10000bbc
    ENUM_TRIGGER_MODE = 0x30000bbd                          # Trigger mode, Reference:GxTriggerModeEntry
    COMMAND_TRIGGER_SOFTWARE = 0x70000bbe                   # The command for generates a software trigger signal
    ENUM_TRIGGER_ACTIVATION = 0x30000bbf                    # Trigger polarity, Reference GxTriggerActivationEntry
    ENUM_TRIGGER_SWITCH = 0x30000bc0                        # The switch of External trigger
    FLOAT_EXPOSURE_TIME = 0x20000bc1                        # Exposure time
    ENUM_EXPOSURE_AUTO = 0x30000bc2                         # Exposure auto
    FLOAT_TRIGGER_FILTER_RAISING = 0x20000bc3               # The Value of rising edge triggered filter
    FLOAT_TRIGGER_FILTER_FALLING = 0x20000bc4               # The Value of falling edge triggered filter
    ENUM_TRIGGER_SOURCE = 0x30000bc5                        # Trigger source, Reference GxTriggerSourceEntry
    ENUM_EXPOSURE_MODE = 0x30000bc6                         # Exposure mode, Reference GxExposureModeEntry
    ENUM_TRIGGER_SELECTOR = 0x30000bc7                      # Trigger type, Reference GxTriggerSelectorEntry
    FLOAT_TRIGGER_DELAY = 0x20000bc8                        # The trigger delay in microsecond
    ENUM_TRANSFER_CONTROL_MODE = 0x30000bc9                 # The control method for the transfers, Reference GxTransferControlModeEntry
    ENUM_TRANSFER_OPERATION_MODE = 0x30000bca               # The operation method for the transfers, Reference GxTransferOperationModeEntry
    COMMAND_TRANSFER_START = 0x70000bcb                     # Starts the streaming of data blocks out of the device
    INT_TRANSFER_BLOCK_COUNT = 0x10000bcc                   # The number of data Blocks that the device should stream before stopping
    BOOL_FRAME_STORE_COVER_ACTIVE = 0x40000bcd              # The switch for frame cover
    ENUM_ACQUISITION_FRAME_RATE_MODE = 0x30000bce           # The switch for Control frame rate
    FLOAT_ACQUISITION_FRAME_RATE = 0x20000bcf               # The value for Control frame rate
    FLOAT_CURRENT_ACQUISITION_FRAME_RATE = 0x20000bd0       # The maximum allowed frame acquisition rate
    ENUM_FIXED_PATTERN_NOISE_CORRECT_MODE = 0x30000bd1      # The switch of fixed pattern noise correct
    INT_ACQUISITION_BURST_FRAME_COUNT = 0x10000bd6          # The acquisition burst frame count
    ENUM_ACQUISITION_STATUS_SELECTOR = 0x30000bd7           # The selector of acquisition status
    BOOL_ACQUISITION_STATUS = 0x40000bd8                    # The acquisition status
    FLOAT_EXPOSURE_DELAY = 0x2000765c                       # The exposure delay

    # ----------------DigitalIO Section-----------------------------------
    ENUM_USER_OUTPUT_SELECTOR = 0x30000fa0                  # selects user settable output signal, Reference GxUserOutputSelectorEntry
    BOOL_USER_OUTPUT_VALUE = 0x40000fa1                     # The state of the output signal
    ENUM_USER_OUTPUT_MODE = 0x30000fa2                      # UserIO output mode, Reference GxUserOutputModeEntry
    ENUM_STROBE_SWITCH = 0x30000fa3                         # Strobe switch
    ENUM_LINE_SELECTOR = 0x30000fa4                         # Line selector, Reference GxLineSelectorEntry
    ENUM_LINE_MODE = 0x30000fa5                             # Line mode, Reference GxLineModeEntry
    BOOL_LINE_INVERTER = 0x40000fa6                         # Pin level reversal
    ENUM_LINE_SOURCE = 0x30000fa7                           # line source, Reference GxLineSourceEntry
    BOOL_LINE_STATUS = 0x40000fa8                           # line status
    INT_LINE_STATUS_ALL = 0x10000fa9                        # all line status
    FLOAT_PULSE_WIDTH = 0x20000faa                          #

    # ----------------AnalogControls Section------------------------------
    ENUM_GAIN_AUTO = 0x30001388                             # gain auto, Reference GxGainAutoEntry
    ENUM_GAIN_SELECTOR = 0x30001389                         # selects gain channel, Reference GxGainSelectorEntry
    ENUM_BLACK_LEVEL_AUTO = 0x3000138b                      # Black level auto, Reference GxBlackLevelAutoEntry
    ENUM_BLACK_LEVEL_SELECTOR = 0x3000138c                  # Black level channel, Reference GxBlackLevelSelectEntry
    ENUM_BALANCE_WHITE_AUTO = 0x3000138e                    # Balance white auto, Reference GxBalanceWhiteAutoEntry
    ENUM_BALANCE_RATIO_SELECTOR = 0x3000138f                # selects Balance white channel, Reference GxBalanceRatioSelectorEntry
    FLOAT_BALANCE_RATIO = 0x20001390                        # Balance white channel ratio
    ENUM_COLOR_CORRECT = 0x30001391                         # Color correct, Reference GxColorCorrectEntry
    ENUM_DEAD_PIXEL_CORRECT = 0x30001392                    # Pixel correct, Reference GxDeadPixelCorrectEntry
    FLOAT_GAIN = 0x20001393                                 # gain
    FLOAT_BLACK_LEVEL = 0x20001394                          # Black level
    BOOL_GAMMA_ENABLE = 0x40001395                          # Gamma enable bit
    ENUM_GAMMA_MODE = 0x30001396                            # Gamma mode
    FLOAT_GAMMA = 0x20001397                                # The value of Gamma
    INT_DIGITAL_SHIFT = 0x10001398                          #

    # ---------------CustomFeature Section--------------------------------
    INT_ADC_LEVEL = 0x10001770                              # AD conversion level
    INT_H_BLANKING = 0x10001771                             # Horizontal blanking
    INT_V_BLANKING = 0x10001772                             # Vertical blanking
    STRING_USER_PASSWORD = 0x50001773                       # User encrypted zone cipher
    STRING_VERIFY_PASSWORD = 0x50001774                     # User encrypted zone check cipher
    BUFFER_USER_DATA = 0x60001775                           # User encrypted area content
    INT_GRAY_VALUE = 0x10001776                             # Expected gray value
    ENUM_AA_LIGHT_ENVIRONMENT = 0x30001777                  # Gain auto, Exposure auto, Light environment type,
                                                            # Reference GxAALightEnvironmentEntry
    INT_AAROI_OFFSETX = 0x10001778                          # The X offset for the rect of interest in pixels for 2A
    INT_AAROI_OFFSETY = 0x10001779                          # The Y offset for the rect of interest in pixels for 2A
    INT_AAROI_WIDTH = 0x1000177a                            # The width offset for the rect of interest in pixels for 2A
    INT_AAROI_HEIGHT = 0x1000177b                           # The height offset for the rect of interest in pixels for 2A
    FLOAT_AUTO_GAIN_MIN = 0x2000177c                        # Automatic gain minimum
    FLOAT_AUTO_GAIN_MAX = 0x2000177d                        # Automatic gain maximum
    FLOAT_AUTO_EXPOSURE_TIME_MIN = 0x2000177e               # Automatic exposure minimum
    FLOAT_AUTO_EXPOSURE_TIME_MAX = 0x2000177f               # Automatic exposure maximum
    BUFFER_FRAME_INFORMATION = 0x60001780                   # Image frame information
    INT_CONTRAST_PARAM = 0x10001781                         # Contrast parameter
    FLOAT_GAMMA_PARAM = 0x20001782                          # Gamma parameter
    INT_COLOR_CORRECTION_PARAM = 0x10001783                 # Color correction param
    ENUM_IMAGE_GRAY_RAISE_SWITCH = 0x30001784               # Image gray raise, Reference GxImageGrayRaiseSwitchEntry
    ENUM_AWB_LAMP_HOUSE = 0x30001785                        # Automatic white balance light source
                                                            # Reference GxAWBLampHouseEntry
    INT_AWBROI_OFFSETX = 0x10001786                         # Offset_X of automatic white balance region
    INT_AWBROI_OFFSETY = 0x10001787                         # Offset_Y of automatic white balance region
    INT_AWBROI_WIDTH = 0x10001788                           # Width of automatic white balance region
    INT_AWBROI_HEIGHT = 0x10001789                          # Height of automatic white balance region
    ENUM_SHARPNESS_MODE = 0x3000178a                        # Sharpness mode, Reference GxSharpnessModeEntry
    FLOAT_SHARPNESS = 0x2000178b                            # Sharpness

    # ---------------UserSetControl Section-------------------------------
    ENUM_USER_SET_SELECTOR = 0x30001b58                     # Parameter group selection, Reference GxUserSetSelectorEntry
    COMMAND_USER_SET_LOAD = 0x70001b59                      # Load parameter group
    COMMAND_USER_SET_SAVE = 0x70001b5a                      # Save parameter group
    ENUM_USER_SET_DEFAULT = 0x30001b5b                      # Startup parameter group, Reference GxUserSetDefaultEntry

    # ---------------Event Section----------------------------------------
    ENUM_EVENT_SELECTOR = 0x30001f40                        # Event source select, Reference GxEventSelectorEntry
    ENUM_EVENT_NOTIFICATION = 0x30001f41                    # Event enabled, Reference GxEventNotificationEntry
    INT_EVENT_EXPOSURE_END = 0x10001f42                     # Exposure end event
    INT_EVENT_EXPOSURE_END_TIMESTAMP = 0x10001f43           # The timestamp of Exposure end event
    INT_EVENT_EXPOSURE_END_FRAME_ID = 0x10001f44            # The frame id of Exposure end event
    INT_EVENT_BLOCK_DISCARD = 0x10001f45                    # Block discard event
    INT_EVENT_BLOCK_DISCARD_TIMESTAMP = 0x10001f46          # The timestamp of Block discard event
    INT_EVENT_OVERRUN = 0x10001f47                          # Event queue overflow event
    INT_EVENT_OVERRUN_TIMESTAMP = 0x10001f48                # The timestamp of event queue overflow event
    INT_EVENT_FRAME_START_OVER_TRIGGER = 0x10001f49         # Trigger signal shield event
    INT_EVENT_FRAME_START_OVER_TRIGGER_TIMESTAMP = 0x10001f4a   # The timestamp of trigger signal shield event
    INT_EVENT_BLOCK_NOT_EMPTY = 0x10001f4b                  # Frame memory not empty event
    INT_EVENT_BLOCK_NOT_EMPTY_TIMESTAMP = 0x10001f4c        # The timestamp of frame memory not empty event
    INT_EVENT_INTERNAL_ERROR = 0x10001f4d                   # Internal erroneous event
    INT_EVENT_INTERNAL_ERROR_TIMESTAMP = 0x10001f4e         # The timestamp of internal erroneous event

    # ---------------LUT Section------------------------------------------
    ENUM_LUT_SELECTOR = 0x30002328                          # Select lut, Reference GxLutSelectorEntry
    BUFFER_LUT_VALUE_ALL = 0x60002329                       # Lut data
    BOOL_LUT_ENABLE = 0x4000232a                            # Lut enable bit
    INT_LUT_INDEX = 0x1000232b                              # Lut index
    INT_LUT_VALUE = 0x1000232c                              # Lut value

    # ---------------Color Transformation Control-------------------------
    ENUM_COLOR_TRANSFORMATION_MODE = 0x30002af8             # Color transformation mode
    BOOL_COLOR_TRANSFORMATION_ENABLE = 0x40002af9           # Color transformation enable bit
    ENUM_COLOR_TRANSFORMATION_VALUE_SELECTOR = 0x30002afa   # The selector of color transformation value
    FLOAT_COLOR_TRANSFORMATION_VALUE = 0x20002afb           # The value of color transformation

    # ---------------ChunkData Section------------------------------------
    BOOL_CHUNK_MODE_ACTIVE = 0x40002711                     # Enable frame information
    ENUM_CHUNK_SELECTOR = 0x30002712                        # Select frame information channel, Reference GxChunkSelectorEntry
    BOOL_CHUNK_ENABLE = 0x40002713                          # Enable single frame information channel

    # ---------------CounterAndTimerControl Section-----------------------
    ENUM_TIMER_SELECTOR = 0x30002ee0                        # Selects which Counter to configure, Refer to GxTimerSelectorEntry
    FLOAT_TIMER_DURATION = 0x20002ee1                       # Sets the duration (in microseconds) of the Timer pulse.
    FLOAT_TIMER_DELAY = 0x20002ee2                          # Sets the duration (in microseconds) of the delay to apply at the reception of a trigger before starting the Timer.
    ENUM_TIMER_TRIGGER_SOURCE = 0x30002ee3                  # Selects the source of the trigger to start the Timer, Refer to GxTimerTriggerSourceEntry
    ENUM_COUNTER_SELECTOR = 0x30002ee4                      # Selects which Counter to configure, Refer to GxCounterSelectorEntry
    ENUM_COUNTER_EVENT_SOURCE = 0x30002ee5                  # Select the events that will be the source to increment the Counter, Refer to GxCounterEventSourceEntry
    ENUM_COUNTER_RESET_SOURCE = 0x30002ee6                  # Selects the signals that will be the source to reset the Counter, Refer to GxCounterResetSourceEntry
    ENUM_COUNTER_RESET_ACTIVATION = 0x30002ee7              # Selects the Activation mode of the Counter Reset Source signal, Refer to GxCounterResetActivationEntry
    COMMAND_COUNTER_RESET = 0x70002ee8                      # Does a software reset of the selected Counter and starts it.

    # ---------------Device Feature---------------------------------------
    INT_COMMAND_TIMEOUT = 0x13000000                        # The time of command timeout
    INT_COMMAND_RETRY_COUNT = 0x13000001                    # Command retry times

    # ---------------DataStream Feature-----------------------------------
    INT_ANNOUNCED_BUFFER_COUNT = 0x14000000                 # The number of Buffer declarations
    INT_DELIVERED_FRAME_COUNT = 0x14000001                  # Number of received frames (including remnant frames)
    INT_LOST_FRAME_COUNT = 0x14000002                       # Number of lost frames caused by buffer deficiency
    INT_INCOMPLETE_FRAME_COUNT = 0x14000003                 # Number of residual frames received
    INT_DELIVERED_PACKET_COUNT = 0x14000004                 # The number of packets received
    INT_RESEND_PACKET_COUNT = 0x14000005                    # Number of retransmission packages
    INT_RESCUED_PACKED_COUNT = 0x14000006                   # Retransmission success package number
    INT_RESEND_COMMAND_COUNT = 0x14000007                   # Retransmission command times
    INT_UNEXPECTED_PACKED_COUNT = 0x14000008                # Exception packet number
    INT_MAX_PACKET_COUNT_IN_ONE_BLOCK = 0x14000009          # Data block maximum retransmission number
    INT_MAX_PACKET_COUNT_IN_ONE_COMMAND = 0x1400000a        # The maximum number of packets contained in one command
    INT_RESEND_TIMEOUT = 0x1400000b                         # Retransmission timeout time
    INT_MAX_WAIT_PACKET_COUNT = 0x1400000c                  # Maximum waiting packet number
    ENUM_RESEND_MODE = 0x3400000d                           # Retransmission mode, Reference GxDSResendModeEntry
    INT_MISSING_BLOCK_ID_COUNT = 0x1400000e                 # BlockID lost number
    INT_BLOCK_TIMEOUT = 0x1400000f                          # Data block timeout time
    INT_STREAM_TRANSFER_SIZE = 0x14000010                   # Data block size
    INT_STREAM_TRANSFER_NUMBER_URB = 0x14000011             # Number of data blocks
    INT_MAX_NUM_QUEUE_BUFFER = 0x14000012                   # The maximum Buffer number of the collection queue
    INT_PACKET_TIMEOUT = 0x14000013                         # Packet timeout time

    def __init__(self):
        pass


class GxDeviceIPInfo(Structure):
    _fields_ = [
        ('device_id', c_char * 68),         # The unique identifier of the device.
        ('mac', c_char * 32),               # MAC address
        ('ip', c_char * 32),                # IP address
        ('subnet_mask', c_char * 32),       # Subnet mask
        ('gateway', c_char * 32),           # Gateway
        ('nic_mac', c_char * 32),           # The MAC address of the corresponding NIC(Network Interface Card).
        ('nic_ip', c_char * 32),            # The IP of the corresponding NIC
        ('nic_subnet_mask', c_char * 32),   # The subnet mask of the corresponding NIC
        ('nic_gateWay', c_char * 32),       # The Gateway of the corresponding NIC
        ('nic_description', c_char * 132),  # The description of the corresponding NIC
        ('reserved', c_char * 512),         # Reserved 512 bytes
    ]

    def __str__(self):
        return "GxDeviceIPInfo\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxDeviceBaseInfo(Structure):
    _fields_ = [
        ('vendor_name', c_char*32),         # Vendor name
        ('model_name', c_char*32),          # TModel name
        ('serial_number', c_char*32),       # Serial number
        ('display_name', c_char*132),       # Display name
        ('device_id', c_char*68),           # The unique identifier of the device.
        ('user_id', c_char*68),             # User's custom name
        ('access_status', c_int),           # Access status that is currently supported by the device
                                            # Refer to GxAccessStatus
        ('device_class', c_int),            # Device type. Such as USB2.0, GEV.
        ('reserved', c_char*300),           # Reserved 300 bytes
    ]

    def __str__(self):
        return "GxDeviceBaseInfo\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxOpenParam(Structure):
    _fields_ = [
        ('content',             c_char_p),
        ('open_mode',           c_uint),
        ('access_mode',         c_uint),
    ]

    def __str__(self):
        return "GxOpenParam\n%s" % "\n".join( "%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxFrameCallbackParam(Structure):
    _fields_ = [
        ('user_param_index',    c_void_p),      # User private data
        ('status',              c_int),         # The return state of the image
        ('image_buf',           c_void_p),      # Image buff address
        ('image_size',          c_int),         # Image data size, Including frame information
        ('width',               c_int),         # Image width
        ('height',              c_int),         # Image height
        ('pixel_format',        c_int),         # Image PixFormat
        ('frame_id',            c_ulonglong),   # The frame id of the image
        ('timestamp',           c_ulonglong),   # Time stamp of image
        ('reserved',            c_int),         # Reserved
    ]

    def __str__(self):
        return "GxFrameCallbackParam\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxFrameData(Structure):
    _fields_ = [
        ('status', c_int),                      # The return state of the image
        ('image_buf', c_void_p),                # Image buff address
        ('width', c_int),                       # Image width
        ('height', c_int),                      # Image height
        ('pixel_format', c_int),                # Image PixFormat
        ('image_size', c_int),                  # Image data size, Including frame information
        ('frame_id', c_ulonglong),              # The frame id of the image
        ('timestamp', c_ulonglong),             # Time stamp of image
        ('buf_id', c_ulonglong),                # Image buff ID
        ('reserved',  c_int),                   # Reserved
    ]

    def __str__(self):
        return "GxFrameData\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxIntRange(Structure):
    _fields_ = [
        ('min',                 c_ulonglong),
        ('max',                 c_ulonglong),
        ('inc',                 c_ulonglong),
        ('reserved',            c_int * 8),
    ]

    def __str__(self):
        return "GxIntRange\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxFloatRange(Structure):
    _fields_ = [
        ('min',                 c_double),
        ('max',                 c_double),
        ('inc',                 c_double),
        ('unit',                c_char * 8),
        ('inc_is_valid',        c_bool),
        ('reserved',            c_char * 31),
    ]

    def __str__(self):
        return "GxFloatRange\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxEnumDescription(Structure):
    _fields_ = [
        ('value',               c_longlong),    # Enum value
        ('symbolic',            c_char * 64),   # Character description
        ('reserved',            c_int * 8),
    ]

    def __str__(self):
        return "GxEnumDescription\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


if hasattr(dll, 'GXInitLib'):
    def gx_init_lib():
        """
        :brief      Initialize the device library for some resource application operations
        :return:    None
        """
        return dll.GXInitLib()


if hasattr(dll, 'GXCloseLib'):
    def gx_close_lib():
        """
        :brief      Close the device library to release resources.
        :return:    None
        """
        return dll.GXCloseLib()


if hasattr(dll, 'GXGetLastError'):
    def gx_get_last_error(size=1024):
        """
        :brief      To get the latest error descriptions information of the program
        :param      size:           string buff length(size=1024)
                                    Type: Int, Minnum: 0
        :return:    status:         State return value, See detail in GxStatusList
                    err_code:       Return the last error code
                    err_content:    the latest error descriptions information of the program
        """
        err_code = c_int()
        err_content_buff = create_string_buffer(size)

        content_size = c_size_t()
        content_size.value = size

        status = dll.GXGetLastError(byref(err_code), byref(err_content_buff), byref(content_size))
        err_content = string_at(err_content_buff, content_size.value-1)

        return status, err_code.value, string_decoding(err_content)


if hasattr(dll, 'GXUpdateDeviceList'):
    def gx_update_device_list(time_out=200):
        """
        :brief      Enumerating currently all available devices in subnet and gets the number of devices.
        :param      time_out:           The timeout time of enumeration (unit: ms).
                                        Type: Int, Minimum:0
        :return:    status:             State return value, See detail in GxStatusList
                    device_num:         The number of devices
        """
        time_out_c = c_uint()
        time_out_c.value = time_out

        device_num = c_uint()
        status = dll.GXUpdateDeviceList(byref(device_num), time_out_c)
        return status, device_num.value


if hasattr(dll, 'GXUpdateAllDeviceList'):
    def gx_update_all_device_list(time_out=200):
        """
        :brief      Enumerating currently all available devices in entire network and gets the number of devices
        :param      time_out:           The timeout time of enumeration (unit: ms).
                                        Type: Int, Minimum: 0
        :return:    status:             State return value, See detail in GxStatusList
                    device_num:         The number of devices
        """
        time_out_c = c_uint()
        time_out_c.value = time_out

        device_num = c_uint()
        status = dll.GXUpdateAllDeviceList(byref(device_num), time_out_c)
        return status, device_num.value


if hasattr(dll, 'GXGetAllDeviceBaseInfo'):
    def gx_get_all_device_base_info(devices_num):
        """
        :brief      To get the basic information of all the devices
        :param      devices_num:        The number of devices
                                        Type: Int, Minimum: 0
        :return:    status:             State return value, See detail in GxStatusList
                    device_ip_info:     The structure pointer of the device information(GxDeviceIPInfo)
        """
        devices_info = (GxDeviceBaseInfo * devices_num)()

        buf_size_c = c_size_t()
        buf_size_c.value = sizeof(GxDeviceBaseInfo) * devices_num

        status = dll.GXGetAllDeviceBaseInfo(byref(devices_info), byref(buf_size_c))
        return status, devices_info
        

if hasattr(dll, 'GXGetDeviceIPInfo'):
    def gx_get_device_ip_info(index):
        """
        :brief      To get the network information of the device.
        :param      index:              Device index
                                        Type: Int, Minimum: 1
        :return:    status:             State return value, See detail in GxStatusList
                    device_ip_info:     The structure pointer of the device information(GxDeviceIPInfo)
        """
        index_c = c_uint()
        index_c.value = index

        device_ip_info = GxDeviceIPInfo()
        status = dll.GXGetDeviceIPInfo(index_c, byref(device_ip_info))

        return status, device_ip_info


if hasattr(dll, 'GXOpenDeviceByIndex'):
    def gx_open_device_by_index(index):
        """
        :brief      Open the device by a specific Index(1, 2, 3, ...)
        :param      index:          Device index
                                    Type: Int, Minimum: 1
        :return:    status:         State return value, See detail in GxStatusList
                    handle:         The device handle returned by the interface
        """
        index_c = c_uint()
        index_c.value = index

        handle_c = c_void_p()
        status = dll.GXOpenDeviceByIndex(index_c, byref(handle_c))
        return status, handle_c.value


if hasattr(dll, 'GXOpenDevice'):
    def gx_open_device(open_param):
        """
        :brief      Open the device by a specific unique identification, such as: SN, IP, MAC, Index etc.
        :param      open_param:     The open device parameter which is configurated by the user.
                                    Type: GxOpenParam
        :return:    status:         State return value, See detail in GxStatusList
                    handle:         The device handle returned by the interface
        """
        handle = c_void_p()
        status = dll.GXOpenDevice(byref(open_param), byref(handle))
        return status, handle.value


if hasattr(dll, 'GXCloseDevice'):
    def gx_close_device(handle):
        """
        :brief      Specify the device handle to close the device
        :param      handle:     The device handle that the user specified to close.
                                Type: Long, Greater than 0
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXCloseDevice(handle_c)
        return status

'''
if hasattr(dll, 'GXGetDevicePersistentIpAddress'):
    def gx_get_device_persistent_ip_address(handle, ip_length=16, subnet_mask_length=16, default_gateway_length=16):
        """
        :brief      Get the persistent IP information of the device
        :param      handle:                 The handle of the device
        :param      ip_length:              The character string length of the device persistent IP address.
        :param      subnet_mask_length:     The character string length of the device persistent subnet mask.
        :param      default_gateway_length: The character string length of the device persistent gateway
        :return:    status:                 State return value, See detail in GxStatusList
                    ip:                     The device persistent IP address(str)
                    subnet_mask:            The device persistent subnet mask(str)
                    default_gateway:        The device persistent gateway
        """
        handle_c = c_void_p()
        handle_c.value = handle

        ip_length_c = c_uint()
        ip_length_c.value = ip_length
        ip_c = create_string_buffer(ip_length)

        subnet_mask_length_c = c_uint()
        subnet_mask_length_c.value = subnet_mask_length
        subnet_mask_c = create_string_buffer(subnet_mask_length)

        default_gateway_length_c = c_uint()
        default_gateway_length_c.value = default_gateway_length
        default_gateway_c = create_string_buffer(default_gateway_length)

        status = dll.GXGetDevicePersistentIpAddress(handle_c, byref(ip_c), byref(ip_length_c),
                                                    byref(subnet_mask_c), byref(subnet_mask_length_c),
                                                    byref(default_gateway_c), byref(default_gateway_length_c))

        ip = string_at(ip_c, ip_length_c.value-1)
        subnet_mask = string_at(subnet_mask_c, subnet_mask_length_c.value-1)
        default_gateway = string_at(default_gateway_c, default_gateway_length_c.value-1)

        return status, string_decoding(ip), string_decoding(subnet_mask), string_decoding(default_gateway)

if hasattr(dll, 'GXSetDevicePersistentIpAddress'):
    def gx_set_device_persistent_ip_address(handle, ip, subnet_mask, default_gate_way):
        """
        :brief      Set the persistent IP information of the device
        :param      handle:             The handle of the device
        :param      ip:                 The persistent IP character string of the device(str)
        :param      subnet_mask:        The persistent subnet mask character string of the device(str)
        :param      default_gate_way:   The persistent gateway character string of the device(str)
        :return:    status:             State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        ip_c = create_string_buffer(string_encoding(ip))
        subnet_mask_c = create_string_buffer(string_encoding(subnet_mask))
        default_gate_way_c = create_string_buffer(string_encoding(default_gate_way))

        status = dll.GXSetDevicePersistentIpAddress(handle_c, byref(ip_c), byref(subnet_mask_c),
                                                    byref(default_gate_way_c))
        return status
'''

if hasattr(dll, 'GXGetFeatureName'):
    def gx_get_feature_name(handle, feature_id):
        """
        :brief      Get the string description for the feature code
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: Int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    name:           The string description for the feature code
        """
        handle_c = c_void_p()
        handle_c.value = handle
        feature_id_c = c_int()
        feature_id_c.value = feature_id

        size_c = c_size_t()
        status = dll.GXGetFeatureName(handle_c, feature_id_c, None, byref(size_c))

        name_buff = create_string_buffer(size_c.value)
        status = dll.GXGetFeatureName(handle_c, feature_id_c, byref(name_buff), byref(size_c))

        name = string_at(name_buff, size_c.value-1)
        return status, string_decoding(name)


if hasattr(dll, 'GXIsImplemented'):
    def gx_is_implemented(handle, feature_id):
        """
        :brief      Inquire the current camera whether support a special feature.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    is_implemented: To return the result whether is support this feature
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        is_implemented = c_bool()
        status = dll.GXIsImplemented(handle_c, feature_id_c, byref(is_implemented))
        return status, is_implemented.value


if hasattr(dll, 'GXIsReadable'):
    def gx_is_readable(handle, feature_id):
        """
        :brief      Inquire if a feature code is currently readable
        :param      handle:             The handle of the device
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    is_readable:        To return the result whether the feature code ID is readable
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        is_readable = c_bool()
        status = dll.GXIsReadable(handle_c, feature_id_c, byref(is_readable))
        return status, is_readable.value


if hasattr(dll, 'GXIsWritable'):
    def gx_is_writable(handle, feature_id):
        """
        :brief      Inquire if a feature code is currently writable
        :param      handle:             The handle of the device.
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    is_writeable:       To return the result whether the feature code ID is writable(Bool)
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        is_writeable = c_bool()
        status = dll.GXIsWritable(handle_c, feature_id_c, byref(is_writeable))
        return status, is_writeable.value


if hasattr(dll, 'GXGetIntRange'):
    def gx_get_int_range(handle, feature_id):
        """
        :brief      To get the minimum value, maximum value and steps of the int type
        :param      handle:         The handle of the device.
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    int_range:      The structure of range description(GxIntRange)
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        int_range = GxIntRange()
        status = dll.GXGetIntRange(handle_c, feature_id_c, byref(int_range))
        return status, int_range


if hasattr(dll, 'GXGetInt'):
    def gx_get_int(handle, feature_id):
        """
        :brief      Get the current value of the int type.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    int_value:      Get the current value of the int type
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        int_value = c_int64()
        status = dll.GXGetInt(handle_c, feature_id_c, byref(int_value))
        return status, int_value.value


if hasattr(dll, 'GXSetInt'):
    def gx_set_int(handle, feature_id, int_value):
        """
        :brief      Set the value of int type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID.
                                    Type: int, Greater than 0
        :param      int_value:      The value that the user will set
                                    Type: long, minnum:0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        value_c = c_int64()
        value_c.value = int_value

        status = dll.GXSetInt(handle_c, feature_id_c, value_c)
        return status


if hasattr(dll, 'GXGetFloatRange'):
    def gx_get_float_range(handle, feature_id):
        """
        :brief      To get the minimum value, maximum value, stepsand unit of the float type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    float_range:    The description structure(GxFloatRange)
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        float_range = GxFloatRange()
        status = dll.GXGetFloatRange(handle_c, feature_id_c, byref(float_range))
        return status, float_range


if hasattr(dll, 'GXSetFloat'):
    def gx_set_float(handle, feature_id, float_value):
        """
        :brief      Set the value of float type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :param      float_value:    The float value that the user will set
                                    Type: double
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        value_c = c_double()
        value_c.value = float_value

        status = dll.GXSetFloat(handle_c, feature_id_c, value_c)
        return status


if hasattr(dll, 'GXGetFloat'):
    def gx_get_float(handle, feature_id):
        """
        :brief      Get the value of float type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        float_value = c_double()
        status = dll.GXGetFloat(handle_c, feature_id_c, byref(float_value))

        return status, float_value.value


if hasattr(dll, 'GXGetEnumEntryNums'):
    def gx_get_enum_entry_nums(handle, feature_id):
        """
        :brief      Get the number of the options for the enumeration item
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    enum_num:       The number of the options for the enumeration item
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        enum_nums = c_uint()
        status = dll.GXGetEnumEntryNums(handle_c, feature_id_c, byref(enum_nums))
        return status, enum_nums.value


if hasattr(dll, 'GXGetEnumDescription'):
    def gx_get_enum_description(handle, feature_id, enum_num):
        """
        :brief      To get the description information of the enumerated type values
                    the number of enumerated items and the value and descriptions of each item
                    please reference GxEnumDescription.
        :param      handle:             The handle of the device
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :param      enum_num:           The number of enumerated information
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    enum_description:   Enumerated information array(GxEnumDescription)
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        buf_size_c = c_size_t()
        buf_size_c.value = sizeof(GxEnumDescription) * enum_num

        enum_description = (GxEnumDescription * enum_num)()
        status = dll.GXGetEnumDescription(handle_c, feature_id_c, byref(enum_description), byref(buf_size_c))
        return status, enum_description


if hasattr(dll, 'GXGetEnum'):
    def gx_get_enum(handle, feature_id):
        """
        :brief      To get the current enumeration value
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    enum_value:     Get the current enumeration value
        """
        handle_c = c_void_p()
        handle_c.value = handle
        feature_id_c = c_int()
        feature_id_c.value = feature_id

        enum_value = c_int64()
        status = dll.GXGetEnum(handle_c, feature_id_c, byref(enum_value))

        return status, enum_value.value


if hasattr(dll, 'GXSetEnum'):
    def gx_set_enum(handle, feature_id, enum_value):
        """
        :brief      Set the enumeration value
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :param      enum_value:     Set the enumeration value
                                    Type: int
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        value_c = c_int64()
        value_c.value = enum_value

        status = dll.GXSetEnum(handle_c, feature_id_c, value_c)
        return status


if hasattr(dll, 'GXGetBool'):
    def gx_get_bool(handle, feature_id):
        """
        :brief      Get the value of bool type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    boot_value:     the value of bool type
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        boot_value = c_bool()
        status = dll.GXGetBool(handle_c, feature_id_c, byref(boot_value))
        return status, boot_value.value


if hasattr(dll, 'GXSetBool'):
    def gx_set_bool(handle, feature_id, bool_value):
        """
        :brief      Set the value of bool type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :param      bool_value:     The bool value that the user will set
                                    Type: Bool
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        value_c = c_bool()
        value_c.value = bool_value

        status = dll.GXSetBool(handle_c, feature_id_c, value_c)
        return status


if hasattr(dll, 'GXGetStringLength'):
    def gx_get_string_length(handle, feature_id):
        """
        :brief      Get the current value length of the character string type. Unit: byte
        :param      handle:             The handle of the device
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    string_length:      the current value length of the character string type
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        string_length = c_size_t()
        status = dll.GXGetStringLength(handle_c, feature_id_c, byref(string_length))

        return status, string_length.value - 1


if hasattr(dll, 'GXGetStringMaxLength'):
    def gx_get_string_max_length(handle, feature_id):
        """
        :brief      Get the maximum length of the string type value,  Unit: byte
        :param      handle:             The handle of the device
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    string_max_length:  the maximum length of the string type value
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        string_max_length = c_size_t()
        status = dll.GXGetStringMaxLength(handle_c, feature_id, byref(string_max_length))

        return status, string_max_length.value - 1


if hasattr(dll, 'GXGetString'):
    def gx_get_string(handle, feature_id):
        """
        :brief      Get the content of the string type value
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        size_c = c_size_t()
        status = dll.GXGetString(handle_c, feature_id_c, None, byref(size_c))

        content_c = create_string_buffer(size_c.value)
        status = dll.GXGetString(handle_c, feature_id_c, byref(content_c), byref(size_c))

        content = string_at(content_c, size_c.value-1)
        return status, string_decoding(content)


if hasattr(dll, 'GXSetString'):
    def gx_set_string(handle, feature_id, content):
        """
        :brief      Set the content of the string value
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :param      content:        The string will be setting(str)
                                    Type: str
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        content_c = create_string_buffer(string_encoding(content))

        status = dll.GXSetString(handle_c, feature_id_c, byref(content_c))
        return status


if hasattr(dll, 'GXGetBufferLength'):
    def gx_get_buffer_length(handle, feature_id):
        """
        :brief      Get the length of the chunk data and the unit is byte,
                    the user can apply the buffer based on the length obtained,
                    and then call the gx_get_buffer to get the chunk data.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    buff_length:    Buff length, Unit: byte
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        buff_length = c_size_t()
        status = dll.GXGetBufferLength(handle_c, feature_id_c, byref(buff_length))
        return status, buff_length.value


if hasattr(dll, 'GXGetBuffer'):
    def gx_get_buffer(handle, feature_id):
        """
        :brief      Get the chunk data
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    buff:           chunk data
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        buff_length_c = c_size_t()
        status = dll.GXGetBuffer(handle_c, feature_id_c, None, byref(buff_length_c))

        buff_c = (c_ubyte * buff_length_c.value)()
        status = dll.GXGetBuffer(handle_c, feature_id_c, byref(buff_c), byref(buff_length_c))
        return status, buff_c


if hasattr(dll, 'GXSetBuffer'):
    def gx_set_buffer(handle, feature_id, buff, buff_size):
        """
        :brief      Set the chunk data
        :param      handle:         The handle of the device
        :param      feature_id:     The feature code ID
                                    Type: long, Greater than 0
        :param      buff:           chunk data buff
                                    Type: Ctype array
        :param      buff_size:      chunk data buff size
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """

        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        buff_size_c = c_size_t()
        buff_size_c.value = buff_size

        status = dll.GXSetBuffer(handle_c, feature_id_c, buff, buff_size_c)
        return status


if hasattr(dll, 'GXSendCommand'):
    def gx_send_command(handle, feature_id):
        """
        :brief      Send the command
        :param      handle:         The handle of the device
                                    Type: long, Greater than 0
        :param      feature_id:     The feature code ID.
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        status = dll.GXSendCommand(handle_c, feature_id_c)
        return status

'''
CAP_CALL = CFUNCTYPE(None, POINTER(GxFrameCallbackParam))
if hasattr(dll, 'GXRegisterCaptureCallback'):
    def gx_register_capture_callback(handle, cap_call):
        """
        :brief      Register the capture callback function
        :param      handle:         The handle of the device
        :param      cap_call:       The callback function that the user will register(@ CAP_CALL)
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXRegisterCaptureCallback(handle_c, None, cap_call)
        return status


if hasattr(dll, 'GXUnregisterCaptureCallback'):
    def gx_unregister_capture_callback(handle):
        """
        :brief      Unregister the capture callback function
        :param      handle:         The handle of the device
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXUnregisterCaptureCallback(handle_c)
        return status
'''

if hasattr(dll, 'GXGetImage'):
    def gx_get_image(handle, frame_data, time_out=200):
        """
        :brief      After starting acquisition, you can call this function to get images directly.
                    Noting that the interface can not be mixed with the callback capture mode.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      frame_data:     [out]User introduced to receive the image data
                                    Type: GxFrameData
        :param      time_out:       The timeout time of capture image.(unit: ms)
                                    Type: int, minnum: 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        time_out_c = c_uint()
        time_out_c.value = time_out

        status = dll.GXGetImage(handle_c, byref(frame_data), time_out_c)
        return status


if hasattr(dll, 'GXFlushQueue'):
    def gx_flush_queue(handle):
        """
        :brief      Empty the cache image in the image output queue.
        :param      handle:     The handle of the device
                                Type: Long, Greater than 0
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXFlushQueue(handle_c)
        return status


'''
OFF_LINE_CALL = CFUNCTYPE(None, c_void_p)
if hasattr(dll, 'GXRegisterDeviceOfflineCallback'):
    def gx_register_device_offline_callback(handle, call_back):
        """
        :brief      At present, the mercury GIGE camera provides the device offline notification event mechanism,
                    the user can call this interface to register the event handle callback function
        :param      handle:             The handle of the device
        :param      call_back:          The user event handle callback function(@ OFF_LINE_CALL)
        :return:    status:             State return value, See detail in GxStatusList
                    call_back_handle:   The handle of offline callback function
                                        the handle is used for unregistering the callback function
        """
        handle_c = c_void_p()
        handle_c.value = handle

        call_back_handle = c_void_p()

        status = dll.GXRegisterDeviceOfflineCallback(handle_c, None, call_back, byref(call_back_handle))
        return status, call_back_handle.value


if hasattr(dll, 'GXUnregisterDeviceOfflineCallback'):
    def gx_unregister_device_offline_callback(handle, call_back_handle):
        """
        :brief      Unregister event handle callback function
        :param      handle:             The handle of the device
        :param      call_back_handle:   The handle of device offline callback function
        :return:    status:             State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        call_back_handle_c = c_void_p()
        call_back_handle_c.value = call_back_handle

        status = dll.GXUnregisterDeviceOfflineCallback(handle, call_back_handle_c)
        return status


if hasattr(dll, 'GXFlushEvent'):
    def gx_flush_event(handle):
        """
        :brief      Empty the device event, such as the frame exposure to end the event data queue
        :param      handle:    The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXFlushEvent(handle_c)
        return status


if hasattr(dll, 'GXGetEventNumInQueue'):
    def gx_get_event_num_in_queue(handle):
        """
        :brief      Get the number of the events in the current remote device event queue cache.
        :param      handle:     The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
                    event_num:  event number.
        """
        handle_c = c_void_p()
        handle_c.value = handle

        event_num = c_uint()

        status = dll.GXGetEventNumInQueue(handle_c, byref(event_num))
        return status, event_num.value


FEATURE_CALL = CFUNCTYPE(None, c_uint, c_void_p)
if hasattr(dll, 'GXRegisterFeatureCallback'):
    def gx_register_feature_callback(handle, call_back, feature_id):
        """
        :brief      Register device attribute update callback function.
                    When the current value of the device property has updated, or the accessible property is changed,
                    call this callback function.
        :param      handle:             The handle of the device
        :param      call_back:          The user event handle callback function(@ FEATURE_CALL)
        :param      feature_id:         The feature code ID
        :return:    status:             State return value, See detail in GxStatusList
                    call_back_handle:   The handle of property update callback function,
                                        to unregister the callback function.
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        call_back_handle = c_void_p()
        status = dll.GXRegisterFeatureCallback(handle_c, None, call_back, feature_id_c, byref(call_back_handle))

        return status, call_back_handle.value


if hasattr(dll, 'GXUnregisterFeatureCallback'):
    """
    """
    def gx_unregister_feature_callback(handle, feature_id, call_back_handle):
        """
        :brief      Unregister device attribute update callback function
        :param      handle:             The handle of the device
        :param      feature_id:         The feature code ID
        :param      call_back_handle:   Handle of property update callback function
        :return:    status:             State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        call_back_handle_c = c_void_p()
        call_back_handle_c.value = call_back_handle

        status = dll.GXUnregisterFeatureCallback(handle_c, feature_id_c, call_back_handle_c)
        return status
'''

if hasattr(dll, 'GXExportConfigFile'):
    def gx_export_config_file(handle, file_path):
        """
        :brief      Export the current parameter of the camera to the configuration file.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      file_path:      The path of the configuration file that to be generated
                                    Type: str
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        file_path_c = create_string_buffer(string_encoding(file_path))
        status = dll.GXExportConfigFile(handle_c, byref(file_path_c))

        return status


if hasattr(dll, 'GXImportConfigFile'):
    def gx_import_config_file(handle, file_path, verify):
        """
        :brief      Import the configuration file for the camera
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      file_path:      The path of the configuration file(str)
                                    Type: str
        :param      verify:         If this value is true, all imported values will be read out
                                    to check whether they are consistent.
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        verify_c = c_bool()
        verify_c.value = verify

        file_path_c = create_string_buffer(string_encoding(file_path))
        status = dll.GXImportConfigFile(handle_c, byref(file_path_c), verify_c)
        return status

'''
if hasattr(dll, 'GXReadRemoteDevicePort'):
    def gx_read_remote_device_port(handle, address, buff, size):
        """
        :brief      Read data for user specified register.
        :param      handle:     The handle of the device
        :param      address:    Register address
        :param      buff:       Output data buff
        :param      size:       Buff size
        :return:    status:     State return value, See detail in GxStatusList
                    size:       Returns the length of the actual read register
        """
        handle_c = c_void_p()
        handle_c.value = handle

        address_c = c_ulonglong()
        address_c.value = address

        size_c = c_uint()
        size_c.value = size

        status = dll.GXReadRemoteDevicePort(handle_c, address_c, byref(buff), byref(size_c))
        return status, size_c.value


if hasattr(dll, 'GXWriteRemoteDevicePort'):
    def gx_write_remote_device_port(handle, address, buff, size):
        """
        :brief      Writes user specified data to a user specified register.
        :param      handle:     The handle of the device
        :param      address:    Register address
        :param      buff:       User data
        :param      size:       User data size
        :return:    status:     State return value, See detail in GxStatusList
                    size:       Returns the length of the actual write register
        """
        handle_c = c_void_p()
        handle_c.value = handle

        address_c = c_ulonglong()
        address_c.value = address

        size_c = c_uint()
        size_c.value = size

        status = dll.GXWriteRemoteDevicePort(handle_c, address_c, byref(buff), byref(size_c))
        return status, size_c.value


if hasattr(dll, 'GXGigEIpConfiguration'):
    def gx_gige_ip_configuration(mac_address, ipconfig_flag, ip_address, subnet_mask, default_gateway, user_id):
        """
        "brief      Configure the static IP address of the camera
        :param      mac_address:        The MAC address of the device(str)
        :param      ipconfig_flag:      IP Configuration mode(GxIPConfigureModeList)
        :param      ip_address:         The IP address to be set(str)
        :param      subnet_mask:        The subnet mask to be set(str)
        :param      default_gateway:    The default gateway to be set(str)
        :param      user_id:            The user-defined name to be set(str)
        :return:    status:             State return value, See detail in GxStatusList
        """
        mac_address_c = create_string_buffer(string_encoding(mac_address))
        ip_address_c = create_string_buffer(string_encoding(ip_address))
        subnet_mask_c = create_string_buffer(string_encoding(subnet_mask))
        default_gateway_c = create_string_buffer(string_encoding(default_gateway))
        user_id_c = create_string_buffer(string_encoding(user_id))

        status = dll.GXGigEIpConfiguration(mac_address_c, ipconfig_flag,
                                           ip_address_c, subnet_mask_c,
                                           default_gateway_c, user_id_c)
        return status


if hasattr(dll, 'GXGigEForceIp'):
    def gx_gige_force_ip(mac_address, ip_address, subnet_mask, default_gate_way):
        """
        :brief      Execute the Force IP
        :param      mac_address:        The MAC address of the device(str)
        :param      ip_address:         The IP address to be set(str)
        :param      subnet_mask:        The subnet mask to be set(str)
        :param      default_gate_way:   The default gateway to be set(str)
        :return:    status:             State return value, See detail in GxStatusList
        """
        mac_address_c = create_string_buffer(string_encoding(mac_address))
        ip_address_c = create_string_buffer(string_encoding(ip_address))
        subnet_mask_c = create_string_buffer(string_encoding(subnet_mask))
        default_gate_way_c = create_string_buffer(string_encoding(default_gate_way))

        status = dll.GXGigEForceIp(mac_address_c, ip_address_c, subnet_mask_c, default_gate_way_c)
        return status
'''

if hasattr(dll, 'GXSetAcqusitionBufferNumber'):
    def gx_set_acquisition_buffer_number(handle, buffer_num):
        """
        :brief      Users Set Acquisition buffer Number
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      buffer_num:     Acquisition buffer Number
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        buffer_num_c = c_uint64()
        buffer_num_c.value = buffer_num

        status = dll.GXSetAcqusitionBufferNumber(handle_c, buffer_num_c)
        return status

'''
if hasattr(dll, 'GXStreamOn'):
    def gx_stream_on(handle):
        """
        :brief      Start acquisition
        :param      handle:     The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXStreamOn(handle_c)
        return status


if hasattr(dll, 'GXDQBuf'):
    def gx_dequeue_buf(handle, time_out):
        """
        :brief      Get a image
                    After the image processing is completed, the gx_queue_buf interface needs to be called
                    otherwise the collection will not be able to continue.
        :param      handle:             The handle of the device
        :param      time_out:           The timeout time of capture image.(unit: ms)
        :return:    status:             State return value, See detail in GxStatusList
                    frame_data:         Image data
                    frame_data_p:       Image buff address
        """
        handle_c = c_void_p()
        handle_c.value = handle

        time_out_c = c_uint()
        time_out_c.value = time_out

        frame_data_p = c_void_p()
        status = dll.GXDQBuf(handle_c, byref(frame_data_p), time_out_c)

        frame_data = GxFrameData()
        memmove(addressof(frame_data), frame_data_p.value, sizeof(frame_data))
        return status, frame_data, frame_data_p.value


if hasattr(dll, 'GXQBuf'):
    def gx_queue_buf(handle, frame_data_p):
        """
        :brief      Put an image Buff back to the GxIAPI library and continue to be used for collection.
        :param      handle:         The handle of the device
        :param      frame_data_p:   Image buff address
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        frame_data_p_p = c_void_p()
        frame_data_p_p.value = frame_data_p

        status = dll.GXQBuf(handle_c, frame_data_p_p)
        return status
        

if hasattr(dll, 'GXDQAllBufs'):
    def gx_dequeue_all_bufs(handle, buff_num, time_out):
        """
        :brief      Get images
                    After the image processing is completed, the gx_queue_all_bufs interface needs to be called
                    otherwise the collection will not be able to continue.
        :param      handle:         The handle of the device
        :param      buff_num:       The number of images expected to be obtained
        :param      time_out:       The timeout time of capture image.(unit: ms)
        :return:    status:         State return value, See detail in GxStatusList
                    frame_data:     Image data arrays
                    frame_count:    The number of images that are actually returned
        """
        handle_c = c_void_p()
        handle_c.value = handle

        time_out_c = c_uint()
        time_out_c.value = time_out

        frame_data_p = (c_void_p * buff_num)()
        frame_count_c = c_uint()

        status = dll.GXDQAllBufs(handle_c, frame_data_p, buff_num, byref(frame_count_c), time_out_c)
        frame_data = (GxFrameData * buff_num)()

        for i in range(buff_num):
            memmove(addressof(frame_data[i]), frame_data_p[i], sizeof(GxFrameData))

        return status, frame_data, frame_count_c.value


if hasattr(dll, 'GXQAllBufs'):
    def gx_queue_all_bufs(handle):
        """
        :brief      The image data Buf is returned to the GxIAPI library and used for collection.
        :param      handle:     The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXQAllBufs(handle_c)
        return status


if hasattr(dll, 'GXStreamOff'):
    def gx_stream_off(handle):
        """
        :brief      Stop acquisition
        :param      handle:     The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXStreamOff(handle_c)
        return status
'''


def string_encoding(string):
    """
    :breif      Python3.X: String encoded as bytes
    :param      string
    :return:
    """
    if sys.version_info.major == 3:
        string = string.encode()
    return string


def string_decoding(string):
    """
    :brief      Python3.X: bytes decoded as string
    :param      string
    :return:
    """
    if sys.version_info.major == 3:
        string = string.decode()
    return string


def range_check(value, min_value, max_value, inc_value=0):
    """
    :brief      Determine if the input parameter is within range
    :param      value:       input value
    :param      min_value:   max value
    :param      max_value:   min value
    :param      inc_value:   step size, default=0
    :return:    True/False
    """
    if value < min_value:
        return False
    elif value > max_value:
        return False
    elif (inc_value != 0) and (value != int(value / inc_value) * inc_value):
        return False
    return True

#!/usr/bin/python
# -*- coding:utf-8 -*-
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-

import numpy
from gxipy.gxwrapper import *
from gxipy.dxwrapper import *
from gxipy.gxidef import *

ERROR_SIZE = 1024
PIXEL_BIT_MASK = 0x00ff0000

if sys.version_info.major > 2:
    INT_TYPE = int
else:
    INT_TYPE = (int, long)
    

class DeviceManager(object):
    __instance_num = 0
    def __new__(cls, *args, **kw):
        cls.__instance_num += 1
        status = gx_init_lib()
        StatusProcessor.process(status, 'DeviceManager', 'init_lib')
        return object.__new__(cls, *args)
    
    def __init__(self):
        self.__device_num = 0
        self.__device_info_list = []

        

    def __del__(self):
        self.__class__.__instance_num -= 1
        if self.__class__.__instance_num <= 0:
            status = gx_close_lib()
            StatusProcessor.process(status, 'DeviceManager', 'close_lib')

    def __get_device_info_list(self, base_info, ip_info, num):
        """
        :brief      Convert GxDeviceBaseInfo and GxDeviceIPInfo to device info list
        :param      base_info:  device base info list[GxDeviceBaseInfo]
        :param      ip_info:    device ip info list[GxDeviceIPInfo]
        :param      num:        device number
        :return:    device info list
        """
        device_info_list = []
        for i in range(num):
            device_info_list.append({
                'index': i+1,
                'vendor_name': string_decoding(base_info[i].vendor_name),
                'model_name': string_decoding(base_info[i].model_name),
                'sn': string_decoding(base_info[i].serial_number),
                'display_name': string_decoding(base_info[i].display_name),
                'device_id': string_decoding(base_info[i].device_id),
                'user_id': string_decoding(base_info[i].user_id),
                'access_status': base_info[i].access_status,
                'device_class': base_info[i].device_class,
                'mac': string_decoding(ip_info[i].mac),
                'ip': string_decoding(ip_info[i].ip),
                'subnet_mask': string_decoding(ip_info[i].subnet_mask),
                'gateway': string_decoding(ip_info[i].gateway),
                'nic_mac': string_decoding(ip_info[i].nic_mac),
                'nic_ip': string_decoding(ip_info[i].nic_ip),
                'nic_subnet_mask': string_decoding(ip_info[i].nic_subnet_mask),
                'nic_gateWay': string_decoding(ip_info[i].nic_gateWay),
                'nic_description': string_decoding(ip_info[i].nic_description)
            })

        return device_info_list

    def __get_ip_info(self, base_info_list, dev_mum):
        """
        :brief      Get the network information
        """

        ip_info_list = []
        for i in range(dev_mum):
            if base_info_list[i].device_class == GxDeviceClassList.GEV:
                status, ip_info = gx_get_device_ip_info(i+1)
                StatusProcessor.process(status, 'DeviceManager', '__get_ip_info')
                ip_info_list.append(ip_info)
            else:
                ip_info_list.append(GxDeviceIPInfo())

        return ip_info_list

    def update_device_list(self, timeout=200):
        """
        :brief      enumerate the same network segment devices
        :param      timeout:    Enumeration timeout, range:[0, 0xFFFFFFFF]
        :return:    dev_num:    device number
                    device_info_list: all device info list
        """
        if not isinstance(timeout, INT_TYPE):
            raise ParameterTypeError("DeviceManager.update_device_list: "
                                     "Expected timeout type is int, not %s" % type(timeout))

        if (timeout < 0) or (timeout > UNSIGNED_INT_MAX):
            print("DeviceManager.update_device_list: "
                  "timeout out of bounds, timeout: minimum=0, maximum=%s" % hex(UNSIGNED_INT_MAX).__str__())
            return 0, None

        status, dev_num = gx_update_device_list(timeout)
        StatusProcessor.process(status, 'DeviceManager', 'update_device_list')

        status, base_info_list = gx_get_all_device_base_info(dev_num)
        StatusProcessor.process(status, 'DeviceManager', 'update_device_list')

        ip_info_list = self.__get_ip_info(base_info_list, dev_num)
        self.__device_num = dev_num
        self.__device_info_list = self.__get_device_info_list(base_info_list, ip_info_list, dev_num)

        return self.__device_num, self.__device_info_list

    def update_all_device_list(self, timeout=200):
        """
        :brief      Enumerate devices on different network segments
        :param      timeout:    Enumeration timeout, range:[0, 0xFFFFFFFF]
        :return:    dev_num:    device number
                    device_info_list:   all device info list
        """
        if not isinstance(timeout, INT_TYPE):
            raise ParameterTypeError("DeviceManager.update_all_device_list: "
                                     "Expected timeout type is int, not %s" % type(timeout))

        if (timeout < 0) or (timeout > UNSIGNED_INT_MAX):
            print("DeviceManager.update_all_device_list: "
                  "timeout out of bounds, timeout: minimum=0, maximum=%s" % hex(UNSIGNED_INT_MAX).__str__())
            return 0, None

        status, dev_num = gx_update_all_device_list(timeout)
        StatusProcessor.process(status, 'DeviceManager', 'update_all_device_list')

        status, base_info_list = gx_get_all_device_base_info(dev_num)
        StatusProcessor.process(status, 'DeviceManager', 'update_all_device_list')

        ip_info_list = self.__get_ip_info(base_info_list, dev_num)
        self.__device_num = dev_num
        self.__device_info_list = self.__get_device_info_list(base_info_list, ip_info_list, dev_num)

        return self.__device_num, self.__device_info_list

    def get_device_number(self):
        """
        :brief      Get device number
        :return:    device number
        """
        return self.__device_num

    def get_device_info(self):
        """
        :brief      Get all device info
        :return:    info_dict:      device info list
        """
        return self.__device_info_list

    def open_device_by_index(self, index, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by index
                    USB3 device return U3VDevice object
                    USB2 device return U2Device object
                    GEV  device return GEVDevice object
        :param      index:          device index must start from 1
        :param      access_mode:    the access of open device
        :return:    Device object
        """
        if not isinstance(index, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_index: "
                                     "Expected index type is int, not %s" % type(index))

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_index: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        if index < 1:
            print("DeviceManager.open_device_by_index: index must start from 1")
            return None
        elif index > UNSIGNED_INT_MAX:
            print("DeviceManager.open_device_by_index: index maximum: %s" % hex(UNSIGNED_INT_MAX).__str__())
            return None

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_index: "
                  "access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        if self.__device_num < index:
            # Re-update the device
            self.update_device_list()
            if self.__device_num < index:
                raise NotFoundDevice("DeviceManager.open_device_by_index: invalid index")

        # open devices by index
        open_param = GxOpenParam()
        open_param.content = string_encoding(str(index))
        open_param.open_mode = GxOpenMode.INDEX
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_index')

        # get device class
        device_class = self.__device_info_list[index-1]["device_class"]

        if device_class == GxDeviceClassList.U3V:
            return U3VDevice(handle)
        elif device_class == GxDeviceClassList.USB2:
            return U2Device(handle)
        elif device_class == GxDeviceClassList.GEV:
            return GEVDevice(handle)
        else:
            raise NotFoundDevice("DeviceManager.open_device_by_index: Does not support this device type.")

    def __get_device_class_by_sn(self, sn):
        """
        :brief:     1.find device by sn in self.__device_info_list
                    2.return different objects according to device class
        :param      sn:      device serial number
        :return:    device class
        """
        for index in range(self.__device_num):
            if self.__device_info_list[index]["sn"] == sn:
                return self.__device_info_list[index]["device_class"]

        # don't find this id in device base info list
        return -1

    def open_device_by_sn(self, sn, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by serial number(SN)
                    USB3 device return U3VDevice object
                    USB2 device return U2Device object
                    GEV device return GEVDevice object
        :param      sn:             device serial number, type: str
        :param      access_mode:    the mode of open device[GxAccessMode]
        :return:    Device object
        """
        if not isinstance(sn, str):
            raise ParameterTypeError("DeviceManager.open_device_by_sn: "
                                     "Expected sn type is str, not %s" % type(sn))

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_sn: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_sn: "
                  "access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        # get device class from self.__device_info_list
        device_class = self.__get_device_class_by_sn(sn)
        if device_class == -1:
            # Re-update the device
            self.update_device_list()
            device_class = self.__get_device_class_by_sn(sn)
            if device_class == -1:
                # don't find this sn
                raise NotFoundDevice("DeviceManager.open_device_by_sn: Not found device")

        # open devices by sn
        open_param = GxOpenParam()
        open_param.content = string_encoding(sn)
        open_param.open_mode = GxOpenMode.SN
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_sn')

        if device_class == GxDeviceClassList.U3V:
            return U3VDevice(handle)
        elif device_class == GxDeviceClassList.USB2:
            return U2Device(handle)
        elif device_class == GxDeviceClassList.GEV:
            return GEVDevice(handle)
        else:
            raise NotFoundDevice("DeviceManager.open_device_by_sn: Does not support this device type.")

    def __get_device_class_by_user_id(self, user_id):
        """
        :brief:     1.find device according to sn in self.__device_info_list
                    2.return different objects according to device class
        :param      user_id:        user ID
        :return:    device class
        """
        for index in range(self.__device_num):
            if self.__device_info_list[index]["user_id"] == user_id:
                return self.__device_info_list[index]["device_class"]

        # don't find this id in device base info list
        return -1

    def open_device_by_user_id(self, user_id, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by user defined name
                    USB3 device return U3VDevice object
                    GEV  device return GEVDevice object
        :param      user_id:        user defined name, type:str
        :param      access_mode:    the mode of open device[GxAccessMode]
        :return:    Device object
        """
        if not isinstance(user_id, str):
            raise ParameterTypeError("DeviceManager.open_device_by_user_id: "
                                     "Expected user_id type is str, not %s" % type(user_id))
        elif user_id.__len__() == 0:
            raise InvalidParameter("DeviceManager.open_device_by_user_id: Don't support user_id's length is 0")

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_user_id: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_user_id: access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        # get device class from self.__device_info_list
        device_class = self.__get_device_class_by_user_id(user_id)
        if device_class == -1:
            # Re-update the device
            self.update_device_list()
            device_class = self.__get_device_class_by_user_id(user_id)
            if device_class == -1:
                # don't find this user_id
                raise NotFoundDevice("DeviceManager.open_device_by_user_id: Not found device")

        # open device by user_id
        open_param = GxOpenParam()
        open_param.content = string_encoding(user_id)
        open_param.open_mode = GxOpenMode.USER_ID
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_user_id')

        if device_class == GxDeviceClassList.U3V:
            return U3VDevice(handle)
        elif device_class == GxDeviceClassList.GEV:
            return GEVDevice(handle)
        else:
            raise NotFoundDevice("DeviceManager.open_device_by_user_id: Does not support this device type.")

    def open_device_by_ip(self, ip, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by device ip address
        :param      ip:             device ip address, type:str
        :param      access_mode:    the mode of open device[GxAccessMode]
        :return:    GEVDevice object
        """
        if not isinstance(ip, str):
            raise ParameterTypeError("DeviceManager.open_device_by_ip: "
                                     "Expected ip type is str, not %s" % type(ip))

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_ip: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_ip: access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        # open device by ip
        open_param = GxOpenParam()
        open_param.content = string_encoding(ip)
        open_param.open_mode = GxOpenMode.IP
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_ip')

        return GEVDevice(handle)

    def open_device_by_mac(self, mac, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by device mac address
        :param      mac:            device mac address, type:str
        :param      access_mode:    the mode of open device[GxAccessMode]
        :return:    GEVDevice object
        """
        if not isinstance(mac, str):
            raise ParameterTypeError("DeviceManager.open_device_by_mac: "
                                     "Expected mac type is str, not %s" % type(mac))

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_mac: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_mac: access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        # open device by ip
        open_param = GxOpenParam()
        open_param.content = string_encoding(mac)
        open_param.open_mode = GxOpenMode.MAC
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_mac')

        return GEVDevice(handle)


class Feature:
    def __init__(self, handle, feature):
        """
        :param  handle:      The handle of the device
        :param  feature:     The feature code ID
        """
        self.__handle = handle
        self.__feature = feature
        self.feature_name = self.get_name()

    def get_name(self):
        """
        brief:  Getting Feature Name
        return: Success:    feature name
                Failed:     convert feature ID to string
        """
        status, name = gx_get_feature_name(self.__handle, self.__feature)
        if status != GxStatusList.SUCCESS:
            name = (hex(self.__feature)).__str__()

        return name

    def is_implemented(self):
        """
        brief:  Determining whether the feature is implemented
        return: is_implemented
        """
        status, is_implemented = gx_is_implemented(self.__handle, self.__feature)
        if status == GxStatusList.SUCCESS:
            return is_implemented
        elif status == GxStatusList.INVALID_PARAMETER:
            return False
        else:
            StatusProcessor.process(status, 'Feature', 'is_implemented')

    def is_readable(self):
        """
        brief:  Determining whether the feature is readable
        return: is_readable
        """
        implemented = self.is_implemented()
        if not implemented:
            return False

        status, is_readable = gx_is_readable(self.__handle, self.__feature)
        StatusProcessor.process(status, 'Feature', 'is_readable')
        return is_readable

    def is_writable(self):
        """
        brief:  Determining whether the feature is writable
        return: is_writable
        """
        implemented = self.is_implemented()
        if not implemented:
            return False

        status, is_writable = gx_is_writable(self.__handle, self.__feature)
        StatusProcessor.process(status, 'Feature', 'is_writable')
        return is_writable


class IntFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param  handle:      The handle of the device
        :param  feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def __range_dict(self, int_range):
        """
        :brief      Convert GxIntRange to dictionary
        :param      int_range:  GxIntRange
        :return:    range_dicts
        """
        range_dicts = {
            "min": int_range.min,
            "max": int_range.max,
            "inc": int_range.inc
        }
        return range_dicts

    def get_range(self):
        """
        :brief      Getting integer range
        :return:    integer range dictionary
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_range is not support" % self.feature_name)
            return None

        status, int_range = gx_get_int_range(self.__handle, self.__feature)
        StatusProcessor.process(status, 'IntFeature', 'get_range')
        return self.__range_dict(int_range)

    def get(self):
        """
        :brief      Getting integer value
        :return:    integer value
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get is not readable" % self.feature_name)
            return None

        status, int_value = gx_get_int(self.__handle, self.__feature)
        StatusProcessor.process(status, 'IntFeature', 'get')
        return int_value

    def set(self, int_value):
        """
        :brief      Setting integer value
        :param      int_value
        :return:    None
        """
        if not isinstance(int_value, INT_TYPE):
            raise ParameterTypeError("IntFeature.set: "
                                     "Expected int_value type is int, not %s" % type(int_value))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        int_range = self.get_range()
        check_ret = range_check(int_value, int_range["min"], int_range["max"], int_range["inc"])
        if not check_ret:
            print("IntFeature.set: "
                  "int_value out of bounds, %s.range=[%d, %d, %d]" %
                  (self.feature_name, int_range["min"], int_range["max"], int_range["inc"]))
            return

        status = gx_set_int(self.__handle, self.__feature, int_value)
        StatusProcessor.process(status, 'IntFeature', 'set')


class FloatFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param      handle:      The handle of the device
        :param      feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def __range_dict(self, float_range):
        """
        :brief      Convert GxFloatRange to dictionary
        :param      float_range:  GxFloatRange
        :return:    range_dicts
        """
        range_dicts = {
            "min": float_range.min,
            "max": float_range.max,
            "inc": float_range.inc,
            "unit": string_decoding(float_range.unit),
            "inc_is_valid": float_range.inc_is_valid
        }
        return range_dicts

    def get_range(self):
        """
        :brief      Getting float range
        :return:    float range dictionary
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_range is not support" % self.feature_name)
            return None

        status, float_range = gx_get_float_range(self.__handle, self.__feature)
        StatusProcessor.process(status, 'FloatFeature', 'get_range')
        return self.__range_dict(float_range)

    def get(self):
        """
        :brief      Getting float value
        :return:    float value
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get: is not readable" % self.feature_name)
            return None

        status, float_value = gx_get_float(self.__handle, self.__feature)
        StatusProcessor.process(status, 'FloatFeature', 'get')
        return float_value

    def set(self, float_value):
        """
        :brief      Setting float value
        :param      float_value
        :return:    None
        """
        if not isinstance(float_value, (INT_TYPE, float)):
            raise ParameterTypeError("FloatFeature.set: "
                                     "Expected float_value type is float, not %s" % type(float_value))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        float_range = self.get_range()
        check_ret = range_check(float_value, float_range["min"], float_range["max"])
        if not check_ret:
            print("FloatFeature.set: float_value out of bounds, %s.range=[%f, %f]" %
                  (self.feature_name, float_range["min"], float_range["max"]))
            return

        status = gx_set_float(self.__handle, self.__feature, float_value)
        StatusProcessor.process(status, 'FloatFeature', 'set')


class EnumFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param handle:      The handle of the device
        :param feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def get_range(self):
        """
        :brief      Getting range of Enum feature
        :return:    enum_dict:    enum range dictionary
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_range: is not support" % self.feature_name)
            return None

        status, enum_num = gx_get_enum_entry_nums(self.__handle, self.__feature)
        StatusProcessor.process(status, 'EnumFeature', 'get_range')

        status, enum_list = gx_get_enum_description(self.__handle, self.__feature, enum_num)
        StatusProcessor.process(status, 'EnumFeature', 'get_range')

        enum_dict = {}
        for i in range(enum_num):
            enum_dict[string_decoding(enum_list[i].symbolic)] = enum_list[i].value

        return enum_dict

    def get(self):
        """
        :brief      Getting value of Enum feature
        :return:    enum_value:     enum value
                    enum_str:       string for enum description
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get: is not readable" % self.feature_name)
            return None, None

        status, enum_value = gx_get_enum(self.__handle, self.__feature)
        StatusProcessor.process(status, 'EnumFeature', 'get')

        range_dict = self.get_range()
        new_dicts = {v: k for k, v in range_dict.items()}
        return enum_value, new_dicts[enum_value]

    def set(self, enum_value):
        """
        :brief      Setting enum value
        :param      enum_value
        :return:    None
        """
        if not isinstance(enum_value, INT_TYPE):
            raise ParameterTypeError("EnumFeature.set: "
                                     "Expected enum_value type is int, not %s" % type(enum_value))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        range_dict = self.get_range()
        enum_value_list = range_dict.values()
        if enum_value not in enum_value_list:
            print("EnumFeature.set: enum_value out of bounds, %s.range:%s" %
                  (self.feature_name, range_dict.__str__()))
            return

        status = gx_set_enum(self.__handle, self.__feature, enum_value)
        StatusProcessor.process(status, 'EnumFeature', 'set')


class BoolFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param handle:      The handle of the device
        :param feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def get(self):
        """
        :brief      Getting bool value
        :return:    bool value[bool]
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get is not readable" % self.feature_name)
            return None

        status, bool_value = gx_get_bool(self.__handle, self.__feature)
        StatusProcessor.process(status, 'BoolFeature', 'get')
        return bool_value

    def set(self, bool_value):
        """
        :brief      Setting bool value
        :param      bool_value[bool]
        :return:    None
        """
        if not isinstance(bool_value, bool):
            raise ParameterTypeError("BoolFeature.set: "
                                     "Expected bool_value type is bool, not %s" % type(bool_value))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        status = gx_set_bool(self.__handle, self.__feature, bool_value)
        StatusProcessor.process(status, 'BoolFeature', 'set')


class StringFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param      handle:      The handle of the device
        :param      feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def get_string_max_length(self):
        """
        :brief      Getting the maximum length that string can set
        :return:    length:     the maximum length that string can set
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_string_max_length is not support" % self.feature_name)
            return None

        status, length = gx_get_string_max_length(self.__handle, self.__feature)
        StatusProcessor.process(status, 'StringFeature', 'get_string_max_length')
        return length

    def get(self):
        """
        :brief      Getting string value
        :return:    strings
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get is not readable" % self.feature_name)
            return None

        status, strings = gx_get_string(self.__handle, self.__feature)
        StatusProcessor.process(status, 'StringFeature', 'get')
        return strings

    def set(self, input_string):
        """
        :brief      Setting string value
        :param      input_string[string]
        :return:    None
        """
        if not isinstance(input_string, str):
            raise ParameterTypeError("StringFeature.set: "
                                     "Expected input_string type is str, not %s" % type(input_string))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        max_length = self.get_string_max_length()
        if input_string.__len__() > max_length:
            print("StringFeature.set: "
                  "input_string length out of bounds, %s.length_max:%s"
                  % (self.feature_name, max_length))
            return

        status = gx_set_string(self.__handle, self.__feature, input_string)
        StatusProcessor.process(status, 'StringFeature', 'set')


class BufferFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param      handle:      The handle of the device
        :param      feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def get_buffer_length(self):
        """
        :brief      Getting buffer length
        :return:    length:     buffer length
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_buffer_length is not support" % self.feature_name)
            return None

        status, length = gx_get_buffer_length(self.__handle, self.__feature)
        StatusProcessor.process(status, 'BuffFeature', 'get_buffer_length')
        return length

    def get_buffer(self):
        """
        :brief      Getting buffer data
        :return:    Buffer object

        """
        readable = self.is_readable()
        if not readable:
            print("%s.get_buffer is not readable" % self.feature_name)
            return None

        status, buf = gx_get_buffer(self.__handle, self.__feature)
        StatusProcessor.process(status, 'BuffFeature', 'get_buffer')
        return Buffer(buf)

    def set_buffer(self, buf):
        """
        :brief      Setting buffer data
        :param      buf:    Buffer object
        :return:    None
        """
        if not isinstance(buf, Buffer):
            raise ParameterTypeError("BuffFeature.set_buffer: "
                                     "Expected buff type is Buffer, not %s" % type(buf))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set_buffer is not writeable" % self.feature_name)
            return

        max_length = self.get_buffer_length()
        if buf.get_length() > max_length:
            print("BuffFeature.set_buffer: "
                  "buff length out of bounds, %s.length_max:%s" % (self.feature_name, max_length))
            return

        status = gx_set_buffer(self.__handle, self.__feature,
                               buf.get_ctype_array(), buf.get_length())
        StatusProcessor.process(status, 'BuffFeature', 'set_buffer')


class CommandFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param      handle:      The handle of the device
        :param      feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def send_command(self):
        """
        :brief      Sending command
        :return:    None
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.send_command is not support" % self.feature_name)
            return

        status = gx_send_command(self.__handle, self.__feature)
        StatusProcessor.process(status, 'CommandFeature', 'send_command')


class Buffer:
    def __init__(self, data_array):
        try:
            addressof(data_array)
        except TypeError:
            error_msg = "Buffer.__init__: param is error type."
            raise ParameterTypeError(error_msg)

        self.data_array = data_array

    @staticmethod
    def from_file(file_name):
        file_object = open(file_name, "rb")
        file_string = file_object.read()
        data_array = create_string_buffer(file_string)
        file_object.close()
        return Buffer(data_array)

    @staticmethod
    def from_string(string_data):
        data_array = create_string_buffer(string_data)
        return Buffer(data_array)

    def get_data(self):
        buff_p = c_void_p()
        buff_p.value = addressof(self.data_array)
        string_data = string_at(buff_p, len(self.data_array))
        return string_data

    def get_ctype_array(self):
        return self.data_array

    def get_numpy_array(self):
        numpy_array = numpy.array(self.data_array)
        return numpy_array

    def get_length(self):
        return len(self.data_array)


class Device:
    """
    The Camera class mainly encapsulates some common operations and function attributes,
    which are the operations and properties usually found in the camera.
    In addition, this class also encapsulates the common operations of  some functions in the C interface,
    such as SetInt, SetFloat, etc. Can not open to the user, so that when the subsequent addition of features,
    Python interface does not upgrade, or only the definition of the control code can support new features
    """
    def __init__(self, handle):
        self.__dev_handle = handle
        self.data_stream = []

        # ---------------Device Information Section--------------------------
        self.DeviceVendorName = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_VENDOR_NAME)
        self.DeviceModelName = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_MODEL_NAME)
        self.DeviceFirmwareVersion = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_FIRMWARE_VERSION)
        self.DeviceVersion = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_VERSION)
        self.DeviceSerialNumber = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_SERIAL_NUMBER)
        self.FactorySettingVersion = StringFeature(self.__dev_handle, GxFeatureID.STRING_FACTORY_SETTING_VERSION)
        self.DeviceUserID = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_USER_ID)
        self.DeviceLinkSelector = IntFeature(self.__dev_handle, GxFeatureID.INT_DEVICE_LINK_SELECTOR)
        self.DeviceLinkThroughputLimitMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_DEVICE_LINK_THROUGHPUT_LIMIT_MODE)
        self.DeviceLinkThroughputLimit = IntFeature(self.__dev_handle, GxFeatureID.INT_DEVICE_LINK_THROUGHPUT_LIMIT)
        self.DeviceLinkCurrentThroughput = IntFeature(self.__dev_handle, GxFeatureID.INT_DEVICE_LINK_CURRENT_THROUGHPUT)
        self.DeviceReset = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_DEVICE_RESET)
        self.TimestampTickFrequency = IntFeature(self.__dev_handle, GxFeatureID.INT_TIMESTAMP_TICK_FREQUENCY)
        self.TimestampLatch = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TIMESTAMP_LATCH)
        self.TimestampReset = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TIMESTAMP_RESET)
        self.TimestampLatchReset = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TIMESTAMP_LATCH_RESET)
        self.TimestampLatchValue = IntFeature(self.__dev_handle, GxFeatureID.INT_TIMESTAMP_LATCH_VALUE)

        # ---------------ImageFormat Section--------------------------------
        self.SensorWidth = IntFeature(self.__dev_handle, GxFeatureID.INT_SENSOR_WIDTH)
        self.SensorHeight = IntFeature(self.__dev_handle, GxFeatureID.INT_SENSOR_HEIGHT)
        self.WidthMax = IntFeature(self.__dev_handle, GxFeatureID.INT_WIDTH_MAX)
        self.HeightMax = IntFeature(self.__dev_handle, GxFeatureID.INT_HEIGHT_MAX)
        self.OffsetX = IntFeature(self.__dev_handle, GxFeatureID.INT_OFFSET_X)
        self.OffsetY = IntFeature(self.__dev_handle, GxFeatureID.INT_OFFSET_Y)
        self.Width = IntFeature(self.__dev_handle, GxFeatureID.INT_WIDTH)
        self.Height = IntFeature(self.__dev_handle, GxFeatureID.INT_HEIGHT)
        self.BinningHorizontal = IntFeature(self.__dev_handle, GxFeatureID.INT_BINNING_HORIZONTAL)
        self.BinningVertical = IntFeature(self.__dev_handle, GxFeatureID.INT_BINNING_VERTICAL)
        self.DecimationHorizontal = IntFeature(self.__dev_handle, GxFeatureID.INT_DECIMATION_HORIZONTAL)
        self.DecimationVertical = IntFeature(self.__dev_handle, GxFeatureID.INT_DECIMATION_VERTICAL)
        self.PixelSize = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_PIXEL_SIZE)
        self.PixelColorFilter = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_PIXEL_COLOR_FILTER)
        self.PixelFormat = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_PIXEL_FORMAT)
        self.ReverseX = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_REVERSE_X)
        self.ReverseY = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_REVERSE_Y)
        self.TestPattern = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TEST_PATTERN)
        self.TestPatternGeneratorSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TEST_PATTERN_GENERATOR_SELECTOR)
        self.RegionSendMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_REGION_SEND_MODE)
        self.RegionMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_REGION_MODE)
        self.RegionSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_REGION_SELECTOR)
        self.CenterWidth = IntFeature(self.__dev_handle, GxFeatureID.INT_CENTER_WIDTH)
        self.CenterHeight = IntFeature(self.__dev_handle, GxFeatureID.INT_CENTER_HEIGHT)
        self.BinningHorizontalMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BINNING_HORIZONTAL_MODE)
        self.BinningVerticalMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BINNING_VERTICAL_MODE)

        # ---------------TransportLayer Section-------------------------------
        self.PayloadSize = IntFeature(self.__dev_handle, GxFeatureID.INT_PAYLOAD_SIZE)

        # ---------------AcquisitionTrigger Section---------------------------
        self.AcquisitionMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_ACQUISITION_MODE)
        self.AcquisitionStart = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_ACQUISITION_START)
        self.AcquisitionStop = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_ACQUISITION_STOP)
        self.TriggerMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_MODE)
        self.TriggerSoftware = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TRIGGER_SOFTWARE)
        self.TriggerActivation = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_ACTIVATION)
        self.ExposureTime = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_EXPOSURE_TIME)
        self.ExposureAuto = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_EXPOSURE_AUTO)
        self.TriggerFilterRaisingEdge = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TRIGGER_FILTER_RAISING)
        self.TriggerFilterFallingEdge = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TRIGGER_FILTER_FALLING)
        self.TriggerSource = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_SOURCE)
        self.ExposureMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_EXPOSURE_MODE)
        self.TriggerSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_SELECTOR)
        self.TriggerDelay = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TRIGGER_DELAY)
        self.TransferControlMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRANSFER_CONTROL_MODE)
        self.TransferOperationMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRANSFER_OPERATION_MODE)
        self.TransferStart = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TRANSFER_START)
        self.TransferBlockCount = IntFeature(self.__dev_handle, GxFeatureID.INT_TRANSFER_BLOCK_COUNT)
        self.FrameBufferOverwriteActive = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_FRAME_STORE_COVER_ACTIVE)
        self.AcquisitionFrameRateMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_ACQUISITION_FRAME_RATE_MODE)
        self.AcquisitionFrameRate = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_ACQUISITION_FRAME_RATE)
        self.CurrentAcquisitionFrameRate = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_CURRENT_ACQUISITION_FRAME_RATE)
        self.FixedPatternNoiseCorrectMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_FIXED_PATTERN_NOISE_CORRECT_MODE)
        self.AcquisitionBurstFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_ACQUISITION_BURST_FRAME_COUNT)
        self.AcquisitionStatusSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_ACQUISITION_STATUS_SELECTOR)
        self.AcquisitionStatus = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_ACQUISITION_STATUS)
        self.ExposureDelay = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_EXPOSURE_DELAY)

        # ----------------DigitalIO Section----------------------------------
        self.UserOutputSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_USER_OUTPUT_SELECTOR)
        self.UserOutputValue = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_USER_OUTPUT_VALUE)
        self.LineSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_LINE_SELECTOR)
        self.LineMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_LINE_MODE)
        self.LineInverter = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_LINE_INVERTER)
        self.LineSource = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_LINE_SOURCE)
        self.LineStatus = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_LINE_STATUS)
        self.LineStatusAll = IntFeature(self.__dev_handle, GxFeatureID.INT_LINE_STATUS_ALL)

        # ----------------AnalogControls Section----------------------------
        self.GainAuto = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_GAIN_AUTO)
        self.GainSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_GAIN_SELECTOR)
        self.BlackLevelAuto = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BLACK_LEVEL_AUTO)
        self.BlackLevelSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BLACK_LEVEL_SELECTOR)
        self.BalanceWhiteAuto = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BALANCE_WHITE_AUTO)
        self.BalanceRatioSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BALANCE_RATIO_SELECTOR)
        self.BalanceRatio = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_BALANCE_RATIO)
        self.DeadPixelCorrect = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_DEAD_PIXEL_CORRECT)
        self.Gain = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_GAIN)
        self.BlackLevel = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_BLACK_LEVEL)
        self.GammaEnable = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_GAMMA_ENABLE)
        self.GammaMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_GAMMA_MODE)
        self.Gamma = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_GAMMA)
        self.DigitalShift = IntFeature(self.__dev_handle, GxFeatureID.INT_DIGITAL_SHIFT)

        # ---------------CustomFeature Section------------------------------
        self.ExpectedGrayValue = IntFeature(self.__dev_handle, GxFeatureID.INT_GRAY_VALUE)
        self.AAROIOffsetX = IntFeature(self.__dev_handle, GxFeatureID.INT_AAROI_OFFSETX)
        self.AAROIOffsetY = IntFeature(self.__dev_handle, GxFeatureID.INT_AAROI_OFFSETY)
        self.AAROIWidth = IntFeature(self.__dev_handle, GxFeatureID.INT_AAROI_WIDTH)
        self.AAROIHeight = IntFeature(self.__dev_handle, GxFeatureID.INT_AAROI_HEIGHT)
        self.AutoGainMin = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_AUTO_GAIN_MIN)
        self.AutoGainMax = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_AUTO_GAIN_MAX)
        self.AutoExposureTimeMin = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_AUTO_EXPOSURE_TIME_MIN)
        self.AutoExposureTimeMax = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_AUTO_EXPOSURE_TIME_MAX)
        self.ContrastParam = IntFeature(self.__dev_handle, GxFeatureID.INT_CONTRAST_PARAM)
        self.GammaParam = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_GAMMA_PARAM)
        self.ColorCorrectionParam = IntFeature(self.__dev_handle, GxFeatureID.INT_COLOR_CORRECTION_PARAM)
        self.AWBLampHouse = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_AWB_LAMP_HOUSE)
        self.AWBROIOffsetX = IntFeature(self.__dev_handle, GxFeatureID.INT_AWBROI_OFFSETX)
        self.AWBROIOffsetY = IntFeature(self.__dev_handle, GxFeatureID.INT_AWBROI_OFFSETY)
        self.AWBROIWidth = IntFeature(self.__dev_handle, GxFeatureID.INT_AWBROI_WIDTH)
        self.AWBROIHeight = IntFeature(self.__dev_handle, GxFeatureID.INT_AWBROI_HEIGHT)
        self.SharpnessMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_SHARPNESS_MODE)
        self.Sharpness = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_SHARPNESS)

        # ---------------UserSetControl Section-------------------------
        self.UserSetSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_USER_SET_SELECTOR)
        self.UserSetLoad = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_USER_SET_LOAD)
        self.UserSetSave = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_USER_SET_SAVE)
        self.UserSetDefault = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_USER_SET_DEFAULT)

        # ---------------LUT Section-------------------------------
        self.LUTSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_LUT_SELECTOR)
        self.LUTValueAll = BufferFeature(self.__dev_handle, GxFeatureID.BUFFER_LUT_VALUE_ALL)
        self.LUTEnable = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_LUT_ENABLE)
        self.LUTIndex = IntFeature(self.__dev_handle, GxFeatureID.INT_LUT_INDEX)
        self.LUTValue = IntFeature(self.__dev_handle, GxFeatureID.INT_LUT_VALUE)

        # ---------------Color Transformation Control--------------
        self.ColorTransformationMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COLOR_TRANSFORMATION_MODE)
        self.ColorTransformationEnable = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_COLOR_TRANSFORMATION_ENABLE)
        self.ColorTransformationValueSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COLOR_TRANSFORMATION_VALUE_SELECTOR)
        self.ColorTransformationValue = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_COLOR_TRANSFORMATION_VALUE)

        # ---------------ChunkData Section-------------------------
        self.ChunkModeActive = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_CHUNK_MODE_ACTIVE)
        self.ChunkSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_CHUNK_SELECTOR)
        self.ChunkEnable = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_CHUNK_ENABLE)

        # ---------------CounterAndTimerControl Section-------------------------
        self.TimerSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TIMER_SELECTOR)
        self.TimerDuration = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TIMER_DURATION)
        self.TimerDelay = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TIMER_DELAY)
        self.TimerTriggerSource = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TIMER_TRIGGER_SOURCE)
        self.CounterSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COUNTER_SELECTOR)
        self.CounterEventSource = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COUNTER_EVENT_SOURCE)
        self.CounterResetSource = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COUNTER_RESET_SOURCE)
        self.CounterResetActivation = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COUNTER_RESET_ACTIVATION)
        self.CounterReset = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_COUNTER_RESET)

    def stream_on(self):
        """
        :brief      send start command, camera start transmission image data
        :return:    none
        """
        status = gx_send_command(self.__dev_handle, GxFeatureID.COMMAND_ACQUISITION_START)
        StatusProcessor.process(status, 'Device', 'stream_on')

        payload_size = self.PayloadSize.get()
        self.data_stream[0].set_payload_size(payload_size)
        self.data_stream[0].acquisition_flag = True

    def stream_off(self):
        """
        :brief      send stop command, camera stop transmission image data
        :return:    none
        """
        self.data_stream[0].acquisition_flag = False
        status = gx_send_command(self.__dev_handle, GxFeatureID.COMMAND_ACQUISITION_STOP)
        StatusProcessor.process(status, 'Device', 'stream_off')

    def export_config_file(self, file_path):
        """
        :brief      Export the current configuration file
        :param      file_path:      file path(type: str)
        :return:    none
        """
        if not isinstance(file_path, str):
            raise ParameterTypeError("Device.export_config_file: "
                                     "Expected file_path type is str, not %s" % type(file_path))

        status = gx_export_config_file(self.__dev_handle, file_path)
        StatusProcessor.process(status, 'Device', 'export_config_file')

    def import_config_file(self, file_path, verify=False):
        """
        :brief      Imported configuration file
        :param      file_path:  file path(type: str)
        :param      verify:     If this value is true, all the imported values will be read out
                                and checked for consistency(type: bool)
        :return:    none
        """
        if not isinstance(file_path, str):
            raise ParameterTypeError("Device.import_config_file: "
                                     "Expected file_path type is str, not %s" % type(file_path))

        if not isinstance(verify, bool):
            raise ParameterTypeError("Device.import_config_file: "
                                     "Expected verify type is bool, not %s" % type(verify))

        status = gx_import_config_file(self.__dev_handle, file_path, verify)
        StatusProcessor.process(status, 'Device', 'import_config_file')

    def close_device(self):
        """
        :brief      close device, close device handle
        :return:    None
        """
        status = gx_close_device(self.__dev_handle)
        StatusProcessor.process(status, 'Device', 'close_device')
        self.__dev_handle = None

    def get_stream_channel_num(self):
        """
        :brief      Get the number of stream channels supported by the current device.
        :return:    the number of stream channels
        """
        return len(self.data_stream)


class GEVDevice(Device):
    def __init__(self, handle):
        self.__dev_handle = handle
        Device.__init__(self, self.__dev_handle)
        self.GevCurrentIPConfigurationLLA = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_GEV_CURRENT_IP_CONFIGURATION_LLA)
        self.GevCurrentIPConfigurationDHCP = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_GEV_CURRENT_IP_CONFIGURATION_DHCP)
        self.GevCurrentIPConfigurationPersistentIP = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_GEV_CURRENT_IP_CONFIGURATION_PERSISTENT_IP)
        self.EstimatedBandwidth = IntFeature(self.__dev_handle, GxFeatureID.INT_ESTIMATED_BANDWIDTH)
        self.GevHeartbeatTimeout = IntFeature(self.__dev_handle, GxFeatureID.INT_GEV_HEARTBEAT_TIMEOUT)
        self.GevSCPSPacketSize = IntFeature(self.__dev_handle, GxFeatureID.INT_GEV_PACKET_SIZE)
        self.GevSCPD = IntFeature(self.__dev_handle, GxFeatureID.INT_GEV_PACKET_DELAY)
        self.GevLinkSpeed = IntFeature(self.__dev_handle, GxFeatureID.INT_GEV_LINK_SPEED)
        self.DeviceCommandTimeout = IntFeature(self.__dev_handle, GxFeatureID.INT_COMMAND_TIMEOUT)
        self.DeviceCommandRetryCount = IntFeature(self.__dev_handle, GxFeatureID.INT_COMMAND_RETRY_COUNT)
        self.data_stream.append(GEVDataStream(self.__dev_handle))


class U3VDevice(Device):
    """
    The U3VDevice class inherits from the Device class. In addition to inheriting the properties of the Device,
    the U3V Device has special attributes such as bandwidth limitation, URBSetting, frame info, etc.
    """
    def __init__(self, handle):
        self.__dev_handle = handle
        Device.__init__(self, self.__dev_handle)
        self.data_stream.append(U3VDataStream(self.__dev_handle))


class U2Device(Device):
    """
    The U2Device class inherits from the Device class
    """
    def __init__(self, handle):
        self.__dev_handle = handle
        Device.__init__(self, self.__dev_handle)
        self.AcquisitionSpeedLevel = IntFeature(self.__dev_handle, GxFeatureID.INT_ACQUISITION_SPEED_LEVEL)
        self.AcquisitionFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_ACQUISITION_FRAME_COUNT)
        self.TriggerSwitch = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_SWITCH)
        self.UserOutputMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_USER_OUTPUT_MODE)
        self.StrobeSwitch = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_STROBE_SWITCH)
        self.ADCLevel = IntFeature(self.__dev_handle, GxFeatureID.INT_ADC_LEVEL)
        self.HBlanking = IntFeature(self.__dev_handle, GxFeatureID.INT_H_BLANKING)
        self.VBlanking = IntFeature(self.__dev_handle, GxFeatureID.INT_V_BLANKING)
        self.UserPassword = StringFeature(self.__dev_handle, GxFeatureID.STRING_USER_PASSWORD)
        self.VerifyPassword = StringFeature(self.__dev_handle, GxFeatureID.STRING_VERIFY_PASSWORD)
        self.UserData = BufferFeature(self.__dev_handle, GxFeatureID.BUFFER_USER_DATA)
        self.AALightEnvironment = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_AA_LIGHT_ENVIRONMENT)
        self.FrameInformation = BufferFeature(self.__dev_handle, GxFeatureID.BUFFER_FRAME_INFORMATION)
        self.ImageGrayRaiseSwitch = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_IMAGE_GRAY_RAISE_SWITCH)
        self.data_stream.append(DataStream(self.__dev_handle))


class DataStream:
    def __init__(self, handle):
        self.__dev_handle = handle
        self.StreamAnnouncedBufferCount = IntFeature(self.__dev_handle, GxFeatureID.INT_ANNOUNCED_BUFFER_COUNT)
        self.StreamDeliveredFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_DELIVERED_FRAME_COUNT)
        self.StreamLostFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_LOST_FRAME_COUNT)
        self.StreamIncompleteFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_INCOMPLETE_FRAME_COUNT)
        self.StreamDeliveredPacketCount = IntFeature(self.__dev_handle, GxFeatureID.INT_DELIVERED_PACKET_COUNT)
        self.payload_size = 0
        self.acquisition_flag = False

    def set_payload_size(self, payload_size):
        self.payload_size = payload_size

    def set_acquisition_buffer_number(self, buf_num):
        """
        :brief      set the number of acquisition buffer
        :param      buf_num:   the number of acquisition buffer, range:[1, 0xFFFFFFFF]
        """
        if not isinstance(buf_num, INT_TYPE):
            raise ParameterTypeError("DataStream.set_acquisition_buffer_number: "
                                     "Expected buf_num type is int, not %s" % type(buf_num))

        if (buf_num < 1) or (buf_num > UNSIGNED_LONG_LONG_MAX):
            print("DataStream.set_acquisition_buffer_number:"
                  "buf_num out of bounds, minimum=1, maximum=%s"
                  % hex(UNSIGNED_LONG_LONG_MAX).__str__())
            return

        status = gx_set_acquisition_buffer_number(self.__dev_handle, buf_num)
        StatusProcessor.process(status, 'DataStream', 'set_acquisition_buffer_number')

    def get_image(self, timeout=1000):
        """
        :brief          Get an image, get successfully create image class object
        :param          timeout:    Acquisition timeout, range:[0, 0xFFFFFFFF]
        :return:        image object
        """
        if not isinstance(timeout, INT_TYPE):
            raise ParameterTypeError("DataStream.get_image: "
                                     "Expected timeout type is int, not %s" % type(timeout))

        if (timeout < 0) or (timeout > UNSIGNED_INT_MAX):
            print("DataStream.get_image: "
                  "timeout out of bounds, minimum=0, maximum=%s"
                  % hex(UNSIGNED_INT_MAX).__str__())
            return None

        if self.acquisition_flag is False:
            print("DataStream.get_image: Current data steam don't  start acquisition")
            return None

        frame_data = GxFrameData()
        frame_data.image_size = self.payload_size
        frame_data.image_buf = None
        image = RawImage(frame_data)

        status = gx_get_image(self.__dev_handle, image.frame_data, timeout)
        if status == GxStatusList.SUCCESS:
            return image
        elif status == GxStatusList.TIMEOUT:
            return None
        else:
            StatusProcessor.process(status, 'DataStream', 'get_image')
            return None

    def flush_queue(self):
        status = gx_flush_queue(self.__dev_handle)
        StatusProcessor.process(status, 'DataStream', 'flush_queue')


class U3VDataStream(DataStream):
    def __init__(self, handle):
        self.__handle = handle
        DataStream.__init__(self, self.__handle)
        self.StreamTransferSize = IntFeature(self.__handle, GxFeatureID.INT_STREAM_TRANSFER_SIZE)
        self.StreamTransferNumberUrb = IntFeature(self.__handle, GxFeatureID.INT_STREAM_TRANSFER_NUMBER_URB)


class GEVDataStream(DataStream):
    def __init__(self, handle):
        self.__handle = handle
        DataStream.__init__(self, self.__handle)
        self.StreamResendPacketCount = IntFeature(self.__handle, GxFeatureID.INT_RESEND_PACKET_COUNT)
        self.StreamRescuedPacketCount = IntFeature(self.__handle, GxFeatureID.INT_RESCUED_PACKED_COUNT)
        self.StreamResendCommandCount = IntFeature(self.__handle, GxFeatureID.INT_RESEND_COMMAND_COUNT)
        self.StreamUnexpectedPacketCount = IntFeature(self.__handle, GxFeatureID.INT_UNEXPECTED_PACKED_COUNT)
        self.MaxPacketCountInOneBlock = IntFeature(self.__handle, GxFeatureID.INT_MAX_PACKET_COUNT_IN_ONE_BLOCK)
        self.MaxPacketCountInOneCommand = IntFeature(self.__handle, GxFeatureID.INT_MAX_PACKET_COUNT_IN_ONE_COMMAND)
        self.ResendTimeout = IntFeature(self.__handle, GxFeatureID.INT_RESEND_TIMEOUT)
        self.MaxWaitPacketCount = IntFeature(self.__handle, GxFeatureID.INT_MAX_WAIT_PACKET_COUNT)
        self.ResendMode = EnumFeature(self.__handle, GxFeatureID.ENUM_RESEND_MODE)
        self.StreamMissingBlockIDCount = IntFeature(self.__handle, GxFeatureID.INT_MISSING_BLOCK_ID_COUNT)
        self.BlockTimeout = IntFeature(self.__handle, GxFeatureID.INT_BLOCK_TIMEOUT)
        self.MaxNumQueueBuffer = IntFeature(self.__handle, GxFeatureID.INT_MAX_NUM_QUEUE_BUFFER)
        self.PacketTimeout = IntFeature(self.__handle, GxFeatureID.INT_PACKET_TIMEOUT)


class UnexpectedError(Exception):
    """
    brief:  Unexpected error exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class NotFoundTL(Exception):
    """
    brief:  not found TL exception
    param:  args             exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class NotFoundDevice(Exception):
    """
    brief:  not found device exception
    param:  args              exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class OffLine(Exception):
    """
    brief:  device offline exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class InvalidParameter(Exception):
    """
    brief:  input invalid parameter exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class InvalidHandle(Exception):
    """
    brief:  invalid handle exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class InvalidCall(Exception):
    """
    brief:  invalid callback exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class InvalidAccess(Exception):
    """
    brief:  invalid access exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class NeedMoreBuffer(Exception):
    """
    brief:  need more buffer exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class FeatureTypeError(Exception):
    """
    brief:  feature id error exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class OutOfRange(Exception):
    """
    brief:  param out of range exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class NotInitApi(Exception):
    """
    brief:  not init api exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class Timeout(Exception):
    """
    brief:  timeout exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class ParameterTypeError(Exception):
    """
    brief:  parameter type error exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


def exception_deal(status, args):
    """
    brief:  deal with different exception
    param:  status         function return value
    param:  args            exception description
    return: none
    """
    if status == GxStatusList.ERROR:
        raise UnexpectedError(args)
    elif status == GxStatusList.NOT_FOUND_TL:
        raise NotFoundTL(args)
    elif status == GxStatusList.NOT_FOUND_DEVICE:
        raise NotFoundDevice(args)
    elif status == GxStatusList.OFFLINE:
        raise OffLine(args)
    elif status == GxStatusList.INVALID_PARAMETER:
        raise InvalidParameter(args)
    elif status == GxStatusList.INVALID_HANDLE:
        raise InvalidHandle(args)
    elif status == GxStatusList.INVALID_CALL:
        raise InvalidCall(args)
    elif status == GxStatusList.INVALID_ACCESS:
        raise InvalidAccess(args)
    elif status == GxStatusList.NEED_MORE_BUFFER:
        raise NeedMoreBuffer(args)
    elif status == GxStatusList.ERROR_TYPE:
        raise FeatureTypeError(args)
    elif status == GxStatusList.OUT_OF_RANGE:
        raise OutOfRange(args)
    elif status == GxStatusList.NOT_INIT_API:
        raise NotInitApi(args)
    elif status == GxStatusList.TIMEOUT:
        raise Timeout(args)
    elif status == GxStatusList.REPEAT_OPENED:
        raise InvalidAccess(args)
    else:
        raise Exception(args)


class StatusProcessor:
    def __init__(self):
        pass

    @staticmethod
    def process(status, class_name, function_name):
        """
        :brief      1.Error code processing
                    2.combine the class name and function name of the transmitted function into a string
                    3.Throw an exception
        :param      status:   function return value
        :param      class_name:  class name
        :param      function_name: function name
        :return:    none
        """
        if status != GxStatusList.SUCCESS:
            ret, err_code, string = gx_get_last_error(ERROR_SIZE)
            error_message = "%s.%s:%s" % (class_name, function_name, string)
            exception_deal(status, error_message)

    @staticmethod
    def printing(status, class_name, function_name):
        """
        :brief      1.Error code processing
                    2.combine the class name and function name of the transmitted function into a string and print it out
        :param      status:   function return value
        :param      class_name:  class name
        :param      function_name: function name
        :return:    none
        """
        if status != GxStatusList.SUCCESS:
            ret, err_code, string = gx_get_last_error(ERROR_SIZE)
            error_message = "%s.%s:%s" % (class_name, function_name, string)
            print(error_message)


class RGBImage:
    def __init__(self, frame_data):
        self.frame_data = frame_data

        if self.frame_data.image_buf is not None:
            self.__image_array = string_at(self.frame_data.image_buf, self.frame_data.image_size)
        else:
            self.__image_array = (c_ubyte * self.frame_data.image_size)()
            self.frame_data.image_buf = addressof(self.__image_array)

    def image_improvement(self, color_correction_param=0, contrast_lut=None, gamma_lut=None):
        """
        :brief:     Improve image quality of the object itself
        :param      color_correction_param:     color correction param address
                                                (get from Device.ColorCorrectionParam.get_int())
        :param      contrast_lut:               contrast lut
        :param      gamma_lut:                  gamma lut
        :return:    None
        """
        if (color_correction_param == 0) and (contrast_lut is None) and (gamma_lut is None):
            return

        if contrast_lut is None:
            contrast_parameter = None
        elif isinstance(contrast_lut, Buffer):
            contrast_parameter = contrast_lut.get_ctype_array()
        else:
            raise ParameterTypeError("RGBImage.image_improvement: "
                                     "Expected contrast_lut type is Buffer, not %s" % type(contrast_lut))

        if gamma_lut is None:
            gamma_parameter = None
        elif isinstance(gamma_lut, Buffer):
            gamma_parameter = gamma_lut.get_ctype_array()
        else:
            raise ParameterTypeError("RGBImage.image_improvement: "
                                     "Expected gamma_lut type is Buffer, not %s" % type(gamma_lut))

        if not isinstance(color_correction_param, INT_TYPE):
            raise ParameterTypeError("RGBImage.image_improvement: "
                                     "Expected color_correction_param type is int, not %s" % type(color_correction_param))

        status = dx_image_improvement(self.frame_data.image_buf, self.frame_data.image_buf,
                                      self.frame_data.width, self.frame_data.height,
                                      color_correction_param, contrast_parameter, gamma_parameter)

        if status != DxStatus.OK:
            raise UnexpectedError("RGBImage.image_improvement: failed, error code:%s" % hex(status).__str__())

    def saturation(self, factor):
        """
        :brief      Saturation adjustment (RGB24)
        :param      factor:                 saturation factor,range(0 ~ 128)
        :return:    RGBImage object
        """
        if not isinstance(factor, INT_TYPE):
            raise ParameterTypeError("RGBImage.saturation: "
                                     "Expected factor type is int, not %s" % type(factor))

        status = dx_saturation(self.frame_data.image_buf, self.frame_data.image_buf,
                               self.frame_data.width * self.frame_data.height, factor)

        if status != DxStatus.OK:
            raise UnexpectedError("RGBImage.saturation: failed, error code:%s" % hex(status).__str__())

    def sharpen(self, factor):
        """
        :brief       Sharpen adjustment (RGB24)
        :param      factor:                 sharpen factor, range(0.1 ~ 5.0)
        :return:    None
        """
        if not isinstance(factor, (INT_TYPE, float)):
            raise ParameterTypeError("RGBImage.sharpen: "
                                     "Expected factor type is float, not %s" % type(factor))

        status = dx_sharpen_24b(self.frame_data.image_buf, self.frame_data.image_buf, self.frame_data.width,
                                self.frame_data.height, factor)

        if status != DxStatus.OK:
            raise UnexpectedError("RGBImage.sharpen: failed, error code:%s" % hex(status).__str__())

    def get_numpy_array(self):
        """
        :brief:     Return data as a numpy.Array type with dimension Image.height * Image.width * 3
        :return:    numpy.Array objects
        """
        image_np = numpy.frombuffer(self.__image_array, dtype=numpy.ubyte).reshape(self.frame_data.height, self.frame_data.width, 3)
        return image_np

    def get_image_size(self):
        """
        :brief      Get RGB data size
        :return:    size
        """
        return self.frame_data.image_size


class RawImage:
    def __init__(self, frame_data):
        self.frame_data = frame_data

        if self.frame_data.image_buf is not None:
            self.__image_array = string_at(self.frame_data.image_buf, self.frame_data.image_size)
        else:
            self.__image_array = (c_ubyte * self.frame_data.image_size)()
            self.frame_data.image_buf = addressof(self.__image_array)

    def __get_bit_depth(self, pixel_format):
        """
        :brief      Calculate pixel depth based on pixel format
        :param      pixel_format
        :return:    pixel depth
        """
        bpp10_tup = (GxPixelFormatEntry.MONO10, GxPixelFormatEntry.BAYER_GR10, GxPixelFormatEntry.BAYER_RG10,
                     GxPixelFormatEntry.BAYER_GB10, GxPixelFormatEntry.BAYER_BG10)

        bpp12_tup = (GxPixelFormatEntry.MONO12, GxPixelFormatEntry.BAYER_GR12, GxPixelFormatEntry.BAYER_RG12,
                     GxPixelFormatEntry.BAYER_GB12, GxPixelFormatEntry.BAYER_BG12)

        bpp16_tup = (GxPixelFormatEntry.MONO16, GxPixelFormatEntry.BAYER_GR16, GxPixelFormatEntry.BAYER_RG16,
                     GxPixelFormatEntry.BAYER_GB16, GxPixelFormatEntry.BAYER_BG16)

        if (pixel_format & PIXEL_BIT_MASK) == GX_PIXEL_8BIT:
            return GxPixelSizeEntry.BPP8
        elif pixel_format in bpp10_tup:
            return GxPixelSizeEntry.BPP10
        elif pixel_format in bpp12_tup:
            return GxPixelSizeEntry.BPP12
        elif pixel_format == GxPixelFormatEntry.MONO14:
            return GxPixelSizeEntry.BPP14
        elif pixel_format in bpp16_tup:
            return GxPixelSizeEntry.BPP16
        elif (pixel_format & PIXEL_BIT_MASK) == GX_PIXEL_24BIT:
            return GxPixelSizeEntry.BPP24
        elif (pixel_format & PIXEL_BIT_MASK) == GX_PIXEL_48BIT:
            return GxPixelSizeEntry.BPP48
        else:
            return -1

    def __get_pixel_color_filter(self, pixel_format):
        """
        :brief      Calculate pixel color filter based on pixel format
        :param      pixel_format
        :return:    pixel color filter
        """
        gr_tup = (GxPixelFormatEntry.BAYER_GR8, GxPixelFormatEntry.BAYER_GR10,
                  GxPixelFormatEntry.BAYER_GR12, GxPixelFormatEntry.BAYER_GR16)
        rg_tup = (GxPixelFormatEntry.BAYER_RG8, GxPixelFormatEntry.BAYER_RG10,
                  GxPixelFormatEntry.BAYER_RG12, GxPixelFormatEntry.BAYER_RG16)
        gb_tup = (GxPixelFormatEntry.BAYER_GB8, GxPixelFormatEntry.BAYER_GB10,
                  GxPixelFormatEntry.BAYER_GB12, GxPixelFormatEntry.BAYER_GB16)
        bg_tup = (GxPixelFormatEntry.BAYER_BG8, GxPixelFormatEntry.BAYER_BG10,
                  GxPixelFormatEntry.BAYER_BG12, GxPixelFormatEntry.BAYER_BG16)
        mono_tup = (GxPixelFormatEntry.MONO8, GxPixelFormatEntry.MONO8_SIGNED,
                    GxPixelFormatEntry.MONO10, GxPixelFormatEntry.MONO12,
                    GxPixelFormatEntry.MONO14, GxPixelFormatEntry.MONO16)

        if pixel_format in gr_tup:
            return DxPixelColorFilter.GR
        elif pixel_format in rg_tup:
            return DxPixelColorFilter.RG
        elif pixel_format in gb_tup:
            return DxPixelColorFilter.GB
        elif pixel_format in bg_tup:
            return DxPixelColorFilter.BG
        elif pixel_format in mono_tup:
            return DxPixelColorFilter.NONE
        else:
            return -1

    def __pixel_format_raw16_to_raw8(self, pixel_format):
        """
        :brief      convert raw16 to raw8, the pixel format need convert to 8bit bayer format
        :param      pixel_format(10bit, 12bit, 16bit)
        :return:    pixel_format(8bit)
        """
        gr16_tup = (GxPixelFormatEntry.BAYER_GR10, GxPixelFormatEntry.BAYER_GR12, GxPixelFormatEntry.BAYER_GR16)
        rg16_tup = (GxPixelFormatEntry.BAYER_RG10, GxPixelFormatEntry.BAYER_RG12, GxPixelFormatEntry.BAYER_RG16)
        gb16_tup = (GxPixelFormatEntry.BAYER_GB10, GxPixelFormatEntry.BAYER_GB12, GxPixelFormatEntry.BAYER_GB16)
        bg16_tup = (GxPixelFormatEntry.BAYER_BG10, GxPixelFormatEntry.BAYER_BG12, GxPixelFormatEntry.BAYER_BG16)
        mono16_tup = (GxPixelFormatEntry.MONO10, GxPixelFormatEntry.MONO12,
                      GxPixelFormatEntry.MONO14, GxPixelFormatEntry.MONO16)

        if pixel_format in gr16_tup:
            return GxPixelFormatEntry.BAYER_GR8
        elif pixel_format in rg16_tup:
            return GxPixelFormatEntry.BAYER_RG8
        elif pixel_format in gb16_tup:
            return GxPixelFormatEntry.BAYER_GB8
        elif pixel_format in bg16_tup:
            return GxPixelFormatEntry.BAYER_BG8
        elif pixel_format in mono16_tup:
            return GxPixelFormatEntry.MONO8
        else:
            return -1

    def __raw16_to_raw8(self, pixel_bit_depth, valid_bits):
        """
        :brief      convert raw16 to raw8
        :param      pixel_bit_depth     pixel bit depth
        :param      valid_bits:         data valid digit[DxValidBit]
        :return:    RAWImage object
        """
        if pixel_bit_depth == GxPixelSizeEntry.BPP10:
            valid_bits = min(valid_bits, DxValidBit.BIT2_9)
        elif pixel_bit_depth == GxPixelSizeEntry.BPP12:
            valid_bits = min(valid_bits, DxValidBit.BIT4_11)
        else:
            print("RawImage.__dx_raw16_to_raw8: Only support 10bit and 12bit")
            return None

        frame_data = GxFrameData()
        frame_data.status = self.frame_data.status
        frame_data.width = self.frame_data.width
        frame_data.height = self.frame_data.height
        frame_data.pixel_format = self.__pixel_format_raw16_to_raw8(self.frame_data.pixel_format)
        frame_data.image_size = self.frame_data.width * self.frame_data.height
        frame_data.frame_id = self.frame_data.frame_id
        frame_data.timestamp = self.frame_data.timestamp
        # frame_data.buf_id = self.frame_data.buf_id
        frame_data.image_buf = None
        image_raw8 = RawImage(frame_data)

        status = dx_raw16_to_raw8(self.frame_data.image_buf, image_raw8.frame_data.image_buf,
                                  self.frame_data.width, self.frame_data.height, valid_bits)

        if status != DxStatus.OK:
            raise UnexpectedError("RawImage.convert: raw16 convert to raw8 failed, Error core: %s"
                                  % hex(status).__str__())
        else:
            return image_raw8

    def __raw8_to_rgb(self, raw8_image, convert_type, pixel_color_filter, flip):
        """
        :brief      convert raw8 to RGB
        :param      raw8_image          RAWImage object, bit depth is 8bit
        :param      convert_type:       Bayer convert type, See detail in DxBayerConvertType
        :param      pixel_color_filter: pixel color filter, See detail in DxPixelColorFilter
        :param      flip:               Output image flip flag
                                        True: turn the image upside down
                                        False: do not flip
        :return:    RAWImage object
        """
        frame_data = GxFrameData()
        frame_data.status = raw8_image.frame_data.status
        frame_data.width = raw8_image.frame_data.width
        frame_data.height = raw8_image.frame_data.height
        frame_data.pixel_format = GxPixelFormatEntry.RGB8_PLANAR
        frame_data.image_size = raw8_image.frame_data.width * raw8_image.frame_data.height * 3
        frame_data.frame_id = raw8_image.frame_data.frame_id
        frame_data.timestamp = raw8_image.frame_data.timestamp
        # frame_data.buf_id = self.frame_data.buf_id
        frame_data.image_buf = None
        image_rgb = RGBImage(frame_data)

        status = dx_raw8_to_rgb24(raw8_image.frame_data.image_buf, image_rgb.frame_data.image_buf,
                                  raw8_image.frame_data.width, raw8_image.frame_data.height,
                                  convert_type, pixel_color_filter, flip)

        if status != DxStatus.OK:
            raise UnexpectedError("RawImage.convert: failed, error code:%s" % hex(status).__str__())

        return image_rgb

    def convert(self, mode, flip=False, valid_bits=DxValidBit.BIT4_11,
                convert_type=DxBayerConvertType.NEIGHBOUR):
        """
        :brief      Image format convert
        :param      mode:           "RAW8":     convert raw16 RAWImage object to raw8 RAWImage object
                                    "RGB":   convert raw8 RAWImage object to RGBImage object
        :param      flip:           Output image flip flag
                                    True: turn the image upside down
                                    False: do not flip
        :param      valid_bits:     Data valid digit, See detail in DxValidBit, raw8 don't this param
        :param      convert_type:   Bayer convert type, See detail in DxBayerConvertType
        :return:    return image object according to mode parameter
        """
        if self.frame_data.status != GxFrameStatusList.SUCCESS:
            print("RawImage.convert: This is a incomplete image")
            return None

        if not isinstance(flip, bool):
            raise ParameterTypeError("RawImage.convert: "
                                     "Expected flip type is bool, not %s" % type(flip))

        if not isinstance(convert_type, INT_TYPE):
            raise ParameterTypeError("RawImage.convert: "
                                     "Expected convert_type type is int, not %s" % type(convert_type))

        if not isinstance(valid_bits, INT_TYPE):
            raise ParameterTypeError("RawImage.convert: "
                                     "Expected valid_bits type is int, not %s" % type(valid_bits))

        if not isinstance(mode, str):
            raise ParameterTypeError("RawImage.convert: "
                                     "Expected mode type is str, not %s" % type(mode))

        convert_type_dict = dict((name, getattr(DxBayerConvertType, name))
                                 for name in dir(DxBayerConvertType) if not name.startswith('__'))
        if convert_type not in convert_type_dict.values():
            print("RawImage.convert: convert_type out of bounds, %s" % convert_type_dict.__str__())
            return None

        valid_bits_dict = dict((name, getattr(DxValidBit, name))
                               for name in dir(DxValidBit) if not name.startswith('__'))
        if valid_bits not in valid_bits_dict.values():
            print("RawImage.convert: valid_bits out of bounds, %s" % valid_bits_dict.__str__())
            return None

        pixel_bit_depth = self.__get_bit_depth(self.frame_data.pixel_format)
        pixel_color_filter = self.__get_pixel_color_filter(self.frame_data.pixel_format)

        if pixel_bit_depth < GxPixelSizeEntry.BPP8 or \
           pixel_bit_depth > GxPixelSizeEntry.BPP12:
            print("RawImage.convert: This pixel format is not support")
            return None

        if mode == "RAW8":
            if flip is True:
                print('''RawImage.convert: mode="RAW8" don't support flip=True''')
                return None

            if pixel_bit_depth in (GxPixelSizeEntry.BPP10, GxPixelSizeEntry.BPP12):
                image_raw8 = self.__raw16_to_raw8(pixel_bit_depth, valid_bits)
                return image_raw8
            else:
                print('RawImage.convert: mode="RAW8" only support 10bit and 12bit')
        elif mode == "RGB":
            if pixel_bit_depth in (GxPixelSizeEntry.BPP10, GxPixelSizeEntry.BPP12):
                image_raw8 = self.__raw16_to_raw8(pixel_bit_depth, valid_bits)
            else:
                image_raw8 = self

            return self.__raw8_to_rgb(image_raw8, convert_type, pixel_color_filter, flip)
        else:
            print('''RawImage.convert: mode="%s", isn't support''' % mode)
            return None

    def defective_pixel_correct(self):
        """
        :brief      Auto raw defective pixel correct,Support image from Raw8 to Raw16, the bit number is actual
                    bit number, when it is more than 8, the actual bit can be every number between 9 to 16.
                    And if image format is packed, you need convert it to Raw16.
                    This function should be used in each frame.
        :return:    None
        """
        pixel_bit_depth = self.__get_bit_depth(self.frame_data.pixel_format)
        status = dx_auto_raw_defective_pixel_correct(self.frame_data.image_buf, self.frame_data.width,
                                                     self.frame_data.height, pixel_bit_depth)

        if status != DxStatus.OK:
            raise UnexpectedError("RawImage.defective_pixel_correct: failed, error code:%s" % hex(status).__str__())

    def get_numpy_array(self):
        """
        :brief      Return data as a numpy.Array type with dimension Image.height * Image.width
        :return:    numpy.Array objects
        """
        if self.frame_data.status != GxFrameStatusList.SUCCESS:
            print("RawImage.get_numpy_array: This is a incomplete image")
            return None

        image_size = self.frame_data.width * self.frame_data.height

        if self.frame_data.pixel_format & PIXEL_BIT_MASK == GX_PIXEL_8BIT:
            image_np = numpy.frombuffer(self.__image_array, dtype=numpy.ubyte, count=image_size).\
                reshape(self.frame_data.height, self.frame_data.width)
        elif self.frame_data.pixel_format & PIXEL_BIT_MASK == GX_PIXEL_16BIT:
            image_np = numpy.frombuffer(self.__image_array, dtype=numpy.uint16, count=image_size).\
                reshape(self.frame_data.height, self.frame_data.width)
        else:
            image_np = None

        return image_np

    def get_data(self):
        """
        :brief      get Raw data
        :return:    raw data[string]
        """
        image_str = string_at(self.__image_array, self.frame_data.image_size)
        return image_str

    def save_raw(self, file_path):
        """
        :brief      save raw data
        :param      file_path:      file path
        :return:    None
        """
        if not isinstance(file_path, str):
            raise ParameterTypeError("RawImage.save_raw: "
                                     "Expected file_path type is str, not %s" % type(file_path))

        try:
            fp = open(file_path, "wb")
            fp.write(self.__image_array)
            fp.close()
        except Exception as error:
            raise UnexpectedError("RawImage.save_raw:%s" % error)

    def get_status(self):
        """
        :brief      get raw data status
        :return:    status
        """
        return self.frame_data.status

    def get_width(self):
        """
        :brief      get width of raw data
        :return:    width
        """
        return self.frame_data.width

    def get_height(self):
        """
        :brief     get height of raw data
        :return:
        """
        return self.frame_data.height

    def get_pixel_format(self):
        """
        :brief      Get image pixel format
        :return:    pixel format
        """
        return self.frame_data.pixel_format

    def get_image_size(self):
        """
        :brief      Get raw data size
        :return:    size
        """
        return self.frame_data.image_size

    def get_frame_id(self):
        """
        :brief      Get  frame id of raw data
        :return:    frame id
        """
        return self.frame_data.frame_id

    def get_timestamp(self):
        """
        :brief      Get timestamp of raw data
        :return:    timestamp
        """
        return self.frame_data.timestamp


class Utility:
    def __init__(self):
        pass

    @staticmethod
    def get_gamma_lut(gamma=1):
        if not (isinstance(gamma, (INT_TYPE, float))):
            raise ParameterTypeError("Utility.get_gamma_lut: "
                                     "Expected gamma type is float, not %s" % type(gamma))

        if (gamma < GAMMA_MIN) or (gamma > GAMMA_MAX):
            print("Utility.get_gamma_lut: gamma out of bounds, range:[0.1, 10.0]")
            return None

        status, gamma_lut, gamma_lut_len = dx_get_gamma_lut(gamma)
        if status != DxStatus.OK:
            print("Utility.get_gamma_lut: get gamma lut failure, Error code:%s" % hex(status).__str__())
            return None

        return Buffer(gamma_lut)

    @staticmethod
    def get_contrast_lut(contrast=0):
        if not (isinstance(contrast, INT_TYPE)):
            raise ParameterTypeError("Utility.get_contrast_lut: "
                                     "Expected contrast type is int, not %s" % type(contrast))

        if (contrast < CONTRAST_MIN) or (contrast > CONTRAST_MAX):
            print("Utility.get_contrast_lut: contrast out of bounds, range:[-50, 100]")
            return None

        status, contrast_lut, contrast_lut_len = dx_get_contrast_lut(contrast)
        if status != DxStatus.OK:
            print("Utility.get_contrast_lut: get contrast lut failure, Error code:%s" % hex(status).__str__())
            return None

        return Buffer(contrast_lut)


#!/usr/bin/python
# -*- coding:utf-8 -*-
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-

import numpy
from gxipy.gxwrapper import *
from gxipy.dxwrapper import *
from gxipy.gxidef import *

ERROR_SIZE = 1024
PIXEL_BIT_MASK = 0x00ff0000

if sys.version_info.major > 2:
    INT_TYPE = int
else:
    INT_TYPE = (int, long)
    

class DeviceManager(object):
    __instance_num = 0
    def __new__(cls, *args, **kw):
        cls.__instance_num += 1
        status = gx_init_lib()
        StatusProcessor.process(status, 'DeviceManager', 'init_lib')
        return object.__new__(cls, *args)
    
    def __init__(self):
        self.__device_num = 0
        self.__device_info_list = []

        

    def __del__(self):
        self.__class__.__instance_num -= 1
        if self.__class__.__instance_num <= 0:
            status = gx_close_lib()
            StatusProcessor.process(status, 'DeviceManager', 'close_lib')

    def __get_device_info_list(self, base_info, ip_info, num):
        """
        :brief      Convert GxDeviceBaseInfo and GxDeviceIPInfo to device info list
        :param      base_info:  device base info list[GxDeviceBaseInfo]
        :param      ip_info:    device ip info list[GxDeviceIPInfo]
        :param      num:        device number
        :return:    device info list
        """
        device_info_list = []
        for i in range(num):
            device_info_list.append({
                'index': i+1,
                'vendor_name': string_decoding(base_info[i].vendor_name),
                'model_name': string_decoding(base_info[i].model_name),
                'sn': string_decoding(base_info[i].serial_number),
                'display_name': string_decoding(base_info[i].display_name),
                'device_id': string_decoding(base_info[i].device_id),
                'user_id': string_decoding(base_info[i].user_id),
                'access_status': base_info[i].access_status,
                'device_class': base_info[i].device_class,
                'mac': string_decoding(ip_info[i].mac),
                'ip': string_decoding(ip_info[i].ip),
                'subnet_mask': string_decoding(ip_info[i].subnet_mask),
                'gateway': string_decoding(ip_info[i].gateway),
                'nic_mac': string_decoding(ip_info[i].nic_mac),
                'nic_ip': string_decoding(ip_info[i].nic_ip),
                'nic_subnet_mask': string_decoding(ip_info[i].nic_subnet_mask),
                'nic_gateWay': string_decoding(ip_info[i].nic_gateWay),
                'nic_description': string_decoding(ip_info[i].nic_description)
            })

        return device_info_list

    def __get_ip_info(self, base_info_list, dev_mum):
        """
        :brief      Get the network information
        """

        ip_info_list = []
        for i in range(dev_mum):
            if base_info_list[i].device_class == GxDeviceClassList.GEV:
                status, ip_info = gx_get_device_ip_info(i+1)
                StatusProcessor.process(status, 'DeviceManager', '__get_ip_info')
                ip_info_list.append(ip_info)
            else:
                ip_info_list.append(GxDeviceIPInfo())

        return ip_info_list

    def update_device_list(self, timeout=200):
        """
        :brief      enumerate the same network segment devices
        :param      timeout:    Enumeration timeout, range:[0, 0xFFFFFFFF]
        :return:    dev_num:    device number
                    device_info_list: all device info list
        """
        if not isinstance(timeout, INT_TYPE):
            raise ParameterTypeError("DeviceManager.update_device_list: "
                                     "Expected timeout type is int, not %s" % type(timeout))

        if (timeout < 0) or (timeout > UNSIGNED_INT_MAX):
            print("DeviceManager.update_device_list: "
                  "timeout out of bounds, timeout: minimum=0, maximum=%s" % hex(UNSIGNED_INT_MAX).__str__())
            return 0, None

        status, dev_num = gx_update_device_list(timeout)
        StatusProcessor.process(status, 'DeviceManager', 'update_device_list')

        status, base_info_list = gx_get_all_device_base_info(dev_num)
        StatusProcessor.process(status, 'DeviceManager', 'update_device_list')

        ip_info_list = self.__get_ip_info(base_info_list, dev_num)
        self.__device_num = dev_num
        self.__device_info_list = self.__get_device_info_list(base_info_list, ip_info_list, dev_num)

        return self.__device_num, self.__device_info_list

    def update_all_device_list(self, timeout=200):
        """
        :brief      Enumerate devices on different network segments
        :param      timeout:    Enumeration timeout, range:[0, 0xFFFFFFFF]
        :return:    dev_num:    device number
                    device_info_list:   all device info list
        """
        if not isinstance(timeout, INT_TYPE):
            raise ParameterTypeError("DeviceManager.update_all_device_list: "
                                     "Expected timeout type is int, not %s" % type(timeout))

        if (timeout < 0) or (timeout > UNSIGNED_INT_MAX):
            print("DeviceManager.update_all_device_list: "
                  "timeout out of bounds, timeout: minimum=0, maximum=%s" % hex(UNSIGNED_INT_MAX).__str__())
            return 0, None

        status, dev_num = gx_update_all_device_list(timeout)
        StatusProcessor.process(status, 'DeviceManager', 'update_all_device_list')

        status, base_info_list = gx_get_all_device_base_info(dev_num)
        StatusProcessor.process(status, 'DeviceManager', 'update_all_device_list')

        ip_info_list = self.__get_ip_info(base_info_list, dev_num)
        self.__device_num = dev_num
        self.__device_info_list = self.__get_device_info_list(base_info_list, ip_info_list, dev_num)

        return self.__device_num, self.__device_info_list

    def get_device_number(self):
        """
        :brief      Get device number
        :return:    device number
        """
        return self.__device_num

    def get_device_info(self):
        """
        :brief      Get all device info
        :return:    info_dict:      device info list
        """
        return self.__device_info_list

    def open_device_by_index(self, index, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by index
                    USB3 device return U3VDevice object
                    USB2 device return U2Device object
                    GEV  device return GEVDevice object
        :param      index:          device index must start from 1
        :param      access_mode:    the access of open device
        :return:    Device object
        """
        if not isinstance(index, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_index: "
                                     "Expected index type is int, not %s" % type(index))

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_index: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        if index < 1:
            print("DeviceManager.open_device_by_index: index must start from 1")
            return None
        elif index > UNSIGNED_INT_MAX:
            print("DeviceManager.open_device_by_index: index maximum: %s" % hex(UNSIGNED_INT_MAX).__str__())
            return None

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_index: "
                  "access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        if self.__device_num < index:
            # Re-update the device
            self.update_device_list()
            if self.__device_num < index:
                raise NotFoundDevice("DeviceManager.open_device_by_index: invalid index")

        # open devices by index
        open_param = GxOpenParam()
        open_param.content = string_encoding(str(index))
        open_param.open_mode = GxOpenMode.INDEX
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_index')

        # get device class
        device_class = self.__device_info_list[index-1]["device_class"]

        if device_class == GxDeviceClassList.U3V:
            return U3VDevice(handle)
        elif device_class == GxDeviceClassList.USB2:
            return U2Device(handle)
        elif device_class == GxDeviceClassList.GEV:
            return GEVDevice(handle)
        else:
            raise NotFoundDevice("DeviceManager.open_device_by_index: Does not support this device type.")

    def __get_device_class_by_sn(self, sn):
        """
        :brief:     1.find device by sn in self.__device_info_list
                    2.return different objects according to device class
        :param      sn:      device serial number
        :return:    device class
        """
        for index in range(self.__device_num):
            if self.__device_info_list[index]["sn"] == sn:
                return self.__device_info_list[index]["device_class"]

        # don't find this id in device base info list
        return -1

    def open_device_by_sn(self, sn, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by serial number(SN)
                    USB3 device return U3VDevice object
                    USB2 device return U2Device object
                    GEV device return GEVDevice object
        :param      sn:             device serial number, type: str
        :param      access_mode:    the mode of open device[GxAccessMode]
        :return:    Device object
        """
        if not isinstance(sn, str):
            raise ParameterTypeError("DeviceManager.open_device_by_sn: "
                                     "Expected sn type is str, not %s" % type(sn))

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_sn: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_sn: "
                  "access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        # get device class from self.__device_info_list
        device_class = self.__get_device_class_by_sn(sn)
        if device_class == -1:
            # Re-update the device
            self.update_device_list()
            device_class = self.__get_device_class_by_sn(sn)
            if device_class == -1:
                # don't find this sn
                raise NotFoundDevice("DeviceManager.open_device_by_sn: Not found device")

        # open devices by sn
        open_param = GxOpenParam()
        open_param.content = string_encoding(sn)
        open_param.open_mode = GxOpenMode.SN
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_sn')

        if device_class == GxDeviceClassList.U3V:
            return U3VDevice(handle)
        elif device_class == GxDeviceClassList.USB2:
            return U2Device(handle)
        elif device_class == GxDeviceClassList.GEV:
            return GEVDevice(handle)
        else:
            raise NotFoundDevice("DeviceManager.open_device_by_sn: Does not support this device type.")

    def __get_device_class_by_user_id(self, user_id):
        """
        :brief:     1.find device according to sn in self.__device_info_list
                    2.return different objects according to device class
        :param      user_id:        user ID
        :return:    device class
        """
        for index in range(self.__device_num):
            if self.__device_info_list[index]["user_id"] == user_id:
                return self.__device_info_list[index]["device_class"]

        # don't find this id in device base info list
        return -1

    def open_device_by_user_id(self, user_id, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by user defined name
                    USB3 device return U3VDevice object
                    GEV  device return GEVDevice object
        :param      user_id:        user defined name, type:str
        :param      access_mode:    the mode of open device[GxAccessMode]
        :return:    Device object
        """
        if not isinstance(user_id, str):
            raise ParameterTypeError("DeviceManager.open_device_by_user_id: "
                                     "Expected user_id type is str, not %s" % type(user_id))
        elif user_id.__len__() == 0:
            raise InvalidParameter("DeviceManager.open_device_by_user_id: Don't support user_id's length is 0")

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_user_id: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_user_id: access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        # get device class from self.__device_info_list
        device_class = self.__get_device_class_by_user_id(user_id)
        if device_class == -1:
            # Re-update the device
            self.update_device_list()
            device_class = self.__get_device_class_by_user_id(user_id)
            if device_class == -1:
                # don't find this user_id
                raise NotFoundDevice("DeviceManager.open_device_by_user_id: Not found device")

        # open device by user_id
        open_param = GxOpenParam()
        open_param.content = string_encoding(user_id)
        open_param.open_mode = GxOpenMode.USER_ID
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_user_id')

        if device_class == GxDeviceClassList.U3V:
            return U3VDevice(handle)
        elif device_class == GxDeviceClassList.GEV:
            return GEVDevice(handle)
        else:
            raise NotFoundDevice("DeviceManager.open_device_by_user_id: Does not support this device type.")

    def open_device_by_ip(self, ip, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by device ip address
        :param      ip:             device ip address, type:str
        :param      access_mode:    the mode of open device[GxAccessMode]
        :return:    GEVDevice object
        """
        if not isinstance(ip, str):
            raise ParameterTypeError("DeviceManager.open_device_by_ip: "
                                     "Expected ip type is str, not %s" % type(ip))

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_ip: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_ip: access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        # open device by ip
        open_param = GxOpenParam()
        open_param.content = string_encoding(ip)
        open_param.open_mode = GxOpenMode.IP
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_ip')

        return GEVDevice(handle)

    def open_device_by_mac(self, mac, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by device mac address
        :param      mac:            device mac address, type:str
        :param      access_mode:    the mode of open device[GxAccessMode]
        :return:    GEVDevice object
        """
        if not isinstance(mac, str):
            raise ParameterTypeError("DeviceManager.open_device_by_mac: "
                                     "Expected mac type is str, not %s" % type(mac))

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_mac: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_mac: access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        # open device by ip
        open_param = GxOpenParam()
        open_param.content = string_encoding(mac)
        open_param.open_mode = GxOpenMode.MAC
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_mac')

        return GEVDevice(handle)


class Feature:
    def __init__(self, handle, feature):
        """
        :param  handle:      The handle of the device
        :param  feature:     The feature code ID
        """
        self.__handle = handle
        self.__feature = feature
        self.feature_name = self.get_name()

    def get_name(self):
        """
        brief:  Getting Feature Name
        return: Success:    feature name
                Failed:     convert feature ID to string
        """
        status, name = gx_get_feature_name(self.__handle, self.__feature)
        if status != GxStatusList.SUCCESS:
            name = (hex(self.__feature)).__str__()

        return name

    def is_implemented(self):
        """
        brief:  Determining whether the feature is implemented
        return: is_implemented
        """
        status, is_implemented = gx_is_implemented(self.__handle, self.__feature)
        if status == GxStatusList.SUCCESS:
            return is_implemented
        elif status == GxStatusList.INVALID_PARAMETER:
            return False
        else:
            StatusProcessor.process(status, 'Feature', 'is_implemented')

    def is_readable(self):
        """
        brief:  Determining whether the feature is readable
        return: is_readable
        """
        implemented = self.is_implemented()
        if not implemented:
            return False

        status, is_readable = gx_is_readable(self.__handle, self.__feature)
        StatusProcessor.process(status, 'Feature', 'is_readable')
        return is_readable

    def is_writable(self):
        """
        brief:  Determining whether the feature is writable
        return: is_writable
        """
        implemented = self.is_implemented()
        if not implemented:
            return False

        status, is_writable = gx_is_writable(self.__handle, self.__feature)
        StatusProcessor.process(status, 'Feature', 'is_writable')
        return is_writable


class IntFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param  handle:      The handle of the device
        :param  feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def __range_dict(self, int_range):
        """
        :brief      Convert GxIntRange to dictionary
        :param      int_range:  GxIntRange
        :return:    range_dicts
        """
        range_dicts = {
            "min": int_range.min,
            "max": int_range.max,
            "inc": int_range.inc
        }
        return range_dicts

    def get_range(self):
        """
        :brief      Getting integer range
        :return:    integer range dictionary
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_range is not support" % self.feature_name)
            return None

        status, int_range = gx_get_int_range(self.__handle, self.__feature)
        StatusProcessor.process(status, 'IntFeature', 'get_range')
        return self.__range_dict(int_range)

    def get(self):
        """
        :brief      Getting integer value
        :return:    integer value
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get is not readable" % self.feature_name)
            return None

        status, int_value = gx_get_int(self.__handle, self.__feature)
        StatusProcessor.process(status, 'IntFeature', 'get')
        return int_value

    def set(self, int_value):
        """
        :brief      Setting integer value
        :param      int_value
        :return:    None
        """
        if not isinstance(int_value, INT_TYPE):
            raise ParameterTypeError("IntFeature.set: "
                                     "Expected int_value type is int, not %s" % type(int_value))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        int_range = self.get_range()
        check_ret = range_check(int_value, int_range["min"], int_range["max"], int_range["inc"])
        if not check_ret:
            print("IntFeature.set: "
                  "int_value out of bounds, %s.range=[%d, %d, %d]" %
                  (self.feature_name, int_range["min"], int_range["max"], int_range["inc"]))
            return

        status = gx_set_int(self.__handle, self.__feature, int_value)
        StatusProcessor.process(status, 'IntFeature', 'set')


class FloatFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param      handle:      The handle of the device
        :param      feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def __range_dict(self, float_range):
        """
        :brief      Convert GxFloatRange to dictionary
        :param      float_range:  GxFloatRange
        :return:    range_dicts
        """
        range_dicts = {
            "min": float_range.min,
            "max": float_range.max,
            "inc": float_range.inc,
            "unit": string_decoding(float_range.unit),
            "inc_is_valid": float_range.inc_is_valid
        }
        return range_dicts

    def get_range(self):
        """
        :brief      Getting float range
        :return:    float range dictionary
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_range is not support" % self.feature_name)
            return None

        status, float_range = gx_get_float_range(self.__handle, self.__feature)
        StatusProcessor.process(status, 'FloatFeature', 'get_range')
        return self.__range_dict(float_range)

    def get(self):
        """
        :brief      Getting float value
        :return:    float value
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get: is not readable" % self.feature_name)
            return None

        status, float_value = gx_get_float(self.__handle, self.__feature)
        StatusProcessor.process(status, 'FloatFeature', 'get')
        return float_value

    def set(self, float_value):
        """
        :brief      Setting float value
        :param      float_value
        :return:    None
        """
        if not isinstance(float_value, (INT_TYPE, float)):
            raise ParameterTypeError("FloatFeature.set: "
                                     "Expected float_value type is float, not %s" % type(float_value))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        float_range = self.get_range()
        check_ret = range_check(float_value, float_range["min"], float_range["max"])
        if not check_ret:
            print("FloatFeature.set: float_value out of bounds, %s.range=[%f, %f]" %
                  (self.feature_name, float_range["min"], float_range["max"]))
            return

        status = gx_set_float(self.__handle, self.__feature, float_value)
        StatusProcessor.process(status, 'FloatFeature', 'set')


class EnumFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param handle:      The handle of the device
        :param feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def get_range(self):
        """
        :brief      Getting range of Enum feature
        :return:    enum_dict:    enum range dictionary
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_range: is not support" % self.feature_name)
            return None

        status, enum_num = gx_get_enum_entry_nums(self.__handle, self.__feature)
        StatusProcessor.process(status, 'EnumFeature', 'get_range')

        status, enum_list = gx_get_enum_description(self.__handle, self.__feature, enum_num)
        StatusProcessor.process(status, 'EnumFeature', 'get_range')

        enum_dict = {}
        for i in range(enum_num):
            enum_dict[string_decoding(enum_list[i].symbolic)] = enum_list[i].value

        return enum_dict

    def get(self):
        """
        :brief      Getting value of Enum feature
        :return:    enum_value:     enum value
                    enum_str:       string for enum description
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get: is not readable" % self.feature_name)
            return None, None

        status, enum_value = gx_get_enum(self.__handle, self.__feature)
        StatusProcessor.process(status, 'EnumFeature', 'get')

        range_dict = self.get_range()
        new_dicts = {v: k for k, v in range_dict.items()}
        return enum_value, new_dicts[enum_value]

    def set(self, enum_value):
        """
        :brief      Setting enum value
        :param      enum_value
        :return:    None
        """
        if not isinstance(enum_value, INT_TYPE):
            raise ParameterTypeError("EnumFeature.set: "
                                     "Expected enum_value type is int, not %s" % type(enum_value))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        range_dict = self.get_range()
        enum_value_list = range_dict.values()
        if enum_value not in enum_value_list:
            print("EnumFeature.set: enum_value out of bounds, %s.range:%s" %
                  (self.feature_name, range_dict.__str__()))
            return

        status = gx_set_enum(self.__handle, self.__feature, enum_value)
        StatusProcessor.process(status, 'EnumFeature', 'set')


class BoolFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param handle:      The handle of the device
        :param feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def get(self):
        """
        :brief      Getting bool value
        :return:    bool value[bool]
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get is not readable" % self.feature_name)
            return None

        status, bool_value = gx_get_bool(self.__handle, self.__feature)
        StatusProcessor.process(status, 'BoolFeature', 'get')
        return bool_value

    def set(self, bool_value):
        """
        :brief      Setting bool value
        :param      bool_value[bool]
        :return:    None
        """
        if not isinstance(bool_value, bool):
            raise ParameterTypeError("BoolFeature.set: "
                                     "Expected bool_value type is bool, not %s" % type(bool_value))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        status = gx_set_bool(self.__handle, self.__feature, bool_value)
        StatusProcessor.process(status, 'BoolFeature', 'set')


class StringFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param      handle:      The handle of the device
        :param      feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def get_string_max_length(self):
        """
        :brief      Getting the maximum length that string can set
        :return:    length:     the maximum length that string can set
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_string_max_length is not support" % self.feature_name)
            return None

        status, length = gx_get_string_max_length(self.__handle, self.__feature)
        StatusProcessor.process(status, 'StringFeature', 'get_string_max_length')
        return length

    def get(self):
        """
        :brief      Getting string value
        :return:    strings
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get is not readable" % self.feature_name)
            return None

        status, strings = gx_get_string(self.__handle, self.__feature)
        StatusProcessor.process(status, 'StringFeature', 'get')
        return strings

    def set(self, input_string):
        """
        :brief      Setting string value
        :param      input_string[string]
        :return:    None
        """
        if not isinstance(input_string, str):
            raise ParameterTypeError("StringFeature.set: "
                                     "Expected input_string type is str, not %s" % type(input_string))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        max_length = self.get_string_max_length()
        if input_string.__len__() > max_length:
            print("StringFeature.set: "
                  "input_string length out of bounds, %s.length_max:%s"
                  % (self.feature_name, max_length))
            return

        status = gx_set_string(self.__handle, self.__feature, input_string)
        StatusProcessor.process(status, 'StringFeature', 'set')


class BufferFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param      handle:      The handle of the device
        :param      feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def get_buffer_length(self):
        """
        :brief      Getting buffer length
        :return:    length:     buffer length
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_buffer_length is not support" % self.feature_name)
            return None

        status, length = gx_get_buffer_length(self.__handle, self.__feature)
        StatusProcessor.process(status, 'BuffFeature', 'get_buffer_length')
        return length

    def get_buffer(self):
        """
        :brief      Getting buffer data
        :return:    Buffer object

        """
        readable = self.is_readable()
        if not readable:
            print("%s.get_buffer is not readable" % self.feature_name)
            return None

        status, buf = gx_get_buffer(self.__handle, self.__feature)
        StatusProcessor.process(status, 'BuffFeature', 'get_buffer')
        return Buffer(buf)

    def set_buffer(self, buf):
        """
        :brief      Setting buffer data
        :param      buf:    Buffer object
        :return:    None
        """
        if not isinstance(buf, Buffer):
            raise ParameterTypeError("BuffFeature.set_buffer: "
                                     "Expected buff type is Buffer, not %s" % type(buf))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set_buffer is not writeable" % self.feature_name)
            return

        max_length = self.get_buffer_length()
        if buf.get_length() > max_length:
            print("BuffFeature.set_buffer: "
                  "buff length out of bounds, %s.length_max:%s" % (self.feature_name, max_length))
            return

        status = gx_set_buffer(self.__handle, self.__feature,
                               buf.get_ctype_array(), buf.get_length())
        StatusProcessor.process(status, 'BuffFeature', 'set_buffer')


class CommandFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param      handle:      The handle of the device
        :param      feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def send_command(self):
        """
        :brief      Sending command
        :return:    None
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.send_command is not support" % self.feature_name)
            return

        status = gx_send_command(self.__handle, self.__feature)
        StatusProcessor.process(status, 'CommandFeature', 'send_command')


class Buffer:
    def __init__(self, data_array):
        try:
            addressof(data_array)
        except TypeError:
            error_msg = "Buffer.__init__: param is error type."
            raise ParameterTypeError(error_msg)

        self.data_array = data_array

    @staticmethod
    def from_file(file_name):
        file_object = open(file_name, "rb")
        file_string = file_object.read()
        data_array = create_string_buffer(file_string)
        file_object.close()
        return Buffer(data_array)

    @staticmethod
    def from_string(string_data):
        data_array = create_string_buffer(string_data)
        return Buffer(data_array)

    def get_data(self):
        buff_p = c_void_p()
        buff_p.value = addressof(self.data_array)
        string_data = string_at(buff_p, len(self.data_array))
        return string_data

    def get_ctype_array(self):
        return self.data_array

    def get_numpy_array(self):
        numpy_array = numpy.array(self.data_array)
        return numpy_array

    def get_length(self):
        return len(self.data_array)


class Device:
    """
    The Camera class mainly encapsulates some common operations and function attributes,
    which are the operations and properties usually found in the camera.
    In addition, this class also encapsulates the common operations of  some functions in the C interface,
    such as SetInt, SetFloat, etc. Can not open to the user, so that when the subsequent addition of features,
    Python interface does not upgrade, or only the definition of the control code can support new features
    """
    def __init__(self, handle):
        self.__dev_handle = handle
        self.data_stream = []

        # ---------------Device Information Section--------------------------
        self.DeviceVendorName = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_VENDOR_NAME)
        self.DeviceModelName = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_MODEL_NAME)
        self.DeviceFirmwareVersion = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_FIRMWARE_VERSION)
        self.DeviceVersion = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_VERSION)
        self.DeviceSerialNumber = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_SERIAL_NUMBER)
        self.FactorySettingVersion = StringFeature(self.__dev_handle, GxFeatureID.STRING_FACTORY_SETTING_VERSION)
        self.DeviceUserID = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_USER_ID)
        self.DeviceLinkSelector = IntFeature(self.__dev_handle, GxFeatureID.INT_DEVICE_LINK_SELECTOR)
        self.DeviceLinkThroughputLimitMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_DEVICE_LINK_THROUGHPUT_LIMIT_MODE)
        self.DeviceLinkThroughputLimit = IntFeature(self.__dev_handle, GxFeatureID.INT_DEVICE_LINK_THROUGHPUT_LIMIT)
        self.DeviceLinkCurrentThroughput = IntFeature(self.__dev_handle, GxFeatureID.INT_DEVICE_LINK_CURRENT_THROUGHPUT)
        self.DeviceReset = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_DEVICE_RESET)
        self.TimestampTickFrequency = IntFeature(self.__dev_handle, GxFeatureID.INT_TIMESTAMP_TICK_FREQUENCY)
        self.TimestampLatch = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TIMESTAMP_LATCH)
        self.TimestampReset = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TIMESTAMP_RESET)
        self.TimestampLatchReset = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TIMESTAMP_LATCH_RESET)
        self.TimestampLatchValue = IntFeature(self.__dev_handle, GxFeatureID.INT_TIMESTAMP_LATCH_VALUE)

        # ---------------ImageFormat Section--------------------------------
        self.SensorWidth = IntFeature(self.__dev_handle, GxFeatureID.INT_SENSOR_WIDTH)
        self.SensorHeight = IntFeature(self.__dev_handle, GxFeatureID.INT_SENSOR_HEIGHT)
        self.WidthMax = IntFeature(self.__dev_handle, GxFeatureID.INT_WIDTH_MAX)
        self.HeightMax = IntFeature(self.__dev_handle, GxFeatureID.INT_HEIGHT_MAX)
        self.OffsetX = IntFeature(self.__dev_handle, GxFeatureID.INT_OFFSET_X)
        self.OffsetY = IntFeature(self.__dev_handle, GxFeatureID.INT_OFFSET_Y)
        self.Width = IntFeature(self.__dev_handle, GxFeatureID.INT_WIDTH)
        self.Height = IntFeature(self.__dev_handle, GxFeatureID.INT_HEIGHT)
        self.BinningHorizontal = IntFeature(self.__dev_handle, GxFeatureID.INT_BINNING_HORIZONTAL)
        self.BinningVertical = IntFeature(self.__dev_handle, GxFeatureID.INT_BINNING_VERTICAL)
        self.DecimationHorizontal = IntFeature(self.__dev_handle, GxFeatureID.INT_DECIMATION_HORIZONTAL)
        self.DecimationVertical = IntFeature(self.__dev_handle, GxFeatureID.INT_DECIMATION_VERTICAL)
        self.PixelSize = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_PIXEL_SIZE)
        self.PixelColorFilter = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_PIXEL_COLOR_FILTER)
        self.PixelFormat = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_PIXEL_FORMAT)
        self.ReverseX = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_REVERSE_X)
        self.ReverseY = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_REVERSE_Y)
        self.TestPattern = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TEST_PATTERN)
        self.TestPatternGeneratorSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TEST_PATTERN_GENERATOR_SELECTOR)
        self.RegionSendMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_REGION_SEND_MODE)
        self.RegionMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_REGION_MODE)
        self.RegionSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_REGION_SELECTOR)
        self.CenterWidth = IntFeature(self.__dev_handle, GxFeatureID.INT_CENTER_WIDTH)
        self.CenterHeight = IntFeature(self.__dev_handle, GxFeatureID.INT_CENTER_HEIGHT)
        self.BinningHorizontalMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BINNING_HORIZONTAL_MODE)
        self.BinningVerticalMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BINNING_VERTICAL_MODE)

        # ---------------TransportLayer Section-------------------------------
        self.PayloadSize = IntFeature(self.__dev_handle, GxFeatureID.INT_PAYLOAD_SIZE)

        # ---------------AcquisitionTrigger Section---------------------------
        self.AcquisitionMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_ACQUISITION_MODE)
        self.AcquisitionStart = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_ACQUISITION_START)
        self.AcquisitionStop = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_ACQUISITION_STOP)
        self.TriggerMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_MODE)
        self.TriggerSoftware = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TRIGGER_SOFTWARE)
        self.TriggerActivation = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_ACTIVATION)
        self.ExposureTime = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_EXPOSURE_TIME)
        self.ExposureAuto = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_EXPOSURE_AUTO)
        self.TriggerFilterRaisingEdge = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TRIGGER_FILTER_RAISING)
        self.TriggerFilterFallingEdge = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TRIGGER_FILTER_FALLING)
        self.TriggerSource = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_SOURCE)
        self.ExposureMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_EXPOSURE_MODE)
        self.TriggerSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_SELECTOR)
        self.TriggerDelay = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TRIGGER_DELAY)
        self.TransferControlMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRANSFER_CONTROL_MODE)
        self.TransferOperationMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRANSFER_OPERATION_MODE)
        self.TransferStart = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TRANSFER_START)
        self.TransferBlockCount = IntFeature(self.__dev_handle, GxFeatureID.INT_TRANSFER_BLOCK_COUNT)
        self.FrameBufferOverwriteActive = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_FRAME_STORE_COVER_ACTIVE)
        self.AcquisitionFrameRateMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_ACQUISITION_FRAME_RATE_MODE)
        self.AcquisitionFrameRate = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_ACQUISITION_FRAME_RATE)
        self.CurrentAcquisitionFrameRate = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_CURRENT_ACQUISITION_FRAME_RATE)
        self.FixedPatternNoiseCorrectMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_FIXED_PATTERN_NOISE_CORRECT_MODE)
        self.AcquisitionBurstFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_ACQUISITION_BURST_FRAME_COUNT)
        self.AcquisitionStatusSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_ACQUISITION_STATUS_SELECTOR)
        self.AcquisitionStatus = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_ACQUISITION_STATUS)
        self.ExposureDelay = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_EXPOSURE_DELAY)

        # ----------------DigitalIO Section----------------------------------
        self.UserOutputSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_USER_OUTPUT_SELECTOR)
        self.UserOutputValue = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_USER_OUTPUT_VALUE)
        self.LineSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_LINE_SELECTOR)
        self.LineMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_LINE_MODE)
        self.LineInverter = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_LINE_INVERTER)
        self.LineSource = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_LINE_SOURCE)
        self.LineStatus = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_LINE_STATUS)
        self.LineStatusAll = IntFeature(self.__dev_handle, GxFeatureID.INT_LINE_STATUS_ALL)

        # ----------------AnalogControls Section----------------------------
        self.GainAuto = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_GAIN_AUTO)
        self.GainSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_GAIN_SELECTOR)
        self.BlackLevelAuto = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BLACK_LEVEL_AUTO)
        self.BlackLevelSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BLACK_LEVEL_SELECTOR)
        self.BalanceWhiteAuto = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BALANCE_WHITE_AUTO)
        self.BalanceRatioSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BALANCE_RATIO_SELECTOR)
        self.BalanceRatio = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_BALANCE_RATIO)
        self.DeadPixelCorrect = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_DEAD_PIXEL_CORRECT)
        self.Gain = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_GAIN)
        self.BlackLevel = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_BLACK_LEVEL)
        self.GammaEnable = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_GAMMA_ENABLE)
        self.GammaMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_GAMMA_MODE)
        self.Gamma = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_GAMMA)
        self.DigitalShift = IntFeature(self.__dev_handle, GxFeatureID.INT_DIGITAL_SHIFT)

        # ---------------CustomFeature Section------------------------------
        self.ExpectedGrayValue = IntFeature(self.__dev_handle, GxFeatureID.INT_GRAY_VALUE)
        self.AAROIOffsetX = IntFeature(self.__dev_handle, GxFeatureID.INT_AAROI_OFFSETX)
        self.AAROIOffsetY = IntFeature(self.__dev_handle, GxFeatureID.INT_AAROI_OFFSETY)
        self.AAROIWidth = IntFeature(self.__dev_handle, GxFeatureID.INT_AAROI_WIDTH)
        self.AAROIHeight = IntFeature(self.__dev_handle, GxFeatureID.INT_AAROI_HEIGHT)
        self.AutoGainMin = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_AUTO_GAIN_MIN)
        self.AutoGainMax = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_AUTO_GAIN_MAX)
        self.AutoExposureTimeMin = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_AUTO_EXPOSURE_TIME_MIN)
        self.AutoExposureTimeMax = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_AUTO_EXPOSURE_TIME_MAX)
        self.ContrastParam = IntFeature(self.__dev_handle, GxFeatureID.INT_CONTRAST_PARAM)
        self.GammaParam = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_GAMMA_PARAM)
        self.ColorCorrectionParam = IntFeature(self.__dev_handle, GxFeatureID.INT_COLOR_CORRECTION_PARAM)
        self.AWBLampHouse = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_AWB_LAMP_HOUSE)
        self.AWBROIOffsetX = IntFeature(self.__dev_handle, GxFeatureID.INT_AWBROI_OFFSETX)
        self.AWBROIOffsetY = IntFeature(self.__dev_handle, GxFeatureID.INT_AWBROI_OFFSETY)
        self.AWBROIWidth = IntFeature(self.__dev_handle, GxFeatureID.INT_AWBROI_WIDTH)
        self.AWBROIHeight = IntFeature(self.__dev_handle, GxFeatureID.INT_AWBROI_HEIGHT)
        self.SharpnessMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_SHARPNESS_MODE)
        self.Sharpness = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_SHARPNESS)

        # ---------------UserSetControl Section-------------------------
        self.UserSetSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_USER_SET_SELECTOR)
        self.UserSetLoad = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_USER_SET_LOAD)
        self.UserSetSave = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_USER_SET_SAVE)
        self.UserSetDefault = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_USER_SET_DEFAULT)

        # ---------------LUT Section-------------------------------
        self.LUTSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_LUT_SELECTOR)
        self.LUTValueAll = BufferFeature(self.__dev_handle, GxFeatureID.BUFFER_LUT_VALUE_ALL)
        self.LUTEnable = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_LUT_ENABLE)
        self.LUTIndex = IntFeature(self.__dev_handle, GxFeatureID.INT_LUT_INDEX)
        self.LUTValue = IntFeature(self.__dev_handle, GxFeatureID.INT_LUT_VALUE)

        # ---------------Color Transformation Control--------------
        self.ColorTransformationMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COLOR_TRANSFORMATION_MODE)
        self.ColorTransformationEnable = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_COLOR_TRANSFORMATION_ENABLE)
        self.ColorTransformationValueSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COLOR_TRANSFORMATION_VALUE_SELECTOR)
        self.ColorTransformationValue = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_COLOR_TRANSFORMATION_VALUE)

        # ---------------ChunkData Section-------------------------
        self.ChunkModeActive = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_CHUNK_MODE_ACTIVE)
        self.ChunkSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_CHUNK_SELECTOR)
        self.ChunkEnable = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_CHUNK_ENABLE)

        # ---------------CounterAndTimerControl Section-------------------------
        self.TimerSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TIMER_SELECTOR)
        self.TimerDuration = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TIMER_DURATION)
        self.TimerDelay = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TIMER_DELAY)
        self.TimerTriggerSource = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TIMER_TRIGGER_SOURCE)
        self.CounterSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COUNTER_SELECTOR)
        self.CounterEventSource = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COUNTER_EVENT_SOURCE)
        self.CounterResetSource = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COUNTER_RESET_SOURCE)
        self.CounterResetActivation = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COUNTER_RESET_ACTIVATION)
        self.CounterReset = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_COUNTER_RESET)

    def stream_on(self):
        """
        :brief      send start command, camera start transmission image data
        :return:    none
        """
        status = gx_send_command(self.__dev_handle, GxFeatureID.COMMAND_ACQUISITION_START)
        StatusProcessor.process(status, 'Device', 'stream_on')

        payload_size = self.PayloadSize.get()
        self.data_stream[0].set_payload_size(payload_size)
        self.data_stream[0].acquisition_flag = True

    def stream_off(self):
        """
        :brief      send stop command, camera stop transmission image data
        :return:    none
        """
        self.data_stream[0].acquisition_flag = False
        status = gx_send_command(self.__dev_handle, GxFeatureID.COMMAND_ACQUISITION_STOP)
        StatusProcessor.process(status, 'Device', 'stream_off')

    def export_config_file(self, file_path):
        """
        :brief      Export the current configuration file
        :param      file_path:      file path(type: str)
        :return:    none
        """
        if not isinstance(file_path, str):
            raise ParameterTypeError("Device.export_config_file: "
                                     "Expected file_path type is str, not %s" % type(file_path))

        status = gx_export_config_file(self.__dev_handle, file_path)
        StatusProcessor.process(status, 'Device', 'export_config_file')

    def import_config_file(self, file_path, verify=False):
        """
        :brief      Imported configuration file
        :param      file_path:  file path(type: str)
        :param      verify:     If this value is true, all the imported values will be read out
                                and checked for consistency(type: bool)
        :return:    none
        """
        if not isinstance(file_path, str):
            raise ParameterTypeError("Device.import_config_file: "
                                     "Expected file_path type is str, not %s" % type(file_path))

        if not isinstance(verify, bool):
            raise ParameterTypeError("Device.import_config_file: "
                                     "Expected verify type is bool, not %s" % type(verify))

        status = gx_import_config_file(self.__dev_handle, file_path, verify)
        StatusProcessor.process(status, 'Device', 'import_config_file')

    def close_device(self):
        """
        :brief      close device, close device handle
        :return:    None
        """
        status = gx_close_device(self.__dev_handle)
        StatusProcessor.process(status, 'Device', 'close_device')
        self.__dev_handle = None

    def get_stream_channel_num(self):
        """
        :brief      Get the number of stream channels supported by the current device.
        :return:    the number of stream channels
        """
        return len(self.data_stream)


class GEVDevice(Device):
    def __init__(self, handle):
        self.__dev_handle = handle
        Device.__init__(self, self.__dev_handle)
        self.GevCurrentIPConfigurationLLA = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_GEV_CURRENT_IP_CONFIGURATION_LLA)
        self.GevCurrentIPConfigurationDHCP = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_GEV_CURRENT_IP_CONFIGURATION_DHCP)
        self.GevCurrentIPConfigurationPersistentIP = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_GEV_CURRENT_IP_CONFIGURATION_PERSISTENT_IP)
        self.EstimatedBandwidth = IntFeature(self.__dev_handle, GxFeatureID.INT_ESTIMATED_BANDWIDTH)
        self.GevHeartbeatTimeout = IntFeature(self.__dev_handle, GxFeatureID.INT_GEV_HEARTBEAT_TIMEOUT)
        self.GevSCPSPacketSize = IntFeature(self.__dev_handle, GxFeatureID.INT_GEV_PACKET_SIZE)
        self.GevSCPD = IntFeature(self.__dev_handle, GxFeatureID.INT_GEV_PACKET_DELAY)
        self.GevLinkSpeed = IntFeature(self.__dev_handle, GxFeatureID.INT_GEV_LINK_SPEED)
        self.DeviceCommandTimeout = IntFeature(self.__dev_handle, GxFeatureID.INT_COMMAND_TIMEOUT)
        self.DeviceCommandRetryCount = IntFeature(self.__dev_handle, GxFeatureID.INT_COMMAND_RETRY_COUNT)
        self.data_stream.append(GEVDataStream(self.__dev_handle))


class U3VDevice(Device):
    """
    The U3VDevice class inherits from the Device class. In addition to inheriting the properties of the Device,
    the U3V Device has special attributes such as bandwidth limitation, URBSetting, frame info, etc.
    """
    def __init__(self, handle):
        self.__dev_handle = handle
        Device.__init__(self, self.__dev_handle)
        self.data_stream.append(U3VDataStream(self.__dev_handle))


class U2Device(Device):
    """
    The U2Device class inherits from the Device class
    """
    def __init__(self, handle):
        self.__dev_handle = handle
        Device.__init__(self, self.__dev_handle)
        self.AcquisitionSpeedLevel = IntFeature(self.__dev_handle, GxFeatureID.INT_ACQUISITION_SPEED_LEVEL)
        self.AcquisitionFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_ACQUISITION_FRAME_COUNT)
        self.TriggerSwitch = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_SWITCH)
        self.UserOutputMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_USER_OUTPUT_MODE)
        self.StrobeSwitch = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_STROBE_SWITCH)
        self.ADCLevel = IntFeature(self.__dev_handle, GxFeatureID.INT_ADC_LEVEL)
        self.HBlanking = IntFeature(self.__dev_handle, GxFeatureID.INT_H_BLANKING)
        self.VBlanking = IntFeature(self.__dev_handle, GxFeatureID.INT_V_BLANKING)
        self.UserPassword = StringFeature(self.__dev_handle, GxFeatureID.STRING_USER_PASSWORD)
        self.VerifyPassword = StringFeature(self.__dev_handle, GxFeatureID.STRING_VERIFY_PASSWORD)
        self.UserData = BufferFeature(self.__dev_handle, GxFeatureID.BUFFER_USER_DATA)
        self.AALightEnvironment = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_AA_LIGHT_ENVIRONMENT)
        self.FrameInformation = BufferFeature(self.__dev_handle, GxFeatureID.BUFFER_FRAME_INFORMATION)
        self.ImageGrayRaiseSwitch = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_IMAGE_GRAY_RAISE_SWITCH)
        self.data_stream.append(DataStream(self.__dev_handle))


class DataStream:
    def __init__(self, handle):
        self.__dev_handle = handle
        self.StreamAnnouncedBufferCount = IntFeature(self.__dev_handle, GxFeatureID.INT_ANNOUNCED_BUFFER_COUNT)
        self.StreamDeliveredFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_DELIVERED_FRAME_COUNT)
        self.StreamLostFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_LOST_FRAME_COUNT)
        self.StreamIncompleteFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_INCOMPLETE_FRAME_COUNT)
        self.StreamDeliveredPacketCount = IntFeature(self.__dev_handle, GxFeatureID.INT_DELIVERED_PACKET_COUNT)
        self.payload_size = 0
        self.acquisition_flag = False

    def set_payload_size(self, payload_size):
        self.payload_size = payload_size

    def set_acquisition_buffer_number(self, buf_num):
        """
        :brief      set the number of acquisition buffer
        :param      buf_num:   the number of acquisition buffer, range:[1, 0xFFFFFFFF]
        """
        if not isinstance(buf_num, INT_TYPE):
            raise ParameterTypeError("DataStream.set_acquisition_buffer_number: "
                                     "Expected buf_num type is int, not %s" % type(buf_num))

        if (buf_num < 1) or (buf_num > UNSIGNED_LONG_LONG_MAX):
            print("DataStream.set_acquisition_buffer_number:"
                  "buf_num out of bounds, minimum=1, maximum=%s"
                  % hex(UNSIGNED_LONG_LONG_MAX).__str__())
            return

        status = gx_set_acquisition_buffer_number(self.__dev_handle, buf_num)
        StatusProcessor.process(status, 'DataStream', 'set_acquisition_buffer_number')

    def get_image(self, timeout=1000):
        """
        :brief          Get an image, get successfully create image class object
        :param          timeout:    Acquisition timeout, range:[0, 0xFFFFFFFF]
        :return:        image object
        """
        if not isinstance(timeout, INT_TYPE):
            raise ParameterTypeError("DataStream.get_image: "
                                     "Expected timeout type is int, not %s" % type(timeout))

        if (timeout < 0) or (timeout > UNSIGNED_INT_MAX):
            print("DataStream.get_image: "
                  "timeout out of bounds, minimum=0, maximum=%s"
                  % hex(UNSIGNED_INT_MAX).__str__())
            return None

        if self.acquisition_flag is False:
            print("DataStream.get_image: Current data steam don't  start acquisition")
            return None

        frame_data = GxFrameData()
        frame_data.image_size = self.payload_size
        frame_data.image_buf = None
        image = RawImage(frame_data)

        status = gx_get_image(self.__dev_handle, image.frame_data, timeout)
        if status == GxStatusList.SUCCESS:
            return image
        elif status == GxStatusList.TIMEOUT:
            return None
        else:
            StatusProcessor.process(status, 'DataStream', 'get_image')
            return None

    def flush_queue(self):
        status = gx_flush_queue(self.__dev_handle)
        StatusProcessor.process(status, 'DataStream', 'flush_queue')


class U3VDataStream(DataStream):
    def __init__(self, handle):
        self.__handle = handle
        DataStream.__init__(self, self.__handle)
        self.StreamTransferSize = IntFeature(self.__handle, GxFeatureID.INT_STREAM_TRANSFER_SIZE)
        self.StreamTransferNumberUrb = IntFeature(self.__handle, GxFeatureID.INT_STREAM_TRANSFER_NUMBER_URB)


class GEVDataStream(DataStream):
    def __init__(self, handle):
        self.__handle = handle
        DataStream.__init__(self, self.__handle)
        self.StreamResendPacketCount = IntFeature(self.__handle, GxFeatureID.INT_RESEND_PACKET_COUNT)
        self.StreamRescuedPacketCount = IntFeature(self.__handle, GxFeatureID.INT_RESCUED_PACKED_COUNT)
        self.StreamResendCommandCount = IntFeature(self.__handle, GxFeatureID.INT_RESEND_COMMAND_COUNT)
        self.StreamUnexpectedPacketCount = IntFeature(self.__handle, GxFeatureID.INT_UNEXPECTED_PACKED_COUNT)
        self.MaxPacketCountInOneBlock = IntFeature(self.__handle, GxFeatureID.INT_MAX_PACKET_COUNT_IN_ONE_BLOCK)
        self.MaxPacketCountInOneCommand = IntFeature(self.__handle, GxFeatureID.INT_MAX_PACKET_COUNT_IN_ONE_COMMAND)
        self.ResendTimeout = IntFeature(self.__handle, GxFeatureID.INT_RESEND_TIMEOUT)
        self.MaxWaitPacketCount = IntFeature(self.__handle, GxFeatureID.INT_MAX_WAIT_PACKET_COUNT)
        self.ResendMode = EnumFeature(self.__handle, GxFeatureID.ENUM_RESEND_MODE)
        self.StreamMissingBlockIDCount = IntFeature(self.__handle, GxFeatureID.INT_MISSING_BLOCK_ID_COUNT)
        self.BlockTimeout = IntFeature(self.__handle, GxFeatureID.INT_BLOCK_TIMEOUT)
        self.MaxNumQueueBuffer = IntFeature(self.__handle, GxFeatureID.INT_MAX_NUM_QUEUE_BUFFER)
        self.PacketTimeout = IntFeature(self.__handle, GxFeatureID.INT_PACKET_TIMEOUT)


class UnexpectedError(Exception):
    """
    brief:  Unexpected error exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class NotFoundTL(Exception):
    """
    brief:  not found TL exception
    param:  args             exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class NotFoundDevice(Exception):
    """
    brief:  not found device exception
    param:  args              exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class OffLine(Exception):
    """
    brief:  device offline exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class InvalidParameter(Exception):
    """
    brief:  input invalid parameter exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class InvalidHandle(Exception):
    """
    brief:  invalid handle exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class InvalidCall(Exception):
    """
    brief:  invalid callback exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class InvalidAccess(Exception):
    """
    brief:  invalid access exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class NeedMoreBuffer(Exception):
    """
    brief:  need more buffer exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class FeatureTypeError(Exception):
    """
    brief:  feature id error exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class OutOfRange(Exception):
    """
    brief:  param out of range exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class NotInitApi(Exception):
    """
    brief:  not init api exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class Timeout(Exception):
    """
    brief:  timeout exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class ParameterTypeError(Exception):
    """
    brief:  parameter type error exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


def exception_deal(status, args):
    """
    brief:  deal with different exception
    param:  status         function return value
    param:  args            exception description
    return: none
    """
    if status == GxStatusList.ERROR:
        raise UnexpectedError(args)
    elif status == GxStatusList.NOT_FOUND_TL:
        raise NotFoundTL(args)
    elif status == GxStatusList.NOT_FOUND_DEVICE:
        raise NotFoundDevice(args)
    elif status == GxStatusList.OFFLINE:
        raise OffLine(args)
    elif status == GxStatusList.INVALID_PARAMETER:
        raise InvalidParameter(args)
    elif status == GxStatusList.INVALID_HANDLE:
        raise InvalidHandle(args)
    elif status == GxStatusList.INVALID_CALL:
        raise InvalidCall(args)
    elif status == GxStatusList.INVALID_ACCESS:
        raise InvalidAccess(args)
    elif status == GxStatusList.NEED_MORE_BUFFER:
        raise NeedMoreBuffer(args)
    elif status == GxStatusList.ERROR_TYPE:
        raise FeatureTypeError(args)
    elif status == GxStatusList.OUT_OF_RANGE:
        raise OutOfRange(args)
    elif status == GxStatusList.NOT_INIT_API:
        raise NotInitApi(args)
    elif status == GxStatusList.TIMEOUT:
        raise Timeout(args)
    elif status == GxStatusList.REPEAT_OPENED:
        raise InvalidAccess(args)
    else:
        raise Exception(args)


class StatusProcessor:
    def __init__(self):
        pass

    @staticmethod
    def process(status, class_name, function_name):
        """
        :brief      1.Error code processing
                    2.combine the class name and function name of the transmitted function into a string
                    3.Throw an exception
        :param      status:   function return value
        :param      class_name:  class name
        :param      function_name: function name
        :return:    none
        """
        if status != GxStatusList.SUCCESS:
            ret, err_code, string = gx_get_last_error(ERROR_SIZE)
            error_message = "%s.%s:%s" % (class_name, function_name, string)
            exception_deal(status, error_message)

    @staticmethod
    def printing(status, class_name, function_name):
        """
        :brief      1.Error code processing
                    2.combine the class name and function name of the transmitted function into a string and print it out
        :param      status:   function return value
        :param      class_name:  class name
        :param      function_name: function name
        :return:    none
        """
        if status != GxStatusList.SUCCESS:
            ret, err_code, string = gx_get_last_error(ERROR_SIZE)
            error_message = "%s.%s:%s" % (class_name, function_name, string)
            print(error_message)


class RGBImage:
    def __init__(self, frame_data):
        self.frame_data = frame_data

        if self.frame_data.image_buf is not None:
            self.__image_array = string_at(self.frame_data.image_buf, self.frame_data.image_size)
        else:
            self.__image_array = (c_ubyte * self.frame_data.image_size)()
            self.frame_data.image_buf = addressof(self.__image_array)

    def image_improvement(self, color_correction_param=0, contrast_lut=None, gamma_lut=None):
        """
        :brief:     Improve image quality of the object itself
        :param      color_correction_param:     color correction param address
                                                (get from Device.ColorCorrectionParam.get_int())
        :param      contrast_lut:               contrast lut
        :param      gamma_lut:                  gamma lut
        :return:    None
        """
        if (color_correction_param == 0) and (contrast_lut is None) and (gamma_lut is None):
            return

        if contrast_lut is None:
            contrast_parameter = None
        elif isinstance(contrast_lut, Buffer):
            contrast_parameter = contrast_lut.get_ctype_array()
        else:
            raise ParameterTypeError("RGBImage.image_improvement: "
                                     "Expected contrast_lut type is Buffer, not %s" % type(contrast_lut))

        if gamma_lut is None:
            gamma_parameter = None
        elif isinstance(gamma_lut, Buffer):
            gamma_parameter = gamma_lut.get_ctype_array()
        else:
            raise ParameterTypeError("RGBImage.image_improvement: "
                                     "Expected gamma_lut type is Buffer, not %s" % type(gamma_lut))

        if not isinstance(color_correction_param, INT_TYPE):
            raise ParameterTypeError("RGBImage.image_improvement: "
                                     "Expected color_correction_param type is int, not %s" % type(color_correction_param))

        status = dx_image_improvement(self.frame_data.image_buf, self.frame_data.image_buf,
                                      self.frame_data.width, self.frame_data.height,
                                      color_correction_param, contrast_parameter, gamma_parameter)

        if status != DxStatus.OK:
            raise UnexpectedError("RGBImage.image_improvement: failed, error code:%s" % hex(status).__str__())

    def saturation(self, factor):
        """
        :brief      Saturation adjustment (RGB24)
        :param      factor:                 saturation factor,range(0 ~ 128)
        :return:    RGBImage object
        """
        if not isinstance(factor, INT_TYPE):
            raise ParameterTypeError("RGBImage.saturation: "
                                     "Expected factor type is int, not %s" % type(factor))

        status = dx_saturation(self.frame_data.image_buf, self.frame_data.image_buf,
                               self.frame_data.width * self.frame_data.height, factor)

        if status != DxStatus.OK:
            raise UnexpectedError("RGBImage.saturation: failed, error code:%s" % hex(status).__str__())

    def sharpen(self, factor):
        """
        :brief       Sharpen adjustment (RGB24)
        :param      factor:                 sharpen factor, range(0.1 ~ 5.0)
        :return:    None
        """
        if not isinstance(factor, (INT_TYPE, float)):
            raise ParameterTypeError("RGBImage.sharpen: "
                                     "Expected factor type is float, not %s" % type(factor))

        status = dx_sharpen_24b(self.frame_data.image_buf, self.frame_data.image_buf, self.frame_data.width,
                                self.frame_data.height, factor)

        if status != DxStatus.OK:
            raise UnexpectedError("RGBImage.sharpen: failed, error code:%s" % hex(status).__str__())

    def get_numpy_array(self):
        """
        :brief:     Return data as a numpy.Array type with dimension Image.height * Image.width * 3
        :return:    numpy.Array objects
        """
        image_np = numpy.frombuffer(self.__image_array, dtype=numpy.ubyte).reshape(self.frame_data.height, self.frame_data.width, 3)
        return image_np

    def get_image_size(self):
        """
        :brief      Get RGB data size
        :return:    size
        """
        return self.frame_data.image_size


class RawImage:
    def __init__(self, frame_data):
        self.frame_data = frame_data

        if self.frame_data.image_buf is not None:
            self.__image_array = string_at(self.frame_data.image_buf, self.frame_data.image_size)
        else:
            self.__image_array = (c_ubyte * self.frame_data.image_size)()
            self.frame_data.image_buf = addressof(self.__image_array)

    def __get_bit_depth(self, pixel_format):
        """
        :brief      Calculate pixel depth based on pixel format
        :param      pixel_format
        :return:    pixel depth
        """
        bpp10_tup = (GxPixelFormatEntry.MONO10, GxPixelFormatEntry.BAYER_GR10, GxPixelFormatEntry.BAYER_RG10,
                     GxPixelFormatEntry.BAYER_GB10, GxPixelFormatEntry.BAYER_BG10)

        bpp12_tup = (GxPixelFormatEntry.MONO12, GxPixelFormatEntry.BAYER_GR12, GxPixelFormatEntry.BAYER_RG12,
                     GxPixelFormatEntry.BAYER_GB12, GxPixelFormatEntry.BAYER_BG12)

        bpp16_tup = (GxPixelFormatEntry.MONO16, GxPixelFormatEntry.BAYER_GR16, GxPixelFormatEntry.BAYER_RG16,
                     GxPixelFormatEntry.BAYER_GB16, GxPixelFormatEntry.BAYER_BG16)

        if (pixel_format & PIXEL_BIT_MASK) == GX_PIXEL_8BIT:
            return GxPixelSizeEntry.BPP8
        elif pixel_format in bpp10_tup:
            return GxPixelSizeEntry.BPP10
        elif pixel_format in bpp12_tup:
            return GxPixelSizeEntry.BPP12
        elif pixel_format == GxPixelFormatEntry.MONO14:
            return GxPixelSizeEntry.BPP14
        elif pixel_format in bpp16_tup:
            return GxPixelSizeEntry.BPP16
        elif (pixel_format & PIXEL_BIT_MASK) == GX_PIXEL_24BIT:
            return GxPixelSizeEntry.BPP24
        elif (pixel_format & PIXEL_BIT_MASK) == GX_PIXEL_48BIT:
            return GxPixelSizeEntry.BPP48
        else:
            return -1

    def __get_pixel_color_filter(self, pixel_format):
        """
        :brief      Calculate pixel color filter based on pixel format
        :param      pixel_format
        :return:    pixel color filter
        """
        gr_tup = (GxPixelFormatEntry.BAYER_GR8, GxPixelFormatEntry.BAYER_GR10,
                  GxPixelFormatEntry.BAYER_GR12, GxPixelFormatEntry.BAYER_GR16)
        rg_tup = (GxPixelFormatEntry.BAYER_RG8, GxPixelFormatEntry.BAYER_RG10,
                  GxPixelFormatEntry.BAYER_RG12, GxPixelFormatEntry.BAYER_RG16)
        gb_tup = (GxPixelFormatEntry.BAYER_GB8, GxPixelFormatEntry.BAYER_GB10,
                  GxPixelFormatEntry.BAYER_GB12, GxPixelFormatEntry.BAYER_GB16)
        bg_tup = (GxPixelFormatEntry.BAYER_BG8, GxPixelFormatEntry.BAYER_BG10,
                  GxPixelFormatEntry.BAYER_BG12, GxPixelFormatEntry.BAYER_BG16)
        mono_tup = (GxPixelFormatEntry.MONO8, GxPixelFormatEntry.MONO8_SIGNED,
                    GxPixelFormatEntry.MONO10, GxPixelFormatEntry.MONO12,
                    GxPixelFormatEntry.MONO14, GxPixelFormatEntry.MONO16)

        if pixel_format in gr_tup:
            return DxPixelColorFilter.GR
        elif pixel_format in rg_tup:
            return DxPixelColorFilter.RG
        elif pixel_format in gb_tup:
            return DxPixelColorFilter.GB
        elif pixel_format in bg_tup:
            return DxPixelColorFilter.BG
        elif pixel_format in mono_tup:
            return DxPixelColorFilter.NONE
        else:
            return -1

    def __pixel_format_raw16_to_raw8(self, pixel_format):
        """
        :brief      convert raw16 to raw8, the pixel format need convert to 8bit bayer format
        :param      pixel_format(10bit, 12bit, 16bit)
        :return:    pixel_format(8bit)
        """
        gr16_tup = (GxPixelFormatEntry.BAYER_GR10, GxPixelFormatEntry.BAYER_GR12, GxPixelFormatEntry.BAYER_GR16)
        rg16_tup = (GxPixelFormatEntry.BAYER_RG10, GxPixelFormatEntry.BAYER_RG12, GxPixelFormatEntry.BAYER_RG16)
        gb16_tup = (GxPixelFormatEntry.BAYER_GB10, GxPixelFormatEntry.BAYER_GB12, GxPixelFormatEntry.BAYER_GB16)
        bg16_tup = (GxPixelFormatEntry.BAYER_BG10, GxPixelFormatEntry.BAYER_BG12, GxPixelFormatEntry.BAYER_BG16)
        mono16_tup = (GxPixelFormatEntry.MONO10, GxPixelFormatEntry.MONO12,
                      GxPixelFormatEntry.MONO14, GxPixelFormatEntry.MONO16)

        if pixel_format in gr16_tup:
            return GxPixelFormatEntry.BAYER_GR8
        elif pixel_format in rg16_tup:
            return GxPixelFormatEntry.BAYER_RG8
        elif pixel_format in gb16_tup:
            return GxPixelFormatEntry.BAYER_GB8
        elif pixel_format in bg16_tup:
            return GxPixelFormatEntry.BAYER_BG8
        elif pixel_format in mono16_tup:
            return GxPixelFormatEntry.MONO8
        else:
            return -1

    def __raw16_to_raw8(self, pixel_bit_depth, valid_bits):
        """
        :brief      convert raw16 to raw8
        :param      pixel_bit_depth     pixel bit depth
        :param      valid_bits:         data valid digit[DxValidBit]
        :return:    RAWImage object
        """
        if pixel_bit_depth == GxPixelSizeEntry.BPP10:
            valid_bits = min(valid_bits, DxValidBit.BIT2_9)
        elif pixel_bit_depth == GxPixelSizeEntry.BPP12:
            valid_bits = min(valid_bits, DxValidBit.BIT4_11)
        else:
            print("RawImage.__dx_raw16_to_raw8: Only support 10bit and 12bit")
            return None

        frame_data = GxFrameData()
        frame_data.status = self.frame_data.status
        frame_data.width = self.frame_data.width
        frame_data.height = self.frame_data.height
        frame_data.pixel_format = self.__pixel_format_raw16_to_raw8(self.frame_data.pixel_format)
        frame_data.image_size = self.frame_data.width * self.frame_data.height
        frame_data.frame_id = self.frame_data.frame_id
        frame_data.timestamp = self.frame_data.timestamp
        # frame_data.buf_id = self.frame_data.buf_id
        frame_data.image_buf = None
        image_raw8 = RawImage(frame_data)

        status = dx_raw16_to_raw8(self.frame_data.image_buf, image_raw8.frame_data.image_buf,
                                  self.frame_data.width, self.frame_data.height, valid_bits)

        if status != DxStatus.OK:
            raise UnexpectedError("RawImage.convert: raw16 convert to raw8 failed, Error core: %s"
                                  % hex(status).__str__())
        else:
            return image_raw8

    def __raw8_to_rgb(self, raw8_image, convert_type, pixel_color_filter, flip):
        """
        :brief      convert raw8 to RGB
        :param      raw8_image          RAWImage object, bit depth is 8bit
        :param      convert_type:       Bayer convert type, See detail in DxBayerConvertType
        :param      pixel_color_filter: pixel color filter, See detail in DxPixelColorFilter
        :param      flip:               Output image flip flag
                                        True: turn the image upside down
                                        False: do not flip
        :return:    RAWImage object
        """
        frame_data = GxFrameData()
        frame_data.status = raw8_image.frame_data.status
        frame_data.width = raw8_image.frame_data.width
        frame_data.height = raw8_image.frame_data.height
        frame_data.pixel_format = GxPixelFormatEntry.RGB8_PLANAR
        frame_data.image_size = raw8_image.frame_data.width * raw8_image.frame_data.height * 3
        frame_data.frame_id = raw8_image.frame_data.frame_id
        frame_data.timestamp = raw8_image.frame_data.timestamp
        # frame_data.buf_id = self.frame_data.buf_id
        frame_data.image_buf = None
        image_rgb = RGBImage(frame_data)

        status = dx_raw8_to_rgb24(raw8_image.frame_data.image_buf, image_rgb.frame_data.image_buf,
                                  raw8_image.frame_data.width, raw8_image.frame_data.height,
                                  convert_type, pixel_color_filter, flip)

        if status != DxStatus.OK:
            raise UnexpectedError("RawImage.convert: failed, error code:%s" % hex(status).__str__())

        return image_rgb

    def convert(self, mode, flip=False, valid_bits=DxValidBit.BIT4_11,
                convert_type=DxBayerConvertType.NEIGHBOUR):
        """
        :brief      Image format convert
        :param      mode:           "RAW8":     convert raw16 RAWImage object to raw8 RAWImage object
                                    "RGB":   convert raw8 RAWImage object to RGBImage object
        :param      flip:           Output image flip flag
                                    True: turn the image upside down
                                    False: do not flip
        :param      valid_bits:     Data valid digit, See detail in DxValidBit, raw8 don't this param
        :param      convert_type:   Bayer convert type, See detail in DxBayerConvertType
        :return:    return image object according to mode parameter
        """
        if self.frame_data.status != GxFrameStatusList.SUCCESS:
            print("RawImage.convert: This is a incomplete image")
            return None

        if not isinstance(flip, bool):
            raise ParameterTypeError("RawImage.convert: "
                                     "Expected flip type is bool, not %s" % type(flip))

        if not isinstance(convert_type, INT_TYPE):
            raise ParameterTypeError("RawImage.convert: "
                                     "Expected convert_type type is int, not %s" % type(convert_type))

        if not isinstance(valid_bits, INT_TYPE):
            raise ParameterTypeError("RawImage.convert: "
                                     "Expected valid_bits type is int, not %s" % type(valid_bits))

        if not isinstance(mode, str):
            raise ParameterTypeError("RawImage.convert: "
                                     "Expected mode type is str, not %s" % type(mode))

        convert_type_dict = dict((name, getattr(DxBayerConvertType, name))
                                 for name in dir(DxBayerConvertType) if not name.startswith('__'))
        if convert_type not in convert_type_dict.values():
            print("RawImage.convert: convert_type out of bounds, %s" % convert_type_dict.__str__())
            return None

        valid_bits_dict = dict((name, getattr(DxValidBit, name))
                               for name in dir(DxValidBit) if not name.startswith('__'))
        if valid_bits not in valid_bits_dict.values():
            print("RawImage.convert: valid_bits out of bounds, %s" % valid_bits_dict.__str__())
            return None

        pixel_bit_depth = self.__get_bit_depth(self.frame_data.pixel_format)
        pixel_color_filter = self.__get_pixel_color_filter(self.frame_data.pixel_format)

        if pixel_bit_depth < GxPixelSizeEntry.BPP8 or \
           pixel_bit_depth > GxPixelSizeEntry.BPP12:
            print("RawImage.convert: This pixel format is not support")
            return None

        if mode == "RAW8":
            if flip is True:
                print('''RawImage.convert: mode="RAW8" don't support flip=True''')
                return None

            if pixel_bit_depth in (GxPixelSizeEntry.BPP10, GxPixelSizeEntry.BPP12):
                image_raw8 = self.__raw16_to_raw8(pixel_bit_depth, valid_bits)
                return image_raw8
            else:
                print('RawImage.convert: mode="RAW8" only support 10bit and 12bit')
        elif mode == "RGB":
            if pixel_bit_depth in (GxPixelSizeEntry.BPP10, GxPixelSizeEntry.BPP12):
                image_raw8 = self.__raw16_to_raw8(pixel_bit_depth, valid_bits)
            else:
                image_raw8 = self

            return self.__raw8_to_rgb(image_raw8, convert_type, pixel_color_filter, flip)
        else:
            print('''RawImage.convert: mode="%s", isn't support''' % mode)
            return None

    def defective_pixel_correct(self):
        """
        :brief      Auto raw defective pixel correct,Support image from Raw8 to Raw16, the bit number is actual
                    bit number, when it is more than 8, the actual bit can be every number between 9 to 16.
                    And if image format is packed, you need convert it to Raw16.
                    This function should be used in each frame.
        :return:    None
        """
        pixel_bit_depth = self.__get_bit_depth(self.frame_data.pixel_format)
        status = dx_auto_raw_defective_pixel_correct(self.frame_data.image_buf, self.frame_data.width,
                                                     self.frame_data.height, pixel_bit_depth)

        if status != DxStatus.OK:
            raise UnexpectedError("RawImage.defective_pixel_correct: failed, error code:%s" % hex(status).__str__())

    def get_numpy_array(self):
        """
        :brief      Return data as a numpy.Array type with dimension Image.height * Image.width
        :return:    numpy.Array objects
        """
        if self.frame_data.status != GxFrameStatusList.SUCCESS:
            print("RawImage.get_numpy_array: This is a incomplete image")
            return None

        image_size = self.frame_data.width * self.frame_data.height

        if self.frame_data.pixel_format & PIXEL_BIT_MASK == GX_PIXEL_8BIT:
            image_np = numpy.frombuffer(self.__image_array, dtype=numpy.ubyte, count=image_size).\
                reshape(self.frame_data.height, self.frame_data.width)
        elif self.frame_data.pixel_format & PIXEL_BIT_MASK == GX_PIXEL_16BIT:
            image_np = numpy.frombuffer(self.__image_array, dtype=numpy.uint16, count=image_size).\
                reshape(self.frame_data.height, self.frame_data.width)
        else:
            image_np = None

        return image_np

    def get_data(self):
        """
        :brief      get Raw data
        :return:    raw data[string]
        """
        image_str = string_at(self.__image_array, self.frame_data.image_size)
        return image_str

    def save_raw(self, file_path):
        """
        :brief      save raw data
        :param      file_path:      file path
        :return:    None
        """
        if not isinstance(file_path, str):
            raise ParameterTypeError("RawImage.save_raw: "
                                     "Expected file_path type is str, not %s" % type(file_path))

        try:
            fp = open(file_path, "wb")
            fp.write(self.__image_array)
            fp.close()
        except Exception as error:
            raise UnexpectedError("RawImage.save_raw:%s" % error)

    def get_status(self):
        """
        :brief      get raw data status
        :return:    status
        """
        return self.frame_data.status

    def get_width(self):
        """
        :brief      get width of raw data
        :return:    width
        """
        return self.frame_data.width

    def get_height(self):
        """
        :brief     get height of raw data
        :return:
        """
        return self.frame_data.height

    def get_pixel_format(self):
        """
        :brief      Get image pixel format
        :return:    pixel format
        """
        return self.frame_data.pixel_format

    def get_image_size(self):
        """
        :brief      Get raw data size
        :return:    size
        """
        return self.frame_data.image_size

    def get_frame_id(self):
        """
        :brief      Get  frame id of raw data
        :return:    frame id
        """
        return self.frame_data.frame_id

    def get_timestamp(self):
        """
        :brief      Get timestamp of raw data
        :return:    timestamp
        """
        return self.frame_data.timestamp


class Utility:
    def __init__(self):
        pass

    @staticmethod
    def get_gamma_lut(gamma=1):
        if not (isinstance(gamma, (INT_TYPE, float))):
            raise ParameterTypeError("Utility.get_gamma_lut: "
                                     "Expected gamma type is float, not %s" % type(gamma))

        if (gamma < GAMMA_MIN) or (gamma > GAMMA_MAX):
            print("Utility.get_gamma_lut: gamma out of bounds, range:[0.1, 10.0]")
            return None

        status, gamma_lut, gamma_lut_len = dx_get_gamma_lut(gamma)
        if status != DxStatus.OK:
            print("Utility.get_gamma_lut: get gamma lut failure, Error code:%s" % hex(status).__str__())
            return None

        return Buffer(gamma_lut)

    @staticmethod
    def get_contrast_lut(contrast=0):
        if not (isinstance(contrast, INT_TYPE)):
            raise ParameterTypeError("Utility.get_contrast_lut: "
                                     "Expected contrast type is int, not %s" % type(contrast))

        if (contrast < CONTRAST_MIN) or (contrast > CONTRAST_MAX):
            print("Utility.get_contrast_lut: contrast out of bounds, range:[-50, 100]")
            return None

        status, contrast_lut, contrast_lut_len = dx_get_contrast_lut(contrast)
        if status != DxStatus.OK:
            print("Utility.get_contrast_lut: get contrast lut failure, Error code:%s" % hex(status).__str__())
            return None

        return Buffer(contrast_lut)


# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.microcontroller as microcontroller

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		self.microcontroller = microcontroller.Microcontroller()
		self.navigationController = core.NavigationController(self.microcontroller)

		# load widgets
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
		
		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		layout.addWidget(self.navigationWidget,2,0)

		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# make connections
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)

	def closeEvent(self, event):
		event.accept()
		self.navigationController.home()
#!/usr/bin/python
# -*- coding:utf-8 -*-
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-

from gxipy.gxiapi import *
from gxipy.gxidef import *


__all__ = ["gxwrapper", "dxwrapper", "gxiapi", "gxidef"]

__version__ = '1.0.1905.9051'

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.microcontroller as microcontroller

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		self.camera = camera.Camera_Simulation()
		self.microcontroller = microcontroller.Microcontroller_Simulation()
		
		self.configurationManager = core.ConfigurationManager()
		self.streamHandler = core.StreamHandler()
		self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
		self.navigationController = core.NavigationController(self.microcontroller)
		self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
		self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController,self.configurationManager)
		self.trackingController = core.TrackingController(self.microcontroller,self.navigationController)
		self.imageSaver = core.ImageSaver()
		self.imageDisplay = core.ImageDisplay()

		# open the camera
		# camera start streaming
		self.camera.open()
		self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera.set_callback(self.streamHandler.on_new_frame)
		self.camera.enable_callback()

		# load widgets
		self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,self.liveController)
		self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager)
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
		self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
		self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)
		self.trackingControlWidget = widgets.TrackingControllerWidget(self.streamHandler,self.trackingController)
		self.multiPointWidget = widgets.MultiPointWidget(self.multipointController,self.configurationManager)

		self.recordTabWidget = QTabWidget()
		self.recordTabWidget.addTab(self.recordingControlWidget, "Simple Recording")
		self.recordTabWidget.addTab(self.trackingControlWidget, "Tracking")
		self.recordTabWidget.addTab(self.multiPointWidget, "Multipoint Acquisition")

		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		# layout.addWidget(self.cameraSettingWidget,0,0)
		layout.addWidget(self.liveControlWidget,1,0)
		layout.addWidget(self.navigationWidget,2,0)
		layout.addWidget(self.autofocusWidget,3,0)
		layout.addWidget(self.recordTabWidget,4,0)

		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)
		
		# widgets_ = QWidget()
		# widgets_.setLayout(layout)
		# scroll = QScrollArea()
		# scroll.setWidget(widgets_)
		# self.setCentralWidget(widgets_)

		# load window
		self.imageDisplayWindow = core.ImageDisplayWindow()
		self.imageArrayDisplayWindow = core.ImageArrayDisplayWindow() 
		self.imageDisplayWindow.show()
		self.imageArrayDisplayWindow.show()

		# make connections
		self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
		self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
		self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
		self.streamHandler.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
		self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)
		self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
		# self.multipointController.image_to_display.connect(self.imageDisplayWindow.display_image)
		self.multipointController.image_to_display_multi.connect(self.imageArrayDisplayWindow.display_image)
		self.multipointController.signal_current_configuration.connect(self.liveControlWidget.set_microscope_mode)
		self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
		self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
		self.liveControlWidget.update_camera_settings()

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.navigationController.home()
		self.liveController.stop_live()
		self.camera.close()
		self.imageSaver.close()
		self.imageDisplay.close()
		self.imageDisplayWindow.close()
		self.imageArrayDisplayWindow.close()

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy
from pathlib import Path

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.microcontroller as microcontroller

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		self.microcontroller = microcontroller.Microcontroller_Simulation()
		self.navigationController = core.NavigationController(self.microcontroller)

		self.camera_1 = camera.Camera_Simulation(sn='FW0190110139') # tracking
		self.camera_2 = camera.Camera_Simulation(sn='FU0190090030')	# fluorescence
		
		self.configurationManager_1 = core.ConfigurationManager(filename=str(Path.home()) + "/configurations_tracking.xml")
		self.configurationManager_2 = core.ConfigurationManager(filename=str(Path.home()) + "/configurations_fluorescence.xml")

		self.streamHandler_1 = core.StreamHandler()
		self.liveController_1 = core.LiveController(self.camera_1,self.microcontroller,self.configurationManager_1,control_illumination=False)
		#self.autofocusControlle_1 = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
		#self.multipointController_1 = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController,self.configurationManager)
		self.imageSaver_1 = core.ImageSaver()

		self.streamHandler_2 = core.StreamHandler()
		self.liveController_2 = core.LiveController(self.camera_2,self.microcontroller,self.configurationManager_2,control_illumination=True)
		self.autofocusController_2 = core.AutoFocusController(self.camera_2,self.navigationController,self.liveController_2)
		self.multipointController_2 = core.MultiPointController(self.camera_2,self.navigationController,self.liveController_2,self.autofocusController_2,self.configurationManager_2)
		self.imageSaver_2 = core.ImageSaver()

		self.trackingController = core.TrackingController(self.microcontroller,self.navigationController)
		
		# open the camera
		# camera start streaming
		self.camera_1.open()
		self.camera_1.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera_1.set_callback(self.streamHandler_1.on_new_frame)
		self.camera_1.enable_callback()

		self.camera_2.open()
		self.camera_2.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera_2.set_callback(self.streamHandler_2.on_new_frame)
		self.camera_2.enable_callback()

		# load widgets
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)

		self.cameraSettingWidget_1 = widgets.CameraSettingsWidget(self.camera_1,self.liveController_1)
		self.liveControlWidget_1 = widgets.LiveControlWidget(self.streamHandler_1,self.liveController_1,self.configurationManager_1)
		self.recordingControlWidget_1 = widgets.RecordingWidget(self.streamHandler_1,self.imageSaver_1)
		#self.trackingControlWidget = widgets.TrackingControllerWidget(self.streamHandler_1,self.trackingController)

		self.cameraSettingWidget_2 = widgets.CameraSettingsWidget(self.camera_2,self.liveController_2)
		self.liveControlWidget_2 = widgets.LiveControlWidget(self.streamHandler_2,self.liveController_2,self.configurationManager_2)
		#self.recordingControlWidget_2 = widgets.RecordingWidget(self.streamHandler_2,self.imageSaver_2)
		self.multiPointWidget_2 = widgets.MultiPointWidget(self.multipointController_2,self.configurationManager_2)
		
		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget_1,0,0)
		layout.addWidget(self.liveControlWidget_1,1,0)
		layout.addWidget(self.navigationWidget,2,0)
		#layout.addWidget(self.autofocusWidget,3,0)
		layout.addWidget(self.recordingControlWidget_1,4,0)
		
		layout.addWidget(self.cameraSettingWidget_2,5,0)
		layout.addWidget(self.liveControlWidget_2,6,0)
		#layout.addWidget(self.recordingControlWidget_2,7,0)
		layout.addWidget(self.multiPointWidget_2,8,0)

		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# load window
		self.imageDisplayWindow_1 = core.ImageDisplayWindow('Tracking')
		self.imageDisplayWindow_1.show()
		self.imageDisplayWindow_2 = core.ImageDisplayWindow('Fluorescence')
		self.imageDisplayWindow_2.show()
		self.imageArrayDisplayWindow = core.ImageArrayDisplayWindow('Multi-channel') 
		self.imageArrayDisplayWindow.show()

		# make connections
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)

		self.streamHandler_1.signal_new_frame_received.connect(self.liveController_1.on_new_frame)
		self.streamHandler_1.image_to_display.connect(self.imageDisplayWindow_1.display_image)
		self.streamHandler_1.packet_image_to_write.connect(self.imageSaver_1.enqueue)
		#self.streamHandler_1.packet_image_for_tracking.connect(self.trackingController.on_new_frame)

		self.liveControlWidget_1.signal_newExposureTime.connect(self.cameraSettingWidget_1.set_exposure_time)
		self.liveControlWidget_1.signal_newAnalogGain.connect(self.cameraSettingWidget_1.set_analog_gain)
		self.liveControlWidget_1.update_camera_settings()

		self.streamHandler_2.signal_new_frame_received.connect(self.liveController_2.on_new_frame)
		self.streamHandler_2.image_to_display.connect(self.imageDisplayWindow_2.display_image)
		self.streamHandler_2.packet_image_to_write.connect(self.imageSaver_2.enqueue)

		self.liveControlWidget_2.signal_newExposureTime.connect(self.cameraSettingWidget_2.set_exposure_time)
		self.liveControlWidget_2.signal_newAnalogGain.connect(self.cameraSettingWidget_2.set_analog_gain)
		self.liveControlWidget_2.update_camera_settings()
		
		self.multipointController_2.image_to_display.connect(self.imageDisplayWindow_2.display_image)
		self.multipointController_2.image_to_display_multi.connect(self.imageArrayDisplayWindow.display_image)
		self.multipointController_2.signal_current_configuration.connect(self.liveControlWidget_2.set_microscope_mode)
		

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.liveController_1.stop_live()
		self.camera_1.close()
		self.imageSaver_1.close()
		self.imageDisplayWindow_1.close()
		self.liveController_2.stop_live()
		self.camera_2.close()
		self.imageSaver_2.close()
		self.imageDisplayWindow_2.close()
		self.imageArrayDisplayWindow.close()

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera_TIS as camera
import control.core as core
import control.microcontroller as microcontroller

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		self.camera = camera.Camera(sn=33910474,width=4000,height=3000,framerate=30,color=False)
		self.microcontroller = microcontroller.Microcontroller()
		
		self.configurationManager = core.ConfigurationManager()
		self.streamHandler = core.StreamHandler()
		self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
		self.navigationController = core.NavigationController(self.microcontroller)
		self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
		self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController,self.configurationManager)
		self.trackingController = core.TrackingController(self.microcontroller,self.navigationController)
		self.imageSaver = core.ImageSaver()
		self.imageDisplay = core.ImageDisplay()

		# open the camera
		# camera start streaming
		self.camera.open()
		self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera.set_callback(self.streamHandler.on_new_frame)
		self.camera.enable_callback()

		# load widgets
		self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,self.liveController)
		self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager)
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
		self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
		self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)
		self.trackingControlWidget = widgets.TrackingControllerWidget(self.streamHandler,self.trackingController)
		self.multiPointWidget = widgets.MultiPointWidget(self.multipointController,self.configurationManager)

		self.recordTabWidget = QTabWidget()
		self.recordTabWidget.addTab(self.recordingControlWidget, "Simple Recording")
		self.recordTabWidget.addTab(self.trackingControlWidget, "Tracking")
		self.recordTabWidget.addTab(self.multiPointWidget, "Multipoint Acquisition")

		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget,0,0)
		layout.addWidget(self.liveControlWidget,1,0)
		layout.addWidget(self.navigationWidget,2,0)
		layout.addWidget(self.autofocusWidget,3,0)
		layout.addWidget(self.recordTabWidget,4,0)
		
		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# load window
		self.imageDisplayWindow = core.ImageDisplayWindow()
		self.imageArrayDisplayWindow = core.ImageArrayDisplayWindow() 
		self.imageDisplayWindow.show()
		self.imageArrayDisplayWindow.show()

		# make connections
		self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
		self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
		self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
		self.streamHandler.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
		self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)
		self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
		# self.multipointController.image_to_display.connect(self.imageDisplayWindow.display_image)
		self.multipointController.signal_current_configuration.connect(self.liveControlWidget.set_microscope_mode)
		self.multipointController.image_to_display_multi.connect(self.imageArrayDisplayWindow.display_image)
		self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
		self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
		self.liveControlWidget.update_camera_settings()

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.navigationController.home()
		self.liveController.stop_live()
		self.camera.close()
		self.imageSaver.close()
		self.imageDisplay.close()
		self.imageDisplayWindow.close()
		self.imageArrayDisplayWindow.close()
# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.widgets_tracking as widgets_tracking
import control.camera_TIS as camera
import control.core as core
import control.core_tracking as core_tracking
import control.microcontroller as microcontroller

SIMULATION = True

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		if SIMULATION is True:
			# self.camera = camera.Camera(sn=48910098)
			self.camera = camera.Camera(sn=17910089)
			self.microcontroller = microcontroller.Microcontroller_Simulation()
		else:
			self.camera = camera.Camera(sn=17910089)
			self.microcontroller = microcontroller.Microcontroller()
		
		self.configurationManager = core.ConfigurationManager()
		self.streamHandler = core.StreamHandler()
		self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
		self.navigationController = core.NavigationController(self.microcontroller)
		#self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
		#self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController)
		self.trackingController = core_tracking.TrackingController(self.microcontroller,self.navigationController)
		self.imageSaver = core.ImageSaver()
		self.imageDisplay = core.ImageDisplay()

		'''
		# thread
		self.thread_multiPoint = QThread()
		self.thread_multiPoint.start()
		self.multipointController.moveToThread(self.thread_multiPoint)
		'''

		# open the camera
		# camera start streaming
		self.camera.open()
		self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera.set_callback(self.streamHandler.on_new_frame)
		self.camera.enable_callback()

		# load widgets
		self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,self.liveController)
		self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager)
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
		#self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
		self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)
		self.trackingControlWidget = widgets_tracking.TrackingControllerWidget(self.streamHandler,self.trackingController)
		#self.multiPointWidget = widgets.MultiPointWidget(self.multipointController)

		self.recordTabWidget = QTabWidget()
		self.recordTabWidget.addTab(self.recordingControlWidget, "Simple Recording")
		self.recordTabWidget.addTab(self.trackingControlWidget, "Tracking")
		#self.recordTabWidget.addTab(self.multiPointWidget, "Multipoint Acquisition")

		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget,0,0)
		layout.addWidget(self.liveControlWidget,1,0)
		layout.addWidget(self.navigationWidget,2,0)
		#layout.addWidget(self.autofocusWidget,3,0)
		layout.addWidget(self.recordTabWidget,4,0)
		
		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# load window
		self.imageDisplayWindow = core.ImageDisplayWindow('Main Display')
		self.imageDisplayWindow.show()

		self.imageDisplayWindow_ThresholdedImage = core.ImageDisplayWindow('Thresholded Image')
		self.imageDisplayWindow_ThresholdedImage.show()

		# make connections
		self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
		self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
		self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
		self.streamHandler.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
		self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)
		#self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
		#self.multipointController.image_to_display.connect(self.imageDisplayWindow.display_image)

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.liveController.stop_live()
		self.camera.close()
		self.imageSaver.close()
		self.imageDisplay.close()
		self.imageDisplayWindow.close()
		self.imageDisplayWindow_ThresholdedImage.close()

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy
from pathlib import Path

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.core_PDAF as core_PDAF
import control.microcontroller as microcontroller

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, is_simulation = False, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		if is_simulation:
			self.microcontroller = microcontroller.Microcontroller_Simulation()
			self.camera_1 = camera.Camera_Simulation(sn='FW0200050063') # tracking
			self.camera_2 = camera.Camera_Simulation(sn='FW0200050068')	# fluorescence
		else:
			self.microcontroller = microcontroller.Microcontroller()
			self.camera_1 = camera.Camera(sn='FW0200050063') # tracking
			self.camera_2 = camera.Camera(sn='FW0200050068')	# fluorescence

		self.navigationController = core.NavigationController(self.microcontroller)
		self.configurationManager = core.ConfigurationManager(filename=str(Path.home()) + "/configurations_PDAF.xml")

		self.streamHandler_1 = core.StreamHandler()
		self.liveController_1 = core.LiveController(self.camera_1,self.microcontroller,self.configurationManager,control_illumination=False)
		self.imageSaver_1 = core.ImageSaver()

		self.streamHandler_2 = core.StreamHandler()
		self.liveController_2 = core.LiveController(self.camera_2,self.microcontroller,self.configurationManager,control_illumination=True)
		self.imageSaver_2 = core.ImageSaver()

		self.twoCamerasPDAFCalibrationController = core_PDAF.TwoCamerasPDAFCalibrationController(self.camera_1,self.camera_2,self.navigationController,self.liveController_1,self.liveController_2,self.configurationManager)
		
		# open the camera
		# camera start streaming
		self.camera_1.open()
		self.camera_1.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera_1.set_callback(self.streamHandler_1.on_new_frame)
		self.camera_1.enable_callback()

		self.camera_2.open()
		self.camera_2.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera_2.set_callback(self.streamHandler_2.on_new_frame)
		self.camera_2.enable_callback()

		# load widgets
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
		self.cameraSettingWidget_1 = widgets.CameraSettingsWidget(self.camera_1,self.liveController_1)
		self.liveControlWidget_1 = widgets.LiveControlWidget(self.streamHandler_1,self.liveController_1,self.configurationManager)
		self.cameraSettingWidget_2 = widgets.CameraSettingsWidget(self.camera_2,self.liveController_2)
		self.liveControlWidget_2 = widgets.LiveControlWidget(self.streamHandler_2,self.liveController_2,self.configurationManager)
		
		self.PDAFCalibrationWidget = widgets.MultiPointWidget(self.twoCamerasPDAFCalibrationController,self.configurationManager)

		
		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget_1,0,0)
		layout.addWidget(self.liveControlWidget_1,1,0)
		layout.addWidget(self.cameraSettingWidget_2,0,1)
		layout.addWidget(self.liveControlWidget_2,1,1)

		layout.addWidget(self.navigationWidget,7,0)
		layout.addWidget(self.PDAFCalibrationWidget,7,1)

		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# load window
		self.imageDisplayWindow_1 = core.ImageDisplayWindow('camera 1')
		self.imageDisplayWindow_1.show()
		self.imageDisplayWindow_2 = core.ImageDisplayWindow('camera 2')
		self.imageDisplayWindow_2.show()

		# make connections
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)

		self.streamHandler_1.signal_new_frame_received.connect(self.liveController_1.on_new_frame)
		self.streamHandler_1.image_to_display.connect(self.imageDisplayWindow_1.display_image)
		self.streamHandler_1.packet_image_to_write.connect(self.imageSaver_1.enqueue)
		#self.streamHandler_1.packet_image_for_tracking.connect(self.trackingController.on_new_frame)

		self.liveControlWidget_1.signal_newExposureTime.connect(self.cameraSettingWidget_1.set_exposure_time)
		self.liveControlWidget_1.signal_newAnalogGain.connect(self.cameraSettingWidget_1.set_analog_gain)
		self.liveControlWidget_1.update_camera_settings()

		self.streamHandler_2.signal_new_frame_received.connect(self.liveController_2.on_new_frame)
		self.streamHandler_2.image_to_display.connect(self.imageDisplayWindow_2.display_image)
		self.streamHandler_2.packet_image_to_write.connect(self.imageSaver_2.enqueue)

		self.liveControlWidget_2.signal_newExposureTime.connect(self.cameraSettingWidget_2.set_exposure_time)
		self.liveControlWidget_2.signal_newAnalogGain.connect(self.cameraSettingWidget_2.set_analog_gain)
		self.liveControlWidget_2.update_camera_settings()
		
		self.twoCamerasPDAFCalibrationController.image_to_display_camera1.connect(self.imageDisplayWindow_1.display_image)
		self.twoCamerasPDAFCalibrationController.image_to_display_camera2.connect(self.imageDisplayWindow_1.display_image)
		self.twoCamerasPDAFCalibrationController.signal_current_configuration.connect(self.liveControlWidget_1.set_microscope_mode)
		self.twoCamerasPDAFCalibrationController.signal_current_configuration.connect(self.liveControlWidget_2.set_microscope_mode)

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.liveController_1.stop_live()
		self.camera_1.close()
		self.imageSaver_1.close()
		self.imageDisplayWindow_1.close()
		self.liveController_2.stop_live()
		self.camera_2.close()
		self.imageSaver_2.close()
		self.imageDisplayWindow_2.close()

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy
from pathlib import Path

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.core_PDAF as core_PDAF
import control.microcontroller as microcontroller

class Internal_States():
	def __init__(self):
		self.w = 500
		self.h = 500
		self.x = 1500
		self.y = 1500

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, is_simulation=False,*args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		if is_simulation:
			self.microcontroller = microcontroller.Microcontroller_Simulation()
			self.camera_1 = camera.Camera_Simulation(sn='FW0200050063') # tracking
			self.camera_2 = camera.Camera_Simulation(sn='FW0200050068')	# fluorescence
		else:
			self.microcontroller = microcontroller.Microcontroller()
			self.camera_1 = camera.Camera(sn='FW0200050063') # tracking
			self.camera_2 = camera.Camera(sn='FW0200050068')	# fluorescence

		self.internal_states = Internal_States()
		
		self.navigationController = core.NavigationController(self.microcontroller)
		self.PDAFController = core_PDAF.PDAFController(self.internal_states)

		self.configurationManager = core.ConfigurationManager(filename=str(Path.home()) + "/configurations_PDAF.xml")

		self.streamHandler_1 = core.StreamHandler()
		self.liveController_1 = core.LiveController(self.camera_1,self.microcontroller,self.configurationManager,control_illumination=False)
		self.imageSaver_1 = core.ImageSaver()

		self.streamHandler_2 = core.StreamHandler()
		self.liveController_2 = core.LiveController(self.camera_2,self.microcontroller,self.configurationManager,control_illumination=True)
		self.imageSaver_2 = core.ImageSaver()

		self.twoCamerasPDAFCalibrationController = core_PDAF.TwoCamerasPDAFCalibrationController(self.camera_1,self.camera_2,self.navigationController,self.liveController_1,self.liveController_2,self.configurationManager)
		
		# open the camera
		# camera start streaming
		self.camera_1.open()
		self.camera_1.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera_1.set_callback(self.streamHandler_1.on_new_frame)
		self.camera_1.enable_callback()

		self.camera_2.open()
		self.camera_2.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera_2.set_callback(self.streamHandler_2.on_new_frame)
		self.camera_2.enable_callback()

		# load widgets
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
		self.cameraSettingWidget_1 = widgets.CameraSettingsWidget(self.camera_1,self.liveController_1)
		self.liveControlWidget_1 = widgets.LiveControlWidget(self.streamHandler_1,self.liveController_1,self.configurationManager)
		self.cameraSettingWidget_2 = widgets.CameraSettingsWidget(self.camera_2,self.liveController_2)
		self.liveControlWidget_2 = widgets.LiveControlWidget(self.streamHandler_2,self.liveController_2,self.configurationManager)
		
		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget_1,0,0)
		layout.addWidget(self.liveControlWidget_1,1,0)
		layout.addWidget(self.cameraSettingWidget_2,0,1)
		layout.addWidget(self.liveControlWidget_2,1,1)

		layout.addWidget(self.navigationWidget,7,0)

		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# load window
		self.imageDisplayWindow_1 = core.ImageDisplayWindow('camera 1')
		self.imageDisplayWindow_1.show()
		self.imageDisplayWindow_2 = core.ImageDisplayWindow('camera 2')
		self.imageDisplayWindow_2.show()

		# make connections
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)

		self.streamHandler_1.signal_new_frame_received.connect(self.liveController_1.on_new_frame)
		self.streamHandler_1.image_to_display.connect(self.imageDisplayWindow_1.display_image)
		self.streamHandler_1.packet_image_to_write.connect(self.imageSaver_1.enqueue)
		#self.streamHandler_1.packet_image_for_tracking.connect(self.trackingController.on_new_frame)

		self.liveControlWidget_1.signal_newExposureTime.connect(self.cameraSettingWidget_1.set_exposure_time)
		self.liveControlWidget_1.signal_newAnalogGain.connect(self.cameraSettingWidget_1.set_analog_gain)
		self.liveControlWidget_1.update_camera_settings()

		self.streamHandler_2.signal_new_frame_received.connect(self.liveController_2.on_new_frame)
		self.streamHandler_2.image_to_display.connect(self.imageDisplayWindow_2.display_image)
		self.streamHandler_2.packet_image_to_write.connect(self.imageSaver_2.enqueue)

		self.liveControlWidget_2.signal_newExposureTime.connect(self.cameraSettingWidget_2.set_exposure_time)
		self.liveControlWidget_2.signal_newAnalogGain.connect(self.cameraSettingWidget_2.set_analog_gain)
		self.liveControlWidget_2.update_camera_settings()

		self.streamHandler_1.image_to_display.connect(self.PDAFController.register_image_from_camera_1) 
		self.streamHandler_2.image_to_display.connect(self.PDAFController.register_image_from_camera_2) 
		

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.liveController_1.stop_live()
		self.camera_1.close()
		self.imageSaver_1.close()
		self.imageDisplayWindow_1.close()
		self.liveController_2.stop_live()
		self.camera_2.close()
		self.imageSaver_2.close()
		self.imageDisplayWindow_2.close()

import sys
from PyQt5.QtWidgets import QApplication, QWidget, QGridLayout, QVBoxLayout, QLabel, QDoubleSpinBox, QSpinBox, QPushButton, QCheckBox, QDialog, QDialogButtonBox
from PyQt5.QtCore import Qt


class NL5SettingsDialog(QDialog):
    def __init__(self, nl5):
        super().__init__()
        self.nl5 = nl5
        self.setWindowTitle("NL5 Settings")
        
        layout = QGridLayout()
        
        # Scan amplitude control
        layout.addWidget(QLabel("Scan Amplitude"), 0, 0)
        self.scan_amplitude_input = QDoubleSpinBox()
        self.scan_amplitude_input.setValue(self.nl5.scan_amplitude)
        layout.addWidget(self.scan_amplitude_input, 0, 1)
        
        # Offset X control
        layout.addWidget(QLabel("Offset X"), 1, 0)
        self.offset_x_input = QDoubleSpinBox()
        self.offset_x_input.setMinimum(-30)
        self.offset_x_input.setValue(self.nl5.offset_x)
        layout.addWidget(self.offset_x_input, 1, 1)
        
        # Bypass offset control
        layout.addWidget(QLabel("Bypass Offset"), 2, 0)
        self.bypass_offset_input = QDoubleSpinBox()
        self.bypass_offset_input.setMinimum(-30)
        self.bypass_offset_input.setValue(self.nl5.bypass_offset)
        layout.addWidget(self.bypass_offset_input, 2, 1)
        
        # Dialog buttons
        buttons = QDialogButtonBox(QDialogButtonBox.Ok | QDialogButtonBox.Cancel)
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addWidget(buttons, 3, 0, 1, 2)
        
        self.setLayout(layout)

    def accept(self):
        self.nl5.set_scan_amplitude(self.scan_amplitude_input.value())
        self.nl5.set_offset_x(self.offset_x_input.value())
        self.nl5.set_bypass_offset(self.bypass_offset_input.value())
        self.nl5.save_settings()
        super().accept()


class NL5Widget(QWidget):
    def __init__(self, nl5):
        super().__init__()
        
        self.nl5 = nl5
        
        # Create layout
        layout = QGridLayout()
        
        # Exposure delay control
        layout.addWidget(QLabel("Exposure Delay"), 0, 0)
        self.exposure_delay_input = QSpinBox()
        self.exposure_delay_input.setValue(self.nl5.exposure_delay_ms)
        self.exposure_delay_input.valueChanged.connect(self.update_exposure_delay)
        layout.addWidget(self.exposure_delay_input, 0, 1, 1, 3)
        
        # Line speed control
        layout.addWidget(QLabel("Line Speed"), 1, 0)
        self.line_speed_input = QSpinBox()
        self.line_speed_input.setMaximum(20000)
        self.line_speed_input.setValue(self.nl5.line_speed)
        self.line_speed_input.valueChanged.connect(self.update_line_speed)
        layout.addWidget(self.line_speed_input, 1, 1)
        
        # FOV X control
        layout.addWidget(QLabel("FOV X"), 1, 2)
        self.fov_x_input = QSpinBox()
        self.fov_x_input.setMaximum(4000)
        self.fov_x_input.setValue(self.nl5.fov_x)
        self.fov_x_input.valueChanged.connect(self.update_fov_x)
        layout.addWidget(self.fov_x_input, 1, 3)

        # Bypass control
        self.bypass_button = QPushButton("Enable Bypass")
        self.bypass_button.setCheckable(True)
        self.bypass_button.toggled.connect(self.update_bypass)
        layout.addWidget(self.bypass_button, 2, 0, 1, 4)
        
        # Start acquisition button
        self.start_acquisition_button = QPushButton("Start Acquisition")
        self.start_acquisition_button.clicked.connect(self.nl5.start_acquisition)
        # layout.addWidget(self.start_acquisition_button, 3, 0, 1, 4)

        # NL5 Settings button
        self.settings_button = QPushButton("NL5 Settings")
        self.settings_button.clicked.connect(self.show_settings_dialog)
        layout.addWidget(self.settings_button, 4, 0, 1, 4)
        
        self.setLayout(layout)
    
    def show_settings_dialog(self):
        dialog = NL5SettingsDialog(self.nl5)
        dialog.exec_()
    
    def update_bypass(self, checked):
        self.nl5.set_bypass(checked)
        self.start_acquisition_button.setEnabled(not checked)
    
    def update_exposure_delay(self, value):
        self.nl5.set_exposure_delay(value)
    
    def update_line_speed(self, value):
        self.nl5.set_line_speed(value)
    
    def update_fov_x(self, value):
        self.nl5.set_fov_x(value)


if __name__ == "__main__":
    app = QApplication(sys.argv)
    
    import NL5
    nl5 = NL5.NL5()
    widget = NL5Widget(nl5)
    widget.show()
    
    sys.exit(app.exec_())
# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera_toupcam as camera
import control.core as core
import control.microcontroller as microcontroller
from control._def import *

import pyqtgraph.dockarea as dock
SINGLE_WINDOW = True # set to False if use separate windows for display and control

import time

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, is_simulation = False, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load window
		if ENABLE_TRACKING:
			self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True,show_LUT=True,autoLevels=True)
			self.imageDisplayWindow.show_ROI_selector()
		else:
			self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True,show_LUT=True,autoLevels=True)
		self.imageArrayDisplayWindow = core.ImageArrayDisplayWindow() 
		# self.imageDisplayWindow.show()
		# self.imageArrayDisplayWindow.show()

		# image display windows
		self.imageDisplayTabs = QTabWidget()
		self.imageDisplayTabs.addTab(self.imageDisplayWindow.widget, "Live View")
		self.imageDisplayTabs.addTab(self.imageArrayDisplayWindow.widget, "Multichannel Acquisition")

		# load objects
		if is_simulation:
			self.camera = camera.Camera_Simulation(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
			self.microcontroller = microcontroller.Microcontroller_Simulation()
		else:
			self.camera = camera.Camera(resolution=(6224,4168),rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
			#self.camera = camera.Camera(resolution=(3104,2084))
			#self.camera = camera.Camera(resolution=(2064,1386))
			# 6224 x 4168
			# 3104 x 2084
			# 2064 x 1386
			try:
				self.microcontroller = microcontroller.Microcontroller(version=CONTROLLER_VERSION)
			except:
				print('! Microcontroller not detected, using simulated microcontroller !')
				self.microcontroller = microcontroller.Microcontroller_Simulation()

		# reset the MCU
		self.microcontroller.reset()

		'''
		# reinitialize motor drivers and DAC (in particular for V2.1 driver board where PG is not functional)
		self.microcontroller.initialize_drivers()
		'''

		# configure the actuators
		self.microcontroller.configure_actuators()

		self.configurationManager = core.ConfigurationManager('./channel_configurations.xml')
		self.streamHandler = core.StreamHandler(display_resolution_scaling=DEFAULT_DISPLAY_CROP/100)
		self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
		self.navigationController = core.NavigationController(self.microcontroller)
		self.slidePositionController = core.SlidePositionController(self.navigationController,self.liveController)
		self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
		self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController,self.configurationManager)
		if ENABLE_TRACKING:
			self.trackingController = core.TrackingController(self.camera,self.microcontroller,self.navigationController,self.configurationManager,self.liveController,self.autofocusController,self.imageDisplayWindow)
		self.imageSaver = core.ImageSaver(image_format=Acquisition.IMAGE_FORMAT)
		self.imageDisplay = core.ImageDisplay()
		self.navigationViewer = core.NavigationViewer()

		# homing
		'''
		self.navigationController.home_y()
		t0 = time.time()
		while self.microcontroller.is_busy():
			time.sleep(0.005)
			if time.time() - t0 > 10:
				print('y homing timeout, the program will exit')
				sys.exit(1)
		
		self.navigationController.home_x()
		t0 = time.time()
		while self.microcontroller.is_busy():
			time.sleep(0.005)
			if time.time() - t0 > 10:
				print('x homing timeout, the program will exit')
				sys.exit(1)
		'''
		'''
		self.slidePositionController.move_to_slide_scanning_position()
		while self.slidePositionController.slide_scanning_position_reached == False:
			time.sleep(0.005)
		print('homing finished')

		# retract the objective
		self.navigationController.home_z()
		# wait for the operation to finish
		t0 = time.time()
		while self.microcontroller.is_busy():
			time.sleep(0.005)
			if time.time() - t0 > 10:
				print('z homing timeout, the program will exit')
				sys.exit(1)
		print('objective retracted')
		self.navigationController.move_z(DEFAULT_Z_POS_MM)

		self.navigationController.set_x_limit_pos_mm(SOFTWARE_POS_LIMIT.X_POSITIVE)
		self.navigationController.set_x_limit_neg_mm(SOFTWARE_POS_LIMIT.X_NEGATIVE)
		self.navigationController.set_y_limit_pos_mm(SOFTWARE_POS_LIMIT.Y_POSITIVE)
		self.navigationController.set_y_limit_neg_mm(SOFTWARE_POS_LIMIT.Y_NEGATIVE)
		self.navigationController.set_z_limit_pos_mm(SOFTWARE_POS_LIMIT.Z_POSITIVE)
		'''

		# open the camera
		# camera start streaming
		self.camera.open()
		self.camera.set_gain_mode('HCG')
		# self.camera.camera.put_Roi(3112,2084,2048,2048)
		# self.camera.set_reverse_x(CAMERA_REVERSE_X) # these are not implemented for the cameras in use
		# self.camera.set_reverse_y(CAMERA_REVERSE_Y) # these are not implemented for the cameras in use
		self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera.set_callback(self.streamHandler.on_new_frame)
		self.camera.enable_callback()
		if ENABLE_STROBE_OUTPUT:
			self.camera.set_line3_to_exposure_active()

		# load widgets
		self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,include_gain_exposure_time=False,include_camera_temperature_setting=True)
		self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager,show_trigger_options=True,show_display_options=True,show_autolevel=True,autolevel=True)
		self.navigationWidget = widgets.NavigationWidget(self.navigationController,self.slidePositionController,widget_configuration='malaria')
		self.dacControlWidget = widgets.DACControWidget(self.microcontroller)
		self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
		self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)
		if ENABLE_TRACKING:
			self.trackingControlWidget = widgets.TrackingControllerWidget(self.trackingController,self.configurationManager,show_configurations=TRACKING_SHOW_MICROSCOPE_CONFIGURATIONS)
		self.multiPointWidget = widgets.MultiPointWidget(self.multipointController,self.configurationManager)

		self.recordTabWidget = QTabWidget()
		if ENABLE_TRACKING:
			self.recordTabWidget.addTab(self.trackingControlWidget, "Tracking")
		self.recordTabWidget.addTab(self.multiPointWidget, "Multipoint Acquisition")
		self.recordTabWidget.addTab(self.recordingControlWidget, "Simple Recording")

		# layout widgets
		layout = QVBoxLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget)
		layout.addWidget(self.liveControlWidget)
		layout.addWidget(self.navigationWidget)
		if SHOW_DAC_CONTROL:
			layout.addWidget(self.dacControlWidget)
		layout.addWidget(self.autofocusWidget)
		layout.addWidget(self.recordTabWidget)
		layout.addWidget(self.navigationViewer)
		layout.addStretch()
		
		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		# self.centralWidget.setFixedSize(self.centralWidget.minimumSize())
		# self.centralWidget.setFixedWidth(self.centralWidget.minimumWidth())
		# self.centralWidget.setMaximumWidth(self.centralWidget.minimumWidth())
		self.centralWidget.setFixedWidth(self.centralWidget.minimumSizeHint().width())
		
		if SINGLE_WINDOW:
			dock_display = dock.Dock('Image Display', autoOrientation = False)
			dock_display.showTitleBar()
			dock_display.addWidget(self.imageDisplayTabs)
			dock_display.setStretch(x=100,y=None)
			dock_controlPanel = dock.Dock('Controls', autoOrientation = False)
			# dock_controlPanel.showTitleBar()
			dock_controlPanel.addWidget(self.centralWidget)
			dock_controlPanel.setStretch(x=1,y=None)
			dock_controlPanel.setFixedWidth(dock_controlPanel.minimumSizeHint().width())
			main_dockArea = dock.DockArea()
			main_dockArea.addDock(dock_display)
			main_dockArea.addDock(dock_controlPanel,'right')
			self.setCentralWidget(main_dockArea)
			desktopWidget = QDesktopWidget()
			height_min = int(0.9*desktopWidget.height())
			width_min =int(0.96*desktopWidget.width())
			self.setMinimumSize(width_min,height_min)
		else:
			self.setCentralWidget(self.centralWidget)
			self.tabbedImageDisplayWindow = QMainWindow()
			self.tabbedImageDisplayWindow.setCentralWidget(self.imageDisplayTabs)
			self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() | Qt.CustomizeWindowHint)
			self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() & ~Qt.WindowCloseButtonHint)
			desktopWidget = QDesktopWidget()
			width = 0.96*desktopWidget.height()
			height = width
			self.tabbedImageDisplayWindow.setFixedSize(width,height)
			self.tabbedImageDisplayWindow.show()

		# make connections
		self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
		self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
		self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
		# self.streamHandler.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
		self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)
		if ENABLE_TRACKING:
			self.navigationController.signal_joystick_button_pressed.connect(self.trackingControlWidget.slot_joystick_button_pressed)
		else:
			self.navigationController.signal_joystick_button_pressed.connect(self.autofocusController.autofocus)
		self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
		self.multipointController.image_to_display.connect(self.imageDisplayWindow.display_image)
		self.multipointController.signal_current_configuration.connect(self.liveControlWidget.set_microscope_mode)
		self.multipointController.image_to_display_multi.connect(self.imageArrayDisplayWindow.display_image)
		self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
		self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
		self.liveControlWidget.update_camera_settings()
		self.liveControlWidget.signal_autoLevelSetting.connect(self.imageDisplayWindow.set_autolevel)

		self.slidePositionController.signal_slide_loading_position_reached.connect(self.navigationWidget.slot_slide_loading_position_reached)
		self.slidePositionController.signal_slide_loading_position_reached.connect(self.multiPointWidget.disable_the_start_aquisition_button)
		self.slidePositionController.signal_slide_scanning_position_reached.connect(self.navigationWidget.slot_slide_scanning_position_reached)
		self.slidePositionController.signal_slide_scanning_position_reached.connect(self.multiPointWidget.enable_the_start_aquisition_button)
		self.slidePositionController.signal_clear_slide.connect(self.navigationViewer.clear_slide)
		self.navigationController.xyPos.connect(self.navigationViewer.update_current_location)
		self.multipointController.signal_register_current_fov.connect(self.navigationViewer.register_fov)

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.navigationController.home()
		self.liveController.stop_live()
		self.camera.close()
		self.imageSaver.close()
		self.imageDisplay.close()
		if not SINGLE_WINDOW:
			self.imageDisplayWindow.close()
			self.imageArrayDisplayWindow.close()
			self.tabbedImageDisplayWindow.close()
		self.microcontroller.close()

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.microcontroller as microcontroller
from control._def import *

import control.widgets_usbspectrometer as widgets_usbspectrometer
import control.core_usbspectrometer as core_usbspectrometer
import control.spectrometer_oceanoptics as spectrometer

import pyqtgraph.dockarea as dock
SINGLE_WINDOW = True # set to False if use separate windows for display and control

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, is_simulation = False, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load window
		if ENABLE_TRACKING:
			self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True)
			self.imageDisplayWindow.show_ROI_selector()
		else:
			self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True)
		self.imageArrayDisplayWindow = core.ImageArrayDisplayWindow() 
		# self.imageDisplayWindow.show()
		# self.imageArrayDisplayWindow.show()

		# image display windows
		self.imageDisplayTabs = QTabWidget()
		self.imageDisplayTabs.addTab(self.imageDisplayWindow.widget, "Live View")
		# self.imageDisplayTabs.addTab(self.imageArrayDisplayWindow.widget, "Multichannel Acquisition")

		# load objects
		if is_simulation:
			self.camera = camera.Camera_Simulation(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
			self.microcontroller = microcontroller.Microcontroller_Simulation()
			self.spectrometer = spectrometer.Spectrometer_Simulation()
		else:
			self.camera = camera.Camera(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
			try:
				self.microcontroller = microcontroller.Microcontroller()
			except:
				print('! Microcontroller not detected, using simulated microcontroller !')
				self.microcontroller = microcontroller.Microcontroller_Simulation()
			try:
				self.spectrometer = spectrometer.Spectrometer()
			except:
				print('! Spectrometer not detected, using simulated microcontroller !')
				self.spectrometer = spectrometer.Spectrometer_Simulation()

		# configure the actuators
		self.microcontroller.configure_actuators()
			
		self.configurationManager = core.ConfigurationManager('./channel_configurations.xml')
		self.streamHandler = core.StreamHandler(display_resolution_scaling=DEFAULT_DISPLAY_CROP/100)
		self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
		self.navigationController = core.NavigationController(self.microcontroller)
		self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
		self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController,self.configurationManager,self.spectrometer)
		if ENABLE_TRACKING:
			self.trackingController = core.TrackingController(self.camera,self.microcontroller,self.navigationController,self.configurationManager,self.liveController,self.autofocusController,self.imageDisplayWindow)
		self.imageSaver = core.ImageSaver(image_format=Acquisition.IMAGE_FORMAT)
		self.imageDisplay = core.ImageDisplay()
		self.spectrometerStreamHandler = core_usbspectrometer.SpectrumStreamHandler()
		self.spectrumSaver = core_usbspectrometer.SpectrumSaver()

		# open the camera
		# camera start streaming
		self.camera.open()
		# self.camera.set_reverse_x(CAMERA_REVERSE_X) # these are not implemented for the cameras in use
		# self.camera.set_reverse_y(CAMERA_REVERSE_Y) # these are not implemented for the cameras in use
		self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera.set_callback(self.streamHandler.on_new_frame)
		self.camera.enable_callback()
		if ENABLE_STROBE_OUTPUT:
			self.camera.set_line3_to_exposure_active()

		self.spectrometer.set_callback(self.spectrometerStreamHandler.on_new_measurement)

		# load widgets
		self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,include_gain_exposure_time=False)
		self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager)
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
		self.dacControlWidget = widgets.DACControWidget(self.microcontroller)
		self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
		self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)
		self.spectrumRecordingWidget = widgets_usbspectrometer.RecordingWidget(self.spectrometerStreamHandler,self.spectrumSaver)
		if ENABLE_TRACKING:
			self.trackingControlWidget = widgets.TrackingControllerWidget(self.trackingController,self.configurationManager,show_configurations=TRACKING_SHOW_MICROSCOPE_CONFIGURATIONS)
		self.multiPointWidget = widgets.MultiPointWidget(self.multipointController,self.configurationManager)

		self.recordTabWidget = QTabWidget()
		if ENABLE_TRACKING:
			self.recordTabWidget.addTab(self.trackingControlWidget, "Tracking")
		self.recordTabWidget.addTab(self.recordingControlWidget, "Recording - Camera")
		self.recordTabWidget.addTab(self.spectrumRecordingWidget, "Recording - Spectrometer")
		self.recordTabWidget.addTab(self.multiPointWidget, "Multipoint Acquisition")
		self.spectrometerControlWidget = widgets_usbspectrometer.SpectrometerControlWidget(self.spectrometer,self.spectrometerStreamHandler)
		self.spectrumDisplay = widgets_usbspectrometer.SpectrumDisplay()

		# layout widgets
		layout = QVBoxLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget)
		layout.addWidget(self.liveControlWidget)
		layout.addWidget(self.navigationWidget)
		if SHOW_DAC_CONTROL:
			layout.addWidget(self.dacControlWidget)
		layout.addWidget(self.autofocusWidget)
		layout.addWidget(self.spectrometerControlWidget)
		layout.addWidget(self.recordTabWidget)
		layout.addStretch()
		
		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		# self.centralWidget.setFixedSize(self.centralWidget.minimumSize())
		# self.centralWidget.setFixedWidth(self.centralWidget.minimumWidth())
		# self.centralWidget.setMaximumWidth(self.centralWidget.minimumWidth())
		self.centralWidget.setFixedWidth(self.centralWidget.minimumSizeHint().width())
		
		if SINGLE_WINDOW:
			dock_display = dock.Dock('Image Display', autoOrientation = False)
			dock_display.showTitleBar()
			dock_display.addWidget(self.imageDisplayTabs)
			dock_display.setStretch(x=100,y=60)
			dock_spectrum = dock.Dock('Spectrum', autoOrientation = False)
			dock_spectrum.showTitleBar()
			dock_spectrum.addWidget(self.spectrumDisplay)
			dock_spectrum.setStretch(x=100,y=40)
			dock_controlPanel = dock.Dock('Controls', autoOrientation = False)
			dock_controlPanel = dock.Dock('Controls', autoOrientation = False)
			# dock_controlPanel.showTitleBar()
			dock_controlPanel.addWidget(self.centralWidget)
			dock_controlPanel.setStretch(x=1,y=None)
			dock_controlPanel.setFixedWidth(dock_controlPanel.minimumSizeHint().width())
			main_dockArea = dock.DockArea()
			main_dockArea.addDock(dock_display)
			main_dockArea.addDock(dock_spectrum,'bottom')
			main_dockArea.addDock(dock_controlPanel,'right')
			self.setCentralWidget(main_dockArea)
			desktopWidget = QDesktopWidget()
			height_min = 0.9*desktopWidget.height()
			width_min = 0.96*desktopWidget.width()
			self.setMinimumSize(width_min,height_min)
		else:
			self.setCentralWidget(self.centralWidget)
			self.tabbedImageDisplayWindow = QMainWindow()
			self.tabbedImageDisplayWindow.setCentralWidget(self.imageDisplayTabs)
			self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() | Qt.CustomizeWindowHint)
			self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() & ~Qt.WindowCloseButtonHint)
			desktopWidget = QDesktopWidget()
			width = 0.96*desktopWidget.height()
			height = width
			self.tabbedImageDisplayWindow.setFixedSize(width,height)
			self.tabbedImageDisplayWindow.show()

		# make connections
		self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
		self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
		self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
		# self.streamHandler.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
		self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)
		if ENABLE_TRACKING:
			self.navigationController.signal_joystick_button_pressed.connect(self.trackingControlWidget.slot_joystick_button_pressed)
		else:
			self.navigationController.signal_joystick_button_pressed.connect(self.autofocusController.autofocus)
		self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
		self.multipointController.image_to_display.connect(self.imageDisplayWindow.display_image)
		self.multipointController.signal_current_configuration.connect(self.liveControlWidget.set_microscope_mode)
		self.multipointController.image_to_display_multi.connect(self.imageArrayDisplayWindow.display_image)
		self.multipointController.spectrum_to_display.connect(self.spectrumDisplay.plot)
		self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
		self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
		self.liveControlWidget.update_camera_settings()
		self.spectrometerStreamHandler.spectrum_to_display.connect(self.spectrumDisplay.plot)
		self.spectrometerStreamHandler.spectrum_to_write.connect(self.spectrumSaver.enqueue)

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.navigationController.home()
		self.liveController.stop_live()
		self.camera.close()
		self.imageSaver.close()
		self.imageDisplay.close()
		self.spectrometer.close()
		self.spectrumSaver.close()
		if not SINGLE_WINDOW:
			self.imageDisplayWindow.close()
			self.imageArrayDisplayWindow.close()
			self.tabbedImageDisplayWindow.close()
		self.microcontroller.close()

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.microcontroller as microcontroller
import control.microcontroller2 as microcontroller2
from control._def import *

import pyqtgraph.dockarea as dock
SINGLE_WINDOW = True # set to False if use separate windows for display and control

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, is_simulation = False, *args, **kwargs):
		super().__init__(*args, **kwargs)

		channels = ['ch 1','ch 2']
		self.channels = channels

		self.imageDisplayWindow = {}
		for i in range(len(channels)):
			self.imageDisplayWindow[channels[i]] = core.ImageDisplayWindow(draw_crosshairs=True)

		# load objects
		self.camera = {}
		if is_simulation:
			for i in range(len(channels)):
				self.camera[channels[i]] = camera.Camera_Simulation(sn=CAMERA_SN[channels[i]],is_global_shutter=True,rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
			self.microcontroller = microcontroller.Microcontroller_Simulation()
			self.microcontroller2 = microcontroller2.Microcontroller2_Simulation()
		else:
			for i in range(len(channels)):
				self.camera[channels[i]] = camera.Camera(sn=CAMERA_SN[channels[i]],is_global_shutter=True,rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
			self.microcontroller = microcontroller.Microcontroller_Simulation()
			self.microcontroller2 = microcontroller2.Microcontroller2()

		# open the camera
		for i in range(len(channels)): 
			self.camera[channels[i]].open()
			self.camera[channels[i]].set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()

		# configure the actuators
		self.microcontroller.configure_actuators()

		# navigation controller and widget
		self.navigationController = core.NavigationController(self.microcontroller)
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
			
		self.configurationManager = {}
		self.streamHandler = {}
		self.liveController = {}
		self.imageSaver = {}

		self.cameraSettingWidget = {}
		self.liveControlWidget = {}
		self.cameraTabWidget = QTabWidget()

		for i in range(len(channels)): 
			# controllers
			self.configurationManager[channels[i]] = core.ConfigurationManager(filename=str(Path.home()) + "/configurations_" + channels[i] + ".xml")
			self.streamHandler[channels[i]] = core.StreamHandler(display_resolution_scaling=DEFAULT_DISPLAY_CROP/100)
			self.liveController[channels[i]] = core.LiveController(self.camera[channels[i]],self.microcontroller,self.configurationManager[channels[i]],use_internal_timer_for_hardware_trigger=False)
			self.imageSaver[channels[i]] = core.ImageSaver(image_format=Acquisition.IMAGE_FORMAT)
			# widgets
			self.cameraSettingWidget[channels[i]] = widgets.CameraSettingsWidget(self.camera[channels[i]],include_gain_exposure_time=False)
			self.liveControlWidget[channels[i]] = widgets.LiveControlWidget(self.streamHandler[channels[i]],self.liveController[channels[i]],self.configurationManager[channels[i]])
			# self.recordingControlWidget[channels[i]] = widgets.RecordingWidget(self.streamHandler[channels[i]],self.imageSaver[channels[i]])
			self.cameraTabWidget.addTab(self.liveControlWidget[channels[i]], channels[i])
			# self.liveControlWidget[channels[i]].setSizePolicy(QSizePolicy.Minimum, QSizePolicy.Minimum)
			# self.liveControlWidget[channels[i]].resize(self.liveControlWidget[channels[i]].minimumSizeHint())
			# self.liveControlWidget[channels[i]].adjustSize()
		self.cameraTabWidget.resize(self.cameraTabWidget.minimumSizeHint())
		self.cameraTabWidget.adjustSize()

		# self.recordTabWidget = QTabWidget()
		# for i in range(len(channels)): 
		# 	self.recordTabWidget.addTab(self.recordingControlWidget[channels[i]], "Simple Recording")
		self.multiCameraRecordingWidget = widgets.MultiCameraRecordingWidget(self.streamHandler,self.imageSaver,self.channels)

		# trigger control
		self.triggerControlWidget = widgets.TriggerControlWidget(self.microcontroller2)

		# layout widgets
		layout = QVBoxLayout() #layout = QStackedLayout()
		# layout.addWidget(self.cameraSettingWidget)
		layout.addWidget(self.cameraTabWidget)
		layout.addWidget(self.triggerControlWidget)
		layout.addWidget(self.multiCameraRecordingWidget)
		# layout.addWidget(self.navigationWidget)
		# layout.addWidget(self.recordTabWidget)
		layout.addStretch()
		
		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		# self.centralWidget.setFixedSize(self.centralWidget.minimumSize())
		# self.centralWidget.setFixedWidth(self.centralWidget.minimumWidth())
		# self.centralWidget.setMaximumWidth(self.centralWidget.minimumWidth())
		self.centralWidget.setFixedWidth(self.centralWidget.minimumSizeHint().width())
		
		dock_display = {}
		for i in range(len(channels)):
			dock_display[channels[i]] = dock.Dock('Image Display ' + channels[i] , autoOrientation = False)
			dock_display[channels[i]].showTitleBar()
			dock_display[channels[i]].addWidget(self.imageDisplayWindow[channels[i]].widget)
			dock_display[channels[i]].setStretch(x=100,y=None)
		dock_controlPanel = dock.Dock('Controls', autoOrientation = False)
		# dock_controlPanel.showTitleBar()
		dock_controlPanel.addWidget(self.centralWidget)
		dock_controlPanel.setStretch(x=1,y=None)
		dock_controlPanel.setFixedWidth(dock_controlPanel.minimumSizeHint().width())
		main_dockArea = dock.DockArea()
		for i in range(len(channels)):
			if i == 0:
				main_dockArea.addDock(dock_display[channels[i]])
			else:
				main_dockArea.addDock(dock_display[channels[i]],'right')
		main_dockArea.addDock(dock_controlPanel,'right')
		self.setCentralWidget(main_dockArea)
		desktopWidget = QDesktopWidget()
		height_min = 0.9*desktopWidget.height()
		width_min = 0.96*desktopWidget.width()
		self.setMinimumSize(width_min,height_min)

		# make connections
		for i in range(len(channels)): 
			self.streamHandler[channels[i]].signal_new_frame_received.connect(self.liveController[channels[i]].on_new_frame)
			self.streamHandler[channels[i]].image_to_display.connect(self.imageDisplayWindow[channels[i]].display_image)
			self.streamHandler[channels[i]].packet_image_to_write.connect(self.imageSaver[channels[i]].enqueue)
			self.liveControlWidget[channels[i]].signal_newExposureTime.connect(self.cameraSettingWidget[channels[i]].set_exposure_time)
			self.liveControlWidget[channels[i]].signal_newAnalogGain.connect(self.cameraSettingWidget[channels[i]].set_analog_gain)
			self.liveControlWidget[channels[i]].update_camera_settings()
			self.triggerControlWidget.signal_toggle_live.connect(self.liveControlWidget[channels[i]].btn_live.setChecked)
			self.triggerControlWidget.signal_toggle_live.connect(self.liveControlWidget[channels[i]].toggle_live)
			self.triggerControlWidget.signal_trigger_mode.connect(self.liveControlWidget[channels[i]].set_trigger_mode)
			self.triggerControlWidget.signal_trigger_fps.connect(self.liveControlWidget[channels[i]].entry_triggerFPS.setValue)
			self.camera[channels[i]].set_callback(self.streamHandler[channels[i]].on_new_frame)
			self.camera[channels[i]].enable_callback()
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.navigationController.home()
		for i in range(len(self.channels)): 
			self.liveController[self.channels[i]].stop_live()
			self.camera[self.channels[i]].close()
			self.imageSaver[self.channels[i]].close()
		self.microcontroller.close()

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

import control.utils as utils
from control._def import *
from control.core import *
import control.tracking as tracking

from queue import Queue
from threading import Thread, Lock
import time
import numpy as np
import pyqtgraph as pg
import cv2
from datetime import datetime

import skimage # pip3 install -U scikit-image
import skimage.registration

class PDAFController(QObject):

    # input: stream from camera 1, stream from camera 2
    # input: from internal_states shared variables
    # output: amount of defocus, which may be read by or emitted to focusTrackingController (that manages focus tracking on/off, PID coefficients)

    def __init__(self,internal_states):
        QObject.__init__(self)
        self.coefficient_shift2defocus = 1
        self.registration_upsample_factor = 5
        self.image1_received = False
        self.image2_received = False
        self.locked = False
        self.shared_variables = internal_states

    def register_image_from_camera_1(self,image):
        if(self.locked==True):
            return
        self.image1 = np.copy(image)
        self.image1_received = True
        if(self.image2_received):
            self.calculate_defocus()

    def register_image_from_camera_2(self,image):
        if(self.locked==True):
            return
        self.image2 = np.copy(image)
        self.image2 = np.fliplr(self.image2) # can be flipud depending on camera orientation
        self.image2_received = True
        if(self.image1_received):
            self.calculate_defocus()

    def calculate_defocus(self):
        self.locked = True
        # cropping parameters
        self.x = self.shared_variables.x
        self.y = self.shared_variables.y
        self.w = self.shared_variables.w*2 # double check which dimension to multiply
        self.h = self.shared_variables.h
        # crop
        self.image1 = self.image1[(self.y-int(self.h/2)):(self.y+int(self.h/2)),(self.x-int(self.w/2)):(self.x+int(self.w/2))]
        self.image2 = self.image2[(self.y-int(self.h/2)):(self.y+int(self.h/2)),(self.x-int(self.w/2)):(self.x+int(self.w/2))] # additional offsets may need to be added
        shift = self._compute_shift_from_image_pair()
        self.defocus = shift*self.coefficient_shift2defocus
        self.image1_received = False
        self.image2_received = False
        self.locked = False

    def _compute_shift_from_image_pair(self):
        # method 1: calculate 2D cross correlation -> find peak or centroid
        '''
        I1 = np.array(self.image1,dtype=np.int)
        I2 = np.array(self.image2,dtype=np.int)
        I1 = I1 - np.mean(I1)
        I2 = I2 - np.mean(I2)
        xcorr = cv2.filter2D(I1,cv2.CV_32F,I2)
        cv2.imshow('xcorr',np.array(255*xcorr/np.max(xcorr),dtype=np.uint8))
        cv2.waitKey(15)  
        '''
        # method 2: use skimage.registration.phase_cross_correlation
        shifts,error,phasediff = skimage.registration.phase_cross_correlation(self.image1,self.image2,upsample_factor=self.registration_upsample_factor,space='real')
        print(shifts) # for debugging
        return shifts[0] # can be shifts[1] - depending on camera orientation

    def close(self):
        pass

class TwoCamerasPDAFCalibrationController(QObject):

    acquisitionFinished = Signal()
    image_to_display_camera1 = Signal(np.ndarray)
    image_to_display_camera2 = Signal(np.ndarray)
    signal_current_configuration = Signal(Configuration)

    z_pos = Signal(float)

    def __init__(self,camera1,camera2,navigationController,liveController1,liveController2,configurationManager=None):
        QObject.__init__(self)

        self.camera1 = camera1
        self.camera2 = camera2
        self.navigationController = navigationController
        self.liveController1 = liveController1
        self.liveController2 = liveController2
        self.configurationManager = configurationManager
        self.NZ = 1
        self.Nt = 1
        self.deltaZ = Acquisition.DZ/1000
        self.deltaZ_usteps = round((Acquisition.DZ/1000)*Motion.STEPS_PER_MM_Z)
        self.crop_width = Acquisition.CROP_WIDTH
        self.crop_height = Acquisition.CROP_HEIGHT
        self.display_resolution_scaling = Acquisition.IMAGE_DISPLAY_SCALING_FACTOR
        self.counter = 0
        self.experiment_ID = None
        self.base_path = None

    def set_NX(self,N):
        self.NX = N
    def set_NY(self,N):
        self.NY = N
    def set_NZ(self,N):
        self.NZ = N
    def set_Nt(self,N):
        self.Nt = N
    def set_deltaX(self,delta):
        self.deltaX = delta
        self.deltaX_usteps = round(delta*Motion.STEPS_PER_MM_XY)
    def set_deltaY(self,delta):
        self.deltaY = delta
        self.deltaY_usteps = round(delta*Motion.STEPS_PER_MM_XY)
    def set_deltaZ(self,delta_um):
        self.deltaZ = delta_um/1000
        self.deltaZ_usteps = round((delta_um/1000)*Motion.STEPS_PER_MM_Z)
    def set_deltat(self,delta):
        self.deltat = delta
    def set_af_flag(self,flag):
        self.do_autofocus = flag

    def set_crop(self,crop_width,height):
        self.crop_width = crop_width
        self.crop_height = crop_height
    def set_base_path(self,path):
        self.base_path = path
    def start_new_experiment(self,experiment_ID): # @@@ to do: change name to prepare_folder_for_new_experiment
        # generate unique experiment ID
        self.experiment_ID = experiment_ID + '_' + datetime.now().strftime('%Y-%m-%d %H-%M-%S.%f')
        self.recording_start_time = time.time()
        # create a new folder
        try:
            os.mkdir(os.path.join(self.base_path,self.experiment_ID))
            if self.configurationManager:
                self.configurationManager.write_configuration(os.path.join(self.base_path,self.experiment_ID)+"/configurations.xml") # save the configuration for the experiment
        except:
            pass

    def set_selected_configurations(self, selected_configurations_name):
        self.selected_configurations = []
        for configuration_name in selected_configurations_name:
            self.selected_configurations.append(next((config for config in self.configurationManager.configurations if config.name == configuration_name)))
        
    def run_acquisition(self): # @@@ to do: change name to run_experiment
        print('start multipoint')
        
        # stop live
        if self.liveController1.is_live:
            self.liveController1.was_live_before_multipoint = True
            self.liveController1.stop_live() # @@@ to do: also uncheck the live button
        else:
            self.liveController1.was_live_before_multipoint = False
        # stop live
        if self.liveController2.is_live:
            self.liveController2.was_live_before_multipoint = True
            self.liveController2.stop_live() # @@@ to do: also uncheck the live button
        else:
            self.liveController2.was_live_before_multipoint = False

        # disable callback
        if self.camera1.callback_is_enabled:
            self.camera1.callback_was_enabled_before_multipoint = True
            self.camera1.stop_streaming()
            self.camera1.disable_callback()
            self.camera1.start_streaming() # @@@ to do: absorb stop/start streaming into enable/disable callback - add a flag is_streaming to the camera class
        else:
            self.camera1.callback_was_enabled_before_multipoint = False
        # disable callback
        if self.camera2.callback_is_enabled:
            self.camera2.callback_was_enabled_before_multipoint = True
            self.camera2.stop_streaming()
            self.camera2.disable_callback()
            self.camera2.start_streaming() # @@@ to do: absorb stop/start streaming into enable/disable callback - add a flag is_streaming to the camera class
        else:
            self.camera2.callback_was_enabled_before_multipoint = False

        for self.time_point in range(self.Nt):
            self._run_multipoint_single()

        # re-enable callback
        if self.camera1.callback_was_enabled_before_multipoint:
            self.camera1.stop_streaming()
            self.camera1.enable_callback()
            self.camera1.start_streaming()
            self.camera1.callback_was_enabled_before_multipoint = False
        # re-enable callback
        if self.camera2.callback_was_enabled_before_multipoint:
            self.camera2.stop_streaming()
            self.camera2.enable_callback()
            self.camera2.start_streaming()
            self.camera2.callback_was_enabled_before_multipoint = False

        if self.liveController1.was_live_before_multipoint:
            self.liveController1.start_live()
        if self.liveController2.was_live_before_multipoint:
            self.liveController2.start_live()

        # emit acquisitionFinished signal
        self.acquisitionFinished.emit()
        QApplication.processEvents()

    def _run_multipoint_single(self):
        # for each time point, create a new folder
        current_path = os.path.join(self.base_path,self.experiment_ID,str(self.time_point))
        os.mkdir(current_path)
        
        # z-stack
        for k in range(self.NZ):
            file_ID = str(k)
            if self.configurationManager:
                # iterate through selected modes
                for config in self.selected_configurations:
                    self.signal_current_configuration.emit(config)
                    self.camera1.send_trigger() 
                    image = self.camera1.read_frame()
                    image = utils.crop_image(image,self.crop_width,self.crop_height)
                    saving_path = os.path.join(current_path, 'camera1_' + file_ID + str(config.name) + '.' + Acquisition.IMAGE_FORMAT)
                    image_to_display = utils.crop_image(image,round(self.crop_width*self.liveController1.display_resolution_scaling), round(self.crop_height*self.liveController1.display_resolution_scaling))
                    self.image_to_display_camera1.emit(image_to_display)
                    if self.camera1.is_color:
                        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)
                    cv2.imwrite(saving_path,image)

                    self.camera2.send_trigger() 
                    image = self.camera2.read_frame()
                    image = utils.crop_image(image,self.crop_width,self.crop_height)
                    saving_path = os.path.join(current_path, 'camera2_' + file_ID + str(config.name) + '.' + Acquisition.IMAGE_FORMAT)
                    image_to_display = utils.crop_image(image,round(self.crop_width*self.liveController2.display_resolution_scaling), round(self.crop_height*self.liveController2.display_resolution_scaling))
                    self.image_to_display_camera2.emit(image_to_display)
                    if self.camera2.is_color:
                        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)
                    cv2.imwrite(saving_path,image)
                    QApplication.processEvents()
            else:
                self.camera1.send_trigger() 
                image = self.camera1.read_frame()
                image = utils.crop_image(image,self.crop_width,self.crop_height)
                saving_path = os.path.join(current_path, 'camera1_' + file_ID + '.' + Acquisition.IMAGE_FORMAT)
                image_to_display = utils.crop_image(image,round(self.crop_width*self.liveController1.display_resolution_scaling), round(self.crop_height*self.liveController1.display_resolution_scaling))
                self.image_to_display_camera1.emit(image_to_display)
                if self.camera1.is_color:
                    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)
                cv2.imwrite(saving_path,image)

                self.camera2.send_trigger() 
                image = self.camera2.read_frame()
                image = utils.crop_image(image,self.crop_width,self.crop_height)
                saving_path = os.path.join(current_path, 'camera2_' + file_ID + '.' + Acquisition.IMAGE_FORMAT)
                image_to_display = utils.crop_image(image,round(self.crop_width*self.liveController2.display_resolution_scaling), round(self.crop_height*self.liveController2.display_resolution_scaling))
                self.image_to_display_camera2.emit(image_to_display)
                if self.camera2.is_color:
                    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)
                cv2.imwrite(saving_path,image)
                QApplication.processEvents()
            # move z
            if k < self.NZ - 1:
                self.navigationController.move_z_usteps(self.deltaZ_usteps)
        
        # move z back
        self.navigationController.move_z_usteps(-self.deltaZ_usteps*(self.NZ-1))

#!/usr/bin/python
# -*- coding:utf-8 -*-
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-
#

GAMMA_MIN = 0.1
GAMMA_MAX = 10.0
CONTRAST_MIN = -50
CONTRAST_MAX = 100
UNSIGNED_INT_MAX = 0xFFFFFFFF
UNSIGNED_LONG_LONG_MAX = 0xFFFFFFFFFFFFFFFF


# frame state code
class GxFrameStatusList:
    SUCCESS = 0                 # Normal frame
    INCOMPLETE = -1             # Residual frame
    INVALID_IMAGE_INFO = -2     # invalid image info

    def __init__(self):
        pass


# Device type code
class GxDeviceClassList:
    UNKNOWN = 0                 # Unknown device type
    USB2 = 1                    # USB2.0 vision device
    GEV = 2                     # Gige vision device
    U3V = 3                     # USB3.0 vision device
    SMART = 4                   # Smart device

    def __init__(self):
        pass


class GxAccessMode:
    READONLY = 2                # Open the device in read-only mode
    CONTROL = 3                 # Open the device in controlled mode
    EXCLUSIVE = 4               # Open the device in exclusive mode

    def __init__(self):
        pass


class GxAccessStatus:
    UNKNOWN = 0                # The device's current status is unknown
    READWRITE = 1              # The device currently supports reading and writing
    READONLY = 2               # The device currently only supports reading
    NOACCESS = 3               # The device currently does neither support reading nor support writing

    def __init__(self):
        pass


class GxIPConfigureModeList:
    DHCP = 0x6                 # Enable the DHCP mode to allocate the IP address by the DHCP server
    LLA = 0x4                  # Enable the LLA mode to allocate the IP addresses
    STATIC_IP = 0x5            # Enable the static IP mode to configure the IP address
    DEFAULT = 0x7              # Enable the default mode to configure the IP address

    def __init__(self):
        pass


class GxPixelSizeEntry:
    BPP8 = 8
    BPP10 = 10
    BPP12 = 12
    BPP14 = 14
    BPP16 = 16
    BPP24 = 24
    BPP30 = 30
    BPP32 = 32
    BPP36 = 36
    BPP48 = 48
    BPP64 = 64

    def __init__(self):
        pass


class GxPixelColorFilterEntry:
    NONE = 0
    BAYER_RG = 1
    BAYER_GB = 2
    BAYER_GR = 3
    BAYER_BG = 4

    def __init__(self):
        pass


GX_PIXEL_MONO = 0x01000000
GX_PIXEL_COLOR = 0x02000000
GX_PIXEL_8BIT = 0x00080000
GX_PIXEL_10BIT = 0x000A0000
GX_PIXEL_12BIT = 0x000C0000
GX_PIXEL_16BIT = 0x00100000
GX_PIXEL_24BIT = 0x00180000
GX_PIXEL_30BIT = 0x001E0000
GX_PIXEL_32BIT = 0x00200000
GX_PIXEL_36BIT = 0x00240000
GX_PIXEL_48BIT = 0x00300000
GX_PIXEL_64BIT = 0x00400000


class GxPixelFormatEntry:
    UNDEFINED = 0
    MONO8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x0001)  # 0x1080001
    MONO8_SIGNED = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x0002)  # 0x1080002
    MONO10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0003)  # 0x1100003
    MONO12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0005)  # 0x1100005
    MONO14 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0025)  # 0x1100025
    MONO16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0007)  # 0x1100007
    BAYER_GR8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x0008)  # 0x1080008
    BAYER_RG8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x0009)  # 0x1080009
    BAYER_GB8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x000A)  # 0x108000A
    BAYER_BG8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x000B)  # 0x108000B
    BAYER_GR10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x000C)  # 0x110000C
    BAYER_RG10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x000D)  # 0x110000D
    BAYER_GB10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x000E)  # 0x110000E
    BAYER_BG10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x000F)  # 0x110000F
    BAYER_GR12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0010)  # 0x1100010
    BAYER_RG12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0011)  # 0x1100011
    BAYER_GB12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0012)  # 0x1100012
    BAYER_BG12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0013)  # 0x1100013
    BAYER_GR16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x002E)  # 0x110002E
    BAYER_RG16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x002F)  # 0x110002F
    BAYER_GB16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0030)  # 0x1100030
    BAYER_BG16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0031)  # 0x1100031
    RGB8_PLANAR = (GX_PIXEL_COLOR | GX_PIXEL_24BIT | 0x0021)  # 0x2180021
    RGB10_PLANAR = (GX_PIXEL_COLOR | GX_PIXEL_48BIT | 0x0022)  # 0x2300022
    RGB12_PLANAR = (GX_PIXEL_COLOR | GX_PIXEL_48BIT | 0x0023)  # 0x2300023
    RGB16_PLANAR = (GX_PIXEL_COLOR | GX_PIXEL_48BIT | 0x0024)  # 0x2300024

    def __init__(self):
        pass


class GxAcquisitionModeEntry:
    SINGLE_FRAME = 0
    MULITI_FRAME = 1
    CONTINUOUS = 2

    def __init__(self):
        pass


class GxTriggerSourceEntry:
    SOFTWARE = 0
    LINE0 = 1
    LINE1 = 2
    LINE2 = 3
    LINE3 = 4


    def __init__(self):
        pass


class GxTriggerActivationEntry:
    FALLING_EDGE = 0
    RISING_EDGE = 1

    def __init__(self):
        pass


class GxExposureModeEntry:
    TIMED = 1
    TRIGGER_WIDTH = 2

    def __init__(self):
        pass


class GxUserOutputSelectorEntry:
    OUTPUT0 = 1
    OUTPUT1 = 2
    OUTPUT2 = 4

    def __init__(self):
        pass


class GxUserOutputModeEntry:
    STROBE = 0
    USER_DEFINED = 1

    def __init__(self):
        pass


class GxGainSelectorEntry:
    ALL = 0
    RED = 1
    GREEN = 2
    BLUE = 3

    def __init__(self):
        pass


class GxBlackLevelSelectEntry:
    ALL = 0
    RED = 1
    GREEN = 2
    BLUE = 3

    def __init__(self):
        pass


class GxBalanceRatioSelectorEntry:
    RED = 0
    GREEN = 1
    BLUE = 2

    def __init__(self):
        pass


class GxAALightEnvironmentEntry:
    NATURE_LIGHT = 0
    AC50HZ = 1
    AC60HZ = 2

    def __init__(self):
        pass


class GxUserSetEntry:
    DEFAULT = 0
    USER_SET0 = 1

    def __init__(self):
        pass


class GxAWBLampHouseEntry:
    ADAPTIVE = 0
    D65 = 1
    FLUORESCENCE = 2
    INCANDESCENT = 3
    D75 = 4
    D50 = 5
    U30 = 6

    def __init__(self):
        pass


class GxTestPatternEntry:
    OFF = 0
    GRAY_FRAME_RAMP_MOVING = 1
    SLANT_LINE_MOVING = 2
    VERTICAL_LINE_MOVING = 3
    SLANT_LINE = 6

    def __init__(self):
        pass


class GxTriggerSelectorEntry:
    FRAME_START = 1
    FRAME_BURST_START = 2

    def __init__(self):
        pass


class GxLineSelectorEntry:
    LINE0 = 0
    LINE1 = 1
    LINE2 = 2
    LINE3 = 3

    def __init__(self):
        pass


class GxLineModeEntry:
    INPUT = 0
    OUTPUT = 1

    def __init__(self):
        pass


class GxLineSourceEntry:
    OFF = 0
    STROBE = 1
    USER_OUTPUT0 = 2
    USER_OUTPUT1 = 3
    USER_OUTPUT2 = 4
    EXPOSURE_ACTIVE = 5
    FRAME_TRIGGER_WAIT = 6
    ACQUISITION_TRIGGER_WAIT = 7
    TIMER1_ACTIVE = 8

    def __init__(self):
        pass


class GxEventSelectorEntry:
    EXPOSURE_END = 0x0004
    BLOCK_DISCARD = 0x9000
    EVENT_OVERRUN = 0x9001
    FRAME_START_OVER_TRIGGER = 0x9002
    BLOCK_NOT_EMPTY = 0x9003
    INTERNAL_ERROR = 0x9004

    def __init__(self):
        pass


class GxLutSelectorEntry:
    LUMINANCE = 0

    def __init__(self):
        pass


class GxTransferControlModeEntry:
    BASIC = 0
    USER_CONTROLED = 1

    def __init__(self):
        pass


class GxTransferOperationModeEntry:
    MULTI_BLOCK = 0

    def __init__(self):
        pass


class GxTestPatternGeneratorSelectorEntry:
    SENSOR = 0          # Sensor test pattern
    REGION0 = 1         # FPGA test pattern

    def __init__(self):
        pass


class GxChunkSelectorEntry:
    FRAME_ID = 1
    TIME_STAMP = 2
    COUNTER_VALUE = 3

    def __init__(self):
        pass

class GxTimerSelectorEntry:
    TIMER1 = 1         

    def __init__(self):
        pass

class GxTimerTriggerSourceEntry:
    EXPOSURE_START = 1

    def __init__(self):
        pass

class GxCounterSelectorEntry:
    COUNTER1 = 1

    def __init__(self):
        pass

class GxCounterEventSourceEntry:
    FRAME_START = 1

    def __init__(self):
        pass

class GxCounterResetSourceEntry:
    OFF = 0
    SOFTWARE = 1
    LINE0 = 2
    LINE1 = 3
    LINE2 = 4
    LINE3 = 5

    def __init__(self):
        pass

class GxCounterResetActivationEntry:
    RISING_EDGE = 1

    def __init__(self):
        pass               

class GxBinningHorizontalModeEntry:
    SUM = 0
    AVERAGE = 1

    def __init__(self):
        pass


class GxBinningVerticalModeEntry:
    SUM = 0
    AVERAGE = 1

    def __init__(self):
        pass


class GxAcquisitionStatusSelectorEntry:
    ACQUISITION_TRIGGER_WAIT = 0
    FRAME_TRIGGER_WAIT = 1

    def __init__(self):
        pass


class GxGammaModeEntry:
    SRGB = 0
    USER = 1

    def __init__(self):
        pass


class GxColorTransformationModeEntry:
    RGB_TO_RGB = 0
    USER = 1

    def __init__(self):
        pass


class GxColorTransformationValueSelectorEntry:
    GAIN00 = 0
    GAIN01 = 1
    GAIN02 = 2
    GAIN10 = 3
    GAIN11 = 4
    GAIN12 = 5
    GAIN20 = 6
    GAIN21 = 7
    GAIN22 = 8

    def __init__(self):
        pass


class GxAutoEntry:
    OFF = 0
    CONTINUOUS = 1
    ONCE = 2

    def __init__(self):
        pass


class GxSwitchEntry:
    OFF = 0
    ON = 1

    def __init__(self):
        pass


class GxRegionSendModeEntry:
    SINGLE_ROI = 0
    MULTI_ROI = 1

    def __init__(self):
        pass


class GxRegionSelectorEntry:
    REGION0 = 0
    REGION1 = 1
    REGION2 = 2
    REGION3 = 3
    REGION4 = 4
    REGION5 = 5
    REGION6 = 6
    REGION7 = 7

    def __init__(self):
        pass


# image interpolation method
class DxBayerConvertType:
    NEIGHBOUR = 0                           # Neighborhood average interpolation algorithm
    ADAPTIVE = 1                            # Edge adaptive interpolation algorithm
    NEIGHBOUR3 = 2                          # The neighborhood average interpolation algorithm for a larger region

    def __init__(self):
        pass


# image valid bit
class DxValidBit:
    BIT0_7 = 0              # bit 0~7
    BIT1_8 = 1              # bit 1~8
    BIT2_9 = 2              # bit 2~9
    BIT3_10 = 3             # bit 3~10
    BIT4_11 = 4             # bit 4~11

    def __init__(self):
        pass


# image mirror method
class DxImageMirrorMode:
    HORIZONTAL_MIRROR = 0                               # Horizontal mirror
    VERTICAL_MIRROR = 1                                 # Vertical mirror

    def __init__(self):
        pass

import serial
from serial.tools import list_ports
import time

class SerialDevice:
    """
    General wrapper for serial devices, with
    automating device finding based on VID/PID
    or serial number.
    """
    def __init__(self, port=None, VID=None,PID=None,SN=None, baudrate=9600, read_timeout=1, **kwargs):
        # Initialize the serial connection
        self.port = port
        self.VID = VID
        self.PID = PID
        self.SN = SN

        self.baudrate = baudrate
        self.read_timeout = read_timeout
        self.serial_kwargs = kwargs
        
        self.serial = None

        if VID is not None and PID is not None:
            for d in list_ports.comports():
                if d.vid == VID and d.pid == PID:
                    self.port = d.device
                    break
        if SN is not None:
            for d in list_ports.comports():
                if d.serial_number == SN:
                    self.port = d.device
                    break

        if self.port is not None:
            self.serial = serial.Serial(self.port, baudrate=baudrate, timeout=read_timeout, **kwargs)

    def open_ser(self, SN=None, VID=None, PID=None, baudrate =None, read_timeout=None,**kwargs):
        if self.serial is not None and not self.serial.is_open:
            self.serial.open()
        
        if SN is None:
            SN = self.SN

        if VID is None:
            VID = self.VID

        if PID is None:
            PID = self.PID

        if baudrate is None:
            baudrate = self.baudrate

        if read_timeout is None:
            read_timeout = self.read_timeout

        for k in self.serial_kwargs.keys():
            if k not in kwargs:
                kwargs[k] = self.serial_kwargs[k]

        if self.serial is None:
            if VID is not None and PID is not None:
                for d in list_ports.comports():
                    if d.vid == VID and d.pid == PID:
                        self.port = d.device
                        break
            if SN is not None:
                for d in list_ports.comports():
                    if d.serial_number == SN:
                        self.port = d.device
                        break
            if self.port is not None:
                self.serial = serial.Serial(self.port,**kwargs)

    def write_and_check(self, command, expected_response, read_delay=0.1, max_attempts=3, attempt_delay=1, check_prefix=True, print_response=False):
        # Write a command and check the response
        for attempt in range(max_attempts):
            self.serial.write(command.encode())
            time.sleep(read_delay)  # Wait for the command to be sent

            response = self.serial.readline().decode().strip()
            if print_response:
                print(response)

            # flush the input buffer
            while self.serial.in_waiting:
                if print_response:
                    print(self.serial.readline().decode().strip())
                else:
                    self.serial.readline().decode().strip()

            # check response
            if response == expected_response:
                return response
            else:
            	print(response)
            
            # check prefix if the full response does not match
            if check_prefix:
                if response.startswith(expected_response):
                    return response
            else:
                time.sleep(attempt_delay)  # Wait before retrying

        raise RuntimeError("Max attempts reached without receiving expected response.")

    def write(self, command):
        self.serial.write(command.encode())

    def close(self):
        # Close the serial connection
        self.serial.close()

class XLight_Simulation:
    def __init__(self):
        self.emission_wheel_pos = 1
        self.dichroic_wheel_pos = 1
        self.disk_motor_state = False
        self.spinning_disk_pos = 0

    def set_emission_filter(self,position, extraction=False):
        self.emission_wheel_pos = position
        return position

    def get_emission_filter(self):
        return self.emission_wheel_pos

    def set_dichroic(self, position, extraction=False):
        self.dichroic_wheel_pos = position
        return position

    def get_dichroic(self):
        return self.dichroic_wheel_pos

    
    def set_disk_position(self, position):
        self.spinning_disk_pos = position
        return position

    def get_disk_position(self):
        return self.spinning_disk_pos

    def set_disk_motor_state(self, state):
        self.disk_motor_state = state
        return state

    def get_disk_motor_state(self):
        return self.disk_motor_state

# CrestOptics X-Light Port specs:
# 9600 baud
# 8 data bits
# 1 stop bit
# No parity
# no flow control

class XLight:
    """Wrapper for communicating with CrestOptics X-Light devices over serial"""
    def __init__(self, SN, sleep_time_for_wheel = 0.25):
        """
        Provide serial number (default is that of the device
        cephla already has) for device-finding purposes. Otherwise, all
        XLight devices should use the same serial protocol
        """
        self.serial_connection = SerialDevice(SN=SN,baudrate=115200,
                bytesize=serial.EIGHTBITS,stopbits=serial.STOPBITS_ONE,
                parity=serial.PARITY_NONE,
                xonxoff=False,rtscts=False,dsrdtr=False)
        self.serial_connection.open_ser()

        self.sleep_time_for_wheel = sleep_time_for_wheel
    
    def set_emission_filter(self,position,extraction=False,validate=True):
        if str(position) not in ["1","2","3","4","5","6","7","8"]:
            raise ValueError("Invalid emission filter wheel position!")
        position_to_write = str(position)
        position_to_read = str(position)
        if extraction:
            position_to_write+="m"

        if validate:
            current_pos = self.serial_connection.write_and_check("B"+position_to_write+"\r","B"+position_to_read)
            self.emission_wheel_pos = int(current_pos[1])
        else:
            self.serial_connection.write("B"+position_to_write+"\r")
            time.sleep(self.sleep_time_for_wheel)
            self.emission_wheel_pos = position

        return self.emission_wheel_pos

    def get_emission_filter(self):
        current_pos = self.serial_connection.write_and_check("rB\r","rB")
        self.emission_wheel_pos = int(current_pos[2])
        return self.emission_wheel_pos

    def set_dichroic(self, position,extraction=False):
        if str(position) not in ["1","2","3","4","5"]:
            raise ValueError("Invalid dichroic wheel position!")
        position_to_write = str(position)
        position_to_read = str(position)
        if extraction:
            position_to_write+="m"

        current_pos = self.serial_connection.write_and_check("C"+position_to_write+"\r","C"+position_to_read)
        self.dichroic_wheel_pos = int(current_pos[1])
        return self.dichroic_wheel_pos

    def get_dichroic(self):
        current_pos = self.serial_connection.write_and_check("rC\r","rC")
        self.dichroic_wheel_pos = int(current_pos[2])
        return self.dichroic_wheel_pos

    def set_disk_position(self,position):
        if str(position) not in ["0","1","2","wide field","confocal"]:
            raise ValueError("Invalid disk position!")
        if position == "wide field":
            position = "0"

        if position == "confocal":
            position = "1'"

        position_to_write = str(position)
        position_to_read = str(position)

        current_pos = self.serial_connection.write_and_check("D"+position_to_write+"\r","D"+position_to_read)
        self.spinning_disk_pos = int(current_pos[1])
        return self.spinning_disk_pos

    def get_disk_position(self):
        current_pos = self.serial_connection.write_and_check("rD\r","rD")
        self.spinning_disk_pos = int(current_pos[2])
        return self.spinning_disk_pos

    def set_disk_motor_state(self, state):
        """Set True for ON, False for OFF"""
        if state:
            state_to_write = "1"
        else:
            state_to_write = "0"

        current_pos = self.serial_connection.write_and_check("N"+state_to_write+"\r","N"+state_to_write)

        self.disk_motor_state = bool(int(current_pos[1]))

    def get_disk_motor_state(self):
        """Return True for on, Off otherwise"""
        current_pos = self.serial_connection.write_and_check("rN\r","rN")
        self.disk_motor_state = bool(int(current_pos[2]))
        return self.disk_motor_state

class LDI:
    """Wrapper for communicating with LDI over serial"""
    def __init__(self, SN="00000001"):
        """
        Provide serial number
        """
        self.serial_connection = SerialDevice(SN=SN,baudrate=9600,
                bytesize=serial.EIGHTBITS,stopbits=serial.STOPBITS_ONE,
                parity=serial.PARITY_NONE, 
                xonxoff=False,rtscts=False,dsrdtr=False)
        self.serial_connection.open_ser()
    
    def run(self):
        self.serial_connection.write_and_check("run!\r","ok")

    def set_intensity(self,channel,intensity):
        channel = str(channel)
        intensity = "{:.2f}".format(intensity)
        print('set:'+channel+'='+intensity+'\r')
        self.serial_connection.write_and_check('set:'+channel+'='+intensity+'\r',"ok")
        print('active channel: ' + str(self.active_channel))
    
    def set_shutter(self,channel,state):
        channel = str(channel)
        state = str(state)
        self.serial_connection.write_and_check('shutter:'+channel+'='+state+'\r',"ok")

    def get_shutter_state(self):
        self.serial_connection.write_and_check('shutter?\r','')

    def set_active_channel(self,channel):
        self.active_channel = channel
        print('[set active channel to ' + str(channel) + ']')

    def set_active_channel_shutter(self,state):
        channel = str(self.active_channel)
        state = str(state)
        print('shutter:'+channel+'='+state+'\r')
        self.serial_connection.write_and_check('shutter:'+channel+'='+state+'\r',"ok")

class SciMicroscopyLEDArray:
    """Wrapper for communicating with SciMicroscopy over serial"""
    def __init__(self, SN, array_distance = 50, turn_on_delay = 0.03):
        """
        Provide serial number
        """
        self.serial_connection = SerialDevice(SN=SN,baudrate=115200,
                bytesize=serial.EIGHTBITS,stopbits=serial.STOPBITS_ONE,
                parity=serial.PARITY_NONE, 
                xonxoff=False,rtscts=False,dsrdtr=False)
        self.serial_connection.open_ser()
        self.check_about()
        self.set_distance(array_distance)
        self.set_brightness(1)

        self.illumination = None
        self.NA = 0.5
        self.turn_on_delay = turn_on_delay

    def write(self,command):
        self.serial_connection.write_and_check(command+'\r','',read_delay=0.01,print_response=True)

    def check_about(self):
        self.serial_connection.write_and_check('about'+'\r','=',read_delay=0.01,print_response=True)

    def set_distance(self,array_distance):
        # array distance in mm
        array_distance = str(int(array_distance))
        self.serial_connection.write_and_check('sad.'+array_distance+'\r','Current array distance from sample is '+array_distance+'mm',read_delay=0.01,print_response=False)

    def set_NA(self,NA):
        self.NA = NA
        NA = str(int(NA*100))
        self.serial_connection.write_and_check('na.'+NA+'\r','Current NA is 0.'+NA,read_delay=0.01,print_response=False)

    def set_color(self,color):
        # (r,g,b), 0-1
        r = int(255*color[0])
        g = int(255*color[1])
        b = int(255*color[2])
        self.serial_connection.write_and_check(f'sc.{r}.{g}.{b}\r',f'Current color balance values are {r}.{g}.{b}',read_delay=0.01,print_response=False)

    def set_brightness(self, brightness):
        # 0 to 100
        brightness = str(int(255*(brightness/100.0)))
        self.serial_connection.write_and_check(f'sb.{brightness}\r',f'Current brightness value is {brightness}.',read_delay=0.01,print_response=False)

    def turn_on_bf(self):
        self.serial_connection.write_and_check(f'bf\r','-==-',read_delay=0.01,print_response=False)

    def turn_on_dpc(self,quadrant):
        self.serial_connection.write_and_check(f'dpc.{quadrant[0]}\r','-==-',read_delay=0.01,print_response=False)

    def turn_on_df(self):
        self.serial_connection.write_and_check(f'df\r','-==-',read_delay=0.01,print_response=False)

    def set_illumination(self,illumination):
        self.illumination = illumination

    def clear(self):
        self.serial_connection.write_and_check('x\r','-==-',read_delay=0.01,print_response=False)

    def turn_on_illumination(self):
        if self.illumination is not None:
            self.serial_connection.write_and_check(f'{self.illumination}\r','-==-',read_delay=0.01,print_response=False)
            time.sleep(self.turn_on_delay)
    def turn_off_illumination(self):
        self.clear()

class CellX:
    """Wrapper for communicating with LDI over serial"""
    def __init__(self, SN=""):
        self.serial_connection = SerialDevice(SN=SN,baudrate=115200,
                bytesize=serial.EIGHTBITS,stopbits=serial.STOPBITS_ONE,
                parity=serial.PARITY_NONE,
                xonxoff=False,rtscts=False,dsrdtr=False)
        self.serial_connection.open_ser()
        self.power = {}

    def turn_on(self, channel):
        self.serial_connection.write_and_check('SOUR'+str(channel)+':AM:STAT ON\r','OK',read_delay=0.01,print_response=False)

    def turn_off(self, channel):
        self.serial_connection.write_and_check('SOUR'+str(channel)+':AM:STAT OFF\r','OK',read_delay=0.01,print_response=False)

    def set_laser_power(self, channel, power):
        try:
            assert power >= 1 and power <= 100
        except AssertionError as e:
            print(f"AssertionError: {e}")
            return
        if channel not in self.power.keys() or power != self.power[channel]:
            self.serial_connection.write_and_check('SOUR'+str(channel)+':POW:LEV:IMM:AMPL '+str(power/1000)+'\r','OK',read_delay=0.01,print_response=False)
            self.power[channel] = power
        else:
            pass # power is the same

    def set_modulation(self, channel, modulation):
        try:
            assert modulation in ['INT','EXT Digital','EXT Analog','EXT Mixed']
        except AssertionError as e:
            print(f"AssertionError: {e}")
            return
        self.serial_connection.write_and_check('SOUR'+str(channel)+':AM:' + modulation +'\r','OK',read_delay=0.01,print_response=False)

    def close(self):
        self.serial_connection.close()

class CellX_Simulation:
    """Wrapper for communicating with LDI over serial"""
    def __init__(self, SN=""):
        self.serial_connection = SerialDevice(SN=SN,baudrate=115200,
                bytesize=serial.EIGHTBITS,stopbits=serial.STOPBITS_ONE,
                parity=serial.PARITY_NONE,
                xonxoff=False,rtscts=False,dsrdtr=False)
        self.serial_connection.open_ser()

    def turn_on(self, channel):
        pass

    def turn_off(self, channel):
        pass

    def set_laser_power(self, channel, power):
        try:
            assert power >= 1 and power <= 100
        except AssertionError as e:
            print(f"AssertionError: {e}")
            return
        if channel not in self.power.keys() or power != self.power[channel]:
            self.power[channel] = power
        else:
            pass # power is the same

    def set_modulation(self, channel, modulation):
        try:
            assert modulation in ['INT','EXT Digital','EXT Analog','EXT Mixed']
        except AssertionError as e:
            print(f"AssertionError: {e}")
            return
        self.serial_connection.write_and_check('SOUR'+str(channel)+'AM:' + modulation +'\r','OK',read_delay=0.01,print_response=False)

    def close(self):
        pass

class FilterDeviceInfo:
    """
    keep filter device information 
    """
    # default: 7.36
    firmware_version = ''
    # default: 250000
    maxspeed = 0
    # default: 900 
    accel = 0

class FilterController_Simulation:
    """
    controller of filter device
    """
    def __init__(self, _baudrate, _bytesize, _parity, _stopbits):
        self.each_hole_microsteps = 4800
        self.current_position = 0
        '''
        the variable be used to keep current offset of wheel
        it could be used by get the index of wheel position, the index could be '1', '2', '3' ... 
        '''
        self.offset_position = 0

        self.deviceinfo = FilterDeviceInfo()

    def __del__(self):
        pass

    def do_homing(self):
        self.current_position = 0
        self.offset_position = 1100

    def wait_homing_finish(self):
        pass

    def set_emission_filter(self, position):
        pass

    def get_emission_filter(self):
        return 1

class FilterController:
    """
    controller of filter device
    """
    def __init__(self, SN, _baudrate, _bytesize, _parity, _stopbits):
        self.each_hole_microsteps = 4800
        self.current_position = 0
        self.offset_position = -8500

        self.deviceinfo = FilterDeviceInfo()
        optical_mounts_ports = [p.device for p in serial.tools.list_ports.comports() if SN == p.serial_number]

        self.serial = serial.Serial(optical_mounts_ports[0], baudrate=_baudrate, bytesize=_bytesize, parity=_parity, stopbits=_stopbits)
        time.sleep(0.2)

        if self.serial.isOpen(): 
            self.deviceinfo.firmware_version = self.get_info('/get version')[1]

            self.send_command_with_reply('/set maxspeed 250000')
            self.send_command_with_reply('/set accel 900')

            self.deviceinfo.maxspeed = self.get_info('/get maxspeed')[1]
            self.deviceinfo.accel = self.get_info('/get accel')[1]

            '''
            print('filter control port open scucessfully')
            print('firmware version: ' + self.deviceinfo.firmware_version)
            print('maxspeed: ' + self.deviceinfo.maxspeed)
            print('accel: ' + self.deviceinfo.accel)
            '''

    def __del__(self):
        if self.serial.isOpen(): 
            self.send_command('/stop')
            time.sleep(0.5)
            self.serial.close()
    
    def send_command(self, cmd):
        cmd = cmd + '\n'
        if self.serial.isOpen(): 
            self.serial.write(cmd.encode('utf-8')) 
        else:
            print('Error: serial port is not open yet')

    def send_command_with_reply(self, cmd):
        cmd = cmd + '\n'
        if self.serial.isOpen(): 
            self.serial.write(cmd.encode('utf-8')) 
            time.sleep(0.01)
            result = self.serial.readline()
            data_string = result.decode('utf-8')
            return_list = data_string.split(' ')
            if return_list[2] == 'OK' and return_list[3] == 'IDLE':
                return True
            else:
                print('execute cmd fail: ' + cmd)
                return False

        else:
            print('Error: serial port is not open yet')

    def get_info(self, cmd):
        cmd = cmd + '\n'
        if self.serial.isOpen(): 
            try:
                self.serial.write(cmd.encode('utf-8')) 
                result = self.serial.readline()
                if not result:
                    print("No response from filter controller")
            except Exception as e:
                print("Error occurred communicating with filter controller")
            data_string = result.decode('utf-8')
            return_list = data_string.split(' ')
            if return_list[2] == 'OK' and return_list[3] == 'IDLE':
                value_string = return_list[5]
                value_string = value_string.strip('\n')
                value_string = value_string.strip('\r')
                return True, value_string
            else:
                return False, '' 

        else:
            print('Error: serial port is not open yet')

    def get_position(self):
        if self.serial.isOpen(): 
            result = self.serial.readline()
            data_string = result.decode('utf-8')
            return_list = data_string.split(' ')
            if return_list[2] == 'OK' and return_list[3] == 'IDLE':
                value_string = return_list[5]
                value_string = value_string.strip('\n')
                value_string = value_string.strip('\r')
                return True, int(value_string) 
            else:
                return False, 0

    def get_index(self):
        index = (self.current_position - self.offset_position) / self.each_hole_microsteps
        return int(index)

    def move_to_offset(self):
        '''
        the function is inner function, be used to move wheel to a given position 
        '''
        cmd_str = '/move rel ' + str(self.offset_position)
        self.send_command(cmd_str)
        timeout = 50
        while timeout != 0:
            timeout -= 1
            time.sleep(0.1)
            self.send_command('/get pos')
            result = self.get_position()
            if result[0] == True and result[1] == self.offset_position:
                self.current_position = self.offset_position
                return
        print('filter move offset timeout')

    def move_index_position(self, pos_index):
        mov_pos = pos_index * self.each_hole_microsteps
        pos = self.current_position + mov_pos
        cmd_str = '/move rel ' + str(mov_pos)
        self.send_command(cmd_str)

        timeout = 50
        while timeout != 0:
            timeout -= 1
            time.sleep(0.005)
            self.send_command('/get pos')
            result = self.get_position()
            if result[0] == True and result[1] == pos:
                self.current_position = pos
                return
        print('filter move timeout')

    def set_emission_filter(self, position):
        if str(position) not in ["1","2","3","4","5","6","7"]:
            raise ValueError("Invalid emission filter wheel position!")

        pos = int(position)
        current_pos = self.get_index() + 1
        if pos == current_pos:
            return

        pos = pos - current_pos
        self.move_index_position(pos)

    def get_emission_filter(self):
        return self.get_index() + 1

    def do_homing(self):
        '''
        the /home command just make the wheel start to move
        '''
        self.send_command('/home')

    def wait_homing_finish(self):
        '''
        the function is used to make the wheel be moving to the setting position 
        '''
        timeout_counter = 100
        while timeout_counter != 0:
            timeout_counter -= 1
            time.sleep(0.5)
            self.send_command('/get pos')
            result = self.get_position()
            if result[0] == True and result[1] == 0:
                self.current_position = 0
                self.move_to_offset()
                return
        print('Filter device homing fail')

import argparse
import cv2
import time
import numpy as np
import PySpin
from control._def import *

class ReadType:
    """
    Use the following constants to determine whether nodes are read
    as Value nodes or their individual types.
    """
    VALUE = 0,
    INDIVIDUAL = 1

try:
    if CHOSEN_READ == 'VALUE':
        CHOSEN_READ = ReadType.VALUE
    else:
        CHOSEN_READ = ReadType.INDIVIDUAL
except:
    CHOSEN_READ = ReadType.INDIVIDUAL

def get_value_node(node):
    """
    Retrieves and prints the display name and value of all node types as value nodes.
    A value node is a general node type that allows for the reading and writing of any node type as a string.

    :param node: Node to get information from.
    :type node: INode
    :param level: Depth to indent output.
    :return: node name and value, both strings
    :rtype: (str (node name),str (node value)
    """
    try:
        # Create value node
        node_value = PySpin.CValuePtr(node)

        # Retrieve display name
        #
        # *** NOTES ***
        # A node's 'display name' is generally more appropriate for output and
        # user interaction whereas its 'name' is what the camera understands.
        # Generally, its name is the same as its display name but without
        # spaces - for instance, the name of the node that houses a camera's
        # serial number is 'DeviceSerialNumber' while its display name is
        # 'Device Serial Number'.
        name = node_value.GetName()

        # Retrieve value of any node type as string
        #
        # *** NOTES ***
        # Because value nodes return any node type as a string, it can be much
        # easier to deal with nodes as value nodes rather than their actual
        # individual types.
        value = node_value.ToString()
        return (name,value)
    except PySpin.SpinnakerException as ex:
        print('Error: %s' % ex)
        return ('',None)


def get_string_node(node):
    """
    Retrieves the display name and value of a string node.

    :param node: Node to get information from.
    :type node: INode
    :return: Tuple of node name and value
    :rtype: (str,str)
    """
    try:
        # Create string node
        node_string = PySpin.CStringPtr(node)

        # Retrieve string node value
        #
        # *** NOTES ***
        # Functions in Spinnaker C++ that use gcstring types
        # are substituted with Python strings in PySpin.
        # The only exception is shown in the DeviceEvents example, where
        # the callback function still uses a wrapped gcstring type.
        name = node_string.GetName()

        # Ensure that the value length is not excessive for printing
        value = node_string.GetValue()

        # Print value; 'level' determines the indentation level of output
        return(name,value)

    except PySpin.SpinnakerException as ex:
        print('Error: %s' % ex)
        return ('',None)

def get_integer_node(node):
    """
    Retrieves and prints the display name and value of an integer node.

    :param node: Node to get information from.
    :type node: INode
    :return: Tuple of node name and value
    :rtype: (str, int)
    """
    try:
        # Create integer node
        node_integer = PySpin.CIntegerPtr(node)

        # Get display name
        name = node_integer.GetName()

        # Retrieve integer node value
        #
        # *** NOTES ***
        # All node types except base nodes have a ToString()
        # method which returns a value as a string.
        value = node_integer.GetValue()

        # Print value
        return (name,value)

    except PySpin.SpinnakerException as ex:
        print('Error: %s' % ex)
        return ('',None)

def get_float_node(node):
    """
    Retrieves the name and value of a float node.

    :param node: Node to get information from.
    :type node: INode
    :return: Tuple of node name and value
    :rtype: (str, float)
    """
    try:

        # Create float node
        node_float = PySpin.CFloatPtr(node)

        # Get display name
        name = node_float.GetName()

        # Retrieve float value
        value = node_float.GetValue()

        # Print value
        return (name,value)

    except PySpin.SpinnakerException as ex:
        print('Error: %s' % ex)
        return ('',None)


def get_boolean_node(node):
    """
    Retrieves the display name and value of a Boolean node.

    :param node: Node to get information from.
    :type node: INode
    :return: Tuple of node name and value
    :rtype: (str, bool)
    """
    try:
        # Create Boolean node
        node_boolean = PySpin.CBooleanPtr(node)

        # Get display name
        name = node_boolean.GetName()

        # Retrieve Boolean value
        value = node_boolean.GetValue()

        # Print Boolean value
        # NOTE: In Python a Boolean will be printed as "True" or "False".
        return (name,value)

    except PySpin.SpinnakerException as ex:
        print('Error: %s' % ex)
        return ('',None)


def get_command_node(node):
    """
    This function retrieves the name and tooltip of a command
    The tooltip is printed below because command nodes do not have an intelligible
    value.

    :param node: Node to get information from.
    :type node: INode
    :return: node name and tooltip as a tuple
    :rtype: (str, str)
    """
    try:
        result = True

        # Create command node
        node_command = PySpin.CCommandPtr(node)

        # Get display name
        name = node_command.GetName()

        # Retrieve tooltip
        #
        # *** NOTES ***
        # All node types have a tooltip available. Tooltips provide useful
        # information about nodes. Command nodes do not have a method to
        # retrieve values as their is no intelligible value to retrieve.
        tooltip = node_command.GetToolTip()

        # Ensure that the value length is not excessive for printing

        # Print display name and tooltip
        return (name, tooltip)

    except PySpin.SpinnakerException as ex:
        print('Error: %s' % ex)
        return ('',None)


def get_enumeration_node_and_current_entry(node):
    """
    This function retrieves and prints the display names of an enumeration node
    and its current entry (which is actually housed in another node unto itself).

    :param node: Node to get information from.
    :type node: INode
    :return: name and symbolic of current entry in enumeration
    :rtype: (str,str)
    """
    try:
        # Create enumeration node
        node_enumeration = PySpin.CEnumerationPtr(node)

        # Retrieve current entry as enumeration node
        #
        # *** NOTES ***
        # Enumeration nodes have three methods to differentiate between: first,
        # GetIntValue() returns the integer value of the current entry node;
        # second, GetCurrentEntry() returns the entry node itself; and third,
        # ToString() returns the symbolic of the current entry.
        node_enum_entry = PySpin.CEnumEntryPtr(node_enumeration.GetCurrentEntry())

        # Get display name
        name = node_enumeration.GetName()

        # Retrieve current symbolic
        #
        # *** NOTES ***
        # Rather than retrieving the current entry node and then retrieving its
        # symbolic, this could have been taken care of in one step by using the
        # enumeration node's ToString() method.
        entry_symbolic = node_enum_entry.GetSymbolic()

        # Print current entry symbolic
        return(name, entry_symbolic)

    except PySpin.SpinnakerException as ex:
        print('Error: %s' % ex)
        return ('',None)


def get_category_node_and_all_features(node):
    """
    This function retrieves and prints out the display name of a category node
    before printing all child nodes. Child nodes that are also category nodes
    are also retrieved recursively

    :param node: Category node to get information from.
    :type node: INode
    :return: Dictionary of category node features
    :rtype: dict
    """
    return_dict = {}
    try:
        # Create category node
        node_category = PySpin.CCategoryPtr(node)

        # Get and print display name
        # Retrieve and iterate through all children
        #
        # *** NOTES ***
        # The two nodes that typically have children are category nodes and
        # enumeration nodes. Throughout the examples, the children of category nodes
        # are referred to as features while the children of enumeration nodes are
        # referred to as entries. Keep in mind that enumeration nodes can be cast as
        # category nodes, but category nodes cannot be cast as enumerations.
        for node_feature in node_category.GetFeatures():

            # Ensure node is readable
            if not PySpin.IsReadable(node_feature):
                continue
            
            # Category nodes must be dealt with separately in order to retrieve subnodes recursively.
            if node_feature.GetPrincipalInterfaceType() == PySpin.intfICategory:
                return_dict[PySpin.CCategoryPtr(node_feature).GetName()] = get_category_node_and_all_features(node_feature)

            # Cast all non-category nodes as value nodes
            #
            # *** NOTES ***
            # If dealing with a variety of node types and their values, it may be
            # simpler to cast them as value nodes rather than as their individual types.
            # However, with this increased ease-of-use, functionality is sacrificed.
            elif CHOSEN_READ == ReadType.VALUE:
                node_name, node_value =  get_value_node(node_feature)
                return_dict[node_name] = node_value

            # Cast all non-category nodes as actual types
            elif CHOSEN_READ == ReadType.INDIVIDUAL:
                node_name = ''
                node_value = None
                if node_feature.GetPrincipalInterfaceType() == PySpin.intfIString:
                    node_name, node_value = get_string_node(node_feature)
                elif node_feature.GetPrincipalInterfaceType() == PySpin.intfIInteger:
                    node_name, node_value = get_integer_node(node_feature)
                elif node_feature.GetPrincipalInterfaceType() == PySpin.intfIFloat:
                    node_name, node_value = get_float_node(node_feature)
                elif node_feature.GetPrincipalInterfaceType() == PySpin.intfIBoolean:
                    node_name, node_value= get_boolean_node(node_feature)
                elif node_feature.GetPrincipalInterfaceType() == PySpin.intfICommand:
                    node_name, node_value =  get_command_node(node_feature)
                elif node_feature.GetPrincipalInterfaceType() == PySpin.intfIEnumeration:
                    node_name, node_value = get_enumeration_node_and_current_entry(node_feature)
                return_dict[node_name] = node_value

    except PySpin.SpinnakerException as ex:
        print('Error: %s' % ex)
    
    return return_dict 


def get_device_info(cam):
    nodemap_tldevice = cam.GetTLDeviceNodeMap()
    device_info_dict = {}
    device_info_dict['TLDevice'] = get_category_node_and_all_features(nodemap_tldevice.GetNode('Root'))
    return device_info_dict

def get_device_info_full(cam, get_genicam=False):
    device_info_dict = {}
    nodemap_gentl = cam.GetTLDeviceNodeMap()
    device_info_dict['TLDevice'] = get_category_node_and_all_features(nodemap_gentl.GetNode('Root'))

    nodemap_tlstream = cam.GetTLStreamNodeMap()
    device_info_dict['TLStream'] = get_category_node_and_all_features(nodemap_tlstream.GetNode('Root'))
    if get_genicam:
        cam.Init()

        nodemap_applayer = cam.GetNodeMap()
        device_info_dict['GenICam'] = get_category_node_and_all_features(nodemap_applayer.GetNode('Root'))

        cam.DeInit()
    return device_info_dict

def retrieve_all_camera_info(get_genicam=False):
    system = PySpin.System.GetInstance()
    cam_list = system.GetCameras()
    device_num = cam_list.GetSize()
    return_list = []
    if device_num > 0:
        for i,cam in enumerate(cam_list):
            return_list.append(get_device_info_full(cam,get_genicam=get_genicam))
        try:
            del cam
        except NameError:
            pass
    cam_list.Clear()
    system.ReleaseInstance()
    return return_list
  


def get_sn_by_model(model_name):
    system = PySpin.System.GetInstance()
    cam_list = system.GetCameras()
    device_num = cam_list.GetSize()
    sn_to_return = None
    if device_num > 0:
        for i,cam in enumerate(cam_list):
            device_info = get_device_info(cam)
            try:
                if device_info['TLDevice']['DeviceInformation']['DeviceModelName'] == model_name:
                    sn_to_return = device_info['TLDevice']['DeviceInformation']['DeviceSerialNumber']
                    break
            except KeyError:
                pass
        try:
            del cam
        except NameError:
            pass
    cam_list.Clear()
    system.ReleaseInstance()
    return sn_to_return

class ImageEventHandler(PySpin.ImageEventHandler):
    def __init__(self,parent):
        super(ImageEventHandler,self).__init__()

        self.camera = parent #Camera() type object

        self._processor = PySpin.ImageProcessor()
        self._processor.SetColorProcessing(PySpin.SPINNAKER_COLOR_PROCESSING_ALGORITHM_HQ_LINEAR)

    def OnImageEvent(self, raw_image):
        
        if raw_image.IsIncomplete():
            print('Image incomplete with image status %i ...' % raw_image.GetImageStatus())
            return
        elif self.camera.is_color and 'mono' not in self.camera.pixel_format.lower():
            if "10" in self.camera.pixel_format or "12" in self.camera.pixel_format or "14" in self.camera.pixel_format or "16" in self.camera.pixel_format:
                rgb_image = self._processor.Convert(raw_image,PySpin.PixelFormat_RGB16)
            else:
                rgb_image = self._processor.Convert(raw_image,PySpin.PixelFormat_RGB8)
            numpy_image = rgb_image.GetNDArray()
        else:
            if self.camera.convert_pixel_format:
                converted_image = self._processor.Convert(raw_image,self.camera.conversion_pixel_format)
                numpy_image = converted_image.GetNDArray()
                if self.camera.conversion_pixel_format == PySpin.PixelFormat_Mono12:
                    numpy_image = numpy_image << 4
            else:
                try:
                    numpy_image = raw_image.GetNDArray()
                except PySpin.SpinnakerException:
                    converted_image = self.one_frame_post_processor.Convert(raw_image, PySpin.PixelFormat_Mono8)
                    numpy_image = converted_image.GetNDArray()
                if self.camera.pixel_format == 'MONO12':
                    numpy_image = numpy_image <<4
        self.camera.current_frame = numpy_image
        self.camera.frame_ID_software = self.camera.frame_ID_software + 1
        self.camera.frame_ID = raw_image.GetFrameID()
        if self.camera.trigger_mode == TriggerMode.HARDWARE:
            if self.camera.frame_ID_offset_hardware_trigger == None:
                self.camera.frame_ID_offset_hardware_trigger = self.camera.frame_ID
            self.camera.frame_ID = self.camera.frame_ID - self.camera.frame_ID_offset_hardware_trigger
        self.camera.timestamp = time.time()
        self.camera.new_image_callback_external(self.camera)
       

class Camera(object):

    def __init__(self,sn=None,is_global_shutter=False,rotate_image_angle=None,flip_image=None, is_color=False):

        self.py_spin_system = PySpin.System.GetInstance()
        self.camera_list = self.py_spin_system.GetCameras()
        self.sn = sn 
        self_is_color = is_color
        # many to be purged
        self.is_global_shutter = is_global_shutter
        self.device_info_dict = None
        self.device_index = 0
        self.camera = None #PySpin CameraPtr type
        self.is_color = None
        self.gamma_lut = None
        self.contrast_lut = None
        self.color_correction_param = None

        self.one_frame_post_processor = PySpin.ImageProcessor()
        self.conversion_pixel_format = PySpin.PixelFormat_Mono8
        self.convert_pixel_format = False
        self.one_frame_post_processor.SetColorProcessing(PySpin.SPINNAKER_COLOR_PROCESSING_ALGORITHM_HQ_LINEAR)

        self.auto_exposure_mode =None
        self.auto_gain_mode = None
        self.auto_wb_mode = None
        self.auto_wb_profile = None

        self.rotate_image_angle = rotate_image_angle
        self.flip_image = flip_image

        self.exposure_time = 1 # unit: ms
        self.analog_gain = 0
        self.frame_ID = -1
        self.frame_ID_software = -1
        self.frame_ID_offset_hardware_trigger = 0
        self.timestamp = 0

        self.image_locked = False
        self.current_frame = None

        self.callback_is_enabled = False
        self.is_streaming = False

        self.GAIN_MAX = 24
        self.GAIN_MIN = 0
        self.GAIN_STEP = 1
        self.EXPOSURE_TIME_MS_MIN = 0.01
        self.EXPOSURE_TIME_MS_MAX = 4000

        self.trigger_mode = None
        self.pixel_size_byte = 1

        # below are values for IMX226 (MER2-1220-32U3M) - to make configurable 
        self.row_period_us = 10
        self.row_numbers = 3036
        self.exposure_delay_us_8bit = 650
        self.exposure_delay_us = self.exposure_delay_us_8bit*self.pixel_size_byte
        self.strobe_delay_us = self.exposure_delay_us + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1)

        self.pixel_format = None # use the default pixel format

        self.is_live = False # this determines whether a new frame received will be handled in the streamHandler

        self.image_event_handler = ImageEventHandler(self)
        # mainly for discarding the last frame received after stop_live() is called, where illumination is being turned off during exposure

    def open(self,index=0, is_color=None):
        if is_color is None:
            is_color = self.is_color
        try:
            self.camera.DeInit()
            del self.camera
        except AttributeError:
            pass
        self.camera_list.Clear()
        self.camera_list = self.py_spin_system.GetCameras()
        device_num = self.camera_list.GetSize()
        if device_num == 0:
            raise RuntimeError('Could not find any USB camera devices!')
        if self.sn is None:
            self.device_index = index
            self.camera = self.camera_list.GetByIndex(index)
        else:
            self.camera = self.camera_list.GetBySerial(str(self.sn))


        self.device_info_dict = get_device_info_full(self.camera, get_genicam=True)
        
        self.camera.Init()
        self.nodemap = self.camera.GetNodeMap()
        
        self.is_color = is_color
        if self.is_color:
            self.set_wb_ratios(2,1,2)


        # set to highest possible framerate
        PySpin.CBooleanPtr(self.nodemap.GetNode('AcquisitionFrameRateEnable')).SetValue(True)
        target_rate = 1000
        for decrement in range(0,1000):
            try:
                PySpin.CFloatPtr(self.nodemap.GetNode('AcquisitionFrameRate')).SetValue(target_rate-decrement)
                break
            except PySpin.SpinnakerException as ex:
                pass

        # turn off device throughput limit
        node_throughput_limit =  PySpin.CIntegerPtr(self.nodemap.GetNode('DeviceLinkThroughputLimit'))
        node_throughput_limit.SetValue(node_throughput_limit.GetMax())

        self.Width = PySpin.CIntegerPtr(self.nodemap.GetNode('Width')).GetValue()
        self.Height = PySpin.CIntegerPtr(self.nodemap.GetNode('Height')).GetValue()
        

        self.WidthMaxAbsolute = PySpin.CIntegerPtr(self.nodemap.GetNode('SensorWidth')).GetValue()
        self.HeightMaxAbsolute = PySpin.CIntegerPtr(self.nodemap.GetNode('SensorHeight')).GetValue()
        
        self.set_ROI(0,0)
        
        self.WidthMaxAbsolute = PySpin.CIntegerPtr(self.nodemap.GetNode('WidthMax')).GetValue()
        self.HeightMaxAbsolute = PySpin.CIntegerPtr(self.nodemap.GetNode('HeightMax')).GetValue()

        self.set_ROI(0,0,self.WidthMaxAbsolute,self.HeightMaxAbsolute)

        self.WidthMax = self.WidthMaxAbsolute
        self.HeightMax = self.HeightMaxAbsolute
        self.OffsetX = PySpin.CIntegerPtr(self.nodemap.GetNode('OffsetX')).GetValue()
        self.OffsetY = PySpin.CIntegerPtr(self.nodemap.GetNode('OffsetY')).GetValue()

        # disable gamma
        PySpin.CBooleanPtr(self.nodemap.GetNode('GammaEnable')).SetValue(False)

    def set_callback(self,function):
        self.new_image_callback_external = function

    def enable_callback(self):
        if self.callback_is_enabled == False:
            # stop streaming
            if self.is_streaming:
                was_streaming = True
                self.stop_streaming()
            else:
                was_streaming = False
            # enable callback
            try:
                self.camera.RegisterEventHandler(self.image_event_handler)
                self.callback_is_enabled = True
            except PySpin.SpinnakerException as ex:
                print('Error: %s' % ex)
            # resume streaming if it was on
            if was_streaming:
                self.start_streaming()
            self.callback_is_enabled = True
        else:
            pass

    def disable_callback(self):
        if self.callback_is_enabled == True:
            # stop streaming
            if self.is_streaming:
                was_streaming = True
                self.stop_streaming()
            else:
                was_streaming = False
            try:
                self.camera.UnregisterEventHandler(self.image_event_handler)
                self.callback_is_enabled = False
            except PySpin.SpinnakerException as ex:
                print('Error: %s' % ex)
            # resume streaming if it was on
            if was_streaming:
                self.start_streaming()
        else:
            pass

    def open_by_sn(self,sn, is_color=None):
        self.sn = sn
        self.open(is_color=is_color)

    def close(self):
        try:
            self.camera.DeInit()
            del self.camera
        except AttributeError:
            pass
        self.camera = None
        self.auto_gain_mode = None
        self.auto_exposure_mode = None
        self.auto_wb_mode = None
        self.auto_wb_profile = None
        self.device_info_dict = None
        self.is_color = None
        self.gamma_lut = None
        self.contrast_lut = None
        self.color_correction_param = None
        self.last_raw_image = None
        self.last_converted_image = None
        self.last_numpy_image = None

    def set_exposure_time(self,exposure_time): ## NOTE: Disables auto-exposure
        use_strobe = (self.trigger_mode == TriggerMode.HARDWARE) # true if using hardware trigger
        self.nodemap = self.camera.GetNodeMap()
        node_auto_exposure = PySpin.CEnumerationPtr(self.nodemap.GetNode('ExposureAuto'))
        node_auto_exposure_off = PySpin.CEnumEntryPtr(node_auto_exposure.GetEntryByName('Off'))
        if not PySpin.IsReadable(node_auto_exposure_off) or not PySpin.IsWritable(node_auto_exposure):
            print("Unable to set exposure manually (cannot disable auto exposure)")
            return
        
        if node_auto_exposure.GetIntValue() != node_auto_exposure_off.GetValue():
            self.auto_exposure_mode = PySpin.CEnumEntryPtr(node_auto_exposure.GetCurrentEntry()).GetValue()

        node_auto_exposure.SetIntValue(node_auto_exposure_off.GetValue())

        node_exposure_time = PySpin.CFloatPtr(self.nodemap.GetNode('ExposureTime'))
        if not PySpin.IsWritable(node_exposure_time):
            print("Unable to set exposure manually after disabling auto exposure")

        if use_strobe == False or self.is_global_shutter:
            self.exposure_time = exposure_time
            node_exposure_time.SetValue(exposure_time*1000.0)
        else:
            # set the camera exposure time such that the active exposure time (illumination on time) is the desired value
            self.exposure_time = exposure_time
            # add an additional 500 us so that the illumination can fully turn off before rows start to end exposure
            camera_exposure_time = self.exposure_delay_us + self.exposure_time*1000 + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1) + 500 # add an additional 500 us so that the illumination can fully turn off before rows start to end exposure
            node_exposure_time.SetValue(camera_exposure_time)

    def update_camera_exposure_time(self):
        self.set_exposure_time(self.exposure_time)

    def set_analog_gain(self,analog_gain): ## NOTE: Disables auto-gain
        self.nodemap = self.camera.GetNodeMap()
    
        node_auto_gain = PySpin.CEnumerationPtr(self.nodemap.GetNode('GainAuto'))
        node_auto_gain_off = PySpin.CEnumEntryPtr(node_auto_gain.GetEntryByName('Off'))
        if not PySpin.IsReadable(node_auto_gain_off) or not PySpin.IsWritable(node_auto_gain):
            print("Unable to set gain manually (cannot disable auto gain)")
            return

        if node_auto_gain.GetIntValue() != node_auto_gain_off.GetValue():
            self.auto_gain_mode = PySpin.CEnumEntryPtr(node_auto_gain.GetCurrentEntry()).GetValue()

        node_auto_gain.SetIntValue(node_auto_gain_off.GetValue())
        
        node_gain = PySpin.CFloatPtr(self.nodemap.GetNode('Gain'))

        if not PySpin.IsWritable(node_gain):
            print("Unable to set gain manually after disabling auto gain")
            return

        self.analog_gain = analog_gain
        node_gain.SetValue(analog_gain)

    def get_awb_ratios(self): ## NOTE: Enables auto WB, defaults to continuous WB
        self.nodemap = self.camera.GetNodeMap()
        node_balance_white_auto = PySpin.CEnumerationPtr(self.nodemap.GetNode("BalanceWhiteAuto"))
        #node_balance_white_auto_options = [PySpin.CEnumEntryPtr(entry).GetName() for entry in node_balance_white_auto.GetEntries()]
        #print("WB Auto options: "+str(node_balance_white_auto_options))

        node_balance_ratio_select = PySpin.CEnumerationPtr(self.nodemap.GetNode("BalanceRatioSelector"))
        #node_balance_ratio_select_options = [PySpin.CEnumEntryPtr(entry).GetName() for entry in node_balance_ratio_select.GetEntries()]
        #print("Balance Ratio Select options: "+str(node_balance_ratio_select_options))
        """
        node_balance_profile = PySpin.CEnumerationPtr(self.nodemap.GetNode("BalanceWhiteAutoProfile"))
        node_balance_profile_options= [PySpin.CEnumEntryPtr(entry).GetName() for entry in node_balance_profile.GetEntries()]
        print("WB Auto Profile options: "+str(node_balance_profile_options))
        """
        node_balance_white_auto_off = PySpin.CEnumEntryPtr(node_balance_white_auto.GetEntryByName('Off'))
        if not PySpin.IsReadable(node_balance_white_auto) or not PySpin.IsReadable(node_balance_white_auto_off):
            print("Unable to check if white balance is auto or not")

        elif PySpin.IsWritable(node_balance_white_auto) and node_balance_white_auto.GetIntValue() == node_balance_white_auto_off.GetValue():
            if self.auto_wb_mode is not None:
                node_balance_white_auto.SetIntValue(self.auto_wb_mode)
            else:
                node_balance_white_continuous = PySpin.CEnumEntryPtr(node_balance_white_auto.GetEntryByName('Continuous'))
                if PySpin.IsReadable(node_balance_white_continuous):
                    node_balance_white_auto.SetIntValue(node_balance_white_continuous.GetValue())
                else:
                    print("Cannot turn on auto white balance in continuous mode")
                    node_balance_white_once = PySpin.CEnumEntryPtr(node_balance_white_auto.GetEntry('Once'))
                    if PySpin.IsReadable(node_balance_white_once):
                        node_balance_white_auto.SetIntValue(node_balance_white_once.GetValue())
                    else:
                        print("Cannot turn on auto white balance in Once mode")
        else:
            print("Cannot turn on auto white balance, or auto white balance is already on")

        balance_ratio_red = PySpin.CEnumEntryPtr(node_balance_ratio_select.GetEntryByName("Red"))
        balance_ratio_green = PySpin.CEnumEntryPtr(node_balance_ratio_select.GetEntryByName("Green"))
        balance_ratio_blue = PySpin.CEnumEntryPtr(node_balance_ratio_select.GetEntryByName("Blue"))
        node_balance_ratio = PySpin.CFloatPtr(self.nodemap.GetNode("BalanceRatio"))
        if not PySpin.IsWritable(node_balance_ratio_select) or not PySpin.IsReadable(balance_ratio_red) or not PySpin.IsReadable(balance_ratio_green) or not PySpin.IsReadable(balance_ratio_blue):
            print("Unable to move balance ratio selector")
            return (0,0,0)

        node_balance_ratio_select.SetIntValue(balance_ratio_red.GetValue())
        if not PySpin.IsReadable(node_balance_ratio):
            print("Unable to read balance ratio for red")
            awb_r = 0
        else:
            awb_r = node_balance_ratio.GetValue()

        node_balance_ratio_select.SetIntValue(balance_ratio_green.GetValue())
        if not PySpin.IsReadable(node_balance_ratio):
            print("Unable to read balance ratio for green")
            awb_g = 0
        else:
            awb_g = node_balance_ratio.GetValue()

        node_balance_ratio_select.SetIntValue(balance_ratio_blue.GetValue())
        if not PySpin.IsReadable(node_balance_ratio):
            print("Unable to read balance ratio for blue")
            awb_b = 0
        else:
            awb_b = node_balance_ratio.GetValue()

        return (awb_r, awb_g, awb_b)

    def set_wb_ratios(self, wb_r=None, wb_g=None, wb_b=None): ## NOTE disables auto WB, stores extant
                                                              ## auto WB mode if any
        self.nodemap = self.camera.GetNodeMap()
        node_balance_white_auto = PySpin.CEnumerationPtr(self.nodemap.GetNode("BalanceWhiteAuto"))
        node_balance_ratio_select = PySpin.CEnumerationPtr(self.nodemap.GetNode("BalanceRatioSelector"))
        node_balance_white_auto_off = PySpin.CEnumEntryPtr(node_balance_white_auto.GetEntryByName('Off'))
        if not PySpin.IsReadable(node_balance_white_auto) or not PySpin.IsReadable(node_balance_white_auto_off):
            print("Unable to check if white balance is auto or not")
        elif node_balance_white_auto.GetIntValue() != node_balance_white_auto_off.GetValue():
            self.auto_wb_value = node_balance_white_auto.GetIntValue()
            if PySpin.IsWritable(node_balance_white_auto):
                node_balance_white_auto.SetIntValue(node_balance_white_auto_off.GetValue())
            else:
                print("Cannot turn off auto WB")
        
        balance_ratio_red = PySpin.CEnumEntryPtr(node_balance_ratio_select.GetEntryByName("Red"))
        balance_ratio_green = PySpin.CEnumEntryPtr(node_balance_ratio_select.GetEntryByName("Green"))
        balance_ratio_blue = PySpin.CEnumEntryPtr(node_balance_ratio_select.GetEntryByName("Blue"))
        node_balance_ratio = PySpin.CFloatPtr(self.nodemap.GetNode("BalanceRatio"))
        if not PySpin.IsWritable(node_balance_ratio_select) or not PySpin.IsReadable(balance_ratio_red) or not PySpin.IsReadable(balance_ratio_green) or not PySpin.IsReadable(balance_ratio_blue):
            print("Unable to move balance ratio selector")
            return

        node_balance_ratio_select.SetIntValue(balance_ratio_red.GetValue())
        if not PySpin.IsWritable(node_balance_ratio):
            print("Unable to write balance ratio for red")
        else:
            if wb_r is not None:
                node_balance_ratio.SetValue(wb_r)

        node_balance_ratio_select.SetIntValue(balance_ratio_green.GetValue())
        if not PySpin.IsWritable(node_balance_ratio):
            print("Unable to write balance ratio for green")
        else:
            if wb_g is not None:
                node_balance_ratio.SetValue(wb_g)

        node_balance_ratio_select.SetIntValue(balance_ratio_blue.GetValue())
        if not PySpin.IsWritable(node_balance_ratio):
            print("Unable to write balance ratio for blue")
        else:
            if wb_b is not None:
                node_balance_ratio.SetValue(wb_b)

    def set_reverse_x(self,value):
        self.nodemap = self.camera.GetNodeMap()
        node_reverse_x = PySpin.CBooleanPtr(self.nodemap.GetNode('ReverseX'))
        if not PySpin.IsWritable(node_reverse_x):
            print("Can't write to reverse X node")
            return
        else:
            node_reverse_x.SetValue(bool(value))

    def set_reverse_y(self,value):
        self.nodemap = self.camera.GetNodeMap()
        node_reverse_y = PySpin.CBooleanPtr(self.nodemap.GetNode('ReverseY'))
        if not PySpin.IsWritable(node_reverse_y):
            print("Can't write to reverse Y node")
            return
        else:
            node_reverse_y.SetValue(bool(value))

    def start_streaming(self):
        self.camera.Init()

        if not self.is_streaming:
            try:
                self.camera.BeginAcquisition()
            except PySpin.SpinnakerException as ex:
                print("Spinnaker exception: "+str(ex))
        if self.camera.IsStreaming():
            print("Camera is streaming")
            self.is_streaming = True

    def stop_streaming(self):
        if self.is_streaming:
            try:
                self.camera.EndAcquisition()
            except PySpin.SpinnakerException as ex:
                print("Spinnaker exception: "+str(ex))
        if not self.camera.IsStreaming():
            print("Camera is not streaming")
            self.is_streaming = False

    def set_pixel_format(self,pixel_format,convert_if_not_native=False):
        if self.is_streaming == True:
            was_streaming = True
            self.stop_streaming()
        else:
            was_streaming = False
        self.nodemap = self.camera.GetNodeMap()
        
        node_pixel_format = PySpin.CEnumerationPtr(self.nodemap.GetNode('PixelFormat'))
        node_adc_bit_depth = PySpin.CEnumerationPtr(self.nodemap.GetNode('AdcBitDepth'))

        if PySpin.IsWritable(node_pixel_format) and PySpin.IsWritable(node_adc_bit_depth):
            pixel_selection =  None
            pixel_size_byte = None
            adc_bit_depth = None
            fallback_pixel_selection = None
            conversion_pixel_format = None
            if pixel_format == 'MONO8':
                pixel_selection = PySpin.CEnumEntryPtr(node_pixel_format.GetEntryByName('Mono8'))
                conversion_pixel_format = PySpin.PixelFormat_Mono8
                pixel_size_byte = 1
                adc_bit_depth = PySpin.CEnumEntryPtr(node_adc_bit_depth.GetEntryByName('Bit10'))
            if pixel_format == 'MONO10': 
                pixel_selection = PySpin.CEnumEntryPtr(node_pixel_format.GetEntryByName('Mono10'))
                fallback_pixel_selection = PySpin.CEnumEntryPtr(node_pixel_format.GetEntryByName('Mono10p'))
                conversion_pixel_format = PySpin.PixelFormat_Mono8
                pixel_size_byte = 1
                adc_bit_depth = PySpin.CEnumEntryPtr(node_adc_bit_depth.GetEntryByName('Bit10'))
            if pixel_format == 'MONO12':
                pixel_selection = PySpin.CEnumEntryPtr(node_pixel_format.GetEntryByName('Mono12'))
                fallback_pixel_selection = PySpin.CEnumEntryPtr(node_pixel_format.GetEntryByName('Mono12p'))
                conversion_pixel_format = PySpin.PixelFormat_Mono16
                pixel_size_byte = 2
                adc_bit_depth = PySpin.CEnumEntryPtr(node_adc_bit_depth.GetEntryByName('Bit12'))
            if pixel_format == 'MONO14': # MONO14/16 are aliases of each other, since they both
                                         # do ADC at bit depth 14
                pixel_selection = PySpin.CEnumEntryPtr(node_pixel_format.GetEntryByName('Mono16'))
                conversion_pixel_format = PySpin.PixelFormat_Mono16
                pixel_size_byte = 2
                adc_bit_depth = PySpin.CEnumEntryPtr(node_adc_bit_depth.GetEntryByName('Bit14'))
            if pixel_format == 'MONO16':
                pixel_selection = PySpin.CEnumEntryPtr(node_pixel_format.GetEntryByName('Mono16'))
                conversion_pixel_format = PySpin.PixelFormat_Mono16
                pixel_size_byte = 2
                adc_bit_depth = PySpin.CEnumEntryPtr(node_adc_bit_depth.GetEntryByName('Bit14'))
            if pixel_format == 'BAYER_RG8':
                pixel_selection = PySpin.CEnumEntryPtr(node_pixel_format.GetEntryByName('BayerRG8'))
                conversion_pixel_format = PySpin.PixelFormat_BayerRG8
                pixel_size_byte = 1
                adc_bit_depth = PySpin.CEnumEntryPtr(node_adc_bit_depth.GetEntryByName('Bit10'))
            if pixel_format == 'BAYER_RG12':
                pixel_selection = PySpin.CEnumEntryPtr(node_pixel_format.GetEntryByName('BayerRG12'))
                conversion_pixel_format = PySpin.PixelFormat_BayerRG12
                pixel_size_byte = 2
                adc_bit_depth = PySpin.CEnumEntryPtr(node_adc_bit_depth.GetEntryByName('Bit12'))

            if pixel_selection is not None and adc_bit_depth is not None:
                if PySpin.IsReadable(pixel_selection):
                    node_pixel_format.SetIntValue(pixel_selection.GetValue())
                    self.pixel_size_byte = pixel_size_byte
                    self.pixel_format = pixel_format
                    self.convert_pixel_format = False
                    if PySpin.IsReadable(adc_bit_depth):
                        node_adc_bit_depth.SetIntValue(adc_bit_depth.GetValue())
                elif PySpin.IsReadable(fallback_pixel_selection):
                    node_pixel_format.SetIntValue(fallback_pixel_selection.GetValue())
                    self.pixel_size_byte = pixel_size_byte
                    self.pixel_format = pixel_format
                    self.conversion_pixel_format = conversion_pixel_format
                    self.convert_pixel_format = True
                    if PySpin.IsReadable(adc_bit_depth):
                        node_adc_bit_depth.SetIntValue(adc_bit_depth.GetValue())
                else:
                    self.convert_pixel_format = convert_if_not_native
                    if convert_if_not_native:
                        self.conversion_pixel_format = conversion_pixel_format
                    print("Pixel format not available for this camera")
                    if PySpin.IsReadable(adc_bit_depth):
                        node_adc_bit_depth.SetIntValue(adc_bit_depth.GetValue())
                        print("Still able to set ADC bit depth to "+adc_bit_depth.GetSymbolic())

            else:
                print("Pixel format not implemented for Squid")

        else:
            print("pixel format is not writable")

        if was_streaming:
           self.start_streaming()

        # update the exposure delay and strobe delay
        self.exposure_delay_us = self.exposure_delay_us_8bit*self.pixel_size_byte
        self.strobe_delay_us = self.exposure_delay_us + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1)

    def set_continuous_acquisition(self):
        self.nodemap = self.camera.GetNodeMap()
        node_trigger_mode = PySpin.CEnumerationPtr(self.nodemap.GetNode('TriggerMode'))
        node_trigger_mode_off = PySpin.CEnumEntryPtr(node_trigger_mode.GetEntryByName('Off'))
        if not PySpin.IsWritable(node_trigger_mode) or not PySpin.IsReadable(node_trigger_mode_off):
            print("Cannot toggle TriggerMode")
            return
        node_trigger_mode.SetIntValue(node_trigger_mode_off.GetValue())
        self.trigger_mode = TriggerMode.CONTINUOUS
        self.update_camera_exposure_time()

    def set_triggered_acquisition_flir(self, source, activation=None):
        self.nodemap = self.camera.GetNodeMap()
        node_trigger_mode = PySpin.CEnumerationPtr(self.nodemap.GetNode('TriggerMode'))
        node_trigger_mode_on = PySpin.CEnumEntryPtr(node_trigger_mode.GetEntryByName('On'))
        if not PySpin.IsWritable(node_trigger_mode) or not PySpin.IsReadable(node_trigger_mode_on):
            print("Cannot toggle TriggerMode")
            return
        node_trigger_source = PySpin.CEnumerationPtr(self.nodemap.GetNode('TriggerSource'))
        node_trigger_source_option = PySpin.CEnumEntryPtr(node_trigger_source.GetEntryByName(str(source)))

        node_trigger_mode.SetIntValue(node_trigger_mode_on.GetValue())

        if not PySpin.IsWritable(node_trigger_source) or not PySpin.IsReadable(node_trigger_source_option):
            print("Cannot set Trigger source")
            return

        node_trigger_source.SetIntValue(node_trigger_source_option.GetValue())

        if source != "Software" and activation is not None: # Set activation criteria for hardware trigger
            node_trigger_activation = PySpin.CEnumerationPtr(self.nodemap.GetNode('TriggerActivation'))
            node_trigger_activation_option = PySpin.CEnumEntryPtr(node_trigger_activation.GetEntryByName(str(activation)))
            if not PySpin.IsWritable(node_trigger_activation) or not PySpin.IsReadable(node_trigger_activation_option): 
                print("Cannot set trigger activation mode")
                return
            node_trigger_activation.SetIntValue(node_trigger_activation_option.GetValue())

    def set_software_triggered_acquisition(self):

        self.set_triggered_acquisition_flir(source='Software')

        self.trigger_mode = TriggerMode.SOFTWARE
        self.update_camera_exposure_time()

    def set_hardware_triggered_acquisition(self, source='Line2', activation='RisingEdge'):
        self.set_triggered_acquisition_flir(source=source, activation=activation)
        self.frame_ID_offset_hardware_trigger = None
        self.trigger_mode = TriggerMode.HARDWARE
        self.update_camera_exposure_time()

    def send_trigger(self):
        if self.is_streaming:
            self.nodemap = self.camera.GetNodeMap()
            node_trigger = PySpin.CCommandPtr(self.nodemap.GetNode('TriggerSoftware'))
            if not PySpin.IsWritable(node_trigger):
                print('Trigger node not writable')
                return
            node_trigger.Execute()
        else:
        	print('trigger not sent - camera is not streaming')

    def read_frame(self):
        if not self.camera.IsStreaming():
            print("Cannot read frame, camera not streaming")
            return np.zeros((self.Width,self.Height))
        callback_was_enabled = False
        if self.callback_is_enabled: # need to disable callback to read stream manually
            callback_was_enabled = True
            self.disable_callback()
        raw_image = self.camera.GetNextImage(1000)
        if raw_image.IsIncomplete():
            print('Image incomplete with image status %d ...' % raw_image.GetImageStatus())
            raw_image.Release()
            return np.zeros((self.Width,self.Height))

        if self.is_color and 'mono' not in self.pixel_format.lower():
            if "10" in self.pixel_format or "12" in self.pixel_format or "14" in self.pixel_format or "16" in self.pixel_format:
                rgb_image = self.one_frame_post_processor.Convert(raw_image,PySpin.PixelFormat_RGB16)
            else:
                rgb_image = self.one_frame_post_processor.Convert(raw_image,PySpin.PixelFormat_RGB8)
            numpy_image = rgb_image.GetNDArray()
            if self.pixel_format == 'BAYER_RG12':
                numpy_image = numpy_image << 4
        else:
            if self.convert_pixel_format:
                converted_image = self.one_frame_post_processor.Convert(raw_image,self.conversion_pixel_format)
                numpy_image = converted_image.GetNDArray()
                if self.conversion_pixel_format == PySpin.PixelFormat_Mono12:
                    numpy_image = numpy_image << 4
            else:
                try:
                    numpy_image = raw_image.GetNDArray()
                except PySpin.SpinnakerException:
                    print("Encountered problem getting ndarray, falling back to conversion to Mono8")
                    converted_image = self.one_frame_post_processor.Convert(raw_image, PySpin.PixelFormat_Mono8)
                    numpy_image = converted_image.GetNDArray()
                if self.pixel_format == 'MONO12':
                    numpy_image = numpy_image <<4
        # self.current_frame = numpy_image
        raw_image.Release()
        if callback_was_enabled: # reenable callback if it was disabled
            self.enable_callback()
        return numpy_image
    
    def set_ROI(self,offset_x=None,offset_y=None,width=None,height=None):

        # stop streaming if streaming is on
        if self.is_streaming == True:
            was_streaming = True
            self.stop_streaming()
        else:
            was_streaming = False

        self.nodemap = self.camera.GetNodeMap()
        node_width = PySpin.CIntegerPtr(self.nodemap.GetNode('Width'))
        node_height = PySpin.CIntegerPtr(self.nodemap.GetNode('Height'))
        node_width_max = PySpin.CIntegerPtr(self.nodemap.GetNode('WidthMax'))
        node_height_max = PySpin.CIntegerPtr(self.nodemap.GetNode('HeightMax'))
        node_offset_x = PySpin.CIntegerPtr(self.nodemap.GetNode('OffsetX'))
        node_offset_y = PySpin.CIntegerPtr(self.nodemap.GetNode('OffsetY'))

        if width is not None:
            # update the camera setting
            if PySpin.IsWritable(node_width):
                node_min = node_width.GetMin()
                node_inc = node_width.GetInc()
                diff = width-node_min
                num_incs = diff//node_inc
                width = node_min+num_incs*node_inc
                self.Width = width
                node_width.SetValue(min(max(int(width),0),node_width_max.GetValue()))
            else:
                print("Width is not implemented or not writable")

        if height is not None:
            # update the camera setting
            if PySpin.IsWritable(node_height):
                node_min = node_height.GetMin()
                node_inc = node_height.GetInc()
                diff = height-node_min
                num_incs = diff//node_inc
                height = node_min+num_incs*node_inc

                self.Height = height
                node_height.SetValue(min(max(int(height),0),node_height_max.GetValue()))
            else:
                print("Height is not implemented or not writable")

        if offset_x is not None:
            # update the camera setting
            if PySpin.IsWritable(node_offset_x):
                node_min = node_offset_x.GetMin()
                node_max = node_offset_x.GetMax()
                node_inc = node_offset_x.GetInc()
                diff = offset_x-node_min
                num_incs = diff//node_inc
                offset_x = node_min+num_incs*node_inc

                self.OffsetX = offset_x
                node_offset_x.SetValue(min(int(offset_x), node_max))
            else:
                print("OffsetX is not implemented or not writable")
        
        if offset_y is not None:
            # update the camera setting
            if PySpin.IsWritable(node_offset_y):
                node_min = node_offset_y.GetMin()
                node_max = node_offset_y.GetMax()
                node_inc = node_offset_y.GetInc()
                diff = offset_y-node_min
                num_incs = diff//node_inc
                offset_y = node_min+num_incs*node_inc

                self.OffsetY = offset_y
                node_offset_y.SetValue(min(int(offset_y), node_max))
            else:
                print("OffsetY is not implemented or not writable")

        
        # restart streaming if it was previously on
        if was_streaming == True:
            self.start_streaming()

    def reset_camera_acquisition_counter(self):
        self.nodemap = self.camera.GetNodeMap()
        node_counter_event_source = PySpin.CEnumerationPtr(self.nodemap.GetNode('CounterEventSource'))
        node_counter_event_source_line2 = PySpin.CEnumEntryPtr(node_counter_event_source.GetEntryByName('Line2'))
        if PySpin.IsWritable(node_counter_event_source) and PySpin.IsReadable(node_counter_event_source_line2):
            node_counter_event_source.SetIntValue(node_counter_event_source_line2.GetValue())
        else:
            print("CounterEventSource is not implemented or not writable, or Line 2 is not an option")

        node_counter_reset = PySpin.CCommandPtr(self.nodemap.GetNode('CounterReset'))

        if PySpin.IsImplemented(node_counter_reset) and PySpin.IsWritable(node_counter_reset):
            node_counter_reset.Execute()
        else:
            print("CounterReset is not implemented")

    def set_line3_to_strobe(self): #FLIR cams don't have the right Line layout for this
        # self.camera.StrobeSwitch.set(gx.GxSwitchEntry.ON)
        #self.nodemap = self.camera.GetNodeMap()
        
        #node_line_selector = PySpin.CEnumerationPtr(self.nodemap.GetNode('LineSelector'))

        #node_line3 = PySpin.CEnumEntryPtr(node_line_selector.GetEntryByName('Line3'))
        
        #self.camera.LineSelector.set(gx.GxLineSelectorEntry.LINE3)
        #self.camera.LineMode.set(gx.GxLineModeEntry.OUTPUT)
        #self.camera.LineSource.set(gx.GxLineSourceEntry.STROBE)
        pass
    
    def set_line3_to_exposure_active(self): #BlackFly cam has no output on Line 3
        # self.camera.StrobeSwitch.set(gx.GxSwitchEntry.ON)
        #self.camera.LineSelector.set(gx.GxLineSelectorEntry.LINE3)
        #self.camera.LineMode.set(gx.GxLineModeEntry.OUTPUT)
        #self.camera.LineSource.set(gx.GxLineSourceEntry.EXPOSURE_ACTIVE)
        pass

    def __del__(self):
        try:
            self.stop_streaming()
            self.camera.DeInit()
            del self.camera
        except AttributeError:
            pass
        self.camera_list.Clear()
        self.py_spin_system.ReleaseInstance()


import sys
import argparse
import cv2
import time
import numpy as np

from control._def import *

import threading
import control.toupcam as toupcam
from control.toupcam_exceptions import hresult_checker


def get_sn_by_model(model_name):
    try:
        device_list = toupcam.Toupcam.EnumV2()
    except:
        print("Problem generating Toupcam device list")
        return None
    for dev in device_list:
        if dev.displayname == model_name:
            return dev.id
    return None # return None if no device with the specified model_name is connected


class Camera(object):

    @staticmethod
    def _event_callback(nEvent, camera):
        if nEvent == toupcam.TOUPCAM_EVENT_IMAGE:
            if camera.is_streaming:
                camera._on_frame_callback()
                camera._software_trigger_sent = False
                # print('  >>> new frame callback')

    def _on_frame_callback(self):
        
        # check if the last image is still locked
        if self.image_locked:
            print('last image is still being processed, a frame is dropped')
            return

        # get the image from the camera
        try:
            self.camera.PullImageV2(self.buf, self.pixel_size_byte*8, None) # the second camera is number of bits per pixel - ignored in RAW mode
            # print('  >>> pull image ok, current frame # = {}'.format(self.frame_ID))
        except toupcam.HRESULTException as ex:
            print('pull image failed, hr=0x{:x}'.format(ex.hr))

        # increament frame ID
        self.frame_ID_software += 1
        self.frame_ID += 1
        self.timestamp = time.time()

        # right now support the raw format only
        if self.data_format == 'RGB':
            if self.pixel_format == 'RGB24':
                # self.current_frame = QImage(self.buf, self.w, self.h, (self.w * 24 + 31) // 32 * 4, QImage.Format_RGB888)
                print('convert buffer to image not yet implemented for the RGB format')
            return()
        else:
            if self.pixel_size_byte == 1:
                raw_image = np.frombuffer(self.buf, dtype='uint8')
            elif self.pixel_size_byte == 2:
                raw_image = np.frombuffer(self.buf, dtype='uint16')
            self.current_frame = raw_image.reshape(self.Height,self.Width)

        # for debugging
        #print(self.current_frame.shape)
        #print(self.current_frame.dtype)

        # frame ID for hardware triggered acquisition
        if self.trigger_mode == TriggerMode.HARDWARE:
            if self.frame_ID_offset_hardware_trigger == None:
                self.frame_ID_offset_hardware_trigger = self.frame_ID
            self.frame_ID = self.frame_ID - self.frame_ID_offset_hardware_trigger

        self.image_is_ready = True

        if self.callback_is_enabled == True:
            self.new_image_callback_external(self)

    def _TDIBWIDTHBYTES(w):
        return (w * 24 + 31) // 32 * 4

    def __init__(self,sn=None,resolution=(3104,2084),is_global_shutter=False,rotate_image_angle=None,flip_image=None):

        # many to be purged
        self.sn = sn
        self.is_global_shutter = is_global_shutter
        self.device_info_list = None
        self.device_index = 0
        self.camera = None
        self.is_color = None
        self.gamma_lut = None
        self.contrast_lut = None
        self.color_correction_param = None

        self.rotate_image_angle = rotate_image_angle
        self.flip_image = flip_image

        self.exposure_time = 1 # unit: ms
        self.analog_gain = 0
        self.frame_ID = -1
        self.frame_ID_software = -1
        self.frame_ID_offset_hardware_trigger = 0
        self.timestamp = 0

        self.image_locked = False
        self.current_frame = None

        self.callback_is_enabled = False
        self.is_streaming = False

        self.GAIN_MAX = 40
        self.GAIN_MIN = 0
        self.GAIN_STEP = 1
        self.EXPOSURE_TIME_MS_MIN = 0.1
        self.EXPOSURE_TIME_MS_MAX = 3600000

        self.ROI_offset_x = CAMERA_CONFIG.ROI_OFFSET_X_DEFAULT
        self.ROI_offset_y = CAMERA_CONFIG.ROI_OFFSET_X_DEFAULT
        self.ROI_width = CAMERA_CONFIG.ROI_WIDTH_DEFAULT
        self.ROI_height = CAMERA_CONFIG.ROI_HEIGHT_DEFAULT

        self.trigger_mode = None
        self.pixel_size_byte = 1

        # below are values for IMX226 (MER2-1220-32U3M) - to make configurable 
        self.row_period_us = 10
        self.row_numbers = 3036
        self.exposure_delay_us_8bit = 650
        self.exposure_delay_us = self.exposure_delay_us_8bit*self.pixel_size_byte
        self.strobe_delay_us = self.exposure_delay_us + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1)

        self.pixel_format = None # use the default pixel format

        # toupcam
        self.data_format = 'RAW'
        self.devices = toupcam.Toupcam.EnumV2()
        self.image_is_ready = False
        self._toupcam_pullmode_started = False
        self._software_trigger_sent = False
        self._last_software_trigger_timestamp = None
        self.resolution = None

        if resolution != None:
            self.resolution = resolution
        self.has_fan = None
        self.has_TEC = None
        self.has_low_noise_mode = None

        # toupcam temperature
        self.temperature_reading_callback = None
        self.terminate_read_temperature_thread = False
        self.thread_read_temperature = threading.Thread(target=self.check_temperature, daemon=True)

        self.brand = 'ToupTek'
        
        self.res_list = []

        self.OffsetX =  CAMERA_CONFIG.ROI_OFFSET_X_DEFAULT
        self.OffsetY = CAMERA_CONFIG.ROI_OFFSET_X_DEFAULT
        self.Width = CAMERA_CONFIG.ROI_WIDTH_DEFAULT
        self.Height = CAMERA_CONFIG.ROI_HEIGHT_DEFAULT

        self.WidthMax = CAMERA_CONFIG.ROI_WIDTH_DEFAULT
        self.HeightMax = CAMERA_CONFIG.ROI_HEIGHT_DEFAULT

        if resolution is not None:
            self.Width = resolution[0]
            self.Height = resolution[1]

    def check_temperature(self):
        while self.terminate_read_temperature_thread == False:
            time.sleep(2)
            # print('[ camera temperature: ' + str(self.get_temperature()) + ' ]')
            temperature = self.get_temperature() 
            if self.temperature_reading_callback is not None:
                try:
                    self.temperature_reading_callback(temperature)
                except TypeError as ex:
                    print("Temperature read callback failed due to error: "+repr(ex))
                    pass

    def open(self,index=0):
        if len(self.devices) > 0:
            print('{}: flag = {:#x}, preview = {}, still = {}'.format(self.devices[0].displayname, self.devices[0].model.flag, self.devices[0].model.preview, self.devices[0].model.still))
            for r in self.devices[index].model.res:
                print('\t = [{} x {}]'.format(r.width, r.height))
            if self.sn is not None:
                index = [idx for idx in range(len(self.devices)) if self.devices[idx].id == self.sn][0]
            highest_res = (0,0)
            self.res_list = []
            for r in self.devices[index].model.res:
                self.res_list.append((r.width,r.height))
                if r.width > highest_res[0] or r.height > highest_res[1]:
                    highest_res = (r.width, r.height)
            self.camera = toupcam.Toupcam.Open(self.devices[index].id)
            self.has_fan = ( self.devices[index].model.flag & toupcam.TOUPCAM_FLAG_FAN ) > 0
            self.has_TEC = ( self.devices[index].model.flag & toupcam.TOUPCAM_FLAG_TEC_ONOFF ) > 0
            self.has_low_noise_mode = ( self.devices[index].model.flag & toupcam.TOUPCAM_FLAG_LOW_NOISE ) > 0
            if self.has_low_noise_mode:
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_LOW_NOISE,0)

            # RGB format: The output of every pixel contains 3 componants which stand for R/G/B value respectively. This output is a processed output from the internal color processing engine.
            # RAW format: In this format, the output is the raw data directly output from the sensor. The RAW format is for the users that want to skip the internal color processing and obtain the raw data for user-specific purpose. With the raw format output enabled, the functions that are related to the internal color processing will not work, such as Toupcam_put_Hue or Toupcam_AwbOnce function and so on
            
            # set temperature
            # print('max fan speed is ' + str(self.camera.FanMaxSpeed()))
            self.set_fan_speed(1)
            self.set_temperature(0)

            self.set_data_format('RAW')
            self.set_pixel_format('MONO16') # 'MONO8'
            self.set_auto_exposure(False)

            # set resolution to full if resolution is not specified or not in the list of supported resolutions
            if self.resolution is None:
                self.resolution = highest_res
            elif self.resolution not in self.res_list:
                self.resolution = highest_res

            # set camera resolution
            self.set_resolution(self.resolution[0],self.resolution[1]) # buffer created when setting resolution
            self._update_buffer_settings()
            
            if self.camera:
                if self.buf:
                    try:
                        self.camera.StartPullModeWithCallback(self._event_callback, self)
                    except toupcam.HRESULTException as ex:
                        print('failed to start camera, hr=0x{:x}'.format(ex.hr))
                        sys.exit(1)
                self._toupcam_pullmode_started = True
            else:
                print('failed to open camera')
                sys.exit(1)
        else:
            print('no camera found')

        self.is_color = False
        if self.is_color:
            pass

        self.thread_read_temperature.start()

    def set_callback(self,function):
        self.new_image_callback_external = function

    def set_temperature_reading_callback(self, func):
        self.temperature_reading_callback = func

    def enable_callback(self):
        self.callback_is_enabled = True

    def disable_callback(self):
        self.callback_is_enabled = False

    def open_by_sn(self,sn):
        pass

    def close(self):
        self.terminate_read_temperature_thread = True
        self.thread_read_temperature.join()
        self.set_fan_speed(0)
        self.camera.Close()
        self.camera = None
        self.buf = None
        self.last_raw_image = None
        self.last_converted_image = None
        self.last_numpy_image = None

    def set_exposure_time(self,exposure_time):
        # exposure time in ms
        self.camera.put_ExpoTime(int(exposure_time*1000))
        # use_strobe = (self.trigger_mode == TriggerMode.HARDWARE) # true if using hardware trigger
        # if use_strobe == False or self.is_global_shutter:
        #     self.exposure_time = exposure_time
        #     self.camera.ExposureTime.set(exposure_time * 1000)
        # else:
        #     # set the camera exposure time such that the active exposure time (illumination on time) is the desired value
        #     self.exposure_time = exposure_time
        #     # add an additional 500 us so that the illumination can fully turn off before rows start to end exposure
        #     camera_exposure_time = self.exposure_delay_us + self.exposure_time*1000 + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1) + 500 # add an additional 500 us so that the illumination can fully turn off before rows start to end exposure
        #     self.camera.ExposureTime.set(camera_exposure_time)
        self.exposure_time = exposure_time

    def update_camera_exposure_time(self):
        pass
        # use_strobe = (self.trigger_mode == TriggerMode.HARDWARE) # true if using hardware trigger
        # if use_strobe == False or self.is_global_shutter:
        #     self.camera.ExposureTime.set(self.exposure_time * 1000)
        # else:
        #     camera_exposure_time = self.exposure_delay_us + self.exposure_time*1000 + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1) + 500 # add an additional 500 us so that the illumination can fully turn off before rows start to end exposure
        #     self.camera.ExposureTime.set(camera_exposure_time)

    def set_analog_gain(self,analog_gain):
        analog_gain = min(self.GAIN_MAX,analog_gain)
        analog_gain = max(self.GAIN_MIN,analog_gain)
        self.analog_gain = analog_gain
        # gain_min, gain_max, gain_default = self.camera.get_ExpoAGainRange() # remove from set_analog_gain
        # for touptek cameras gain is 100-10000 (for 1x - 100x)
        self.camera.put_ExpoAGain(int(100*(10**(analog_gain/20))))
        # self.camera.Gain.set(analog_gain)

    def get_awb_ratios(self):
        try:
            self.camera.AwbInit()
            return self.camera.get_WhiteBalanceGain()
        except toupcam.HRESULTException as ex:
            err_type = hresult_checker(ex,'E_NOTIMPL')
            print("AWB not implemented")
            return (0,0,0)

    def set_wb_ratios(self, wb_r=None, wb_g=None, wb_b=None):
        try:
            camera.put_WhiteBalanceGain(wb_r,wb_g,wb_b)
        except toupcam.HRESULTException as ex:
            err_type = hresult_checker(ex,'E_NOTIMPL')
            print("White balance not implemented")

    def set_reverse_x(self,value):
        pass

    def set_reverse_y(self,value):
        pass

    def start_streaming(self):
        if self.buf and (self._toupcam_pullmode_started == False):
            try:
                self.camera.StartPullModeWithCallback(self._event_callback, self)
                self._toupcam_pullmode_started = True
            except toupcam.HRESULTException as ex:
                print('failed to start camera, hr: '+hresult_checker(ex))
                self.close()
                sys.exit(1)
        print('  start streaming')
        self.is_streaming = True

    def stop_streaming(self):
        self.camera.Stop()
        self.is_streaming = False
        self._toupcam_pullmode_started = False

    def set_pixel_format(self,pixel_format):

        was_streaming = False
        if self.is_streaming:
            was_streaming = True
            self.stop_streaming()

        self.pixel_format = pixel_format

        if self.data_format == 'RAW':
            if pixel_format == 'MONO8':
                self.pixel_size_byte = 1
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_BITDEPTH,0)
            elif pixel_format == 'MONO12':
                self.pixel_size_byte = 2
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_BITDEPTH,1)
            elif pixel_format == 'MONO14':
                self.pixel_size_byte = 2
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_BITDEPTH,1)
            elif pixel_format == 'MONO16':
                self.pixel_size_byte = 2
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_BITDEPTH,1)
        else:
            # RGB data format
            if pixel_format == 'MONO8':
                self.pixel_size_byte = 1
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_BITDEPTH,0)
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_RGB,3) # for monochrome camera only
            if pixel_format == 'MONO12':
                self.pixel_size_byte = 2
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_BITDEPTH,1)
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_RGB,4) # for monochrome camera only
            if pixel_format == 'MONO14':
                self.pixel_size_byte = 2
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_BITDEPTH,1)
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_RGB,4) # for monochrome camera only
            if pixel_format == 'MONO16':
                self.pixel_size_byte = 2
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_BITDEPTH,1)
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_RGB,4) # for monochrome camera only
            if pixel_format == 'RGB24':
                self.pixel_size_byte = 3
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_BITDEPTH,0)
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_RGB,0)
            if pixel_format == 'RGB32':
                self.pixel_size_byte = 4
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_BITDEPTH,0)
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_RGB,2)
            if pixel_format == 'RGB48':
                self.pixel_size_byte = 6
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_BITDEPTH,1)
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_RGB,1)

        self._update_buffer_settings()

        if was_streaming:
            self.start_streaming()
        #     if pixel_format == 'BAYER_RG8':
        #         self.camera.PixelFormat.set(gx.GxPixelFormatEntry.BAYER_RG8)
        #         self.pixel_size_byte = 1
        #     if pixel_format == 'BAYER_RG12':
        #         self.camera.PixelFormat.set(gx.GxPixelFormatEntry.BAYER_RG12)
        #         self.pixel_size_byte = 2
        #     self.pixel_format = pixel_format
        # else:
        #     print("pixel format is not implemented or not writable")

        # if was_streaming:
        #    self.start_streaming()

        # # update the exposure delay and strobe delay
        # self.exposure_delay_us = self.exposure_delay_us_8bit*self.pixel_size_byte
        # self.strobe_delay_us = self.exposure_delay_us + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1)

        # It is forbidden to call Toupcam_put_Option with TOUPCAM_OPTION_BITDEPTH in the callback context of 
        # PTOUPCAM_EVENT_CALLBACK and PTOUPCAM_DATA_CALLBACK_V3, the return value is E_WRONG_THREAD

    def set_auto_exposure(self,enabled):
        try:
            self.camera.put_AutoExpoEnable(enabled)
        except toupcam.HRESULTException as ex:
            print("Unable to set auto exposure: "+repr(ex))

    def set_data_format(self,data_format):
        self.data_format = data_format
        if data_format == 'RGB':
            self.camera.put_Option(toupcam.TOUPCAM_OPTION_RAW,0) # 0 is RGB mode, 1 is RAW mode
        elif data_format == 'RAW':
            self.camera.put_Option(toupcam.TOUPCAM_OPTION_RAW,1) # 1 is RAW mode, 0 is RGB mode

    def set_resolution(self,width,height):
        was_streaming = False
        if self.is_streaming:
            self.stop_streaming()
            was_streaming = True
        try:
            self.camera.put_Size(width,height)
        except toupcam.HRESULTException as ex:
            err_type = hresult_checker(ex,'E_INVALIDARG','E_BUSY','E_ACCESDENIED', 'E_UNEXPECTED')
            if err_type == 'E_INVALIDARG':
                print(f"Resolution ({width},{height}) not supported by camera")
            else:
                print(f"Resolution cannot be set due to error: "+err_type)
        self._update_buffer_settings()
        if was_streaming:
            self.start_streaming()

    def _update_buffer_settings(self):
        # resize the buffer
        xoffset, yoffset, width, height = self.camera.get_Roi()

        self.Width = width
        self.Height = height

        # calculate buffer size
        if (self.data_format == 'RGB') & (self.pixel_size_byte != 4):
            bufsize = _TDIBWIDTHBYTES(width * self.pixel_size_byte * 8) * height
        else:
            bufsize = width * self.pixel_size_byte * height
        print('image size: {} x {}, bufsize = {}'.format(width, height, bufsize))
        # create the buffer
        self.buf = bytes(bufsize)

    def get_temperature(self):
        try:
            return self.camera.get_Temperature()/10
        except toupcam.HRESULTException as ex:
            error_type = hresult_checker(ex)
            print("Could not get temperature, error: "+error_type)
            return 0

    def set_temperature(self,temperature):
        try:
            self.camera.put_Temperature(int(temperature*10))
        except toupcam.HRESULTException as ex:
            error_type = hresult_checker(ex)
            print("Unable to set temperature: "+error_type)

    def set_fan_speed(self,speed):
        if self.has_fan:
            try:
                self.camera.put_Option(toupcam.TOUPCAM_OPTION_FAN,speed)
            except toupcam.HRESULTException as ex:
                error_type = hresult_checker(ex)
                print("Unable to set fan speed: "+error_type)
        else:
            pass

    def set_continuous_acquisition(self):
        self.camera.put_Option(toupcam.TOUPCAM_OPTION_TRIGGER,0)
        self.trigger_mode = TriggerMode.CONTINUOUS
        # self.update_camera_exposure_time()

    def set_software_triggered_acquisition(self):
        self.camera.put_Option(toupcam.TOUPCAM_OPTION_TRIGGER,1)
        self.trigger_mode = TriggerMode.SOFTWARE
        # self.update_camera_exposure_time()

    def set_hardware_triggered_acquisition(self):
        self.camera.put_Option(toupcam.TOUPCAM_OPTION_TRIGGER,2)
        self.frame_ID_offset_hardware_trigger = None
        self.trigger_mode = TriggerMode.HARDWARE

        # select trigger source to GPIO0
        try:
            self.camera.IoControl(1, toupcam.TOUPCAM_IOCONTROLTYPE_SET_TRIGGERSOURCE, 1)
        except toupcam.HRESULTException as ex:
            error_type = hresult_checker(ex)
            print("Unable to select trigger source: " + error_type)
        # set GPIO1 to trigger wait
        try:
            self.camera.IoControl(3, toupcam.TOUPCAM_IOCONTROLTYPE_SET_OUTPUTMODE, 0)
            self.camera.IoControl(3, toupcam.TOUPCAM_IOCONTROLTYPE_SET_OUTPUTINVERTER, 0)
        except toupcam.HRESULTException as ex:
            error_type = hresult_checker(ex)
            print("Unable to set GPIO1 for trigger ready: " + error_type)

        # self.update_camera_exposure_time()

    def set_trigger_width_mode(self):
        self.camera.IoControl(1, toupcam.TOUPCAM_IOCONTROLTYPE_SET_PWMSOURCE, 1) # set PWM source to GPIO0
        self.camera.IoControl(1, toupcam.TOUPCAM_IOCONTROLTYPE_SET_TRIGGERSOURCE, 4) # trigger source to PWM

    def set_gain_mode(self,mode):
        if mode == 'LCG':
            self.camera.put_Option(toupcam.TOUPCAM_OPTION_CG,0)
        elif mode == 'HCG':
            self.camera.put_Option(toupcam.TOUPCAM_OPTION_CG,1)
        elif mode == 'HDR':
            self.camera.put_Option(toupcam.TOUPCAM_OPTION_CG,2)
            
    def send_trigger(self):
        if self._last_software_trigger_timestamp!= None:
            if (time.time() - self._last_software_trigger_timestamp) > (1.5*self.exposure_time/1000*1.02 + 4):
                print('last software trigger timed out')
                self._software_trigger_sent = False
        if self.is_streaming and (self._software_trigger_sent == False):
            self.camera.Trigger(1)
            self._software_trigger_sent = True
            self._last_software_trigger_timestamp = time.time()
            print('  >>> trigger sent')
        else:
            if self.is_streaming == False:
                print('trigger not sent - camera is not streaming')
            else:
                # print('trigger not sent - waiting for the last trigger to complete')
                pass
                #print("{:.3f}".format(time.time()-self._last_software_trigger_timestamp) + ' s since the last trigger')

    def stop_exposure(self):
        if self.is_streaming and self._software_trigger_sent == True:
            self.camera.Trigger(0)
            self._software_trigger_sent = False
        else:
            pass

    def read_frame(self,reset_image_ready_flag=True):
        # set reset_image_ready_flag to True when read_frame() is called immediately after triggering the acquisition
        if reset_image_ready_flag:
            self.image_is_ready = False
        timestamp_t0 = time.time()
        while (time.time() - timestamp_t0) <= (self.exposure_time/1000)*1.02 + 4:
            time.sleep(0.005)
            if self.image_is_ready:
                self.image_is_ready = False
                return self.current_frame
        print('read frame timed out')
        return None
    
    def set_ROI(self,offset_x=None,offset_y=None,width=None,height=None):
        if offset_x is not None:
            ROI_offset_x = 2*(offset_x//2)
        else:
            ROI_offset_x = self.ROI_offset_x
        #     # stop streaming if streaming is on
        #     if self.is_streaming == True:
        #         was_streaming = True
        #         self.stop_streaming()
        #     else:
        #         was_streaming = False
        #     # update the camera setting
        #     if self.camera.OffsetX.is_implemented() and self.camera.OffsetX.is_writable():
        #         self.camera.OffsetX.set(self.ROI_offset_x)
        #     else:
        #         print("OffsetX is not implemented or not writable")
        #     # restart streaming if it was previously on
        #     if was_streaming == True:
        #         self.start_streaming()

        if offset_y is not None:
            ROI_offset_y = 2*(offset_y//2)
        else:
            ROI_offset_y = self.ROI_offset_y
        #         # stop streaming if streaming is on
        #     if self.is_streaming == True:
        #         was_streaming = True
        #         self.stop_streaming()
        #     else:
        #         was_streaming = False
        #     # update the camera setting
        #     if self.camera.OffsetY.is_implemented() and self.camera.OffsetY.is_writable():
        #         self.camera.OffsetY.set(self.ROI_offset_y)
        #     else:
        #         print("OffsetX is not implemented or not writable")
        #     # restart streaming if it was previously on
        #     if was_streaming == True:
        #         self.start_streaming()

        if width is not None:
            ROI_width = max(16,2*(width//2))
        else:
            ROI_width = self.ROI_width
        #     # stop streaming if streaming is on
        #     if self.is_streaming == True:
        #         was_streaming = True
        #         self.stop_streaming()
        #     else:
        #         was_streaming = False
        #     # update the camera setting
        #     if self.camera.Width.is_implemented() and self.camera.Width.is_writable():
        #         self.camera.Width.set(self.ROI_width)
        #     else:
        #         print("OffsetX is not implemented or not writable")
        #     # restart streaming if it was previously on
        #     if was_streaming == True:
        #         self.start_streaming()

        if height is not None:
            ROI_height = max(16,2*(height//2))
        else:
            ROI_height = self.ROI_height
        #     # stop streaming if streaming is on
        #     if self.is_streaming == True:
        #         was_streaming = True
        #         self.stop_streaming()
        #     else:
        #         was_streaming = False
        #     # update the camera setting
        #     if self.camera.Height.is_implemented() and self.camera.Height.is_writable():
        #         self.camera.Height.set(self.ROI_height)
        #     else:
        #         print("Height is not implemented or not writable")
        #     # restart streaming if it was previously on
        #     if was_streaming == True:
        #         self.start_streaming()
        was_streaming = False
        if self.is_streaming:
            self.stop_streaming()
            was_streaming = True

        if width == 0 and height == 0:
            self.ROI_offset_x = 0
            self.ROI_offset_y = 0
            self.OffsetX = 0
            self.OffsetY = 0
            self.ROI_height = 0
            self.ROI_width = 0
            self.camera.put_Roi(0,0,0,0)
            width, height = self.camera.get_Size()
            self.Width = width
            self.Height = height
            self.ROI_height = height
            self.ROI_width = width
            self._update_buffer_settings()

        else:
            try:
                self.camera.put_Roi(ROI_offset_x,ROI_offset_y,ROI_width,ROI_height)
                self.ROI_height = ROI_height
                self.Height = ROI_height
                self.ROI_width = ROI_width
                self.Width = ROI_width

                self.ROI_offset_x = ROI_offset_x
                self.OffsetX = ROI_offset_x

                self.ROI_offset_y = ROI_offset_y
                self.OffsetY = ROI_offset_y
            except toupcam.HRESULTException as ex:
                err_type = hresult_checker(ex,'E_INVALIDARG')
                print("ROI bounds invalid, not changing ROI.")
            self._update_buffer_settings()
        if was_streaming:
            self.start_streaming()

    def reset_camera_acquisition_counter(self):
        # if self.camera.CounterEventSource.is_implemented() and self.camera.CounterEventSource.is_writable():
        #     self.camera.CounterEventSource.set(gx.GxCounterEventSourceEntry.LINE2)
        # else:
        #     print("CounterEventSource is not implemented or not writable")

        # if self.camera.CounterReset.is_implemented():
        #     self.camera.CounterReset.send_command()
        # else:
        #     print("CounterReset is not implemented")
        pass

    def set_line3_to_strobe(self):
        # # self.camera.StrobeSwitch.set(gx.GxSwitchEntry.ON)
        # self.camera.LineSelector.set(gx.GxLineSelectorEntry.LINE3)
        # self.camera.LineMode.set(gx.GxLineModeEntry.OUTPUT)
        # self.camera.LineSource.set(gx.GxLineSourceEntry.STROBE)
        pass

    def set_line3_to_exposure_active(self):
        # # self.camera.StrobeSwitch.set(gx.GxSwitchEntry.ON)
        # self.camera.LineSelector.set(gx.GxLineSelectorEntry.LINE3)
        # self.camera.LineMode.set(gx.GxLineModeEntry.OUTPUT)
        # self.camera.LineSource.set(gx.GxLineSourceEntry.EXPOSURE_ACTIVE)
        pass

class Camera_Simulation(object):
    
    def __init__(self,sn=None,is_global_shutter=False,rotate_image_angle=None,flip_image=None):
        # many to be purged
        self.sn = sn
        self.is_global_shutter = is_global_shutter
        self.device_info_list = None
        self.device_index = 0
        self.camera = None
        self.is_color = None
        self.gamma_lut = None
        self.contrast_lut = None
        self.color_correction_param = None

        self.rotate_image_angle = rotate_image_angle
        self.flip_image = flip_image

        self.exposure_time = 0
        self.analog_gain = 0
        self.frame_ID = 0
        self.frame_ID_software = -1
        self.frame_ID_offset_hardware_trigger = 0
        self.timestamp = 0

        self.image_locked = False
        self.current_frame = None

        self.callback_is_enabled = False
        self.is_streaming = False

        self.GAIN_MAX = 40
        self.GAIN_MIN = 0
        self.GAIN_STEP = 1
        self.EXPOSURE_TIME_MS_MIN = 0.1
        self.EXPOSURE_TIME_MS_MAX = 3600000

        self.trigger_mode = None
        self.pixel_size_byte = 1

        # below are values for IMX226 (MER2-1220-32U3M) - to make configurable 
        self.row_period_us = 10
        self.row_numbers = 3036
        self.exposure_delay_us_8bit = 650
        self.exposure_delay_us = self.exposure_delay_us_8bit*self.pixel_size_byte
        self.strobe_delay_us = self.exposure_delay_us + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1)

        self.pixel_format = 'MONO16'

        self.Width = 3000
        self.Height = 3000
        self.WidthMax = 4000
        self.HeightMax = 3000
        self.OffsetX = 0
        self.OffsetY = 0

        self.brand = 'ToupTek'

    def open(self,index=0):
        pass

    def set_callback(self,function):
        self.new_image_callback_external = function

    def set_temperature_reading_callback(self, func):
        self.temperature_reading_callback = func

    def enable_callback(self):
        self.callback_is_enabled = True

    def disable_callback(self):
        self.callback_is_enabled = False

    def open_by_sn(self,sn):
        pass

    def close(self):
        pass

    def set_exposure_time(self,exposure_time):
        pass

    def update_camera_exposure_time(self):
        pass

    def set_analog_gain(self,analog_gain):
        pass

    def get_awb_ratios(self):
        pass

    def set_wb_ratios(self, wb_r=None, wb_g=None, wb_b=None):
        pass

    def start_streaming(self):
        self.frame_ID_software = 0

    def stop_streaming(self):
        pass

    def set_pixel_format(self,pixel_format):
        self.pixel_format = pixel_format
        print(pixel_format)
        self.frame_ID = 0

    def get_temperature(self):
        return 0

    def set_temperature(self,temperature):
        pass

    def set_fan_speed(self,speed):
        pass

    def set_continuous_acquisition(self):
        pass

    def set_software_triggered_acquisition(self):
        pass

    def set_hardware_triggered_acquisition(self):
        pass

    def set_gain_mode(self,mode):
        pass

    def send_trigger(self):
        self.frame_ID = self.frame_ID + 1
        self.timestamp = time.time()
        if self.frame_ID == 1:
            if self.pixel_format == 'MONO8':
                self.current_frame = np.random.randint(255,size=(2000,2000),dtype=np.uint8)
                self.current_frame[901:1100,901:1100] = 200
            elif self.pixel_format == 'MONO12':
                self.current_frame = np.random.randint(4095,size=(2000,2000),dtype=np.uint16)
                self.current_frame[901:1100,901:1100] = 200*16
                self.current_frame = self.current_frame << 4
            elif self.pixel_format == 'MONO16':
                self.current_frame = np.random.randint(65535,size=(2000,2000),dtype=np.uint16)
                self.current_frame[901:1100,901:1100] = 200*256
        else:
            self.current_frame = np.roll(self.current_frame,10,axis=0)
            pass 
            # self.current_frame = np.random.randint(255,size=(768,1024),dtype=np.uint8)
        if self.new_image_callback_external is not None and self.callback_is_enabled:
            self.new_image_callback_external(self)

    def stop_exposure(self):
        if self.is_streaming and self._software_trigger_sent == True:
            self._software_trigger_sent = False
        else:
            pass

    def read_frame(self):
        return self.current_frame

    def _on_frame_callback(self, user_param, raw_image):
        pass

    def set_ROI(self,offset_x=None,offset_y=None,width=None,height=None):
        pass

    def reset_camera_acquisition_counter(self):
        pass

    def set_line3_to_strobe(self):
        pass

    def set_line3_to_exposure_active(self):
        pass

# set QT_API environment variable
import os 
import sys
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

from control.processing_handler import ProcessingHandler

import control.utils as utils
from control._def import *

import control.tracking as tracking
try:
    from control.multipoint_custom_script_entry import *
    print('custom multipoint script found')
except:
    pass
import control.serial_peripherals as serial_peripherals

from queue import Queue
from threading import Thread, Lock
import time
import numpy as np
import pyqtgraph as pg
import scipy
import scipy.signal
import cv2
from datetime import datetime

from lxml import etree as ET
from pathlib import Path
import control.utils_config as utils_config

import math
import json
import pandas as pd

import imageio as iio

import subprocess


class ObjectiveStore:
    def __init__(self, objectives_dict = OBJECTIVES, default_objective = DEFAULT_OBJECTIVE):
        self.objectives_dict = objectives_dict
        self.default_objective = default_objective
        self.current_objective = default_objective

class StreamHandler(QObject):

    image_to_display = Signal(np.ndarray)
    packet_image_to_write = Signal(np.ndarray, int, float)
    packet_image_for_tracking = Signal(np.ndarray, int, float)
    signal_new_frame_received = Signal()

    def __init__(self,crop_width=Acquisition.CROP_WIDTH,crop_height=Acquisition.CROP_HEIGHT,display_resolution_scaling=1):
        QObject.__init__(self)
        self.fps_display = 1
        self.fps_save = 1
        self.fps_track = 1
        self.timestamp_last_display = 0
        self.timestamp_last_save = 0
        self.timestamp_last_track = 0

        self.crop_width = crop_width
        self.crop_height = crop_height
        self.display_resolution_scaling = display_resolution_scaling

        self.save_image_flag = False
        self.track_flag = False
        self.handler_busy = False

        # for fps measurement
        self.timestamp_last = 0
        self.counter = 0
        self.fps_real = 0

    def start_recording(self):
        self.save_image_flag = True

    def stop_recording(self):
        self.save_image_flag = False

    def start_tracking(self):
        self.tracking_flag = True

    def stop_tracking(self):
        self.tracking_flag = False

    def set_display_fps(self,fps):
        self.fps_display = fps

    def set_save_fps(self,fps):
        self.fps_save = fps

    def set_crop(self,crop_width,crop_height):
        self.crop_width = crop_width
        self.crop_height = crop_height

    def set_display_resolution_scaling(self, display_resolution_scaling):
        self.display_resolution_scaling = display_resolution_scaling/100
        print(self.display_resolution_scaling)

    def on_new_frame(self, camera):

        if camera.is_live:

            camera.image_locked = True
            self.handler_busy = True
            self.signal_new_frame_received.emit() # self.liveController.turn_off_illumination()

            # measure real fps
            timestamp_now = round(time.time())
            if timestamp_now == self.timestamp_last:
                self.counter = self.counter+1
            else:
                self.timestamp_last = timestamp_now
                self.fps_real = self.counter
                self.counter = 0
                print('real camera fps is ' + str(self.fps_real))

            # moved down (so that it does not modify the camera.current_frame, which causes minor problems for simulation) - 1/30/2022
            # # rotate and flip - eventually these should be done in the camera
            # camera.current_frame = utils.rotate_and_flip_image(camera.current_frame,rotate_image_angle=camera.rotate_image_angle,flip_image=camera.flip_image)

            # crop image
            image_cropped = utils.crop_image(camera.current_frame,self.crop_width,self.crop_height)
            image_cropped = np.squeeze(image_cropped)
            
            # # rotate and flip - moved up (1/10/2022)
            # image_cropped = utils.rotate_and_flip_image(image_cropped,rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
            # added on 1/30/2022
            # @@@ to move to camera 
            image_cropped = utils.rotate_and_flip_image(image_cropped,rotate_image_angle=camera.rotate_image_angle,flip_image=camera.flip_image)

            # send image to display
            time_now = time.time()
            if time_now-self.timestamp_last_display >= 1/self.fps_display:
                # self.image_to_display.emit(cv2.resize(image_cropped,(round(self.crop_width*self.display_resolution_scaling), round(self.crop_height*self.display_resolution_scaling)),cv2.INTER_LINEAR))
                self.image_to_display.emit(utils.crop_image(image_cropped,round(self.crop_width*self.display_resolution_scaling), round(self.crop_height*self.display_resolution_scaling)))
                self.timestamp_last_display = time_now

            # send image to write
            if self.save_image_flag and time_now-self.timestamp_last_save >= 1/self.fps_save:
                if camera.is_color:
                    image_cropped = cv2.cvtColor(image_cropped,cv2.COLOR_RGB2BGR)
                self.packet_image_to_write.emit(image_cropped,camera.frame_ID,camera.timestamp)
                self.timestamp_last_save = time_now

            # send image to track
            if self.track_flag and time_now-self.timestamp_last_track >= 1/self.fps_track:
                # track is a blocking operation - it needs to be
                # @@@ will cropping before emitting the signal lead to speedup?
                self.packet_image_for_tracking.emit(image_cropped,camera.frame_ID,camera.timestamp)
                self.timestamp_last_track = time_now

            self.handler_busy = False
            camera.image_locked = False

    '''
    def on_new_frame_from_simulation(self,image,frame_ID,timestamp):
        # check whether image is a local copy or pointer, if a pointer, needs to prevent the image being modified while this function is being executed
        
        self.handler_busy = True

        # crop image
        image_cropped = utils.crop_image(image,self.crop_width,self.crop_height)

        # send image to display
        time_now = time.time()
        if time_now-self.timestamp_last_display >= 1/self.fps_display:
            self.image_to_display.emit(cv2.resize(image_cropped,(round(self.crop_width*self.display_resolution_scaling), round(self.crop_height*self.display_resolution_scaling)),cv2.INTER_LINEAR))
            self.timestamp_last_display = time_now

        # send image to write
        if self.save_image_flag and time_now-self.timestamp_last_save >= 1/self.fps_save:
            self.packet_image_to_write.emit(image_cropped,frame_ID,timestamp)
            self.timestamp_last_save = time_now

        # send image to track
        if time_now-self.timestamp_last_display >= 1/self.fps_track:
            # track emit
            self.timestamp_last_track = time_now

        self.handler_busy = False
    '''

class ImageSaver(QObject):

    stop_recording = Signal()

    def __init__(self,image_format=Acquisition.IMAGE_FORMAT):
        QObject.__init__(self)
        self.base_path = './'
        self.experiment_ID = ''
        self.image_format = image_format
        self.max_num_image_per_folder = 1000
        self.queue = Queue(10) # max 10 items in the queue
        self.image_lock = Lock()
        self.stop_signal_received = False
        self.thread = Thread(target=self.process_queue)
        self.thread.start()
        self.counter = 0
        self.recording_start_time = 0
        self.recording_time_limit = -1

    def process_queue(self):
        while True:
            # stop the thread if stop signal is received
            if self.stop_signal_received:
                return
            # process the queue
            try:
                [image,frame_ID,timestamp] = self.queue.get(timeout=0.1)
                self.image_lock.acquire(True)
                folder_ID = int(self.counter/self.max_num_image_per_folder)
                file_ID = int(self.counter%self.max_num_image_per_folder)
                # create a new folder
                if file_ID == 0:
                    os.mkdir(os.path.join(self.base_path,self.experiment_ID,str(folder_ID)))

                if image.dtype == np.uint16:
                    # need to use tiff when saving 16 bit images
                    saving_path = os.path.join(self.base_path,self.experiment_ID,str(folder_ID),str(file_ID) + '_' + str(frame_ID) + '.tiff')
                    iio.imwrite(saving_path,image)
                else:
                    saving_path = os.path.join(self.base_path,self.experiment_ID,str(folder_ID),str(file_ID) + '_' + str(frame_ID) + '.' + self.image_format)
                    cv2.imwrite(saving_path,image)

                self.counter = self.counter + 1
                self.queue.task_done()
                self.image_lock.release()
            except:
                pass
                            
    def enqueue(self,image,frame_ID,timestamp):
        try:
            self.queue.put_nowait([image,frame_ID,timestamp])
            if ( self.recording_time_limit>0 ) and ( time.time()-self.recording_start_time >= self.recording_time_limit ):
                self.stop_recording.emit()
            # when using self.queue.put(str_), program can be slowed down despite multithreading because of the block and the GIL
        except:
            print('imageSaver queue is full, image discarded')

    def set_base_path(self,path):
        self.base_path = path

    def set_recording_time_limit(self,time_limit):
        self.recording_time_limit = time_limit

    def start_new_experiment(self,experiment_ID,add_timestamp=True):
        if add_timestamp:
            # generate unique experiment ID
            self.experiment_ID = experiment_ID + '_' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S.%f')
        else:
            self.experiment_ID = experiment_ID
        self.recording_start_time = time.time()
        # create a new folder
        try:
            os.mkdir(os.path.join(self.base_path,self.experiment_ID))
            # to do: save configuration
        except:
            pass
        # reset the counter
        self.counter = 0

    def close(self):
        self.queue.join()
        self.stop_signal_received = True
        self.thread.join()


class ImageSaver_Tracking(QObject):
    def __init__(self,base_path,image_format='bmp'):
        QObject.__init__(self)
        self.base_path = base_path
        self.image_format = image_format
        self.max_num_image_per_folder = 1000
        self.queue = Queue(100) # max 100 items in the queue
        self.image_lock = Lock()
        self.stop_signal_received = False
        self.thread = Thread(target=self.process_queue)
        self.thread.start()

    def process_queue(self):
        while True:
            # stop the thread if stop signal is received
            if self.stop_signal_received:
                return
            # process the queue
            try:
                [image,frame_counter,postfix] = self.queue.get(timeout=0.1)
                self.image_lock.acquire(True)
                folder_ID = int(frame_counter/self.max_num_image_per_folder)
                file_ID = int(frame_counter%self.max_num_image_per_folder)
                # create a new folder
                if file_ID == 0:
                    os.mkdir(os.path.join(self.base_path,str(folder_ID)))
                if image.dtype == np.uint16:
                    saving_path = os.path.join(self.base_path,str(folder_ID),str(file_ID) + '_' + str(frame_counter) + '_' + postfix + '.tiff')
                    iio.imwrite(saving_path,image)
                else:
                    saving_path = os.path.join(self.base_path,str(folder_ID),str(file_ID) + '_' + str(frame_counter) + '_' + postfix + '.' + self.image_format)
                    cv2.imwrite(saving_path,image)
                self.queue.task_done()
                self.image_lock.release()
            except:
                pass
                            
    def enqueue(self,image,frame_counter,postfix):
        try:
            self.queue.put_nowait([image,frame_counter,postfix])
        except:
            print('imageSaver queue is full, image discarded')

    def close(self):
        self.queue.join()
        self.stop_signal_received = True
        self.thread.join()


'''
class ImageSaver_MultiPointAcquisition(QObject):
'''

class ImageDisplay(QObject):

    image_to_display = Signal(np.ndarray)

    def __init__(self):
        QObject.__init__(self)
        self.queue = Queue(10) # max 10 items in the queue
        self.image_lock = Lock()
        self.stop_signal_received = False
        self.thread = Thread(target=self.process_queue)
        self.thread.start()        
        
    def process_queue(self):
        while True:
            # stop the thread if stop signal is received
            if self.stop_signal_received:
                return
            # process the queue
            try:
                [image,frame_ID,timestamp] = self.queue.get(timeout=0.1)
                self.image_lock.acquire(True)
                self.image_to_display.emit(image)
                self.image_lock.release()
                self.queue.task_done()
            except:
                pass

    # def enqueue(self,image,frame_ID,timestamp):
    def enqueue(self,image):
        try:
            self.queue.put_nowait([image,None,None])
            # when using self.queue.put(str_) instead of try + nowait, program can be slowed down despite multithreading because of the block and the GIL
            pass
        except:
            print('imageDisplay queue is full, image discarded')

    def emit_directly(self,image):
        self.image_to_display.emit(image)

    def close(self):
        self.queue.join()
        self.stop_signal_received = True
        self.thread.join()

class Configuration:
    def __init__(self,mode_id=None,name=None,color=None,camera_sn=None,exposure_time=None,analog_gain=None,illumination_source=None,illumination_intensity=None,z_offset=None,pixel_format=None,_pixel_format_options=None,emission_filter_position=None):
        self.id = mode_id
        self.name = name
        self.color = color
        self.exposure_time = exposure_time
        self.analog_gain = analog_gain
        self.illumination_source = illumination_source
        self.illumination_intensity = illumination_intensity
        self.camera_sn = camera_sn
        self.z_offset = z_offset
        self.pixel_format = pixel_format
        if self.pixel_format is None:
            self.pixel_format = "default"
        self._pixel_format_options = _pixel_format_options
        if _pixel_format_options is None:
            self._pixel_format_options = self.pixel_format
        self.emission_filter_position = emission_filter_position

class LiveController(QObject):
    
    def __init__(self,camera,microcontroller,configurationManager,parent=None,control_illumination=True,use_internal_timer_for_hardware_trigger=True,for_displacement_measurement=False):
        QObject.__init__(self)
        self.microscope = parent
        self.camera = camera
        self.microcontroller = microcontroller
        self.configurationManager = configurationManager
        self.currentConfiguration = None
        self.trigger_mode = TriggerMode.SOFTWARE # @@@ change to None
        self.is_live = False
        self.control_illumination = control_illumination
        self.illumination_on = False
        self.use_internal_timer_for_hardware_trigger = use_internal_timer_for_hardware_trigger # use QTimer vs timer in the MCU
        self.for_displacement_measurement = for_displacement_measurement

        self.fps_trigger = 1;
        self.timer_trigger_interval = (1/self.fps_trigger)*1000

        self.timer_trigger = QTimer()
        self.timer_trigger.setInterval(int(self.timer_trigger_interval))
        self.timer_trigger.timeout.connect(self.trigger_acquisition)

        self.trigger_ID = -1

        self.fps_real = 0
        self.counter = 0
        self.timestamp_last = 0

        self.display_resolution_scaling = DEFAULT_DISPLAY_CROP/100

        self.enable_channel_auto_filter_switching = True

        if USE_LDI_SERIAL_CONTROL:
            self.ldi = serial_peripherals.LDI()
      
        if SUPPORT_SCIMICROSCOPY_LED_ARRAY:
            # to do: add error handling
            self.led_array = serial_peripherals.SciMicroscopyLEDArray(SCIMICROSCOPY_LED_ARRAY_SN,SCIMICROSCOPY_LED_ARRAY_DISTANCE,SCIMICROSCOPY_LED_ARRAY_TURN_ON_DELAY)
            self.led_array.set_NA(SCIMICROSCOPY_LED_ARRAY_DEFAULT_NA)

    # illumination control
    def turn_on_illumination(self):
        if USE_LDI_SERIAL_CONTROL and 'Fluorescence' in self.currentConfiguration.name:
            self.ldi.set_active_channel_shutter(1)
        elif SUPPORT_SCIMICROSCOPY_LED_ARRAY and 'LED matrix' in self.currentConfiguration.name:
            self.led_array.turn_on_illumination()
        else:
            self.microcontroller.turn_on_illumination()
        self.illumination_on = True

    def turn_off_illumination(self):
        if USE_LDI_SERIAL_CONTROL and 'Fluorescence' in self.currentConfiguration.name:
            self.ldi.set_active_channel_shutter(0)
        elif SUPPORT_SCIMICROSCOPY_LED_ARRAY and 'LED matrix' in self.currentConfiguration.name:
            self.led_array.turn_off_illumination()
        else:
            self.microcontroller.turn_off_illumination()
        self.illumination_on = False

    def set_illumination(self,illumination_source,intensity,update_channel_settings=True):
        if illumination_source < 10: # LED matrix
            if SUPPORT_SCIMICROSCOPY_LED_ARRAY:
                # set color
                if 'BF LED matrix full_R' in self.currentConfiguration.name:
                    self.led_array.set_color((1,0,0))
                elif 'BF LED matrix full_G' in self.currentConfiguration.name:
                    self.led_array.set_color((0,1,0))
                elif 'BF LED matrix full_B' in self.currentConfiguration.name:
                    self.led_array.set_color((0,0,1))
                else:
                    self.led_array.set_color(SCIMICROSCOPY_LED_ARRAY_DEFAULT_COLOR)
                # set intensity
                self.led_array.set_brightness(intensity)
                # set mode
                if 'BF LED matrix left half' in self.currentConfiguration.name:
                    self.led_array.set_illumination('dpc.l')
                if 'BF LED matrix right half' in self.currentConfiguration.name:
                    self.led_array.set_illumination('dpc.r')
                if 'BF LED matrix top half' in self.currentConfiguration.name:
                    self.led_array.set_illumination('dpc.t')
                if 'BF LED matrix bottom half' in self.currentConfiguration.name:
                    self.led_array.set_illumination('dpc.b')
                if 'BF LED matrix full' in self.currentConfiguration.name:
                    self.led_array.set_illumination('bf')
                if 'DF LED matrix' in self.currentConfiguration.name:
                    self.led_array.set_illumination('df')
            else:
                self.microcontroller.set_illumination_led_matrix(illumination_source,r=(intensity/100)*LED_MATRIX_R_FACTOR,g=(intensity/100)*LED_MATRIX_G_FACTOR,b=(intensity/100)*LED_MATRIX_B_FACTOR)
        else:
            # update illumination
            if USE_LDI_SERIAL_CONTROL and 'Fluorescence' in self.currentConfiguration.name:
                # set LDI active channel
                print('set active channel to ' + str(illumination_source))
                self.ldi.set_active_channel(int(illumination_source))
                if update_channel_settings:
                    # set intensity for active channel
                    print('set intensity')
                    self.ldi.set_intensity(int(illumination_source),intensity)
            elif ENABLE_NL5 and NL5_USE_DOUT and 'Fluorescence' in self.currentConfiguration.name:
                wavelength = int(self.currentConfiguration.name[13:16])
                self.microscope.nl5.set_active_channel(NL5_WAVENLENGTH_MAP[wavelength])
                if NL5_USE_AOUT and update_channel_settings:
                    self.microscope.nl5.set_laser_power(NL5_WAVENLENGTH_MAP[wavelength],int(intensity))
                if ENABLE_CELLX:
                    self.microscope.cellx.set_laser_power(NL5_WAVENLENGTH_MAP[wavelength],int(intensity))
            else:
                self.microcontroller.set_illumination(illumination_source,intensity)

        # set emission filter position
        if ENABLE_SPINNING_DISK_CONFOCAL:
            try:
                self.microscope.xlight.set_emission_filter(XLIGHT_EMISSION_FILTER_MAPPING[illumination_source],extraction=False,validate=XLIGHT_VALIDATE_WHEEL_POS)
            except Exception as e:
                print('not setting emission filter position due to ' + str(e))

        if USE_ZABER_EMISSION_FILTER_WHEEL and self.enable_channel_auto_filter_switching:
            try:
                self.microscope.emission_filter_wheel.set_emission_filter(str(self.currentConfiguration.emission_filter_position))
            except Exception as e:
                print('not setting emission filter position due to ' + str(e))


    def start_live(self):
        self.is_live = True
        self.camera.is_live = True
        self.camera.start_streaming()
        if self.trigger_mode == TriggerMode.SOFTWARE or ( self.trigger_mode == TriggerMode.HARDWARE and self.use_internal_timer_for_hardware_trigger ):
            self.camera.enable_callback() # in case it's disabled e.g. by the laser AF controller
            self._start_triggerred_acquisition()
        # if controlling the laser displacement measurement camera
        if self.for_displacement_measurement:
            self.microcontroller.set_pin_level(MCU_PINS.AF_LASER,1)

    def stop_live(self):
        if self.is_live:
            self.is_live = False
            self.camera.is_live = False
            if hasattr(self.camera,'stop_exposure'):
                self.camera.stop_exposure()
            if self.trigger_mode == TriggerMode.SOFTWARE:
                self._stop_triggerred_acquisition()
            # self.camera.stop_streaming() # 20210113 this line seems to cause problems when using af with multipoint
            if self.trigger_mode == TriggerMode.CONTINUOUS:
                self.camera.stop_streaming()
            if ( self.trigger_mode == TriggerMode.SOFTWARE ) or ( self.trigger_mode == TriggerMode.HARDWARE and self.use_internal_timer_for_hardware_trigger ):
                self._stop_triggerred_acquisition()
            if self.control_illumination:
                self.turn_off_illumination()
            # if controlling the laser displacement measurement camera
            if self.for_displacement_measurement:
                self.microcontroller.set_pin_level(MCU_PINS.AF_LASER,0)

    # software trigger related
    def trigger_acquisition(self):
        if self.trigger_mode == TriggerMode.SOFTWARE:
            if self.control_illumination and self.illumination_on == False:
                self.turn_on_illumination()
            self.trigger_ID = self.trigger_ID + 1
            self.camera.send_trigger()
            # measure real fps
            timestamp_now = round(time.time())
            if timestamp_now == self.timestamp_last:
                self.counter = self.counter+1
            else:
                self.timestamp_last = timestamp_now
                self.fps_real = self.counter
                self.counter = 0
                # print('real trigger fps is ' + str(self.fps_real))
        elif self.trigger_mode == TriggerMode.HARDWARE:
            self.trigger_ID = self.trigger_ID + 1
            if ENABLE_NL5 and NL5_USE_DOUT:
                self.microscope.nl5.start_acquisition()
            else:
                self.microcontroller.send_hardware_trigger(control_illumination=True,illumination_on_time_us=self.camera.exposure_time*1000)

    def _start_triggerred_acquisition(self):
        self.timer_trigger.start()

    def _set_trigger_fps(self,fps_trigger):
        self.fps_trigger = fps_trigger
        self.timer_trigger_interval = (1/self.fps_trigger)*1000
        self.timer_trigger.setInterval(int(self.timer_trigger_interval))

    def _stop_triggerred_acquisition(self):
        self.timer_trigger.stop()

    # trigger mode and settings
    def set_trigger_mode(self,mode):
        if mode == TriggerMode.SOFTWARE:
            if self.is_live and ( self.trigger_mode == TriggerMode.HARDWARE and self.use_internal_timer_for_hardware_trigger ):
                self._stop_triggerred_acquisition()
            self.camera.set_software_triggered_acquisition()
            if self.is_live:
                self._start_triggerred_acquisition()
        if mode == TriggerMode.HARDWARE:
            if self.trigger_mode == TriggerMode.SOFTWARE and self.is_live:
                self._stop_triggerred_acquisition()
            # self.camera.reset_camera_acquisition_counter()
            self.camera.set_hardware_triggered_acquisition()
            self.microcontroller.set_strobe_delay_us(self.camera.strobe_delay_us)
            if self.is_live and self.use_internal_timer_for_hardware_trigger:
                self._start_triggerred_acquisition()
        if mode == TriggerMode.CONTINUOUS: 
            if ( self.trigger_mode == TriggerMode.SOFTWARE ) or ( self.trigger_mode == TriggerMode.HARDWARE and self.use_internal_timer_for_hardware_trigger ):
                self._stop_triggerred_acquisition()
            self.camera.set_continuous_acquisition()
        self.trigger_mode = mode

    def set_trigger_fps(self,fps):
        if ( self.trigger_mode == TriggerMode.SOFTWARE ) or ( self.trigger_mode == TriggerMode.HARDWARE and self.use_internal_timer_for_hardware_trigger ):
            self._set_trigger_fps(fps)
    
    # set microscope mode
    # @@@ to do: change softwareTriggerGenerator to TriggerGeneratror
    def set_microscope_mode(self,configuration):

        self.currentConfiguration = configuration
        print("setting microscope mode to " + self.currentConfiguration.name)
        
        # temporarily stop live while changing mode
        if self.is_live is True:
            self.timer_trigger.stop()
            if self.control_illumination:
                self.turn_off_illumination()

        # set camera exposure time and analog gain
        self.camera.set_exposure_time(self.currentConfiguration.exposure_time)
        self.camera.set_analog_gain(self.currentConfiguration.analog_gain)

        # set illumination
        if self.control_illumination:
            self.set_illumination(self.currentConfiguration.illumination_source,self.currentConfiguration.illumination_intensity)

        # restart live 
        if self.is_live is True:
            if self.control_illumination:
                self.turn_on_illumination()
            self.timer_trigger.start()

    def get_trigger_mode(self):
        return self.trigger_mode

    # slot
    def on_new_frame(self):
        if self.fps_trigger <= 5:
            if self.control_illumination and self.illumination_on == True:
                self.turn_off_illumination()

    def set_display_resolution_scaling(self, display_resolution_scaling):
        self.display_resolution_scaling = display_resolution_scaling/100

class NavigationController(QObject):

    xPos = Signal(float)
    yPos = Signal(float)
    zPos = Signal(float)
    thetaPos = Signal(float)
    xyPos = Signal(float,float)
    signal_joystick_button_pressed = Signal()

    # x y z axis pid enable flag
    pid_enable_flag = [False, False, False]


    def __init__(self,microcontroller, parent=None):
        # parent should be set to OctopiGUI instance to enable updates
        # to camera settings, e.g. binning, that would affect click-to-move
        QObject.__init__(self)
        self.microcontroller = microcontroller
        self.parent = parent
        self.x_pos_mm = 0
        self.y_pos_mm = 0
        self.z_pos_mm = 0
        self.z_pos = 0
        self.theta_pos_rad = 0
        self.x_microstepping = MICROSTEPPING_DEFAULT_X
        self.y_microstepping = MICROSTEPPING_DEFAULT_Y
        self.z_microstepping = MICROSTEPPING_DEFAULT_Z
        self.click_to_move = False
        self.theta_microstepping = MICROSTEPPING_DEFAULT_THETA
        self.enable_joystick_button_action = True

        # to be moved to gui for transparency
        self.microcontroller.set_callback(self.update_pos)

        # self.timer_read_pos = QTimer()
        # self.timer_read_pos.setInterval(PosUpdate.INTERVAL_MS)
        # self.timer_read_pos.timeout.connect(self.update_pos)
        # self.timer_read_pos.start()

        # scan start position
        self.scan_begin_position_x = 0
        self.scan_begin_position_y = 0

    def set_flag_click_to_move(self, flag):
        self.click_to_move = flag

    def get_flag_click_to_move(self):
        return self.click_to_move


    def scan_preview_move_from_click(self, click_x, click_y, image_width, image_height, Nx=1, Ny=1, dx_mm=0.9, dy_mm=0.9):
        """
        napariTiledDisplay uses the Nx, Ny, dx_mm, dy_mm fields to move to the correct fov first
        imageArrayDisplayWindow assumes only a single fov (default values do not impact calculation but this is less correct)
        """
        # check if click to move enabled
        if not self.click_to_move:
            print("allow click to move")
            return
        # restore to raw coordicate
        click_x = image_width / 2.0 + click_x
        click_y = image_height / 2.0 - click_y
        print("click - (x, y):", (click_x, click_y))
        cx = click_x * Nx // image_width
        cy = click_y * Ny // image_height
        print("fov - (col, row):", (cx, cy))
        pixel_sign_x = 1
        pixel_sign_y = 1 if INVERTED_OBJECTIVE else -1
 
        # move to selected fov
        self.move_x_to(self.scan_begin_position_x+dx_mm*cx*pixel_sign_x)
        self.move_y_to(self.scan_begin_position_y-dy_mm*cy*pixel_sign_y)

        # move to actual click, offset from center fov
        tile_width = (image_width / Nx) * PRVIEW_DOWNSAMPLE_FACTOR
        tile_height = (image_height / Ny) * PRVIEW_DOWNSAMPLE_FACTOR
        offset_x = (click_x * PRVIEW_DOWNSAMPLE_FACTOR) % tile_width
        offset_y = (click_y * PRVIEW_DOWNSAMPLE_FACTOR) % tile_height
        offset_x_centered = int(offset_x - tile_width / 2)
        offset_y_centered = int(tile_height / 2 - offset_y)
        self.move_from_click(offset_x_centered, offset_y_centered, tile_width, tile_height)

    def move_from_click(self, click_x, click_y, image_width, image_height):
        if self.click_to_move:
            try:
                highest_res = (0,0)
                for res in self.parent.camera.res_list:
                    if res[0] > highest_res[0] or res[1] > higest_res[1]:
                        highest_res = res
                resolution = self.parent.camera.resolution

                try:
                    pixel_binning_x = highest_res[0]/resolution[0]
                    pixel_binning_y = highest_res[1]/resolution[1]
                    if pixel_binning_x < 1:
                        pixel_binning_x = 1
                    if pixel_binning_y < 1:
                        pixel_binning_y = 1
                except:
                    pixel_binning_x=1
                    pixel_binning_y=1
            except AttributeError:
                pixel_binning_x = 1
                pixel_binning_y = 1

            try:
                current_objective = self.parent.objectiveStore.current_objective
                objective_info = self.parent.objectiveStore.objectives_dict.get(current_objective, {})
            except (AttributeError, KeyError):
                objective_info = OBJECTIVES[DEFAULT_OBJECTIVE]

            magnification = objective_info["magnification"]
            objective_tube_lens_mm = objective_info["tube_lens_f_mm"]
            tube_lens_mm = TUBE_LENS_MM
            pixel_size_um = CAMERA_PIXEL_SIZE_UM[CAMERA_SENSOR]

            pixel_size_xy = pixel_size_um/(magnification/(objective_tube_lens_mm/tube_lens_mm))

            pixel_size_x = pixel_size_xy*pixel_binning_x
            pixel_size_y = pixel_size_xy*pixel_binning_y

            pixel_sign_x = 1
            pixel_sign_y = 1 if INVERTED_OBJECTIVE else -1

            delta_x = pixel_sign_x*pixel_size_x*click_x/1000.0
            delta_y = pixel_sign_y*pixel_size_y*click_y/1000.0

            self.move_x(delta_x)
            self.move_y(delta_y)

    def move_to_cached_position(self):
        if not os.path.isfile("cache/last_coords.txt"):
            return
        with open("cache/last_coords.txt","r") as f:
            for line in f:
                try:
                    x,y,z = line.strip("\n").strip().split(",")
                    x = float(x)
                    y = float(y)
                    z = float(z)
                    self.move_to(x,y)
                    self.move_z_to(z)
                    break
                except:
                    pass
                break

    def cache_current_position(self):
        with open("cache/last_coords.txt","w") as f:
            f.write(",".join([str(self.x_pos_mm),str(self.y_pos_mm),str(self.z_pos_mm)]))

    def move_x(self,delta):
        self.microcontroller.move_x_usteps(int(delta/(SCREW_PITCH_X_MM/(self.x_microstepping*FULLSTEPS_PER_REV_X))))

    def move_y(self,delta):
        self.microcontroller.move_y_usteps(int(delta/(SCREW_PITCH_Y_MM/(self.y_microstepping*FULLSTEPS_PER_REV_Y))))

    def move_z(self,delta):
        self.microcontroller.move_z_usteps(int(delta/(SCREW_PITCH_Z_MM/(self.z_microstepping*FULLSTEPS_PER_REV_Z))))

    def move_x_to(self,delta):
        self.microcontroller.move_x_to_usteps(STAGE_MOVEMENT_SIGN_X*int(delta/(SCREW_PITCH_X_MM/(self.x_microstepping*FULLSTEPS_PER_REV_X))))

    def move_y_to(self,delta):
        self.microcontroller.move_y_to_usteps(STAGE_MOVEMENT_SIGN_Y*int(delta/(SCREW_PITCH_Y_MM/(self.y_microstepping*FULLSTEPS_PER_REV_Y))))

    def move_z_to(self,delta):
        self.microcontroller.move_z_to_usteps(STAGE_MOVEMENT_SIGN_Z*int(delta/(SCREW_PITCH_Z_MM/(self.z_microstepping*FULLSTEPS_PER_REV_Z))))

    def move_x_usteps(self,usteps):
        self.microcontroller.move_x_usteps(usteps)

    def move_y_usteps(self,usteps):
        self.microcontroller.move_y_usteps(usteps)

    def move_z_usteps(self,usteps):
        self.microcontroller.move_z_usteps(usteps)

    def update_pos(self,microcontroller):
        # get position from the microcontroller
        x_pos, y_pos, z_pos, theta_pos = microcontroller.get_pos()
        self.z_pos = z_pos
        # calculate position in mm or rad
        if USE_ENCODER_X:
            self.x_pos_mm = x_pos*ENCODER_POS_SIGN_X*ENCODER_STEP_SIZE_X_MM
        else:
            self.x_pos_mm = x_pos*STAGE_POS_SIGN_X*(SCREW_PITCH_X_MM/(self.x_microstepping*FULLSTEPS_PER_REV_X))
        if USE_ENCODER_Y:
            self.y_pos_mm = y_pos*ENCODER_POS_SIGN_Y*ENCODER_STEP_SIZE_Y_MM
        else:
            self.y_pos_mm = y_pos*STAGE_POS_SIGN_Y*(SCREW_PITCH_Y_MM/(self.y_microstepping*FULLSTEPS_PER_REV_Y))
        if USE_ENCODER_Z:
            self.z_pos_mm = z_pos*ENCODER_POS_SIGN_Z*ENCODER_STEP_SIZE_Z_MM
        else:
            self.z_pos_mm = z_pos*STAGE_POS_SIGN_Z*(SCREW_PITCH_Z_MM/(self.z_microstepping*FULLSTEPS_PER_REV_Z))
        if USE_ENCODER_THETA:
            self.theta_pos_rad = theta_pos*ENCODER_POS_SIGN_THETA*ENCODER_STEP_SIZE_THETA
        else:
            self.theta_pos_rad = theta_pos*STAGE_POS_SIGN_THETA*(2*math.pi/(self.theta_microstepping*FULLSTEPS_PER_REV_THETA))
        # emit the updated position
        self.xPos.emit(self.x_pos_mm)
        self.yPos.emit(self.y_pos_mm)
        self.zPos.emit(self.z_pos_mm*1000)
        self.thetaPos.emit(self.theta_pos_rad*360/(2*math.pi))
        self.xyPos.emit(self.x_pos_mm,self.y_pos_mm)

        if microcontroller.signal_joystick_button_pressed_event:
            if self.enable_joystick_button_action:
                self.signal_joystick_button_pressed.emit()
            print('joystick button pressed')
            microcontroller.signal_joystick_button_pressed_event = False

    def home_x(self):
        self.microcontroller.home_x()

    def home_y(self):
        self.microcontroller.home_y()

    def home_z(self):
        self.microcontroller.home_z()

    def home_theta(self):
        self.microcontroller.home_theta()

    def home_xy(self):
        self.microcontroller.home_xy()

    def zero_x(self):
        self.microcontroller.zero_x()

    def zero_y(self):
        self.microcontroller.zero_y()

    def zero_z(self):
        self.microcontroller.zero_z()

    def zero_theta(self):
        self.microcontroller.zero_tehta()

    def home(self):
        pass

    def set_x_limit_pos_mm(self,value_mm):
        if STAGE_MOVEMENT_SIGN_X > 0:
            self.microcontroller.set_lim(LIMIT_CODE.X_POSITIVE,int(value_mm/(SCREW_PITCH_X_MM/(self.x_microstepping*FULLSTEPS_PER_REV_X))))
        else:
            self.microcontroller.set_lim(LIMIT_CODE.X_NEGATIVE,STAGE_MOVEMENT_SIGN_X*int(value_mm/(SCREW_PITCH_X_MM/(self.x_microstepping*FULLSTEPS_PER_REV_X))))

    def set_x_limit_neg_mm(self,value_mm):
        if STAGE_MOVEMENT_SIGN_X > 0:
            self.microcontroller.set_lim(LIMIT_CODE.X_NEGATIVE,int(value_mm/(SCREW_PITCH_X_MM/(self.x_microstepping*FULLSTEPS_PER_REV_X))))
        else:
            self.microcontroller.set_lim(LIMIT_CODE.X_POSITIVE,STAGE_MOVEMENT_SIGN_X*int(value_mm/(SCREW_PITCH_X_MM/(self.x_microstepping*FULLSTEPS_PER_REV_X))))

    def set_y_limit_pos_mm(self,value_mm):
        if STAGE_MOVEMENT_SIGN_Y > 0:
            self.microcontroller.set_lim(LIMIT_CODE.Y_POSITIVE,int(value_mm/(SCREW_PITCH_Y_MM/(self.y_microstepping*FULLSTEPS_PER_REV_Y))))
        else:
            self.microcontroller.set_lim(LIMIT_CODE.Y_NEGATIVE,STAGE_MOVEMENT_SIGN_Y*int(value_mm/(SCREW_PITCH_Y_MM/(self.y_microstepping*FULLSTEPS_PER_REV_Y))))

    def set_y_limit_neg_mm(self,value_mm):
        if STAGE_MOVEMENT_SIGN_Y > 0:
            self.microcontroller.set_lim(LIMIT_CODE.Y_NEGATIVE,int(value_mm/(SCREW_PITCH_Y_MM/(self.y_microstepping*FULLSTEPS_PER_REV_Y))))
        else:
            self.microcontroller.set_lim(LIMIT_CODE.Y_POSITIVE,STAGE_MOVEMENT_SIGN_Y*int(value_mm/(SCREW_PITCH_Y_MM/(self.y_microstepping*FULLSTEPS_PER_REV_Y))))

    def set_z_limit_pos_mm(self,value_mm):
        if STAGE_MOVEMENT_SIGN_Z > 0:
            self.microcontroller.set_lim(LIMIT_CODE.Z_POSITIVE,int(value_mm/(SCREW_PITCH_Z_MM/(self.z_microstepping*FULLSTEPS_PER_REV_Z))))
        else:
            self.microcontroller.set_lim(LIMIT_CODE.Z_NEGATIVE,STAGE_MOVEMENT_SIGN_Z*int(value_mm/(SCREW_PITCH_Z_MM/(self.z_microstepping*FULLSTEPS_PER_REV_Z))))

    def set_z_limit_neg_mm(self,value_mm):
        if STAGE_MOVEMENT_SIGN_Z > 0:
            self.microcontroller.set_lim(LIMIT_CODE.Z_NEGATIVE,int(value_mm/(SCREW_PITCH_Z_MM/(self.z_microstepping*FULLSTEPS_PER_REV_Z))))
        else:
            self.microcontroller.set_lim(LIMIT_CODE.Z_POSITIVE,STAGE_MOVEMENT_SIGN_Z*int(value_mm/(SCREW_PITCH_Z_MM/(self.z_microstepping*FULLSTEPS_PER_REV_Z))))
    
    def move_to(self,x_mm,y_mm):
        self.move_x_to(x_mm)
        self.move_y_to(y_mm)

    def configure_encoder(self, axis, transitions_per_revolution,flip_direction):
        self.microcontroller.configure_stage_pid(axis, transitions_per_revolution=int(transitions_per_revolution), flip_direction=flip_direction)

    def set_pid_control_enable(self, axis, enable_flag):
        self.pid_enable_flag[axis] = enable_flag;
        if self.pid_enable_flag[axis] is True:
            self.microcontroller.turn_on_stage_pid(axis)
        else:
            self.microcontroller.turn_off_stage_pid(axis)

    def turnoff_axis_pid_control(self):
        for i in range(len(self.pid_enable_flag)):
            if self.pid_enable_flag[i] is True:
                self.microcontroller.turn_off_stage_pid(i)

    def get_pid_control_flag(self, axis):
        return self.pid_enable_flag[axis]

    def keep_scan_begin_position(self, x, y):
        self.scan_begin_position_x = x
        self.scan_begin_position_y = y

    def set_axis_PID_arguments(self, axis, pid_p, pid_i, pid_d):
        self.microcontroller.set_pid_arguments(axis, pid_p, pid_i, pid_d)

class SlidePositionControlWorker(QObject):
    
    finished = Signal()
    signal_stop_live = Signal()
    signal_resume_live = Signal()

    def __init__(self,slidePositionController,home_x_and_y_separately=False):
        QObject.__init__(self)
        self.slidePositionController = slidePositionController
        self.navigationController = slidePositionController.navigationController
        self.microcontroller = self.navigationController.microcontroller
        self.liveController = self.slidePositionController.liveController
        self.home_x_and_y_separately = home_x_and_y_separately

    def wait_till_operation_is_completed(self,timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S):
        while self.microcontroller.is_busy():
            time.sleep(SLEEP_TIME_S)
            if time.time() - timestamp_start > SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S:
                print('Error - slide position switching timeout, the program will exit')
                self.navigationController.move_x(0)
                self.navigationController.move_y(0)
                sys.exit(1)

    def move_to_slide_loading_position(self):
        was_live = self.liveController.is_live
        if was_live:
            self.signal_stop_live.emit()

        # retract z
        timestamp_start = time.time()
        self.slidePositionController.z_pos = self.navigationController.z_pos # zpos at the beginning of the scan
        self.navigationController.move_z_to(OBJECTIVE_RETRACTED_POS_MM)
        self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
        print('z retracted')
        self.slidePositionController.objective_retracted = True
        
        # move to position
        # for well plate
        if self.slidePositionController.is_for_wellplate:
            # reset limits
            self.navigationController.set_x_limit_pos_mm(100)
            self.navigationController.set_x_limit_neg_mm(-100)
            self.navigationController.set_y_limit_pos_mm(100)
            self.navigationController.set_y_limit_neg_mm(-100)
            # home for the first time
            if self.slidePositionController.homing_done == False:
                print('running homing first')
                timestamp_start = time.time()
                # x needs to be at > + 20 mm when homing y
                self.navigationController.move_x(20)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                # home y
                self.navigationController.home_y()
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                self.navigationController.zero_y()
                # home x
                self.navigationController.home_x()
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                self.navigationController.zero_x()
                self.slidePositionController.homing_done = True
            # homing done previously
            else:
                timestamp_start = time.time()
                self.navigationController.move_x_to(20)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                self.navigationController.move_y_to(SLIDE_POSITION.LOADING_Y_MM)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                self.navigationController.move_x_to(SLIDE_POSITION.LOADING_X_MM)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
            # set limits again
            self.navigationController.set_x_limit_pos_mm(SOFTWARE_POS_LIMIT.X_POSITIVE)
            self.navigationController.set_x_limit_neg_mm(SOFTWARE_POS_LIMIT.X_NEGATIVE)
            self.navigationController.set_y_limit_pos_mm(SOFTWARE_POS_LIMIT.Y_POSITIVE)
            self.navigationController.set_y_limit_neg_mm(SOFTWARE_POS_LIMIT.Y_NEGATIVE)
        else:

            # for glass slide
            if self.slidePositionController.homing_done == False or SLIDE_POTISION_SWITCHING_HOME_EVERYTIME:
                if self.home_x_and_y_separately:
                    timestamp_start = time.time()
                    self.navigationController.home_x()
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                    self.navigationController.zero_x()
                    self.navigationController.move_x(SLIDE_POSITION.LOADING_X_MM)
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                    self.navigationController.home_y()
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                    self.navigationController.zero_y()
                    self.navigationController.move_y(SLIDE_POSITION.LOADING_Y_MM)
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                else:
                    timestamp_start = time.time()
                    self.navigationController.home_xy()
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                    self.navigationController.zero_x()
                    self.navigationController.zero_y()
                    self.navigationController.move_x(SLIDE_POSITION.LOADING_X_MM)
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                    self.navigationController.move_y(SLIDE_POSITION.LOADING_Y_MM)
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                self.slidePositionController.homing_done = True
            else:
                timestamp_start = time.time()
                self.navigationController.move_y(SLIDE_POSITION.LOADING_Y_MM-self.navigationController.y_pos_mm)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                self.navigationController.move_x(SLIDE_POSITION.LOADING_X_MM-self.navigationController.x_pos_mm)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)

        if was_live:
            self.signal_resume_live.emit()

        self.slidePositionController.slide_loading_position_reached = True
        self.finished.emit()

    def move_to_slide_scanning_position(self):
        was_live = self.liveController.is_live
        if was_live:
            self.signal_stop_live.emit()

        # move to position
        # for well plate
        if self.slidePositionController.is_for_wellplate:
            # home for the first time
            if self.slidePositionController.homing_done == False:
                timestamp_start = time.time()

                # x needs to be at > + 20 mm when homing y
                self.navigationController.move_x(20)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                # home y
                self.navigationController.home_y()
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                self.navigationController.zero_y()
                # home x
                self.navigationController.home_x()
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                self.navigationController.zero_x()
                self.slidePositionController.homing_done = True
                # move to scanning position
                self.navigationController.move_x_to(SLIDE_POSITION.SCANNING_X_MM)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)

                self.navigationController.move_y_to(SLIDE_POSITION.SCANNING_Y_MM)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                   
            else:
                timestamp_start = time.time()
                self.navigationController.move_x_to(SLIDE_POSITION.SCANNING_X_MM)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                self.navigationController.move_y_to(SLIDE_POSITION.SCANNING_Y_MM)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
        else:
            if self.slidePositionController.homing_done == False or SLIDE_POTISION_SWITCHING_HOME_EVERYTIME:
                if self.home_x_and_y_separately:
                    timestamp_start = time.time()
                    self.navigationController.home_y()
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                    self.navigationController.zero_y()
                    self.navigationController.move_y(SLIDE_POSITION.SCANNING_Y_MM)
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                    self.navigationController.home_x()
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                    self.navigationController.zero_x()
                    self.navigationController.move_x(SLIDE_POSITION.SCANNING_X_MM)
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                else:
                    timestamp_start = time.time()
                    self.navigationController.home_xy()
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                    self.navigationController.zero_x()
                    self.navigationController.zero_y()
                    self.navigationController.move_y(SLIDE_POSITION.SCANNING_Y_MM)
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                    self.navigationController.move_x(SLIDE_POSITION.SCANNING_X_MM)
                    self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                self.slidePositionController.homing_done = True
            else:
                timestamp_start = time.time()
                self.navigationController.move_y(SLIDE_POSITION.SCANNING_Y_MM-self.navigationController.y_pos_mm)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                self.navigationController.move_x(SLIDE_POSITION.SCANNING_X_MM-self.navigationController.x_pos_mm)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)

        # restore z
        if self.slidePositionController.objective_retracted:
            if self.navigationController.get_pid_control_flag(2) is False:
                _usteps_to_clear_backlash = max(160,20*self.navigationController.z_microstepping)
                self.navigationController.microcontroller.move_z_to_usteps(self.slidePositionController.z_pos - STAGE_MOVEMENT_SIGN_Z*_usteps_to_clear_backlash)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
                self.navigationController.move_z_usteps(_usteps_to_clear_backlash)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
            else:
                self.navigationController.microcontroller.move_z_to_usteps(self.slidePositionController.z_pos)
                self.wait_till_operation_is_completed(timestamp_start, SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S)
            self.slidePositionController.objective_retracted = False
            print('z position restored')
        
        if was_live:
            self.signal_resume_live.emit()

        self.slidePositionController.slide_scanning_position_reached = True
        self.finished.emit()

class SlidePositionController(QObject):

    signal_slide_loading_position_reached = Signal()
    signal_slide_scanning_position_reached = Signal()
    signal_clear_slide = Signal()

    def __init__(self,navigationController,liveController,is_for_wellplate=False):
        QObject.__init__(self)
        self.navigationController = navigationController
        self.liveController = liveController
        self.slide_loading_position_reached = False
        self.slide_scanning_position_reached = False
        self.homing_done = False
        self.is_for_wellplate = is_for_wellplate
        self.retract_objective_before_moving = RETRACT_OBJECTIVE_BEFORE_MOVING_TO_LOADING_POSITION
        self.objective_retracted = False
        self.thread = None

    def move_to_slide_loading_position(self):
        # create a QThread object
        self.thread = QThread()
        # create a worker object
        self.slidePositionControlWorker = SlidePositionControlWorker(self)
        # move the worker to the thread
        self.slidePositionControlWorker.moveToThread(self.thread)
        # connect signals and slots
        self.thread.started.connect(self.slidePositionControlWorker.move_to_slide_loading_position)
        self.slidePositionControlWorker.signal_stop_live.connect(self.slot_stop_live,type=Qt.BlockingQueuedConnection)
        self.slidePositionControlWorker.signal_resume_live.connect(self.slot_resume_live,type=Qt.BlockingQueuedConnection)
        self.slidePositionControlWorker.finished.connect(self.signal_slide_loading_position_reached.emit)
        self.slidePositionControlWorker.finished.connect(self.slidePositionControlWorker.deleteLater)
        self.slidePositionControlWorker.finished.connect(self.thread.quit)
        self.thread.finished.connect(self.thread.quit)
        # self.slidePositionControlWorker.finished.connect(self.threadFinished,type=Qt.BlockingQueuedConnection)
        # start the thread
        self.thread.start()

    def move_to_slide_scanning_position(self):
    	# create a QThread object
        self.thread = QThread()
        # create a worker object
        self.slidePositionControlWorker = SlidePositionControlWorker(self)
        # move the worker to the thread
        self.slidePositionControlWorker.moveToThread(self.thread)
        # connect signals and slots
        self.thread.started.connect(self.slidePositionControlWorker.move_to_slide_scanning_position)
        self.slidePositionControlWorker.signal_stop_live.connect(self.slot_stop_live,type=Qt.BlockingQueuedConnection)
        self.slidePositionControlWorker.signal_resume_live.connect(self.slot_resume_live,type=Qt.BlockingQueuedConnection)
        self.slidePositionControlWorker.finished.connect(self.signal_slide_scanning_position_reached.emit)
        self.slidePositionControlWorker.finished.connect(self.slidePositionControlWorker.deleteLater)
        self.slidePositionControlWorker.finished.connect(self.thread.quit)
        self.thread.finished.connect(self.thread.quit)
        # self.slidePositionControlWorker.finished.connect(self.threadFinished,type=Qt.BlockingQueuedConnection)
        # start the thread
        print('before thread.start()')
        self.thread.start()
        self.signal_clear_slide.emit()

    def slot_stop_live(self):
        self.liveController.stop_live()

    def slot_resume_live(self):
        self.liveController.start_live()

    # def threadFinished(self):
    # 	print('========= threadFinished ========= ')

class AutofocusWorker(QObject):

    finished = Signal()
    image_to_display = Signal(np.ndarray)
    # signal_current_configuration = Signal(Configuration)

    def __init__(self,autofocusController):
        QObject.__init__(self)
        self.autofocusController = autofocusController

        self.camera = self.autofocusController.camera
        self.microcontroller = self.autofocusController.navigationController.microcontroller
        self.navigationController = self.autofocusController.navigationController
        self.liveController = self.autofocusController.liveController

        self.N = self.autofocusController.N
        self.deltaZ = self.autofocusController.deltaZ
        self.deltaZ_usteps = self.autofocusController.deltaZ_usteps
        
        self.crop_width = self.autofocusController.crop_width
        self.crop_height = self.autofocusController.crop_height

    def run(self):
        self.run_autofocus()
        self.finished.emit()

    def wait_till_operation_is_completed(self):
        while self.microcontroller.is_busy():
            time.sleep(SLEEP_TIME_S)

    def run_autofocus(self):
        # @@@ to add: increase gain, decrease exposure time
        # @@@ can move the execution into a thread - done 08/21/2021
        focus_measure_vs_z = [0]*self.N
        focus_measure_max = 0

        z_af_offset_usteps = self.deltaZ_usteps*round(self.N/2)
        # self.navigationController.move_z_usteps(-z_af_offset_usteps) # combine with the back and forth maneuver below
        # self.wait_till_operation_is_completed()

        # maneuver for achiving uniform step size and repeatability when using open-loop control
        # can be moved to the firmware
        if self.navigationController.get_pid_control_flag(2) is False:
            _usteps_to_clear_backlash = max(160,20*self.navigationController.z_microstepping)
            self.navigationController.move_z_usteps(-_usteps_to_clear_backlash-z_af_offset_usteps)
            self.wait_till_operation_is_completed()
            self.navigationController.move_z_usteps(_usteps_to_clear_backlash)
            self.wait_till_operation_is_completed()
        else:
            self.navigationController.move_z_usteps(-z_af_offset_usteps)
            self.wait_till_operation_is_completed()

        steps_moved = 0
        for i in range(self.N):
            self.navigationController.move_z_usteps(self.deltaZ_usteps)
            self.wait_till_operation_is_completed()
            steps_moved = steps_moved + 1
            # trigger acquisition (including turning on the illumination) and read frame
            if self.liveController.trigger_mode == TriggerMode.SOFTWARE:
                self.liveController.turn_on_illumination()
                self.wait_till_operation_is_completed()
                self.camera.send_trigger()
                image = self.camera.read_frame()
            elif self.liveController.trigger_mode == TriggerMode.HARDWARE:
                if 'Fluorescence' in config.name and ENABLE_NL5 and NL5_USE_DOUT:
                    self.camera.image_is_ready = False # to remove
                    self.microscope.nl5.start_acquisition()
                    image = self.camera.read_frame(reset_image_ready_flag=False)
                else:
                    self.microcontroller.send_hardware_trigger(control_illumination=True,illumination_on_time_us=self.camera.exposure_time*1000)
                    image = self.camera.read_frame()
            if image is None:
                continue
            # tunr of the illumination if using software trigger
            if self.liveController.trigger_mode == TriggerMode.SOFTWARE:
                self.liveController.turn_off_illumination()
            image = utils.crop_image(image,self.crop_width,self.crop_height)
            image = utils.rotate_and_flip_image(image,rotate_image_angle=self.camera.rotate_image_angle,flip_image=self.camera.flip_image)
            self.image_to_display.emit(image)
            QApplication.processEvents()
            timestamp_0 = time.time()
            focus_measure = utils.calculate_focus_measure(image,FOCUS_MEASURE_OPERATOR)
            timestamp_1 = time.time()
            print('             calculating focus measure took ' + str(timestamp_1-timestamp_0) + ' second')
            focus_measure_vs_z[i] = focus_measure
            print(i,focus_measure)
            focus_measure_max = max(focus_measure, focus_measure_max)
            if focus_measure < focus_measure_max*AF.STOP_THRESHOLD:
                break

        QApplication.processEvents()

        # move to the starting location
        # self.navigationController.move_z_usteps(-steps_moved*self.deltaZ_usteps) # combine with the back and forth maneuver below
        # self.wait_till_operation_is_completed()

        # maneuver for achiving uniform step size and repeatability when using open-loop control
        if self.navigationController.get_pid_control_flag(2) is False:
            _usteps_to_clear_backlash = max(160,20*self.navigationController.z_microstepping)
            self.navigationController.move_z_usteps(-_usteps_to_clear_backlash-steps_moved*self.deltaZ_usteps)
            # determine the in-focus position
            idx_in_focus = focus_measure_vs_z.index(max(focus_measure_vs_z))
            self.wait_till_operation_is_completed()
            self.navigationController.move_z_usteps(_usteps_to_clear_backlash+(idx_in_focus+1)*self.deltaZ_usteps)
            self.wait_till_operation_is_completed()
        else:
            # determine the in-focus position
            idx_in_focus = focus_measure_vs_z.index(max(focus_measure_vs_z))
            self.navigationController.move_z_usteps((idx_in_focus+1)*self.deltaZ_usteps-steps_moved*self.deltaZ_usteps)
            self.wait_till_operation_is_completed()

        QApplication.processEvents()

        # move to the calculated in-focus position
        # self.navigationController.move_z_usteps(idx_in_focus*self.deltaZ_usteps)
        # self.wait_till_operation_is_completed() # combine with the movement above
        if idx_in_focus == 0:
            print('moved to the bottom end of the AF range')
        if idx_in_focus == self.N-1:
            print('moved to the top end of the AF range')

class AutoFocusController(QObject):

    z_pos = Signal(float)
    autofocusFinished = Signal()
    image_to_display = Signal(np.ndarray)

    def __init__(self,camera,navigationController,liveController):
        QObject.__init__(self)
        self.camera = camera
        self.navigationController = navigationController
        self.liveController = liveController
        self.N = None
        self.deltaZ = None
        self.deltaZ_usteps = None
        self.crop_width = AF.CROP_WIDTH
        self.crop_height = AF.CROP_HEIGHT
        self.autofocus_in_progress = False
        self.focus_map_coords = []
        self.use_focus_map = False

    def set_N(self,N):
        self.N = N

    def set_deltaZ(self,deltaZ_um):
        mm_per_ustep_Z = SCREW_PITCH_Z_MM/(self.navigationController.z_microstepping*FULLSTEPS_PER_REV_Z)
        self.deltaZ = deltaZ_um/1000
        self.deltaZ_usteps = round((deltaZ_um/1000)/mm_per_ustep_Z)

    def set_crop(self,crop_width,crop_height):
        self.crop_width = crop_width
        self.crop_height = crop_height

    def autofocus(self, focus_map_override=False):
        if self.use_focus_map and (not focus_map_override):
            self.autofocus_in_progress = True
            self.navigationController.microcontroller.wait_till_operation_is_completed()
            x = self.navigationController.x_pos_mm
            y = self.navigationController.y_pos_mm
            
            # z here is in mm because that's how the navigation controller stores it
            target_z = utils.interpolate_plane(*self.focus_map_coords[:3], (x,y))
            print(f"Interpolated target z as {target_z} mm from focus map, moving there.")
            self.navigationController.move_z_to(target_z)
            self.navigationController.microcontroller.wait_till_operation_is_completed()
            self.autofocus_in_progress = False
            self.autofocusFinished.emit()
            return
        # stop live
        if self.liveController.is_live:
            self.was_live_before_autofocus = True
            self.liveController.stop_live()
        else:
            self.was_live_before_autofocus = False

        # temporarily disable call back -> image does not go through streamHandler
        if self.camera.callback_is_enabled:
            self.callback_was_enabled_before_autofocus = True
            self.camera.disable_callback()
        else:
            self.callback_was_enabled_before_autofocus = False

        self.autofocus_in_progress = True

        # create a QThread object
        try:
            if self.thread.isRunning():
                print('*** autofocus thread is still running ***')
                self.thread.terminate()
                self.thread.wait()
                print('*** autofocus threaded manually stopped ***')
        except:
            pass
        self.thread = QThread()
        # create a worker object
        self.autofocusWorker = AutofocusWorker(self)
        # move the worker to the thread
        self.autofocusWorker.moveToThread(self.thread)
        # connect signals and slots
        self.thread.started.connect(self.autofocusWorker.run)
        self.autofocusWorker.finished.connect(self._on_autofocus_completed)
        self.autofocusWorker.finished.connect(self.autofocusWorker.deleteLater)
        self.autofocusWorker.finished.connect(self.thread.quit)
        self.autofocusWorker.image_to_display.connect(self.slot_image_to_display)
        # self.thread.finished.connect(self.thread.deleteLater)
        self.thread.finished.connect(self.thread.quit)
        # start the thread
        self.thread.start()
        
    def _on_autofocus_completed(self):
        # re-enable callback
        if self.callback_was_enabled_before_autofocus:
            self.camera.enable_callback()
        
        # re-enable live if it's previously on
        if self.was_live_before_autofocus:
            self.liveController.start_live()

        # emit the autofocus finished signal to enable the UI
        self.autofocusFinished.emit()
        QApplication.processEvents()
        print('autofocus finished')

        # update the state
        self.autofocus_in_progress = False

    def slot_image_to_display(self,image):
        self.image_to_display.emit(image)

    def wait_till_autofocus_has_completed(self):
        while self.autofocus_in_progress == True:
            QApplication.processEvents()
            time.sleep(0.005)
        print('autofocus wait has completed, exit wait')

    def set_focus_map_use(self, enable):
        if not enable:
            print("Disabling focus map.")
            self.use_focus_map = False
            return
        if len(self.focus_map_coords) < 3:
            print("Not enough coordinates (less than 3) for focus map generation, disabling focus map.")
            self.use_focus_map = False
            return
        x1,y1,_ = self.focus_map_coords[0]
        x2,y2,_ = self.focus_map_coords[1]
        x3,y3,_ = self.focus_map_coords[2]

        detT = (y2 - y3) * (x1 - x3) + (x3 - x2) * (y1 - y3)
        if detT == 0:
            print("Your 3 x-y coordinates are linear, cannot use to interpolate, disabling focus map.")
            self.use_focus_map = False
            return

        if enable:
            print("Enabling focus map.")
            self.use_focus_map = True

    def clear_focus_map(self):
        self.focus_map_coords = []
        self.set_focus_map_use(False)

    def gen_focus_map(self, coord1,coord2,coord3):
        """
        Navigate to 3 coordinates and get your focus-map coordinates
        by autofocusing there and saving the z-values.
        :param coord1-3: Tuples of (x,y) values, coordinates in mm.
        :raise: ValueError if coordinates are all on the same line
        """
        x1,y1 = coord1
        x2,y2 = coord2
        x3,y3 = coord3
        detT = (y2 - y3) * (x1 - x3) + (x3 - x2) * (y1 - y3)
        if detT == 0:
            raise ValueError("Your 3 x-y coordinates are linear")
        
        self.focus_map_coords = []

        for coord in [coord1,coord2,coord3]:
            print(f"Navigating to coordinates ({coord[0]},{coord[1]}) to sample for focus map")
            self.navigationController.move_to(coord[0],coord[1])
            self.navigationController.microcontroller.wait_till_operation_is_completed()
            print("Autofocusing")
            self.autofocus(True)
            self.wait_till_autofocus_has_completed()
            #self.navigationController.microcontroller.wait_till_operation_is_completed()
            x = self.navigationController.x_pos_mm
            y = self.navigationController.y_pos_mm
            z = self.navigationController.z_pos_mm
            print(f"Adding coordinates ({x},{y},{z}) to focus map")
            self.focus_map_coords.append((x,y,z))

        print("Generated focus map.")

    def add_current_coords_to_focus_map(self):
        if len(self.focus_map_coords) >= 3:
            print("Replacing last coordinate on focus map.")
        self.navigationController.microcontroller.wait_till_operation_is_completed()
        print("Autofocusing")
        self.autofocus(True)
        self.wait_till_autofocus_has_completed()
        #self.navigationController.microcontroller.wait_till_operation_is_completed()
        x = self.navigationController.x_pos_mm
        y = self.navigationController.y_pos_mm
        z = self.navigationController.z_pos_mm
        if len(self.focus_map_coords) >= 2:
            x1,y1,_ = self.focus_map_coords[0]
            x2,y2,_ = self.focus_map_coords[1]
            x3 = x
            y3 = y

            detT = (y2-y3) * (x1-x3) + (x3-x2) * (y1-y3)
            if detT == 0:
                raise ValueError("Your 3 x-y coordinates are linear. Navigate to a different coordinate or clear and try again.")
        if len(self.focus_map_coords) >= 3:
            self.focus_map_coords.pop()
        self.focus_map_coords.append((x,y,z))
        print(f"Added triple ({x},{y},{z}) to focus map")


class MultiPointWorker(QObject):

    finished = Signal()
    image_to_display = Signal(np.ndarray)
    spectrum_to_display = Signal(np.ndarray)
    image_to_display_multi = Signal(np.ndarray,int)
    image_to_display_tiled_preview = Signal(np.ndarray)
    signal_current_configuration = Signal(Configuration)
    signal_register_current_fov = Signal(float,float)
    signal_detection_stats = Signal(object)
    signal_z_piezo_um = Signal(float)
    napari_layers_update = Signal(np.ndarray, int, int, int, str)
    napari_layers_init = Signal(int, int, object, bool)

    signal_update_stats = Signal(object)

    def __init__(self,multiPointController):
        QObject.__init__(self)
        self.multiPointController = multiPointController

        self.signal_update_stats.connect(self.update_stats)
        self.start_time = 0
        self.processingHandler = multiPointController.processingHandler
        self.camera = self.multiPointController.camera
        self.microcontroller = self.multiPointController.microcontroller
        self.usb_spectrometer = self.multiPointController.usb_spectrometer
        self.navigationController = self.multiPointController.navigationController
        self.liveController = self.multiPointController.liveController
        self.autofocusController = self.multiPointController.autofocusController
        self.configurationManager = self.multiPointController.configurationManager
        self.NX = self.multiPointController.NX
        self.NY = self.multiPointController.NY
        self.NZ = self.multiPointController.NZ
        self.Nt = self.multiPointController.Nt
        self.deltaX = self.multiPointController.deltaX
        self.deltaX_usteps = self.multiPointController.deltaX_usteps
        self.deltaY = self.multiPointController.deltaY
        self.deltaY_usteps = self.multiPointController.deltaY_usteps
        self.deltaZ = self.multiPointController.deltaZ
        self.deltaZ_usteps = self.multiPointController.deltaZ_usteps
        self.dt = self.multiPointController.deltat
        self.do_autofocus = self.multiPointController.do_autofocus
        self.do_reflection_af= self.multiPointController.do_reflection_af
        self.crop_width = self.multiPointController.crop_width
        self.crop_height = self.multiPointController.crop_height
        self.display_resolution_scaling = self.multiPointController.display_resolution_scaling
        self.counter = self.multiPointController.counter
        self.experiment_ID = self.multiPointController.experiment_ID
        self.base_path = self.multiPointController.base_path
        self.selected_configurations = self.multiPointController.selected_configurations
        self.use_piezo = self.multiPointController.use_piezo
        self.detection_stats = {}
        self.async_detection_stats = {}

        self.timestamp_acquisition_started = self.multiPointController.timestamp_acquisition_started
        self.time_point = 0

        self.microscope = self.multiPointController.parent

        self.t_dpc = []
        self.t_inf = []
        self.t_over=[]

        self.tiled_preview = None
        

    def update_stats(self, new_stats):
        for k in new_stats.keys():
            try:
                self.detection_stats[k]+=new_stats[k]
            except:
                self.detection_stats[k] = 0
                self.detection_stats[k]+=new_stats[k]
        if "Total RBC" in self.detection_stats and "Total Positives" in self.detection_stats:
            self.detection_stats["Positives per 5M RBC"] = 5e6*(self.detection_stats["Total Positives"]/self.detection_stats["Total RBC"])
        self.signal_detection_stats.emit(self.detection_stats)

    def run(self):

        self.start_time = time.perf_counter_ns()
        if self.camera.is_streaming == False:
             self.camera.start_streaming()

        if self.multiPointController.location_list is None:
            # use scanCoordinates for well plates or regular multipoint scan
            if self.multiPointController.scanCoordinates!=None:
                # use scan coordinates for the scan
                self.multiPointController.scanCoordinates.get_selected_wells()
                self.scan_coordinates_mm = self.multiPointController.scanCoordinates.coordinates_mm
                self.scan_coordinates_name = self.multiPointController.scanCoordinates.name
                self.use_scan_coordinates = True
            else:
                # use the current position for the scan
                self.scan_coordinates_mm = [(self.navigationController.x_pos_mm,self.navigationController.y_pos_mm)]
                self.scan_coordinates_name = ['']
                self.use_scan_coordinates = False
        else:
            # use location_list specified by the multipoint controlller
            self.scan_coordinates_mm = self.multiPointController.location_list
            self.scan_coordinates_name = None
            self.use_scan_coordinates = True

        while self.time_point < self.Nt:
            # check if abort acquisition has been requested
            if self.multiPointController.abort_acqusition_requested:
                break
            # run single time point
            self.run_single_time_point()
            self.time_point = self.time_point + 1
            # continous acquisition
            if self.dt == 0:
                pass
            # timed acquisition
            else:
                # check if the aquisition has taken longer than dt or integer multiples of dt, if so skip the next time point(s)
                while time.time() > self.timestamp_acquisition_started + self.time_point*self.dt:
                    print('skip time point ' + str(self.time_point+1))
                    self.time_point = self.time_point+1
                # check if it has reached Nt
                if self.time_point == self.Nt:
                    break # no waiting after taking the last time point
                # wait until it's time to do the next acquisition
                while time.time() < self.timestamp_acquisition_started + self.time_point*self.dt:
                    if self.multiPointController.abort_acqusition_requested:
                        break
                    time.sleep(0.05)
        self.processingHandler.processing_queue.join()
        self.processingHandler.upload_queue.join()
        elapsed_time = time.perf_counter_ns()-self.start_time
        print("Time taken for acquisition/processing: "+str(elapsed_time/10**9))
        self.finished.emit()

    def wait_till_operation_is_completed(self):
        while self.microcontroller.is_busy():
            time.sleep(SLEEP_TIME_S)

    def run_single_time_point(self):
        start = time.time()
        print(time.time())
        # disable joystick button action
        self.navigationController.enable_joystick_button_action = False

        print('multipoint acquisition - time point ' + str(self.time_point+1))
        
        # for each time point, create a new folder
        current_path = os.path.join(self.base_path,self.experiment_ID,str(self.time_point))
        os.mkdir(current_path)

        slide_path = os.path.join(self.base_path, self.experiment_ID)


        # create a dataframe to save coordinates
        if IS_HCS:
            if self.use_piezo:
                self.coordinates_pd = pd.DataFrame(columns = ['well', 'i', 'j', 'k', 'x (mm)', 'y (mm)', 'z (um)', 'z_piezo (um)', 'time'])
            else:
                self.coordinates_pd = pd.DataFrame(columns = ['well', 'i', 'j', 'k', 'x (mm)', 'y (mm)', 'z (um)', 'time'])
        else:
            if self.use_piezo:
                self.coordinates_pd = pd.DataFrame(columns = ['i', 'j', 'k', 'x (mm)', 'y (mm)', 'z (um)', 'z_piezo (um)', 'time'])
            else:
                self.coordinates_pd = pd.DataFrame(columns = ['i', 'j', 'k', 'x (mm)', 'y (mm)', 'z (um)', 'time'])


        n_regions = len(self.scan_coordinates_mm)

        for coordinate_id in range(n_regions):

            coordiante_mm = self.scan_coordinates_mm[coordinate_id]
            print(coordiante_mm)

            if self.scan_coordinates_name is None:
                # flexible scan, use a sequencial ID
                coordiante_name = str(coordinate_id)
            else:
                coordiante_name = self.scan_coordinates_name[coordinate_id]
            
            if self.use_scan_coordinates:
                # move to the specified coordinate
                self.navigationController.move_x_to(coordiante_mm[0]-self.deltaX*(self.NX-1)/2)
                self.navigationController.move_y_to(coordiante_mm[1]-self.deltaY*(self.NY-1)/2)
                # check if z is included in the coordinate
                if len(coordiante_mm) == 3:
                    if coordiante_mm[2] >= self.navigationController.z_pos_mm:
                        self.navigationController.move_z_to(coordiante_mm[2])
                        self.wait_till_operation_is_completed()
                    else:
                        self.navigationController.move_z_to(coordiante_mm[2])
                        self.wait_till_operation_is_completed()
                        # remove backlash
                        if self.navigationController.get_pid_control_flag(2) is False:
                            _usteps_to_clear_backlash = max(160,20*self.navigationController.z_microstepping)
                            self.navigationController.move_z_usteps(-_usteps_to_clear_backlash) # to-do: combine this with the above
                            self.wait_till_operation_is_completed()
                            self.navigationController.move_z_usteps(_usteps_to_clear_backlash)
                            self.wait_till_operation_is_completed()
                else:
                    self.wait_till_operation_is_completed()
                time.sleep(SCAN_STABILIZATION_TIME_MS_Y/1000)
                if len(coordiante_mm) == 3:
                    time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)
                # add '_' to the coordinate name
                coordiante_name = coordiante_name + '_'


            self.x_scan_direction = 1
            self.dx_usteps = 0 # accumulated x displacement
            self.dy_usteps = 0 # accumulated y displacement
            self.dz_usteps = 0 # accumulated z displacement
            z_pos = self.navigationController.z_pos # zpos at the beginning of the scan

            # z stacking config
            if Z_STACKING_CONFIG == 'FROM TOP':
                self.deltaZ_usteps = -abs(self.deltaZ_usteps)

            if USE_NAPARI_FOR_MULTIPOINT or USE_NAPARI_FOR_TILED_DISPLAY:
                init_napari_layers = False

            # reset piezo to home position
            if self.use_piezo:
                self.z_piezo_um = OBJECTIVE_PIEZO_HOME_UM
                dac = int(65535 * (self.z_piezo_um / OBJECTIVE_PIEZO_RANGE_UM))
                self.navigationController.microcontroller.analog_write_onboard_DAC(7, dac)
                if self.liveController.trigger_mode == TriggerMode.SOFTWARE: # for hardware trigger, delay is in waiting for the last row to start exposure
                    time.sleep(MULTIPOINT_PIEZO_DELAY_MS/1000)
                if MULTIPOINT_PIEZO_UPDATE_DISPLAY:
                    self.signal_z_piezo_um.emit(self.z_piezo_um)

            # along y
            for i in range(self.NY):

                self.FOV_counter = 0 # for AF, so that AF at the beginning of each new row

                # along x
                for j in range(self.NX):

                    if RUN_CUSTOM_MULTIPOINT and "multipoint_custom_script_entry" in globals():

                        print('run custom multipoint')
                        multipoint_custom_script_entry(self,self.time_point,current_path,coordinate_id,coordiante_name,i,j)

                    else:

                        # autofocus
                        if self.do_reflection_af == False:
                            # contrast-based AF; perform AF only if when not taking z stack or doing z stack from center
                            if ( (self.NZ == 1) or Z_STACKING_CONFIG == 'FROM CENTER' ) and (self.do_autofocus) and (self.FOV_counter%Acquisition.NUMBER_OF_FOVS_PER_AF==0):
                            # temporary: replace the above line with the line below to AF every FOV
                            # if (self.NZ == 1) and (self.do_autofocus):
                                configuration_name_AF = MULTIPOINT_AUTOFOCUS_CHANNEL
                                config_AF = next((config for config in self.configurationManager.configurations if config.name == configuration_name_AF))
                                self.signal_current_configuration.emit(config_AF)
                                if (self.FOV_counter%Acquisition.NUMBER_OF_FOVS_PER_AF==0) or self.autofocusController.use_focus_map:
                                    self.autofocusController.autofocus()
                                    self.autofocusController.wait_till_autofocus_has_completed()
                                # upate z location of scan_coordinates_mm after AF
                                if len(coordiante_mm) == 3:
                                    self.scan_coordinates_mm[coordinate_id,2] = self.navigationController.z_pos_mm
                                    # update the coordinate in the widget
                                    try:
                                        self.microscope.multiPointWidget2._update_z(coordinate_id,self.navigationController.z_pos_mm)
                                    except:
                                        pass
                        else:
                            # initialize laser autofocus if it has not been done
                            if self.microscope.laserAutofocusController.is_initialized==False:
                                # initialize the reflection AF
                                self.microscope.laserAutofocusController.initialize_auto()
                                # do contrast AF for the first FOV (if contrast AF box is checked)
                                if self.do_autofocus and ( (self.NZ == 1) or Z_STACKING_CONFIG == 'FROM CENTER' ) :
                                    configuration_name_AF = MULTIPOINT_AUTOFOCUS_CHANNEL
                                    config_AF = next((config for config in self.configurationManager.configurations if config.name == configuration_name_AF))
                                    self.signal_current_configuration.emit(config_AF)
                                    self.autofocusController.autofocus()
                                    self.autofocusController.wait_till_autofocus_has_completed()
                                # set the current plane as reference
                                self.microscope.laserAutofocusController.set_reference()
                            else:
                                try:
                                    if self.navigationController.get_pid_control_flag(2) is False:
                                        self.microscope.laserAutofocusController.move_to_target(0)
                                        self.microscope.laserAutofocusController.move_to_target(0) # for stepper in open loop mode, repeat the operation to counter backlash
                                    else:
                                        self.microscope.laserAutofocusController.move_to_target(0)
                                except:
                                    file_ID = coordiante_name + str(i) + '_' + str(j if self.x_scan_direction==1 else self.NX-1-j)
                                    saving_path = os.path.join(current_path, file_ID + '_focus_camera.bmp')
                                    iio.imwrite(saving_path,self.microscope.laserAutofocusController.image) 
                                    print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! laser AF failed !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')

                        if (self.NZ > 1):
                            # move to bottom of the z stack
                            if Z_STACKING_CONFIG == 'FROM CENTER':
                                self.navigationController.move_z_usteps(-self.deltaZ_usteps*round((self.NZ-1)/2))
                                self.wait_till_operation_is_completed()
                                time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)
                            # maneuver for achiving uniform step size and repeatability when using open-loop control
                            self.navigationController.move_z_usteps(-160)
                            self.wait_till_operation_is_completed()
                            self.navigationController.move_z_usteps(160)
                            self.wait_till_operation_is_completed()
                            time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)

                        # z-stack
                        for k in range(self.NZ):
                            
                            # Ensure that i/y-indexing is always top to bottom
                            sgn_i = -1 if self.deltaY >= 0 else 1
                            if INVERTED_OBJECTIVE: # to do
                                sgn_i = -sgn_i
                            sgn_j = self.x_scan_direction if self.deltaX >= 0 else -self.x_scan_direction

                            real_i = self.NY-1-i if sgn_i == -1 else i
                            real_j = j if sgn_j == 1 else self.NX-1-j

                            file_ID = coordiante_name + str(self.NY-1-i if sgn_i == -1 else i) + '_' + str(j if sgn_j == 1 else self.NX-1-j) + '_' + str(k)
                            # metadata = dict(x = self.navigationController.x_pos_mm, y = self.navigationController.y_pos_mm, z = self.navigationController.z_pos_mm)
                            # metadata = json.dumps(metadata)

                            # laser af characterization mode
                            if LASER_AF_CHARACTERIZATION_MODE:
                                image = self.microscope.laserAutofocusController.get_image()
                                saving_path = os.path.join(current_path, file_ID + '_laser af camera' + '.bmp')
                                iio.imwrite(saving_path,image)

                            current_round_images = {}
                            # iterate through selected modes
                            for config in self.selected_configurations:
                                if config.z_offset is not None: # perform z offset for config, assume
                                                                # z_offset is in um
                                    if config.z_offset != 0.0:
                                        print("Moving to Z offset "+str(config.z_offset))
                                        self.navigationController.move_z(config.z_offset/1000)
                                        self.wait_till_operation_is_completed()
                                        time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)

                                if 'USB Spectrometer' not in config.name and 'RGB' not in config.name:
                                    # update the current configuration
                                    self.signal_current_configuration.emit(config)
                                    self.wait_till_operation_is_completed()
                                    # trigger acquisition (including turning on the illumination) and read frame
                                    if self.liveController.trigger_mode == TriggerMode.SOFTWARE:
                                        self.liveController.turn_on_illumination()
                                        self.wait_till_operation_is_completed()
                                        self.camera.send_trigger()
                                        image = self.camera.read_frame()
                                    elif self.liveController.trigger_mode == TriggerMode.HARDWARE:
                                        if 'Fluorescence' in config.name and ENABLE_NL5 and NL5_USE_DOUT:
                                            self.camera.image_is_ready = False # to remove
                                            self.microscope.nl5.start_acquisition()
                                            image = self.camera.read_frame(reset_image_ready_flag=False)
                                        else:
                                            self.microcontroller.send_hardware_trigger(control_illumination=True,illumination_on_time_us=self.camera.exposure_time*1000)
                                            image = self.camera.read_frame()
                                    
                                    if image is None:
                                        print('self.camera.read_frame() returned None')
                                        continue
                                    # tunr of the illumination if using software trigger
                                    if self.liveController.trigger_mode == TriggerMode.SOFTWARE:
                                        self.liveController.turn_off_illumination()

                                    # process the image -  @@@ to move to camera
                                    image = utils.crop_image(image,self.crop_width,self.crop_height)
                                    image = utils.rotate_and_flip_image(image,rotate_image_angle=self.camera.rotate_image_angle,flip_image=self.camera.flip_image)
                                    # self.image_to_display.emit(cv2.resize(image,(round(self.crop_width*self.display_resolution_scaling), round(self.crop_height*self.display_resolution_scaling)),cv2.INTER_LINEAR))

                                    image_to_display = utils.crop_image(image,round(self.crop_width*self.display_resolution_scaling), round(self.crop_height*self.display_resolution_scaling))
                                    self.image_to_display.emit(image_to_display)
                                    self.image_to_display_multi.emit(image_to_display,config.illumination_source)

                                    if image.dtype == np.uint16:
                                        saving_path = os.path.join(current_path, file_ID + '_' + str(config.name).replace(' ','_') + '.tiff')
                                        if self.camera.is_color:
                                            if 'BF LED matrix' in config.name:
                                                if MULTIPOINT_BF_SAVING_OPTION == 'RGB2GRAY':
                                                    image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)
                                                elif MULTIPOINT_BF_SAVING_OPTION == 'Green Channel Only':
                                                    image = image[:,:,1]
                                        iio.imwrite(saving_path,image)
                                    else:
                                        saving_path = os.path.join(current_path, file_ID + '_' + str(config.name).replace(' ','_') + '.' + Acquisition.IMAGE_FORMAT)
                                        if self.camera.is_color:
                                            if 'BF LED matrix' in config.name:
                                                if MULTIPOINT_BF_SAVING_OPTION == 'RGB2GRAY':
                                                    image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)
                                                elif MULTIPOINT_BF_SAVING_OPTION == 'Green Channel Only':
                                                    image = image[:,:,1]
                                        iio.imwrite(saving_path,image)

                                    if USE_NAPARI_FOR_MULTIPOINT or USE_NAPARI_FOR_TILED_DISPLAY:
                                        if not init_napari_layers:
                                            print("init napari layers")
                                            init_napari_layers = True
                                            self.napari_layers_init.emit(image.shape[0],image.shape[1], image.dtype, False)
                                        self.napari_layers_update.emit(image, real_i, real_j, k, config.name)

                                    current_round_images[config.name] = np.copy(image)

                                    # dpc generation
                                    keys_to_check = ['BF LED matrix left half', 'BF LED matrix right half', 'BF LED matrix top half', 'BF LED matrix bottom half']
                                    if all(key in current_round_images for key in keys_to_check):
                                        # generate dpc
                                        pass

                                    # RGB generation
                                    keys_to_check = ['BF LED matrix full_R', 'BF LED matrix full_G', 'BF LED matrix full_B']
                                    if all(key in current_round_images for key in keys_to_check):
                                        print('constructing RGB image')
                                        print(current_round_images['BF LED matrix full_R'].dtype)
                                        size = current_round_images['BF LED matrix full_R'].shape
                                        rgb_image = np.zeros((*size, 3),dtype=current_round_images['BF LED matrix full_R'].dtype)
                                        print(rgb_image.shape)
                                        rgb_image[:, :, 0] = current_round_images['BF LED matrix full_R']
                                        rgb_image[:, :, 1] = current_round_images['BF LED matrix full_G']
                                        rgb_image[:, :, 2] = current_round_images['BF LED matrix full_B']

                                        # send image to display
                                        image_to_display = utils.crop_image(rgb_image,round(self.crop_width*self.display_resolution_scaling), round(self.crop_height*self.display_resolution_scaling))

                                        # write the image
                                        if len(rgb_image.shape) == 3:
                                            print('writing RGB image')
                                            if rgb_image.dtype == np.uint16:
                                                iio.imwrite(os.path.join(current_path, file_ID + '_BF_LED_matrix_full_RGB.tiff'), rgb_image)
                                            else:
                                                iio.imwrite(os.path.join(current_path, file_ID + '_BF_LED_matrix_full_RGB.' + Acquisition.IMAGE_FORMAT),rgb_image)

                                    QApplication.processEvents()

                                # RGB
                                elif 'RGB' in config.name:
                                    # go through the channels
                                    channels = ['BF LED matrix full_R', 'BF LED matrix full_G', 'BF LED matrix full_B']
                                    images = {}

                                    for config_ in self.configurationManager.configurations:
                                        if config_.name in channels:
                                            # update the current configuration
                                            self.signal_current_configuration.emit(config_)
                                            self.wait_till_operation_is_completed()

                                            # trigger acquisition (including turning on the illumination)
                                            if self.liveController.trigger_mode == TriggerMode.SOFTWARE:
                                                self.liveController.turn_on_illumination()
                                                self.wait_till_operation_is_completed()
                                                self.camera.send_trigger()
                                            elif self.liveController.trigger_mode == TriggerMode.HARDWARE:
                                                self.microcontroller.send_hardware_trigger(control_illumination=True, illumination_on_time_us=self.camera.exposure_time * 1000)

                                            # read camera frame
                                            image = self.camera.read_frame()
                                            if image is None:
                                                print('self.camera.read_frame() returned None')
                                                continue

                                            # turn off the illumination if using software trigger
                                            if self.liveController.trigger_mode == TriggerMode.SOFTWARE:
                                                self.liveController.turn_off_illumination()

                                            # process the image  -  @@@ to move to camera
                                            image = utils.crop_image(image, self.crop_width, self.crop_height)
                                            image = utils.rotate_and_flip_image(image, rotate_image_angle=self.camera.rotate_image_angle, flip_image=self.camera.flip_image)

                                            # add the image to dictionary
                                            images[config_.name] = np.copy(image)

                                    # Check if the image is RGB or monochrome
                                    i_size = images['BF LED matrix full_R'].shape
                                    i_dtype = images['BF LED matrix full_R'].dtype

                                    if len(i_size) == 3:
                                        # If already RGB, write and emit individual channels
                                        print('writing R, G, B channels')

                                        for channel in channels:
                                            image_to_display = utils.crop_image(images[channel], round(self.crop_width * self.display_resolution_scaling), round(self.crop_height * self.display_resolution_scaling))
                                            self.image_to_display.emit(image_to_display)
                                            self.image_to_display_multi.emit(image_to_display, config.illumination_source)

                                            if USE_NAPARI_FOR_MULTIPOINT or USE_NAPARI_FOR_TILED_DISPLAY:
                                                if not init_napari_layers:
                                                    print(f"init napari {channel} layer")
                                                    init_napari_layers = True
                                                    self.napari_layers_init.emit(i_size[0], i_size[1], i_dtype, True)
                                                self.napari_layers_update.emit(images[channel], real_i, real_j, k, config.name)

                                            file_name = file_ID + '_' + channel.replace(' ', '_') + ('.tiff' if i_dtype == np.uint16 else '.' + Acquisition.IMAGE_FORMAT)
                                            iio.imwrite(os.path.join(current_path, file_name), images[channel])

                                    else:
                                        # If monochrome, reconstruct RGB image
                                        print('constructing RGB image')

                                        rgb_image = np.zeros((*i_size, 3), dtype=i_dtype)
                                        rgb_image[:, :, 0] = images['BF LED matrix full_R']
                                        rgb_image[:, :, 1] = images['BF LED matrix full_G']
                                        rgb_image[:, :, 2] = images['BF LED matrix full_B']

                                        # send image to display
                                        image_to_display = utils.crop_image(rgb_image, round(self.crop_width * self.display_resolution_scaling), round(self.crop_height * self.display_resolution_scaling))
                                        self.image_to_display.emit(image_to_display)
                                        self.image_to_display_multi.emit(image_to_display, config.illumination_source)

                                        if USE_NAPARI_FOR_MULTIPOINT or USE_NAPARI_FOR_TILED_DISPLAY:
                                            if not init_napari_layers:
                                                print("init napari rgb layer")
                                                init_napari_layers = True
                                                print(rgb_image.dtype)
                                                self.napari_layers_init.emit(rgb_image.shape[0], rgb_image.shape[1], rgb_image.dtype, True)
                                            self.napari_layers_update.emit(rgb_image, real_i, real_j, k, config.name)

                                        # write the RGB image
                                        print('writing RGB image')
                                        file_name = file_ID + '_BF_LED_matrix_full_RGB' + ('.tiff' if rgb_image.dtype == np.uint16 else '.' + Acquisition.IMAGE_FORMAT)
                                        iio.imwrite(os.path.join(current_path, file_name), rgb_image)

                                # USB spectrometer
                                else:
                                    if self.usb_spectrometer != None:
                                        for l in range(N_SPECTRUM_PER_POINT):
                                            data = self.usb_spectrometer.read_spectrum()
                                            self.spectrum_to_display.emit(data)
                                            saving_path = os.path.join(current_path, file_ID + '_' + str(config.name).replace(' ','_') + '_' + str(l) + '.csv')
                                            np.savetxt(saving_path,data,delimiter=',')
                                
                                
                                if config.z_offset is not None: # undo Z offset
                                                                # assume z_offset is in um
                                    if config.z_offset != 0.0:
                                        print("Moving back from Z offset "+str(config.z_offset))
                                        self.navigationController.move_z(-config.z_offset/1000)
                                        self.wait_till_operation_is_completed()
                                        time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)

                            # tiled preview
                            if SHOW_TILED_PREVIEW and 'BF LED matrix full' in current_round_images:
                                # initialize the variable
                                if self.tiled_preview is None:
                                    size = current_round_images['BF LED matrix full'].shape
                                    if len(size) == 2:
                                        self.tiled_preview = np.zeros((int(self.NY*size[0]/PRVIEW_DOWNSAMPLE_FACTOR),self.NX*int(size[1]/PRVIEW_DOWNSAMPLE_FACTOR)),dtype=current_round_images['BF LED matrix full'].dtype)
                                    else:
                                        self.tiled_preview = np.zeros((int(self.NY*size[0]/PRVIEW_DOWNSAMPLE_FACTOR),self.NX*int(size[1]/PRVIEW_DOWNSAMPLE_FACTOR),size[2]),dtype=current_round_images['BF LED matrix full'].dtype)
                                # downsample the image
                                I = current_round_images['BF LED matrix full']
                                width = int(I.shape[1]/PRVIEW_DOWNSAMPLE_FACTOR)
                                height = int(I.shape[0]/PRVIEW_DOWNSAMPLE_FACTOR)
                                I = cv2.resize(I, (width,height), interpolation=cv2.INTER_AREA)
                                # populate the tiled_preview
                                if sgn_j == 1:
                                    self.tiled_preview[(self.NY-i-1)*height:(self.NY-i)*height, j*width:(j+1)*width, ] = I
                                else:
                                    self.tiled_preview[(self.NY-i-1)*height:(self.NY-i)*height, (self.NX-j-1)*width:(self.NX-j)*width, ] = I
                                # emit the result
                                self.image_to_display_tiled_preview.emit(self.tiled_preview)

                            # add the coordinate of the current location
                            if IS_HCS:
                                if self.use_piezo:
                                    new_row = pd.DataFrame({'well': coordiante_name.replace("_", ""),
                                                            'i':[self.NY-1-i if sgn_i == -1 else i],'j':[j if sgn_j == 1 else self.NX-1-j],'k':[k],
                                                            'x (mm)':[self.navigationController.x_pos_mm],
                                                            'y (mm)':[self.navigationController.y_pos_mm],
                                                            'z (um)':[self.navigationController.z_pos_mm*1000],
                                                            'z_piezo (um)':[self.z_piezo_um-OBJECTIVE_PIEZO_HOME_UM],
                                                            'time':datetime.now().strftime('%Y-%m-%d_%H-%M-%S.%f')})
                                else:
                                    new_row = pd.DataFrame({'well': coordiante_name.replace("_", ""),
                                                            'i':[self.NY-1-i if sgn_i == -1 else i],'j':[j if sgn_j == 1 else self.NX-1-j],'k':[k],
                                                            'x (mm)':[self.navigationController.x_pos_mm],
                                                            'y (mm)':[self.navigationController.y_pos_mm],
                                                            'z (um)':[self.navigationController.z_pos_mm*1000],
                                                            'time':datetime.now().strftime('%Y-%m-%d_%H-%M-%S.%f')})
                            else:
                                if self.use_piezo:
                                    new_row = pd.DataFrame({'i':[self.NY-1-i if sgn_i == -1 else i],'j':[j if sgn_j == 1 else self.NX-1-j],'k':[k],
                                                            'x (mm)':[self.navigationController.x_pos_mm],
                                                            'y (mm)':[self.navigationController.y_pos_mm],
                                                            'z (um)':[self.navigationController.z_pos_mm*1000],
                                                            'z_piezo (um)':[self.z_piezo_um-OBJECTIVE_PIEZO_HOME_UM],
                                                            'time':datetime.now().strftime('%Y-%m-%d_%H-%M-%S.%f')})
                                else:
                                    new_row = pd.DataFrame({'i':[self.NY-1-i if sgn_i == -1 else i],'j':[j if sgn_j == 1 else self.NX-1-j],'k':[k],
                                                            'x (mm)':[self.navigationController.x_pos_mm],
                                                            'y (mm)':[self.navigationController.y_pos_mm],
                                                            'z (um)':[self.navigationController.z_pos_mm*1000],
                                                            'time':datetime.now().strftime('%Y-%m-%d_%H-%M-%S.%f')})

                            self.coordinates_pd = pd.concat([self.coordinates_pd, new_row], ignore_index=True)

                            # register the current fov in the navigationViewer
                            self.signal_register_current_fov.emit(self.navigationController.x_pos_mm,self.navigationController.y_pos_mm)

                            # check if the acquisition should be aborted
                            if self.multiPointController.abort_acqusition_requested:
                                self.liveController.turn_off_illumination()
                                self.navigationController.move_x_usteps(-self.dx_usteps)
                                self.wait_till_operation_is_completed()
                                self.navigationController.move_y_usteps(-self.dy_usteps)
                                self.wait_till_operation_is_completed()

                                if self.navigationController.get_pid_control_flag(2) is False:
                                    _usteps_to_clear_backlash = max(160,20*self.navigationController.z_microstepping)
                                    self.navigationController.move_z_usteps(-self.dz_usteps-_usteps_to_clear_backlash)
                                    self.wait_till_operation_is_completed()
                                    self.navigationController.move_z_usteps(_usteps_to_clear_backlash)
                                    self.wait_till_operation_is_completed()
                                else:
                                    self.navigationController.move_z_usteps(-self.dz_usteps)
                                    self.wait_till_operation_is_completed()

                                self.coordinates_pd.to_csv(os.path.join(current_path,'coordinates.csv'),index=False,header=True)
                                self.navigationController.enable_joystick_button_action = True
                                return

                            if self.NZ > 1:
                                # move z
                                if k < self.NZ - 1:
                                    if self.use_piezo:
                                        self.z_piezo_um += self.deltaZ*1000
                                        dac = int(65535 * (self.z_piezo_um / OBJECTIVE_PIEZO_RANGE_UM))
                                        self.navigationController.microcontroller.analog_write_onboard_DAC(7, dac)
                                        if self.liveController.trigger_mode == TriggerMode.SOFTWARE: # for hardware trigger, delay is in waiting for the last row to start exposure
                                            time.sleep(MULTIPOINT_PIEZO_DELAY_MS/1000)
                                        if MULTIPOINT_PIEZO_UPDATE_DISPLAY:
                                            self.signal_z_piezo_um.emit(self.z_piezo_um)
                                    else:
                                        self.navigationController.move_z_usteps(self.deltaZ_usteps)
                                        self.wait_till_operation_is_completed()
                                        time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)
                                        self.dz_usteps = self.dz_usteps + self.deltaZ_usteps

                        if self.NZ > 1:
                            # move z back
                            if self.use_piezo:
                                self.z_piezo_um = OBJECTIVE_PIEZO_HOME_UM
                                dac = int(65535 * (self.z_piezo_um / OBJECTIVE_PIEZO_RANGE_UM))
                                self.navigationController.microcontroller.analog_write_onboard_DAC(7, dac)
                                if self.liveController.trigger_mode == TriggerMode.SOFTWARE: # for hardware trigger, delay is in waiting for the last row to start exposure
                                    time.sleep(MULTIPOINT_PIEZO_DELAY_MS/1000)
                                if MULTIPOINT_PIEZO_UPDATE_DISPLAY:
                                    self.signal_z_piezo_um.emit(self.z_piezo_um)
                            else:
                                _usteps_to_clear_backlash = max(160,20*self.navigationController.z_microstepping)
                                if Z_STACKING_CONFIG == 'FROM CENTER':
                                    if self.navigationController.get_pid_control_flag(2) is False:
                                        _usteps_to_clear_backlash = max(160,20*self.navigationController.z_microstepping)
                                        self.navigationController.move_z_usteps( -self.deltaZ_usteps*(self.NZ-1) + self.deltaZ_usteps*round((self.NZ-1)/2) - _usteps_to_clear_backlash)
                                        self.wait_till_operation_is_completed()
                                        self.navigationController.move_z_usteps(_usteps_to_clear_backlash)
                                        self.wait_till_operation_is_completed()
                                    else:
                                        self.navigationController.move_z_usteps( -self.deltaZ_usteps*(self.NZ-1) + self.deltaZ_usteps*round((self.NZ-1)/2) )
                                        self.wait_till_operation_is_completed()
                                    self.dz_usteps = self.dz_usteps - self.deltaZ_usteps*(self.NZ-1) + self.deltaZ_usteps*round((self.NZ-1)/2)
                                else:
                                    if self.navigationController.get_pid_control_flag(2) is False:
                                        _usteps_to_clear_backlash = max(160,20*self.navigationController.z_microstepping)
                                        self.navigationController.move_z_usteps(-self.deltaZ_usteps*(self.NZ-1) - _usteps_to_clear_backlash)
                                        self.wait_till_operation_is_completed()
                                        self.navigationController.move_z_usteps(_usteps_to_clear_backlash)
                                        self.wait_till_operation_is_completed()
                                    else:
                                        self.navigationController.move_z_usteps(-self.deltaZ_usteps*(self.NZ-1))
                                        self.wait_till_operation_is_completed()
                                    self.dz_usteps = self.dz_usteps - self.deltaZ_usteps*(self.NZ-1)

                        # update FOV counter
                        self.FOV_counter = self.FOV_counter + 1

                    if self.NX > 1:
                        # move x
                        if j < self.NX - 1:
                            self.navigationController.move_x_usteps(self.x_scan_direction*self.deltaX_usteps)
                            self.wait_till_operation_is_completed()
                            time.sleep(SCAN_STABILIZATION_TIME_MS_X/1000)
                            self.dx_usteps = self.dx_usteps + self.x_scan_direction*self.deltaX_usteps

                # finished X scan
                '''
                # instead of move back, reverse scan direction (12/29/2021)
                if self.NX > 1:
                    # move x back
                    self.navigationController.move_x_usteps(-self.deltaX_usteps*(self.NX-1))
                    self.wait_till_operation_is_completed()
                    time.sleep(SCAN_STABILIZATION_TIME_MS_X/1000)
                '''
                self.x_scan_direction = -self.x_scan_direction

                if self.NY > 1:
                    # move y
                    if i < self.NY - 1:
                        self.navigationController.move_y_usteps(self.deltaY_usteps)
                        self.wait_till_operation_is_completed()
                        time.sleep(SCAN_STABILIZATION_TIME_MS_Y/1000)
                        self.dy_usteps = self.dy_usteps + self.deltaY_usteps

            # finished XY scan
            if n_regions == 1:
                # only move to the start position if there's only one region in the scan
                if self.NY > 1:
                    # move y back
                    self.navigationController.move_y_usteps(-self.deltaY_usteps*(self.NY-1))
                    self.wait_till_operation_is_completed()
                    time.sleep(SCAN_STABILIZATION_TIME_MS_Y/1000)
                    self.dy_usteps = self.dy_usteps - self.deltaY_usteps*(self.NY-1)

                # move x back at the end of the scan
                if self.x_scan_direction == -1:
                    self.navigationController.move_x_usteps(-self.deltaX_usteps*(self.NX-1))
                    self.wait_till_operation_is_completed()
                    time.sleep(SCAN_STABILIZATION_TIME_MS_X/1000)

                if SHOW_TILED_PREVIEW:
                    self.navigationController.keep_scan_begin_position(self.navigationController.x_pos_mm, self.navigationController.y_pos_mm)

                # move z back
                if self.navigationController.get_pid_control_flag(2) is False:
                    _usteps_to_clear_backlash = max(160,20*self.navigationController.z_microstepping)
                    self.navigationController.microcontroller.move_z_to_usteps(z_pos - STAGE_MOVEMENT_SIGN_Z*_usteps_to_clear_backlash)
                    self.wait_till_operation_is_completed()
                    self.navigationController.move_z_usteps(_usteps_to_clear_backlash)
                    self.wait_till_operation_is_completed()
                else:
                    self.navigationController.microcontroller.move_z_to_usteps(z_pos)
                    self.wait_till_operation_is_completed()

        # finished region scan
        self.coordinates_pd.to_csv(os.path.join(current_path,'coordinates.csv'),index=False,header=True)
        self.navigationController.enable_joystick_button_action = True
        print(time.time())
        print(time.time()-start)

class MultiPointController(QObject):

    acquisitionFinished = Signal()
    image_to_display = Signal(np.ndarray)
    image_to_display_multi = Signal(np.ndarray,int)
    image_to_display_tiled_preview = Signal(np.ndarray)
    spectrum_to_display = Signal(np.ndarray)
    signal_current_configuration = Signal(Configuration)
    signal_register_current_fov = Signal(float,float)
    detection_stats = Signal(object)
    napari_layers_update = Signal(np.ndarray, int, int, int, str)
    napari_layers_init = Signal(int, int, object, bool)
    signal_z_piezo_um = Signal(float)

    def __init__(self,camera,navigationController,liveController,autofocusController,configurationManager,usb_spectrometer=None,scanCoordinates=None,parent=None):
        QObject.__init__(self)

        self.camera = camera
        self.processingHandler = ProcessingHandler()
        self.microcontroller = navigationController.microcontroller # to move to gui for transparency
        self.navigationController = navigationController
        self.liveController = liveController
        self.autofocusController = autofocusController
        self.configurationManager = configurationManager
        self.NX = 1
        self.NY = 1
        self.NZ = 1
        self.Nt = 1
        mm_per_ustep_X = SCREW_PITCH_X_MM/(self.navigationController.x_microstepping*FULLSTEPS_PER_REV_X)
        mm_per_ustep_Y = SCREW_PITCH_Y_MM/(self.navigationController.y_microstepping*FULLSTEPS_PER_REV_Y)
        mm_per_ustep_Z = SCREW_PITCH_Z_MM/(self.navigationController.z_microstepping*FULLSTEPS_PER_REV_Z)
        self.deltaX = Acquisition.DX
        self.deltaX_usteps = round(self.deltaX/mm_per_ustep_X)
        self.deltaY = Acquisition.DY
        self.deltaY_usteps = round(self.deltaY/mm_per_ustep_Y)
        self.deltaZ = Acquisition.DZ/1000
        self.deltaZ_usteps = round(self.deltaZ/mm_per_ustep_Z)
        self.deltat = 0
        self.do_autofocus = False
        self.do_reflection_af = False
        self.gen_focus_map = False
        self.focus_map_storage = []
        self.already_using_fmap = False
        self.crop_width = Acquisition.CROP_WIDTH
        self.crop_height = Acquisition.CROP_HEIGHT
        self.display_resolution_scaling = Acquisition.IMAGE_DISPLAY_SCALING_FACTOR
        self.counter = 0
        self.experiment_ID = None
        self.base_path = None
        self.use_piezo = MULTIPOINT_USE_PIEZO_FOR_ZSTACKS #TODO: change to false and get value from widget
        self.selected_configurations = []
        self.usb_spectrometer = usb_spectrometer
        self.scanCoordinates = scanCoordinates
        self.parent = parent

        self.old_images_per_page = 1
        try:
            if self.parent is not None:
                self.old_images_per_page = self.parent.dataHandler.n_images_per_page
        except:
            pass
        self.location_list = None # for flexible multipoint

    def set_NX(self,N):
        self.NX = N
    def set_NY(self,N):
        self.NY = N
    def set_NZ(self,N):
        self.NZ = N
    def set_Nt(self,N):
        self.Nt = N
    def set_deltaX(self,delta):
        mm_per_ustep_X = SCREW_PITCH_X_MM/(self.navigationController.x_microstepping*FULLSTEPS_PER_REV_X)
        self.deltaX = delta
        self.deltaX_usteps = round(delta/mm_per_ustep_X)
    def set_deltaY(self,delta):
        mm_per_ustep_Y = SCREW_PITCH_Y_MM/(self.navigationController.y_microstepping*FULLSTEPS_PER_REV_Y)
        self.deltaY = delta
        self.deltaY_usteps = round(delta/mm_per_ustep_Y)
    def set_deltaZ(self,delta_um):
        mm_per_ustep_Z = SCREW_PITCH_Z_MM/(self.navigationController.z_microstepping*FULLSTEPS_PER_REV_Z)
        self.deltaZ = delta_um/1000
        self.deltaZ_usteps = round((delta_um/1000)/mm_per_ustep_Z)
    def set_deltat(self,delta):
        self.deltat = delta
    def set_af_flag(self,flag):
        self.do_autofocus = flag
    def set_reflection_af_flag(self,flag):
        self.do_reflection_af = flag
    def set_gen_focus_map_flag(self, flag):
        self.gen_focus_map = flag
        if not flag:
            self.autofocusController.set_focus_map_use(False)
    def set_crop(self,crop_width,height):
        self.crop_width = crop_width
        self.crop_height = crop_height

    def set_base_path(self,path):
        self.base_path = path

    def start_new_experiment(self,experiment_ID): # @@@ to do: change name to prepare_folder_for_new_experiment
        # generate unique experiment ID
        self.experiment_ID = experiment_ID.replace(' ','_') + '_' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S.%f')
        self.recording_start_time = time.time()
        # create a new folder
        os.mkdir(os.path.join(self.base_path,self.experiment_ID))
        configManagerThrowaway = ConfigurationManager(self.configurationManager.config_filename)
        configManagerThrowaway.write_configuration_selected(self.selected_configurations,os.path.join(self.base_path,self.experiment_ID)+"/configurations.xml") # save the configuration for the experiment
        acquisition_parameters = {'dx(mm)':self.deltaX, 'Nx':self.NX, 'dy(mm)':self.deltaY, 'Ny':self.NY, 'dz(um)':self.deltaZ*1000,'Nz':self.NZ,'dt(s)':self.deltat,'Nt':self.Nt,'with AF':self.do_autofocus,'with reflection AF':self.do_reflection_af}
        try: # write objective data if it is available
            current_objective = self.parent.objectiveStore.current_objective
            objective_info = self.parent.objectiveStore.objectives_dict.get(current_objective, {})
            acquisition_parameters['objective'] = {}
            for k in objective_info.keys():
                acquisition_parameters['objective'][k]=objective_info[k]
            acquisition_parameters['objective']['name']=current_objective
        except:
            try:
                objective_info = OBJECTIVES[DEFAULT_OBJECTIVE]
                acquisition_parameters['objective'] = {}
                for k in objective_info.keys():
                    acquisition_parameters['objective'][k] = objective_info[k]
                acquisition_parameters['objective']['name']=DEFAULT_OBJECTIVE
            except:
                pass
        acquisition_parameters['sensor_pixel_size_um'] = CAMERA_PIXEL_SIZE_UM[CAMERA_SENSOR]
        acquisition_parameters['tube_lens_mm'] = TUBE_LENS_MM
        f = open(os.path.join(self.base_path,self.experiment_ID)+"/acquisition parameters.json","w")
        f.write(json.dumps(acquisition_parameters))
        f.close()


    def set_selected_configurations(self, selected_configurations_name):
        self.selected_configurations = []
        for configuration_name in selected_configurations_name:
            self.selected_configurations.append(next((config for config in self.configurationManager.configurations if config.name == configuration_name)))
        
    def run_acquisition(self, location_list=None): # @@@ to do: change name to run_experiment
        print('start multipoint')
        print(str(self.Nt) + '_' + str(self.NX) + '_' + str(self.NY) + '_' + str(self.NZ))

        if location_list is not None:
            print(location_list)
            self.location_list = location_list
        else:
            self.location_list = None

        self.abort_acqusition_requested = False

        self.configuration_before_running_multipoint = self.liveController.currentConfiguration
        # stop live
        if self.liveController.is_live:
            self.liveController_was_live_before_multipoint = True
            self.liveController.stop_live() # @@@ to do: also uncheck the live button
        else:
            self.liveController_was_live_before_multipoint = False

        # disable callback
        if self.camera.callback_is_enabled:
            self.camera_callback_was_enabled_before_multipoint = True
            self.camera.disable_callback()
        else:
            self.camera_callback_was_enabled_before_multipoint = False

        if self.usb_spectrometer != None:
            if self.usb_spectrometer.streaming_started == True and self.usb_spectrometer.streaming_paused == False:
                self.usb_spectrometer.pause_streaming()
                self.usb_spectrometer_was_streaming = True
            else:
                self.usb_spectrometer_was_streaming = False

        if self.parent is not None:
            try:
                self.parent.imageDisplayTabs.setCurrentWidget(self.parent.imageArrayDisplayWindow.widget)
            except:
                pass
            try:
                self.parent.recordTabWidget.setCurrentWidget(self.parent.statsDisplayWidget)
            except:
                pass
        
        # run the acquisition
        self.timestamp_acquisition_started = time.time()

        if SHOW_TILED_PREVIEW:
            self.navigationController.keep_scan_begin_position(self.navigationController.x_pos_mm, self.navigationController.y_pos_mm)

        # create a QThread object
        if self.gen_focus_map and not self.do_reflection_af:
            print("Generating focus map for multipoint grid")
            starting_x_mm = self.navigationController.x_pos_mm
            starting_y_mm = self.navigationController.y_pos_mm
            fmap_Nx = max(2,self.NX-1)
            fmap_Ny = max(2,self.NY-1)
            fmap_dx = self.deltaX
            fmap_dy = self.deltaY
            if abs(fmap_dx) < 0.1 and fmap_dx != 0.0:
                fmap_dx = 0.1*fmap_dx/(abs(fmap_dx))
            elif fmap_dx == 0.0:
                fmap_dx = 0.1
            if abs(fmap_dy) < 0.1 and fmap_dy != 0.0:
                 fmap_dy = 0.1*fmap_dy/(abs(fmap_dy))
            elif fmap_dy == 0.0:
                fmap_dy = 0.1
            try:
                self.focus_map_storage = []
                self.already_using_fmap = self.autofocusController.use_focus_map
                for x,y,z in self.autofocusController.focus_map_coords:
                    self.focus_map_storage.append((x,y,z))
                coord1 = (starting_x_mm, starting_y_mm)
                coord2 = (starting_x_mm+fmap_Nx*fmap_dx,starting_y_mm)
                coord3 = (starting_x_mm,starting_y_mm+fmap_Ny*fmap_dy)
                self.autofocusController.gen_focus_map(coord1, coord2, coord3)
                self.autofocusController.set_focus_map_use(True)
                self.navigationController.move_to(starting_x_mm, starting_y_mm)
                self.navigationController.microcontroller.wait_till_operation_is_completed()
            except ValueError:
                print("Invalid coordinates for focus map, aborting.")
                return

        self.thread = QThread()
        # create a worker object
        self.processingHandler.start_processing()
        self.processingHandler.start_uploading()
        self.multiPointWorker = MultiPointWorker(self)
        # move the worker to the thread
        self.multiPointWorker.moveToThread(self.thread)
        # connect signals and slots
        self.thread.started.connect(self.multiPointWorker.run)
        self.multiPointWorker.signal_detection_stats.connect(self.slot_detection_stats)
        self.multiPointWorker.finished.connect(self._on_acquisition_completed)
        self.multiPointWorker.finished.connect(self.multiPointWorker.deleteLater)
        self.multiPointWorker.finished.connect(self.thread.quit)
        self.multiPointWorker.image_to_display.connect(self.slot_image_to_display)
        self.multiPointWorker.image_to_display_multi.connect(self.slot_image_to_display_multi)
        self.multiPointWorker.image_to_display_tiled_preview.connect(self.slot_image_to_display_tiled_preview)
        self.multiPointWorker.spectrum_to_display.connect(self.slot_spectrum_to_display)
        self.multiPointWorker.signal_current_configuration.connect(self.slot_current_configuration,type=Qt.BlockingQueuedConnection)
        self.multiPointWorker.signal_register_current_fov.connect(self.slot_register_current_fov)
        self.multiPointWorker.napari_layers_init.connect(self.slot_napari_layers_init)
        self.multiPointWorker.napari_layers_update.connect(self.slot_napari_layers_update)
        self.multiPointWorker.signal_z_piezo_um.connect(self.slot_z_piezo_um)
        # self.thread.finished.connect(self.thread.deleteLater)
        self.thread.finished.connect(self.thread.quit)
        # start the thread
        self.thread.start()

    def _on_acquisition_completed(self):
        # restore the previous selected mode
        if self.gen_focus_map:
            self.autofocusController.clear_focus_map()
            for x,y,z in self.focus_map_storage:
                self.autofocusController.focus_map_coords.append((x,y,z))
            self.autofocusController.use_focus_map = self.already_using_fmap
        self.signal_current_configuration.emit(self.configuration_before_running_multipoint)

        # re-enable callback
        if self.camera_callback_was_enabled_before_multipoint:
            self.camera.enable_callback()
            self.camera_callback_was_enabled_before_multipoint = False
        
        # re-enable live if it's previously on
        if self.liveController_was_live_before_multipoint:
            self.liveController.start_live()

        if self.usb_spectrometer != None:
            if self.usb_spectrometer_was_streaming:
                self.usb_spectrometer.resume_streaming()
        
        # emit the acquisition finished signal to enable the UI
        self.processingHandler.end_processing()
        if self.parent is not None:
            try:
                self.parent.dataHandler.set_number_of_images_per_page(self.old_images_per_page)
                self.parent.dataHandler.sort('Sort by prediction score')
                self.parent.dataHandler.signal_populate_page0.emit()
            except:
                pass
        self.acquisitionFinished.emit()
        QApplication.processEvents()

    def request_abort_aquisition(self):
        self.abort_acqusition_requested = True

    def slot_detection_stats(self, stats):
        self.detection_stats.emit(stats)

    def slot_image_to_display(self,image):
        self.image_to_display.emit(image)

    def slot_image_to_display_tiled_preview(self,image):
        self.image_to_display_tiled_preview.emit(image)

    def slot_spectrum_to_display(self,data):
        self.spectrum_to_display.emit(data)

    def slot_image_to_display_multi(self,image,illumination_source):
        self.image_to_display_multi.emit(image,illumination_source)

    def slot_current_configuration(self,configuration):
        self.signal_current_configuration.emit(configuration)

    def slot_register_current_fov(self,x_mm,y_mm):
        self.signal_register_current_fov.emit(x_mm,y_mm)

    def slot_napari_layers_update(self, image, i, j, k, channel):
        self.napari_layers_update.emit(image, i, j, k, channel)

    def slot_napari_layers_init(self, image_height, image_width, dtype, rgb):
        self.napari_layers_init.emit(image_height, image_width, dtype, rgb)

    def slot_z_piezo_um(self, displacement_um):
        self.signal_z_piezo_um.emit(displacement_um)


class TrackingController(QObject):

    signal_tracking_stopped = Signal()
    image_to_display = Signal(np.ndarray)
    image_to_display_multi = Signal(np.ndarray,int)
    signal_current_configuration = Signal(Configuration)

    def __init__(self,camera,microcontroller,navigationController,configurationManager,liveController,autofocusController,imageDisplayWindow):
        QObject.__init__(self)
        self.camera = camera
        self.microcontroller = microcontroller
        self.navigationController = navigationController
        self.configurationManager = configurationManager
        self.liveController = liveController
        self.autofocusController = autofocusController
        self.imageDisplayWindow = imageDisplayWindow
        self.tracker = tracking.Tracker_Image()
        # self.tracker_z = tracking.Tracker_Z()
        # self.pid_controller_x = tracking.PID_Controller()
        # self.pid_controller_y = tracking.PID_Controller()
        # self.pid_controller_z = tracking.PID_Controller()

        self.tracking_time_interval_s = 0

        self.crop_width = Acquisition.CROP_WIDTH
        self.crop_height = Acquisition.CROP_HEIGHT
        self.display_resolution_scaling = Acquisition.IMAGE_DISPLAY_SCALING_FACTOR
        self.counter = 0
        self.experiment_ID = None
        self.base_path = None
        self.selected_configurations = []

        self.flag_stage_tracking_enabled = True
        self.flag_AF_enabled = False
        self.flag_save_image = False
        self.flag_stop_tracking_requested = False

        self.pixel_size_um = None
        self.objective = None

    def start_tracking(self):
        
        # save pre-tracking configuration
        print('start tracking')
        self.configuration_before_running_tracking = self.liveController.currentConfiguration
        
        # stop live
        if self.liveController.is_live:
            self.was_live_before_tracking = True
            self.liveController.stop_live() # @@@ to do: also uncheck the live button
        else:
            self.was_live_before_tracking = False

        # disable callback
        if self.camera.callback_is_enabled:
            self.camera_callback_was_enabled_before_tracking = True
            self.camera.disable_callback()
        else:
            self.camera_callback_was_enabled_before_tracking = False

        # hide roi selector
        self.imageDisplayWindow.hide_ROI_selector()

        # run tracking
        self.flag_stop_tracking_requested = False
        # create a QThread object
        try:
            if self.thread.isRunning():
                print('*** previous tracking thread is still running ***')
                self.thread.terminate()
                self.thread.wait()
                print('*** previous tracking threaded manually stopped ***')
        except:
            pass
        self.thread = QThread()
        # create a worker object
        self.trackingWorker = TrackingWorker(self)
        # move the worker to the thread
        self.trackingWorker.moveToThread(self.thread)
        # connect signals and slots
        self.thread.started.connect(self.trackingWorker.run)
        self.trackingWorker.finished.connect(self._on_tracking_stopped)
        self.trackingWorker.finished.connect(self.trackingWorker.deleteLater)
        self.trackingWorker.finished.connect(self.thread.quit)
        self.trackingWorker.image_to_display.connect(self.slot_image_to_display)
        self.trackingWorker.image_to_display_multi.connect(self.slot_image_to_display_multi)
        self.trackingWorker.signal_current_configuration.connect(self.slot_current_configuration,type=Qt.BlockingQueuedConnection)
        # self.thread.finished.connect(self.thread.deleteLater)
        self.thread.finished.connect(self.thread.quit)
        # start the thread
        self.thread.start()

    def _on_tracking_stopped(self):

        # restore the previous selected mode
        self.signal_current_configuration.emit(self.configuration_before_running_tracking)

        # re-enable callback
        if self.camera_callback_was_enabled_before_tracking:
            self.camera.enable_callback()
            self.camera_callback_was_enabled_before_tracking = False
        
        # re-enable live if it's previously on
        if self.was_live_before_tracking:
            self.liveController.start_live()

        # show ROI selector
        self.imageDisplayWindow.show_ROI_selector()
        
        # emit the acquisition finished signal to enable the UI
        self.signal_tracking_stopped.emit()
        QApplication.processEvents()

    def start_new_experiment(self,experiment_ID): # @@@ to do: change name to prepare_folder_for_new_experiment
        # generate unique experiment ID
        self.experiment_ID = experiment_ID + '_' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S.%f')
        self.recording_start_time = time.time()
        # create a new folder
        try:
            os.mkdir(os.path.join(self.base_path,self.experiment_ID))
            self.configurationManager.write_configuration(os.path.join(self.base_path,self.experiment_ID)+"/configurations.xml") # save the configuration for the experiment
        except:
            print('error in making a new folder')
            pass

    def set_selected_configurations(self, selected_configurations_name):
        self.selected_configurations = []
        for configuration_name in selected_configurations_name:
            self.selected_configurations.append(next((config for config in self.configurationManager.configurations if config.name == configuration_name)))

    def toggle_stage_tracking(self,state):
        self.flag_stage_tracking_enabled = state > 0
        print('set stage tracking enabled to ' + str(self.flag_stage_tracking_enabled))

    def toggel_enable_af(self,state):
        self.flag_AF_enabled = state > 0
        print('set af enabled to ' + str(self.flag_AF_enabled))

    def toggel_save_images(self,state):
        self.flag_save_image = state > 0
        print('set save images to ' + str(self.flag_save_image))

    def set_base_path(self,path):
        self.base_path = path

    def stop_tracking(self):
        self.flag_stop_tracking_requested = True
        print('stop tracking requested')

    def slot_image_to_display(self,image):
        self.image_to_display.emit(image)

    def slot_image_to_display_multi(self,image,illumination_source):
        self.image_to_display_multi.emit(image,illumination_source)

    def slot_current_configuration(self,configuration):
        self.signal_current_configuration.emit(configuration)

    def update_pixel_size(self, pixel_size_um):
        self.pixel_size_um = pixel_size_um

    def update_tracker_selection(self,tracker_str):
        self.tracker.update_tracker_type(tracker_str)

    def set_tracking_time_interval(self,time_interval):
        self.tracking_time_interval_s = time_interval

    def update_image_resizing_factor(self,image_resizing_factor):
        self.image_resizing_factor = image_resizing_factor
        print('update tracking image resizing factor to ' + str(self.image_resizing_factor))
        self.pixel_size_um_scaled = self.pixel_size_um/self.image_resizing_factor

    # PID-based tracking
    '''
    def on_new_frame(self,image,frame_ID,timestamp):
        # initialize the tracker when a new track is started
        if self.tracking_frame_counter == 0:
            # initialize the tracker
            # initialize the PID controller
            pass

        # crop the image, resize the image 
        # [to fill]

        # get the location
        [x,y] = self.tracker_xy.track(image)
        z = self.track_z.track(image)

        # get motion commands
        dx = self.pid_controller_x.get_actuation(x)
        dy = self.pid_controller_y.get_actuation(y)
        dz = self.pid_controller_z.get_actuation(z)

        # read current location from the microcontroller
        current_stage_position = self.microcontroller.read_received_packet()

        # save the coordinate information (possibly enqueue image for saving here to if a separate ImageSaver object is being used) before the next movement
        # [to fill]

        # generate motion commands
        motion_commands = self.generate_motion_commands(self,dx,dy,dz)

        # send motion commands
        self.microcontroller.send_command(motion_commands)

    def start_a_new_track(self):
        self.tracking_frame_counter = 0
    '''

class TrackingWorker(QObject):

    finished = Signal()
    image_to_display = Signal(np.ndarray)
    image_to_display_multi = Signal(np.ndarray,int)
    signal_current_configuration = Signal(Configuration)

    def __init__(self,trackingController):
        QObject.__init__(self)
        self.trackingController = trackingController

        self.camera = self.trackingController.camera
        self.microcontroller = self.trackingController.microcontroller
        self.navigationController = self.trackingController.navigationController
        self.liveController = self.trackingController.liveController
        self.autofocusController = self.trackingController.autofocusController
        self.configurationManager = self.trackingController.configurationManager
        self.imageDisplayWindow = self.trackingController.imageDisplayWindow
        self.crop_width = self.trackingController.crop_width
        self.crop_height = self.trackingController.crop_height
        self.display_resolution_scaling = self.trackingController.display_resolution_scaling
        self.counter = self.trackingController.counter
        self.experiment_ID = self.trackingController.experiment_ID
        self.base_path = self.trackingController.base_path
        self.selected_configurations = self.trackingController.selected_configurations
        self.tracker = trackingController.tracker
        
        self.number_of_selected_configurations = len(self.selected_configurations)

        # self.tracking_time_interval_s = self.trackingController.tracking_time_interval_s
        # self.flag_stage_tracking_enabled = self.trackingController.flag_stage_tracking_enabled
        # self.flag_AF_enabled = False
        # self.flag_save_image = False
        # self.flag_stop_tracking_requested = False

        self.image_saver = ImageSaver_Tracking(base_path=os.path.join(self.base_path,self.experiment_ID),image_format='bmp')

    def run(self):

        tracking_frame_counter = 0
        t0 = time.time()

        # save metadata
        self.txt_file = open( os.path.join(self.base_path,self.experiment_ID,"metadata.txt"), "w+")
        self.txt_file.write('t0: ' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S.%f') + '\n')
        self.txt_file.write('objective: ' + self.trackingController.objective + '\n')
        self.txt_file.close()

        # create a file for logging 
        self.csv_file = open( os.path.join(self.base_path,self.experiment_ID,"track.csv"), "w+")
        self.csv_file.write('dt (s), x_stage (mm), y_stage (mm), z_stage (mm), x_image (mm), y_image(mm), image_filename\n')

        # reset tracker
        self.tracker.reset()

        # get the manually selected roi
        init_roi = self.imageDisplayWindow.get_roi_bounding_box()
        self.tracker.set_roi_bbox(init_roi)

        # tracking loop
        while self.trackingController.flag_stop_tracking_requested == False:

            print('tracking_frame_counter: ' + str(tracking_frame_counter) )
            if tracking_frame_counter == 0:
                is_first_frame = True
            else:
                is_first_frame = False

            # timestamp
            timestamp_last_frame = time.time()

            # switch to the tracking config
            config = self.selected_configurations[0]
            self.signal_current_configuration.emit(config)
            self.wait_till_operation_is_completed()

            # do autofocus 
            if self.trackingController.flag_AF_enabled and tracking_frame_counter > 1:
                # do autofocus
                print('>>> autofocus')
                self.autofocusController.autofocus()
                self.autofocusController.wait_till_autofocus_has_completed()
                print('>>> autofocus completed')

            # get current position
            x_stage = self.navigationController.x_pos_mm
            y_stage = self.navigationController.y_pos_mm
            z_stage = self.navigationController.z_pos_mm

            # grab an image
            config = self.selected_configurations[0]
            if(self.number_of_selected_configurations > 1):
                self.signal_current_configuration.emit(config)
                self.wait_till_operation_is_completed()
                self.liveController.turn_on_illumination()        # keep illumination on for single configuration acqusition
                self.wait_till_operation_is_completed()
            t = time.time()
            self.camera.send_trigger() 
            image = self.camera.read_frame()
            if(self.number_of_selected_configurations > 1):
                self.liveController.turn_off_illumination()       # keep illumination on for single configuration acqusition
            # image crop, rotation and flip
            image = utils.crop_image(image,self.crop_width,self.crop_height)
            image = np.squeeze(image)
            image = utils.rotate_and_flip_image(image,rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
            # get image size
            image_shape = image.shape
            image_center = np.array([image_shape[1]*0.5,image_shape[0]*0.5])

            # image the rest configurations
            for config_ in self.selected_configurations[1:]:
                self.signal_current_configuration.emit(config_)
                self.wait_till_operation_is_completed()
                self.liveController.turn_on_illumination()
                self.wait_till_operation_is_completed()
                self.camera.send_trigger() 
                image_ = self.camera.read_frame()
                self.liveController.turn_off_illumination()
                image_ = utils.crop_image(image_,self.crop_width,self.crop_height)
                image_ = np.squeeze(image_)
                image_ = utils.rotate_and_flip_image(image_,rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
                # display image
                # self.image_to_display.emit(cv2.resize(image,(round(self.crop_width*self.display_resolution_scaling), round(self.crop_height*self.display_resolution_scaling)),cv2.INTER_LINEAR))
                image_to_display_ = utils.crop_image(image_,round(self.crop_width*self.liveController.display_resolution_scaling), round(self.crop_height*self.liveController.display_resolution_scaling))
                # self.image_to_display.emit(image_to_display_)
                self.image_to_display_multi.emit(image_to_display_,config_.illumination_source)
                # save image
                if self.trackingController.flag_save_image:
                    if self.camera.is_color:
                        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)
                    self.image_saver.enqueue(image_,tracking_frame_counter,str(config_.name))

            # track
            objectFound,centroid,rect_pts = self.tracker.track(image, None, is_first_frame = is_first_frame)
            if objectFound == False:
                print('')
                break
            in_plane_position_error_pixel = image_center - centroid 
            in_plane_position_error_mm = in_plane_position_error_pixel*self.trackingController.pixel_size_um_scaled/1000
            x_error_mm = in_plane_position_error_mm[0]
            y_error_mm = in_plane_position_error_mm[1]

            # display the new bounding box and the image
            self.imageDisplayWindow.update_bounding_box(rect_pts)
            self.imageDisplayWindow.display_image(image)

            # move
            if self.trackingController.flag_stage_tracking_enabled:
                x_correction_usteps = int(x_error_mm/(SCREW_PITCH_X_MM/FULLSTEPS_PER_REV_X/self.navigationController.x_microstepping))
                y_correction_usteps = int(y_error_mm/(SCREW_PITCH_Y_MM/FULLSTEPS_PER_REV_Y/self.navigationController.y_microstepping))
                self.microcontroller.move_x_usteps(TRACKING_MOVEMENT_SIGN_X*x_correction_usteps)
                self.microcontroller.move_y_usteps(TRACKING_MOVEMENT_SIGN_Y*y_correction_usteps) 

            # save image
            if self.trackingController.flag_save_image:
                self.image_saver.enqueue(image,tracking_frame_counter,str(config.name))

            # save position data            
            # self.csv_file.write('dt (s), x_stage (mm), y_stage (mm), z_stage (mm), x_image (mm), y_image(mm), image_filename\n')
            self.csv_file.write(str(t)+','+str(x_stage)+','+str(y_stage)+','+str(z_stage)+','+str(x_error_mm)+','+str(y_error_mm)+','+str(tracking_frame_counter)+'\n')
            if tracking_frame_counter%100 == 0:
                self.csv_file.flush()

            # wait for movement to complete
            self.wait_till_operation_is_completed() # to do - make sure both x movement and y movement are complete

            # wait till tracking interval has elapsed
            while(time.time() - timestamp_last_frame < self.trackingController.tracking_time_interval_s):
                time.sleep(0.005)

            # increament counter 
            tracking_frame_counter = tracking_frame_counter + 1

        # tracking terminated
        self.csv_file.close()
        self.image_saver.close()
        self.finished.emit()

    def wait_till_operation_is_completed(self):
        while self.microcontroller.is_busy():
            time.sleep(SLEEP_TIME_S)


class ImageDisplayWindow(QMainWindow):

    image_click_coordinates = Signal(int, int, int, int)

    def __init__(self, window_title='', draw_crosshairs = False, show_LUT=False, autoLevels=False):
        super().__init__()
        self.setWindowTitle(window_title)
        self.setWindowFlags(self.windowFlags() | Qt.CustomizeWindowHint)
        self.setWindowFlags(self.windowFlags() & ~Qt.WindowCloseButtonHint)
        self.widget = QWidget()
        self.show_LUT = show_LUT
        self.autoLevels = autoLevels

        # interpret image data as row-major instead of col-major
        pg.setConfigOptions(imageAxisOrder='row-major')

        self.graphics_widget = pg.GraphicsLayoutWidget()
        self.graphics_widget.view = self.graphics_widget.addViewBox()
        self.graphics_widget.view.invertY()
        
        ## lock the aspect ratio so pixels are always square
        self.graphics_widget.view.setAspectLocked(True)
        
        ## Create image item
        if self.show_LUT:
            self.graphics_widget.view = pg.ImageView()
            self.graphics_widget.img = self.graphics_widget.view.getImageItem()
            self.graphics_widget.img.setBorder('w')
            self.graphics_widget.view.ui.roiBtn.hide()
            self.graphics_widget.view.ui.menuBtn.hide()
            # self.LUTWidget = self.graphics_widget.view.getHistogramWidget()
            # self.LUTWidget.autoHistogramRange()
            # self.graphics_widget.view.autolevels()
        else:
            self.graphics_widget.img = pg.ImageItem(border='w')
            self.graphics_widget.view.addItem(self.graphics_widget.img)

        ## Create ROI
        self.roi_pos = (500,500)
        self.roi_size = (500,500)
        self.ROI = pg.ROI(self.roi_pos, self.roi_size, scaleSnap=True, translateSnap=True)
        self.ROI.setZValue(10)
        self.ROI.addScaleHandle((0,0), (1,1))
        self.ROI.addScaleHandle((1,1), (0,0))
        self.graphics_widget.view.addItem(self.ROI)
        self.ROI.hide()
        self.ROI.sigRegionChanged.connect(self.update_ROI)
        self.roi_pos = self.ROI.pos()
        self.roi_size = self.ROI.size()

        ## Variables for annotating images
        self.draw_rectangle = False
        self.ptRect1 = None
        self.ptRect2 = None
        self.DrawCirc = False
        self.centroid = None
        self.DrawCrossHairs = False
        self.image_offset = np.array([0, 0])

        ## Layout
        layout = QGridLayout()
        if self.show_LUT:
            layout.addWidget(self.graphics_widget.view, 0, 0) 
        else:
            layout.addWidget(self.graphics_widget, 0, 0) 
        self.widget.setLayout(layout)
        self.setCentralWidget(self.widget)

        # set window size
        desktopWidget = QDesktopWidget();
        width = min(desktopWidget.height()*0.9,1000) #@@@TO MOVE@@@#
        height = width
        self.setFixedSize(int(width),int(height))
        if self.show_LUT:
            self.graphics_widget.view.getView().scene().sigMouseClicked.connect(self.mouse_clicked)
        else:
            self.graphics_widget.view.scene().sigMouseClicked.connect(self.mouse_clicked)
        
    def is_within_image(self, coordinates):
        try:
            image_width = self.graphics_widget.img.width()
            image_height = self.graphics_widget.img.height()

            return 0 <= coordinates.x() < image_width and 0 <= coordinates.y() < image_height
        except:
            return False

    def mouse_clicked(self, evt):
        try:
            pos = evt.pos()
            if self.show_LUT:
                view_coord = self.graphics_widget.view.getView().mapSceneToView(pos)
            else:
                view_coord = self.graphics_widget.view.mapSceneToView(pos)
            image_coord = self.graphics_widget.img.mapFromView(view_coord)
        except:
            return

        if self.is_within_image(image_coord):
            x_pixel_centered = int(image_coord.x() - self.graphics_widget.img.width()/2)
            y_pixel_centered = int(image_coord.y() - self.graphics_widget.img.height()/2)
            self.image_click_coordinates.emit(x_pixel_centered, y_pixel_centered, self.graphics_widget.img.width(), self.graphics_widget.img.height()) 

    def display_image(self,image):
        if ENABLE_TRACKING:
            image = np.copy(image)
            self.image_height = image.shape[0],
            self.image_width = image.shape[1]
            if(self.draw_rectangle):
                cv2.rectangle(image, self.ptRect1, self.ptRect2,(255,255,255) , 4)
                self.draw_rectangle = False
            self.graphics_widget.img.setImage(image,autoLevels=self.autoLevels)
        else:
            self.graphics_widget.img.setImage(image,autoLevels=self.autoLevels)

    def update_ROI(self):
        self.roi_pos = self.ROI.pos()
        self.roi_size = self.ROI.size()

    def show_ROI_selector(self):
        self.ROI.show()

    def hide_ROI_selector(self):
        self.ROI.hide()

    def get_roi(self):
        return self.roi_pos,self.roi_size

    def update_bounding_box(self,pts):
        self.draw_rectangle=True
        self.ptRect1=(pts[0][0],pts[0][1])
        self.ptRect2=(pts[1][0],pts[1][1])

    def get_roi_bounding_box(self):
        self.update_ROI()
        width = self.roi_size[0]
        height = self.roi_size[1]
        xmin = max(0, self.roi_pos[0])
        ymin = max(0, self.roi_pos[1])
        return np.array([xmin, ymin, width, height])

    def set_autolevel(self,enabled):
        self.autoLevels = enabled
        print('set autolevel to ' + str(enabled))

class NavigationViewer(QFrame):

    def __init__(self, sample = 'glass slide', invertX = False, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

        # interpret image data as row-major instead of col-major
        pg.setConfigOptions(imageAxisOrder='row-major')
        self.graphics_widget = pg.GraphicsLayoutWidget()
        self.graphics_widget.setBackground("w")
        self.graphics_widget.view = self.graphics_widget.addViewBox(invertX=invertX,invertY=True)
        ## lock the aspect ratio so pixels are always square
        self.graphics_widget.view.setAspectLocked(True)
        ## Create image item
        self.graphics_widget.img = pg.ImageItem(border='w')
        self.graphics_widget.view.addItem(self.graphics_widget.img)

        self.grid = QVBoxLayout()
        self.grid.addWidget(self.graphics_widget)
        self.setLayout(self.grid)

        if sample == 'glass slide':
            self.background_image = cv2.imread('images/slide carrier_828x662.png')
        elif sample == '384 well plate':
            self.background_image = cv2.imread('images/384 well plate_1509x1010.png')
        elif sample == '96 well plate':
            self.background_image = cv2.imread('images/96 well plate_1509x1010.png')
        elif sample == '24 well plate':
            self.background_image = cv2.imread('images/24 well plate_1509x1010.png')
        elif sample == '12 well plate':
            self.background_image = cv2.imread('images/12 well plate_1509x1010.png')
        elif sample == '6 well plate':
            self.background_image = cv2.imread('images/6 well plate_1509x1010.png')
        elif sample == '1536 well plate':
            self.background_image = cv2.imread('images/1536 well plate_1509x1010.png')
        
        self.current_image = np.copy(self.background_image)
        self.current_image_display = np.copy(self.background_image)
        self.image_height = self.background_image.shape[0]
        self.image_width = self.background_image.shape[1]

        self.location_update_threshold_mm = 0.2
        self.sample = sample

        if sample == 'glass slide':
            self.origin_x_pixel = 200
            self.origin_y_pixel = 120
            self.mm_per_pixel = 0.1453
            self.fov_size_mm = 3000*1.85/(50/9)/1000
        else:
            self.location_update_threshold_mm = 0.05
            self.mm_per_pixel = 0.084665
            self.fov_size_mm = 3000*1.85/(50/10)/1000
            self.origin_x_pixel = A1_X_PIXEL - (A1_X_MM)/self.mm_per_pixel
            self.origin_y_pixel = A1_Y_PIXEL - (A1_Y_MM)/self.mm_per_pixel

        self.box_color = (255, 0, 0)
        self.box_line_thickness = 2

        self.x_mm = None
        self.y_mm = None

        self.update_display()

    def update_current_location(self,x_mm,y_mm):
        if self.x_mm != None and self.y_mm != None:
            # update only when the displacement has exceeded certain value
            if abs(x_mm - self.x_mm) > self.location_update_threshold_mm or abs(y_mm - self.y_mm) > self.location_update_threshold_mm:
                self.draw_current_fov(x_mm,y_mm)
                self.update_display()
                self.x_mm = x_mm
                self.y_mm = y_mm
        else:
            self.draw_current_fov(x_mm,y_mm)
            self.update_display()
            self.x_mm = x_mm
            self.y_mm = y_mm

    def draw_current_fov(self,x_mm,y_mm):
        self.current_image_display = np.copy(self.current_image)
        if self.sample == 'glass slide':
            current_FOV_top_left = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel - self.fov_size_mm/2/self.mm_per_pixel),
                                    round(self.image_height - (self.origin_y_pixel + y_mm/self.mm_per_pixel) - self.fov_size_mm/2/self.mm_per_pixel))
            current_FOV_bottom_right = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel + self.fov_size_mm/2/self.mm_per_pixel),
                                    round(self.image_height - (self.origin_y_pixel + y_mm/self.mm_per_pixel) + self.fov_size_mm/2/self.mm_per_pixel))
        else:
            current_FOV_top_left = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel - self.fov_size_mm/2/self.mm_per_pixel),
                                    round((self.origin_y_pixel + y_mm/self.mm_per_pixel) - self.fov_size_mm/2/self.mm_per_pixel))
            current_FOV_bottom_right = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel + self.fov_size_mm/2/self.mm_per_pixel),
                                    round((self.origin_y_pixel + y_mm/self.mm_per_pixel) + self.fov_size_mm/2/self.mm_per_pixel))
        cv2.rectangle(self.current_image_display, current_FOV_top_left, current_FOV_bottom_right, self.box_color, self.box_line_thickness)

    def update_display(self):
        self.graphics_widget.img.setImage(self.current_image_display,autoLevels=False)

    def clear_slide(self):
        self.current_image = np.copy(self.background_image)
        self.current_image_display = np.copy(self.background_image)
        self.update_display()

    def register_fov(self,x_mm,y_mm):
        color = (0,0,255)
        if self.sample == 'glass slide':
            current_FOV_top_left = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel - self.fov_size_mm/2/self.mm_per_pixel),
                                    round(self.image_height - (self.origin_y_pixel + y_mm/self.mm_per_pixel) - self.fov_size_mm/2/self.mm_per_pixel))
            current_FOV_bottom_right = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel + self.fov_size_mm/2/self.mm_per_pixel),
                                    round(self.image_height - (self.origin_y_pixel + y_mm/self.mm_per_pixel) + self.fov_size_mm/2/self.mm_per_pixel))
        else:
            current_FOV_top_left = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel - self.fov_size_mm/2/self.mm_per_pixel),
                                    round((self.origin_y_pixel + y_mm/self.mm_per_pixel) - self.fov_size_mm/2/self.mm_per_pixel))
            current_FOV_bottom_right = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel + self.fov_size_mm/2/self.mm_per_pixel),
                                    round((self.origin_y_pixel + y_mm/self.mm_per_pixel) + self.fov_size_mm/2/self.mm_per_pixel))
        cv2.rectangle(self.current_image, current_FOV_top_left, current_FOV_bottom_right, color, self.box_line_thickness)

    def register_fov_to_image(self,x_mm,y_mm):
        color = (252,174,30)
        if self.sample == 'glass slide':
            current_FOV_top_left = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel - self.fov_size_mm/2/self.mm_per_pixel),
                                    round(self.image_height - (self.origin_y_pixel + y_mm/self.mm_per_pixel) - self.fov_size_mm/2/self.mm_per_pixel))
            current_FOV_bottom_right = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel + self.fov_size_mm/2/self.mm_per_pixel),
                                    round(self.image_height - (self.origin_y_pixel + y_mm/self.mm_per_pixel) + self.fov_size_mm/2/self.mm_per_pixel))
        else:
            current_FOV_top_left = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel - self.fov_size_mm/2/self.mm_per_pixel),
                                    round((self.origin_y_pixel + y_mm/self.mm_per_pixel) - self.fov_size_mm/2/self.mm_per_pixel))
            current_FOV_bottom_right = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel + self.fov_size_mm/2/self.mm_per_pixel),
                                    round((self.origin_y_pixel + y_mm/self.mm_per_pixel) + self.fov_size_mm/2/self.mm_per_pixel))
        cv2.rectangle(self.current_image, current_FOV_top_left, current_FOV_bottom_right, color, self.box_line_thickness)

    def deregister_fov_to_image(self,x_mm,y_mm):
        color = (255,255,255)
        if self.sample == 'glass slide':
            current_FOV_top_left = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel - self.fov_size_mm/2/self.mm_per_pixel),
                                    round(self.image_height - (self.origin_y_pixel + y_mm/self.mm_per_pixel) - self.fov_size_mm/2/self.mm_per_pixel))
            current_FOV_bottom_right = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel + self.fov_size_mm/2/self.mm_per_pixel),
                                    round(self.image_height - (self.origin_y_pixel + y_mm/self.mm_per_pixel) + self.fov_size_mm/2/self.mm_per_pixel))
        else:
            current_FOV_top_left = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel - self.fov_size_mm/2/self.mm_per_pixel),
                                    round((self.origin_y_pixel + y_mm/self.mm_per_pixel) - self.fov_size_mm/2/self.mm_per_pixel))
            current_FOV_bottom_right = (round(self.origin_x_pixel + x_mm/self.mm_per_pixel + self.fov_size_mm/2/self.mm_per_pixel),
                                    round((self.origin_y_pixel + y_mm/self.mm_per_pixel) + self.fov_size_mm/2/self.mm_per_pixel))
        cv2.rectangle(self.current_image, current_FOV_top_left, current_FOV_bottom_right, color, self.box_line_thickness)


class ImageArrayDisplayWindow(QMainWindow):

    def __init__(self, window_title=''):
        super().__init__()
        self.setWindowTitle(window_title)
        self.setWindowFlags(self.windowFlags() | Qt.CustomizeWindowHint)
        self.setWindowFlags(self.windowFlags() & ~Qt.WindowCloseButtonHint)
        self.widget = QWidget()

        # interpret image data as row-major instead of col-major
        pg.setConfigOptions(imageAxisOrder='row-major')

        self.graphics_widget_1 = pg.GraphicsLayoutWidget()
        self.graphics_widget_1.view = self.graphics_widget_1.addViewBox()
        self.graphics_widget_1.view.setAspectLocked(True)
        self.graphics_widget_1.img = pg.ImageItem(border='w')
        self.graphics_widget_1.view.addItem(self.graphics_widget_1.img) 
        self.graphics_widget_1.view.invertY()

        self.graphics_widget_2 = pg.GraphicsLayoutWidget()
        self.graphics_widget_2.view = self.graphics_widget_2.addViewBox()
        self.graphics_widget_2.view.setAspectLocked(True)
        self.graphics_widget_2.img = pg.ImageItem(border='w')
        self.graphics_widget_2.view.addItem(self.graphics_widget_2.img)
        self.graphics_widget_2.view.invertY()

        self.graphics_widget_3 = pg.GraphicsLayoutWidget()
        self.graphics_widget_3.view = self.graphics_widget_3.addViewBox()
        self.graphics_widget_3.view.setAspectLocked(True)
        self.graphics_widget_3.img = pg.ImageItem(border='w')
        self.graphics_widget_3.view.addItem(self.graphics_widget_3.img)
        self.graphics_widget_3.view.invertY()

        self.graphics_widget_4 = pg.GraphicsLayoutWidget()
        self.graphics_widget_4.view = self.graphics_widget_4.addViewBox()
        self.graphics_widget_4.view.setAspectLocked(True)
        self.graphics_widget_4.img = pg.ImageItem(border='w')
        self.graphics_widget_4.view.addItem(self.graphics_widget_4.img)
        self.graphics_widget_4.view.invertY()
        ## Layout
        layout = QGridLayout()
        layout.addWidget(self.graphics_widget_1, 0, 0)
        layout.addWidget(self.graphics_widget_2, 0, 1)
        layout.addWidget(self.graphics_widget_3, 1, 0)
        layout.addWidget(self.graphics_widget_4, 1, 1) 
        self.widget.setLayout(layout)
        self.setCentralWidget(self.widget)

        # set window size
        desktopWidget = QDesktopWidget();
        width = min(desktopWidget.height()*0.9,1000) #@@@TO MOVE@@@#
        height = width
        self.setFixedSize(int(width),int(height))

    def display_image(self,image,illumination_source):
        if illumination_source < 11:
            self.graphics_widget_1.img.setImage(image,autoLevels=False)
        elif illumination_source == 11:
            self.graphics_widget_2.img.setImage(image,autoLevels=False)
        elif illumination_source == 12:
            self.graphics_widget_3.img.setImage(image,autoLevels=False)
        elif illumination_source == 13:
            self.graphics_widget_4.img.setImage(image,autoLevels=False)

class ConfigurationManager(QObject):
    def __init__(self,filename="channel_configurations.xml"):
        QObject.__init__(self)
        self.config_filename = filename
        self.configurations = []
        self.read_configurations()
        
    def save_configurations(self):
        self.write_configuration(self.config_filename)

    def write_configuration(self,filename):
        self.config_xml_tree.write(filename, encoding="utf-8", xml_declaration=True, pretty_print=True)

    def read_configurations(self):
        print('read config')
        if(os.path.isfile(self.config_filename)==False):
            utils_config.generate_default_configuration(self.config_filename)
            print('genenrate default config files')
        self.config_xml_tree = ET.parse(self.config_filename)
        self.config_xml_tree_root = self.config_xml_tree.getroot()
        self.num_configurations = 0
        for mode in self.config_xml_tree_root.iter('mode'):
            self.num_configurations += 1
            print("name:", mode.get('Name'), "color:", self.get_channel_color(mode.get('Name')))
            self.configurations.append(
                Configuration(
                    mode_id = mode.get('ID'),
                    name = mode.get('Name'),
                    color = self.get_channel_color(mode.get('Name')),
                    exposure_time = float(mode.get('ExposureTime')),
                    analog_gain = float(mode.get('AnalogGain')),
                    illumination_source = int(mode.get('IlluminationSource')),
                    illumination_intensity = float(mode.get('IlluminationIntensity')),
                    camera_sn = mode.get('CameraSN'),
                    z_offset = float(mode.get('ZOffset')),
                    pixel_format = mode.get('PixelFormat'),
                    _pixel_format_options = mode.get('_PixelFormat_options'),
                    emission_filter_position = int(mode.get('EmissionFilterPosition', 1))
                )
            )

    def update_configuration(self,configuration_id,attribute_name,new_value):
        conf_list = self.config_xml_tree_root.xpath("//mode[contains(@ID," + "'" + str(configuration_id) + "')]")
        mode_to_update = conf_list[0]
        mode_to_update.set(attribute_name,str(new_value))
        self.save_configurations()

    def update_configuration_without_writing(self, configuration_id, attribute_name, new_value):
        conf_list = self.config_xml_tree_root.xpath("//mode[contains(@ID," + "'" + str(configuration_id) + "')]")
        mode_to_update = conf_list[0]
        mode_to_update.set(attribute_name,str(new_value))

    def write_configuration_selected(self,selected_configurations,filename): # to be only used with a throwaway instance
        for conf in self.configurations:
            self.update_configuration_without_writing(conf.id, "Selected", 0)
        for conf in selected_configurations:
            self.update_configuration_without_writing(conf.id, "Selected", 1)
        self.write_configuration(filename)
        for conf in selected_configurations:
            self.update_configuration_without_writing(conf.id, "Selected", 0)

    def get_channel_color(self, channel):
        channel_info = CHANNEL_COLORS_MAP.get(self.extract_wavelength(channel), {'hex': 0xFFFFFF, 'name': 'gray'})
        return channel_info['hex']

    def extract_wavelength(self, name):
        # Split the string and find the wavelength number immediately after "Fluorescence"
        parts = name.split()
        if 'Fluorescence' in parts:
            index = parts.index('Fluorescence') + 1
            if index < len(parts):
                return parts[index].split()[0]  # Assuming 'Fluorescence 488 nm Ex' and taking '488'
        for color in ['R', 'G', 'B']:
            if color in parts or "full_" + color in parts:
                return color
        return None

class PlateReaderNavigationController(QObject):

    signal_homing_complete = Signal()
    signal_current_well = Signal(str)

    def __init__(self,microcontroller):
        QObject.__init__(self)
        self.microcontroller = microcontroller
        self.x_pos_mm = 0
        self.y_pos_mm = 0
        self.z_pos_mm = 0
        self.z_pos = 0
        self.x_microstepping = MICROSTEPPING_DEFAULT_X
        self.y_microstepping = MICROSTEPPING_DEFAULT_Y
        self.z_microstepping = MICROSTEPPING_DEFAULT_Z
        self.column = ''
        self.row = ''

        # to be moved to gui for transparency
        self.microcontroller.set_callback(self.update_pos)

        self.is_homing = False
        self.is_scanning = False

    def move_x_usteps(self,usteps):
        self.microcontroller.move_x_usteps(usteps)

    def move_y_usteps(self,usteps):
        self.microcontroller.move_y_usteps(usteps)

    def move_z_usteps(self,usteps):
        self.microcontroller.move_z_usteps(usteps)

    def move_x_to_usteps(self,usteps):
        self.microcontroller.move_x_to_usteps(usteps)

    def move_y_to_usteps(self,usteps):
        self.microcontroller.move_y_to_usteps(usteps)

    def move_z_to_usteps(self,usteps):
        self.microcontroller.move_z_to_usteps(usteps)

    def moveto(self,column,row):
        if column != '':
            mm_per_ustep_X = SCREW_PITCH_X_MM/(self.x_microstepping*FULLSTEPS_PER_REV_X)
            x_mm = PLATE_READER.OFFSET_COLUMN_1_MM + (int(column)-1)*PLATE_READER.COLUMN_SPACING_MM
            x_usteps = STAGE_MOVEMENT_SIGN_X*round(x_mm/mm_per_ustep_X)
            self.move_x_to_usteps(x_usteps)
        if row != '':
            mm_per_ustep_Y = SCREW_PITCH_Y_MM/(self.y_microstepping*FULLSTEPS_PER_REV_Y)
            y_mm = PLATE_READER.OFFSET_ROW_A_MM + (ord(row) - ord('A'))*PLATE_READER.ROW_SPACING_MM
            y_usteps = STAGE_MOVEMENT_SIGN_Y*round(y_mm/mm_per_ustep_Y)
            self.move_y_to_usteps(y_usteps)

    def moveto_row(self,row):
        # row: int, starting from 0
        mm_per_ustep_Y = SCREW_PITCH_Y_MM/(self.y_microstepping*FULLSTEPS_PER_REV_Y)
        y_mm = PLATE_READER.OFFSET_ROW_A_MM + row*PLATE_READER.ROW_SPACING_MM
        y_usteps = round(y_mm/mm_per_ustep_Y)
        self.move_y_to_usteps(y_usteps)

    def moveto_column(self,column):
        # column: int, starting from 0
        mm_per_ustep_X = SCREW_PITCH_X_MM/(self.x_microstepping*FULLSTEPS_PER_REV_X)
        x_mm = PLATE_READER.OFFSET_COLUMN_1_MM + column*PLATE_READER.COLUMN_SPACING_MM
        x_usteps = round(x_mm/mm_per_ustep_X)
        self.move_x_to_usteps(x_usteps)

    def update_pos(self,microcontroller):
        # get position from the microcontroller
        x_pos, y_pos, z_pos, theta_pos = microcontroller.get_pos()
        self.z_pos = z_pos
        # calculate position in mm or rad
        if USE_ENCODER_X:
            self.x_pos_mm = x_pos*STAGE_POS_SIGN_X*ENCODER_STEP_SIZE_X_MM
        else:
            self.x_pos_mm = x_pos*STAGE_POS_SIGN_X*(SCREW_PITCH_X_MM/(self.x_microstepping*FULLSTEPS_PER_REV_X))
        if USE_ENCODER_Y:
            self.y_pos_mm = y_pos*STAGE_POS_SIGN_Y*ENCODER_STEP_SIZE_Y_MM
        else:
            self.y_pos_mm = y_pos*STAGE_POS_SIGN_Y*(SCREW_PITCH_Y_MM/(self.y_microstepping*FULLSTEPS_PER_REV_Y))
        if USE_ENCODER_Z:
            self.z_pos_mm = z_pos*STAGE_POS_SIGN_Z*ENCODER_STEP_SIZE_Z_MM
        else:
            self.z_pos_mm = z_pos*STAGE_POS_SIGN_Z*(SCREW_PITCH_Z_MM/(self.z_microstepping*FULLSTEPS_PER_REV_Z))
        # check homing status
        if self.is_homing and self.microcontroller.mcu_cmd_execution_in_progress == False:
            self.signal_homing_complete.emit()
        # for debugging
        # print('X: ' + str(self.x_pos_mm) + ' Y: ' + str(self.y_pos_mm))
        # check and emit current position
        column = round((self.x_pos_mm - PLATE_READER.OFFSET_COLUMN_1_MM)/PLATE_READER.COLUMN_SPACING_MM)
        if column >= 0 and column <= PLATE_READER.NUMBER_OF_COLUMNS:
            column = str(column+1)
        else:
            column = ' '
        row = round((self.y_pos_mm - PLATE_READER.OFFSET_ROW_A_MM)/PLATE_READER.ROW_SPACING_MM)
        if row >= 0 and row <= PLATE_READER.NUMBER_OF_ROWS:
            row = chr(ord('A')+row)
        else:
            row = ' '

        if self.is_scanning:
            self.signal_current_well.emit(row+column)

    def home(self):
        self.is_homing = True
        self.microcontroller.home_xy()

    def home_x(self):
        self.microcontroller.home_x()

    def home_y(self):
        self.microcontroller.home_y()

class ScanCoordinates(object):
    def __init__(self):
        self.coordinates_mm = []
        self.name = []
        self.well_selector = None

    def _index_to_row(self,index):
        index += 1
        row = ""
        while index > 0:
            index -= 1
            row = chr(index % 26 + ord('A')) + row
            index //= 26
        return row

    def add_well_selector(self,well_selector):
        self.well_selector = well_selector

    def get_selected_wells(self):
        # get selected wells from the widget
        selected_wells = self.well_selector.get_selected_cells()
        selected_wells = np.array(selected_wells)
        # clear the previous selection
        self.coordinates_mm = []
        self.name = []
        if len(selected_wells) == 0:
            return
        # populate the coordinates
        rows = np.unique(selected_wells[:,0])
        _increasing = True
        for row in rows:
            items = selected_wells[selected_wells[:,0]==row]
            columns = items[:,1]
            columns = np.sort(columns)
            if _increasing==False:
                columns = np.flip(columns)
            for column in columns:
                x_mm = A1_X_MM + column*WELL_SPACING_MM + WELLPLATE_OFFSET_X_mm
                y_mm = A1_Y_MM + row*WELL_SPACING_MM + WELLPLATE_OFFSET_Y_mm
                self.coordinates_mm.append((x_mm,y_mm))
                self.name.append(self._index_to_row(row)+str(column+1))
            _increasing = not _increasing


class LaserAutofocusController(QObject):

    image_to_display = Signal(np.ndarray)
    signal_displacement_um = Signal(float)

    def __init__(self,microcontroller,camera,liveController,navigationController,has_two_interfaces=True,use_glass_top=True, look_for_cache=True):
        QObject.__init__(self)
        self.microcontroller = microcontroller
        self.camera = camera
        self.liveController = liveController
        self.navigationController = navigationController

        self.is_initialized = False
        self.x_reference = 0
        self.pixel_to_um = 1
        self.x_offset = 0
        self.y_offset = 0
        self.x_width = 3088
        self.y_width = 2064

        self.has_two_interfaces = has_two_interfaces # e.g. air-glass and glass water, set to false when (1) using oil immersion (2) using 1 mm thick slide (3) using metal coated slide or Si wafer
        self.use_glass_top = use_glass_top
        self.spot_spacing_pixels = None # spacing between the spots from the two interfaces (unit: pixel)
        
        self.look_for_cache = look_for_cache

        self.image = None # for saving the focus camera image for debugging when centroid cannot be found

        if look_for_cache:
            cache_path = "cache/laser_af_reference_plane.txt"
            try:
                with open(cache_path, "r") as cache_file:
                    for line in cache_file:
                        value_list = line.split(",")
                        x_offset = float(value_list[0])
                        y_offset = float(value_list[1])
                        width = int(value_list[2])
                        height = int(value_list[3])
                        pixel_to_um = float(value_list[4])
                        x_reference = float(value_list[5])
                        self.initialize_manual(x_offset,y_offset,width,height,pixel_to_um,x_reference)
                        break
            except (FileNotFoundError, ValueError,IndexError) as e:
                print("Unable to read laser AF state cache, exception below:")
                print(e)
                pass

    def initialize_manual(self, x_offset, y_offset, width, height, pixel_to_um, x_reference, write_to_cache=True):
        cache_string = ",".join([str(x_offset),str(y_offset), str(width),str(height), str(pixel_to_um), str(x_reference)])
        if write_to_cache:
            cache_path = Path("cache/laser_af_reference_plane.txt")
            cache_path.parent.mkdir(parents=True, exist_ok=True)
            cache_path.write_text(cache_string)
        # x_reference is relative to the full sensor
        self.pixel_to_um = pixel_to_um
        self.x_offset = int((x_offset//8)*8)
        self.y_offset = int((y_offset//2)*2)
        self.width = int((width//8)*8)
        self.height = int((height//2)*2)
        self.x_reference = x_reference - self.x_offset # self.x_reference is relative to the cropped region
        self.camera.set_ROI(self.x_offset,self.y_offset,self.width,self.height)
        self.is_initialized = True

    def initialize_auto(self):

        # first find the region to crop
        # then calculate the convert factor

        # set camera to use full sensor
        self.camera.set_ROI(0,0,None,None) # set offset first
        self.camera.set_ROI(0,0,3088,2064)
        # update camera settings
        self.camera.set_exposure_time(FOCUS_CAMERA_EXPOSURE_TIME_MS)
        self.camera.set_analog_gain(FOCUS_CAMERA_ANALOG_GAIN)
        
        # turn on the laser
        self.microcontroller.turn_on_AF_laser()
        self.wait_till_operation_is_completed()

        # get laser spot location
        x,y = self._get_laser_spot_centroid()

        # turn off the laser
        self.microcontroller.turn_off_AF_laser()
        self.wait_till_operation_is_completed()

        x_offset = x - LASER_AF_CROP_WIDTH/2
        y_offset = y - LASER_AF_CROP_HEIGHT/2
        print('laser spot location on the full sensor is (' + str(int(x)) + ',' + str(int(y)) + ')')

        # set camera crop
        self.initialize_manual(x_offset, y_offset, LASER_AF_CROP_WIDTH, LASER_AF_CROP_HEIGHT, 1, x)

        # turn on laser 
        self.microcontroller.turn_on_AF_laser()
        self.wait_till_operation_is_completed()

        # move z to - 6 um
        self.navigationController.move_z(-0.018)
        self.wait_till_operation_is_completed()
        self.navigationController.move_z(0.012)
        self.wait_till_operation_is_completed()
        time.sleep(0.02)

        # measure
        x0,y0 = self._get_laser_spot_centroid()

        # move z to 6 um
        self.navigationController.move_z(0.006)
        self.wait_till_operation_is_completed()
        time.sleep(0.02)

        # measure
        x1,y1 = self._get_laser_spot_centroid()

        # turn off laser
        self.microcontroller.turn_off_AF_laser()
        self.wait_till_operation_is_completed()

        if x1-x0 == 0:
            # for simulation
             self.pixel_to_um = 0.4
        else:
            # calculate the conversion factor
            self.pixel_to_um = 6.0/(x1-x0)
        print('pixel to um conversion factor is ' + str(self.pixel_to_um) + ' um/pixel')

        # set reference
        self.x_reference = x1

        if self.look_for_cache:
            cache_path = "cache/laser_af_reference_plane.txt"
            try:
                x_offset = None
                y_offset = None
                width = None
                height = None
                pixel_to_um = None
                x_reference = None
                with open(cache_path, "r") as cache_file:
                    for line in cache_file:
                        value_list = line.split(",")
                        x_offset = float(value_list[0])
                        y_offset = float(value_list[1])
                        width = int(value_list[2])
                        height = int(value_list[3])
                        pixel_to_um = self.pixel_to_um
                        x_reference = self.x_reference+self.x_offset
                        break
                cache_string = ",".join([str(x_offset),str(y_offset), str(width),str(height), str(pixel_to_um), str(x_reference)])
                cache_path = Path("cache/laser_af_reference_plane.txt")
                cache_path.parent.mkdir(parents=True, exist_ok=True)
                cache_path.write_text(cache_string)
            except (FileNotFoundError, ValueError,IndexError) as e:
                print("Unable to read laser AF state cache, exception below:")
                print(e)
                pass

    def measure_displacement(self):
        # turn on the laser
        self.microcontroller.turn_on_AF_laser()
        self.wait_till_operation_is_completed()
        # get laser spot location
        x,y = self._get_laser_spot_centroid()
        # turn off the laser
        self.microcontroller.turn_off_AF_laser()
        self.wait_till_operation_is_completed()
        # calculate displacement
        displacement_um = (x - self.x_reference)*self.pixel_to_um
        self.signal_displacement_um.emit(displacement_um)
        return displacement_um

    def move_to_target(self,target_um):
        current_displacement_um = self.measure_displacement()
        um_to_move = target_um - current_displacement_um
        # limit the range of movement
        um_to_move = min(um_to_move,200)
        um_to_move = max(um_to_move,-200)
        self.navigationController.move_z(um_to_move/1000)
        self.wait_till_operation_is_completed()
        # update the displacement measurement
        self.measure_displacement()

    def set_reference(self):
        # turn on the laser
        self.microcontroller.turn_on_AF_laser()
        self.wait_till_operation_is_completed()
        # get laser spot location
        x,y = self._get_laser_spot_centroid()
        # turn off the laser
        self.microcontroller.turn_off_AF_laser()
        self.wait_till_operation_is_completed()
        self.x_reference = x
        self.signal_displacement_um.emit(0)

    def _caculate_centroid(self,image):
        if self.has_two_interfaces == False:
            h,w = image.shape
            x,y = np.meshgrid(range(w),range(h))
            I = image.astype(float)
            I = I - np.amin(I)
            I[I/np.amax(I)<0.2] = 0
            x = np.sum(x*I)/np.sum(I)
            y = np.sum(y*I)/np.sum(I)
            return x,y
        else:
            I = image
            # get the y position of the spots
            tmp = np.sum(I,axis=1)
            y0 = np.argmax(tmp)
            # crop along the y axis
            I = I[y0-96:y0+96,:]
            # signal along x
            tmp = np.sum(I,axis=0)
            # find peaks
            peak_locations,_ = scipy.signal.find_peaks(tmp,distance=100)
            idx = np.argsort(tmp[peak_locations])
            peak_0_location = peak_locations[idx[-1]]
            peak_1_location = peak_locations[idx[-2]] # for air-glass-water, the smaller peak corresponds to the glass-water interface
            self.spot_spacing_pixels = peak_1_location-peak_0_location
            '''
            # find peaks - alternative
            if self.spot_spacing_pixels is not None:
                peak_locations,_ = scipy.signal.find_peaks(tmp,distance=100)
                idx = np.argsort(tmp[peak_locations])
                peak_0_location = peak_locations[idx[-1]]
                peak_1_location = peak_locations[idx[-2]] # for air-glass-water, the smaller peak corresponds to the glass-water interface
                self.spot_spacing_pixels = peak_1_location-peak_0_location
            else:
                peak_0_location = np.argmax(tmp)
                peak_1_location = peak_0_location + self.spot_spacing_pixels
            '''
            # choose which surface to use
            if self.use_glass_top:
                x1 = peak_1_location
            else:
                x1 = peak_0_location
            # find centroid
            h,w = I.shape
            x,y = np.meshgrid(range(w),range(h))
            I = I[:,max(0,x1-64):min(w-1,x1+64)]
            x = x[:,max(0,x1-64):min(w-1,x1+64)]
            y = y[:,max(0,x1-64):min(w-1,x1+64)]
            I = I.astype(float)
            I = I - np.amin(I)
            I[I/np.amax(I)<0.1] = 0
            x1 = np.sum(x*I)/np.sum(I)
            y1 = np.sum(y*I)/np.sum(I)
            return x1,y0-96+y1

    def _get_laser_spot_centroid(self):
        # disable camera callback
        self.camera.disable_callback()
        tmp_x = 0
        tmp_y = 0
        for i in range(LASER_AF_AVERAGING_N):
            # send camera trigger
            if self.liveController.trigger_mode == TriggerMode.SOFTWARE:            
                self.camera.send_trigger()
            elif self.liveController.trigger_mode == TriggerMode.HARDWARE:
                # self.microcontroller.send_hardware_trigger(control_illumination=True,illumination_on_time_us=self.camera.exposure_time*1000)
                pass # to edit
            # read camera frame
            image = self.camera.read_frame()
            self.image = image
            # optionally display the image
            if LASER_AF_DISPLAY_SPOT_IMAGE:
                self.image_to_display.emit(image)
            # calculate centroid
            x,y = self._caculate_centroid(image)
            tmp_x = tmp_x + x
            tmp_y = tmp_y + y
        x = tmp_x/LASER_AF_AVERAGING_N
        y = tmp_y/LASER_AF_AVERAGING_N
        return x,y

    def wait_till_operation_is_completed(self):
        while self.microcontroller.is_busy():
            time.sleep(SLEEP_TIME_S)

    def get_image(self):
        # turn on the laser
        self.microcontroller.turn_on_AF_laser()
        self.wait_till_operation_is_completed()
        # send trigger, grab image and display image
        self.camera.send_trigger()
        image = self.camera.read_frame()
        self.image_to_display.emit(image)
        # turn off the laser
        self.microcontroller.turn_off_AF_laser()
        self.wait_till_operation_is_completed()
        return image

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.core_volumetric_imaging as core_volumetric_imaging
import control.microcontroller as microcontroller

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		self.camera = camera.Camera()
		self.microcontroller = microcontroller.Microcontroller_Simulation()
		
		self.configurationManager = core.ConfigurationManager()
		self.streamHandler = core_volumetric_imaging.StreamHandler(crop_width=500,crop_height=500)
		self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
		self.navigationController = core.NavigationController(self.microcontroller)
		self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
		self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController,self.configurationManager)
		self.trackingController = core.TrackingController(self.microcontroller,self.navigationController)
		self.imageSaver = core.ImageSaver()
		self.imageDisplay = core.ImageDisplay()

		# open the camera
		# camera start streaming
		self.camera.open()
		self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera.set_callback(self.streamHandler.on_new_frame)
		self.camera.enable_callback()

		# load widgets
		self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,self.liveController)
		self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager)
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
		self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
		self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)
		self.trackingControlWidget = widgets.TrackingControllerWidget(self.streamHandler,self.trackingController)
		self.multiPointWidget = widgets.MultiPointWidget(self.multipointController,self.configurationManager)

		self.recordTabWidget = QTabWidget()
		self.recordTabWidget.addTab(self.recordingControlWidget, "Simple Recording")
		# self.recordTabWidget.addTab(self.trackingControlWidget, "Tracking")
		# self.recordTabWidget.addTab(self.multiPointWidget, "Multipoint Acquisition")

		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget,0,0)
		layout.addWidget(self.liveControlWidget,1,0)
		# layout.addWidget(self.navigationWidget,2,0)
		# layout.addWidget(self.autofocusWidget,3,0)
		layout.addWidget(self.recordTabWidget,4,0)
		
		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# load window
		self.imageDisplayWindow = core.ImageDisplayWindow()
		self.imageArrayDisplayWindow = core_volumetric_imaging.ImageArrayDisplayWindow() 
		self.imageDisplayWindow.show()
		self.imageArrayDisplayWindow.show()

		# make connections
		self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
		self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
		self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
		self.streamHandler.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
		self.streamHandler.packet_image_for_array_display.connect(self.imageArrayDisplayWindow.display_image)
		self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)
		self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
		# self.multipointController.image_to_display.connect(self.imageDisplayWindow.display_image)
		self.multipointController.signal_current_configuration.connect(self.liveControlWidget.set_microscope_mode)
		self.multipointController.image_to_display_multi.connect(self.imageArrayDisplayWindow.display_image)
		self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
		self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
		self.liveControlWidget.update_camera_settings()

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.navigationController.home()
		self.liveController.stop_live()
		self.camera.close()
		self.imageSaver.close()
		self.imageDisplay.close()
		self.imageDisplayWindow.close()
		self.imageArrayDisplayWindow.close()
# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

import control.utils as utils
from control._def import *
import control.tracking as tracking

from queue import Queue
from threading import Thread, Lock
import time
import numpy as np
import pyqtgraph as pg
import cv2
from datetime import datetime

class TrackingController(QObject):
    def __init__(self,microcontroller,navigationController):
        QObject.__init__(self)
        self.microcontroller = microcontroller
        self.navigationController = navigationController
        self.tracker_xy = tracking.Tracker_XY()
        self.tracker_z = tracking.Tracker_Z()
        self.pid_controller_x = tracking.PID_Controller()
        self.pid_controller_y = tracking.PID_Controller()
        self.pid_controller_z = tracking.PID_Controller()
        self.tracking_frame_counter = 0

    def on_new_frame(self,image,frame_ID,timestamp):
        # initialize the tracker when a new track is started
        if self.tracking_frame_counter == 0:
            # initialize the tracker
            # initialize the PID controller
            pass

        # crop the image, resize the image 
        # [to fill]

        # get the location
        [x,y] = self.tracker_xy.track(image)
        z = self.track_z.track(image)
        # note that z tracking may use a different image from a different camera, we can implement two different on_new_frame callback function, one for xy tracking and one for z tracking
        # another posibility is to read the current frame(s) from the z tracking camera (instead of using callback) when a new frame for XY tracking arrives
        # if would be ideal if xy and z tracking runs in independent threads (processes?) (not Threading) and push error correction commands to a shared queue
        # more thoughts are needed

        # get motion commands
        dx = self.pid_controller_x.get_actuation(x)
        dy = self.pid_controller_y.get_actuation(y)
        dz = self.pid_controller_z.get_actuation(z)

        # read current location from the microcontroller
        current_stage_position = self.microcontroller.read_received_packet()

        # save the coordinate information (possibly enqueue image for saving here to if a separate ImageSaver object is being used) before the next movement
        # [to fill]

        # generate motion commands
        motion_commands = self.generate_motion_commands(self,dx,dy,dz)

        # send motion commands
        self.microcontroller.send_command(motion_commands)

    def start_a_new_track(self):
        self.tracking_frame_counter = 0
def signed_to_unsigned(n, num_bits):
    """
    Helper function to do 2s complement conversion on returned error codes.
    Returns function as a string representation in hexadecimal form.
    """
    return hex(n & ((1 << num_bits) -1))

hresult_error_lookup = {
        'E_ACCESSDENIED':"0x80070005",
        'E_INVALIDARG':"0x80070057",
        'E_NOTIMPL':"0x80004001",
        'E_POINTER':"0x80004003",
        'E_UNEXPECTED':"0x8000ffff",
        'E_WRONG_THREAD':"0x8001010e",
        'E_GEN_FAILURE':"0x8007001f",
        'E_BUSY':"0x800700aa",
        'E_PENDING':"0x8000000a",
        'E_TIMEOUT':"0x8001011f",
        'E_FAIL':"0x80004005"
        }

def hresult_checker(exception, *error_names):
    """
    Gets the hresult_checker's actual type,
    raises it again if unmatchable. Can
    supply it with multiple error name
    strings (see hresult_error_lookup)
    to return only if one of these is
    matched and raise otherwise.

    :return: String containing which
    error type it was, if a valid
    error.
    :raise: HRESULTException if unmatchable
    """
    try:
        exception.hr
    except AttributeError:
        raise exception
    for k in hresult_error_lookup.keys():
        if hresult_error_lookup[k].lower() == signed_to_unsigned(exception.hr, 32).lower():
            if len(error_names) > 0:
                if k in error_names:
                    return k
            else:
                return k
    raise exception

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.microcontroller as microcontroller

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		self.camera = camera.Camera()
		self.microcontroller = microcontroller.Microcontroller_Simulation()
		
		self.configurationManager = core.ConfigurationManager()
		self.streamHandler = core.StreamHandler()
		self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
		self.imageSaver = core.ImageSaver()
		self.imageDisplay = core.ImageDisplay()

		# open the camera
		# camera start streaming
		self.camera.open()
		self.camera.set_software_triggered_acquisition()
		self.camera.set_callback(self.streamHandler.on_new_frame)
		self.camera.enable_callback()

		# load widgets
		self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,self.liveController)
		self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager)
		self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)

		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget,0,0)
		layout.addWidget(self.liveControlWidget,1,0)
		layout.addWidget(self.recordingControlWidget,4,0)
		
		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# load window
		self.imageDisplayWindow = core.ImageDisplayWindow()
		self.imageDisplayWindow.show()

		# make connections
		self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
		self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
		self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
		self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
		self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
		self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
		self.liveControlWidget.update_camera_settings()
		
	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.liveController.stop_live()
		self.camera.close()
		self.imageSaver.close()
		self.imageDisplay.close()
		self.imageDisplayWindow.close()
# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy
import sys

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.microcontroller as microcontroller
from control._def import *

import pyqtgraph.dockarea as dock
import time

SINGLE_WINDOW = True # set to False if use separate windows for display and control

class OctopiGUI(QMainWindow):

    # variables
    fps_software_trigger = 100

    def __init__(self, is_simulation = False, *args, **kwargs):
        super().__init__(*args, **kwargs)

        self.objectiveStore = core.ObjectiveStore()
        self.objectivesWidget = widgets.ObjectivesWidget(self.objectiveStore)

        # load window
        if ENABLE_TRACKING:
            self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True)
            self.imageDisplayWindow.show_ROI_selector()
        else:
            self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True)
        self.imageArrayDisplayWindow = core.ImageArrayDisplayWindow() 
        # self.imageDisplayWindow.show()
        # self.imageArrayDisplayWindow.show()

        # image display windows
        self.imageDisplayTabs = QTabWidget()
        self.imageDisplayTabs.addTab(self.imageDisplayWindow.widget, "Live View")
        self.imageDisplayTabs.addTab(self.imageArrayDisplayWindow.widget, "Multichannel Acquisition")

        # load objects
        if is_simulation:
            self.camera = camera.Camera_Simulation(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
            self.microcontroller = microcontroller.Microcontroller_Simulation()
        else:
            try:
                self.camera = camera.Camera(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
                self.camera.open()
            except:
                self.camera = camera.Camera_Simulation(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
                self.camera.open()
                print('! camera not detected, using simulated camera !')
            try:
                self.microcontroller = microcontroller.Microcontroller(version=CONTROLLER_VERSION)
            except:
                print('! Microcontroller not detected, using simulated microcontroller !')
                self.microcontroller = microcontroller.Microcontroller_Simulation()

        # reset the MCU
        self.microcontroller.reset()

        # reinitialize motor drivers and DAC (in particular for V2.1 driver board where PG is not functional)
        self.microcontroller.initialize_drivers()

        # configure the actuators
        self.microcontroller.configure_actuators()

        self.configurationManager = core.ConfigurationManager()
        self.streamHandler = core.StreamHandler(display_resolution_scaling=DEFAULT_DISPLAY_CROP/100)
        self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
        self.navigationController = core.NavigationController(self.microcontroller, parent=self)
        self.slidePositionController = core.SlidePositionController(self.navigationController,self.liveController)
        self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
        self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController,self.configurationManager,parent=self)
        if ENABLE_TRACKING:
            self.trackingController = core.TrackingController(self.camera,self.microcontroller,self.navigationController,self.configurationManager,self.liveController,self.autofocusController,self.imageDisplayWindow)
        self.imageSaver = core.ImageSaver()
        self.imageDisplay = core.ImageDisplay()
        self.navigationViewer = core.NavigationViewer()

        # retract the objective
        self.navigationController.home_z()
        # wait for the operation to finish
        t0 = time.time()
        while self.microcontroller.is_busy():
            time.sleep(0.005)
            if time.time() - t0 > 10:
                print('z homing timeout, the program will exit')
                sys.exit(1)
        print('objective retracted')

        # homing
        self.navigationController.set_x_limit_pos_mm(100)
        self.navigationController.set_x_limit_neg_mm(-100)
        self.navigationController.set_y_limit_pos_mm(100)
        self.navigationController.set_y_limit_neg_mm(-100)
        print('start homing')
        self.navigationController.home_y()
        t0 = time.time()
        while self.microcontroller.is_busy():
            time.sleep(0.005)
            if time.time() - t0 > 10:
                print('y homing timeout, the program will exit')
                sys.exit(1)
        self.navigationController.home_x()
        t0 = time.time()
        while self.microcontroller.is_busy():
            time.sleep(0.005)
            if time.time() - t0 > 10:
                print('x homing timeout, the program will exit')
                sys.exit(1)
        print('homing finished')

        # set software limit
        self.navigationController.set_x_limit_pos_mm(SOFTWARE_POS_LIMIT.X_POSITIVE)
        self.navigationController.set_x_limit_neg_mm(SOFTWARE_POS_LIMIT.X_NEGATIVE)
        self.navigationController.set_y_limit_pos_mm(SOFTWARE_POS_LIMIT.Y_POSITIVE)
        self.navigationController.set_y_limit_neg_mm(SOFTWARE_POS_LIMIT.Y_NEGATIVE)

        # move to center
        self.navigationController.move_x(SLIDE_POSITION.SCANNING_X_MM)
        while self.microcontroller.is_busy():
            time.sleep(0.005)
        self.navigationController.move_y(SLIDE_POSITION.SCANNING_Y_MM)
        while self.microcontroller.is_busy():
            time.sleep(0.005)

        # raise the objective
        self.navigationController.move_z(DEFAULT_Z_POS_MM)
        # wait for the operation to finish
        t0 = time.time() 
        while self.microcontroller.is_busy():
            time.sleep(0.005)
            if time.time() - t0 > 5:
                print('z return timeout, the program will exit')
                sys.exit(1)

        # set software limit
        self.navigationController.set_x_limit_pos_mm(SOFTWARE_POS_LIMIT.X_POSITIVE)
        self.navigationController.set_x_limit_neg_mm(SOFTWARE_POS_LIMIT.X_NEGATIVE)
        self.navigationController.set_y_limit_pos_mm(SOFTWARE_POS_LIMIT.Y_POSITIVE)
        self.navigationController.set_y_limit_neg_mm(SOFTWARE_POS_LIMIT.Y_NEGATIVE)
        self.navigationController.set_z_limit_pos_mm(SOFTWARE_POS_LIMIT.Z_POSITIVE)

        # open the camera
        # camera start streaming
        # self.camera.set_reverse_x(CAMERA_REVERSE_X) # these are not implemented for the cameras in use
        # self.camera.set_reverse_y(CAMERA_REVERSE_Y) # these are not implemented for the cameras in use
        self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
        self.camera.set_callback(self.streamHandler.on_new_frame)
        self.camera.enable_callback()


        # load widgets
        self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,include_gain_exposure_time=False)
        self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager,show_display_options=True)
        self.navigationWidget = widgets.NavigationWidget(self.navigationController,self.slidePositionController,widget_configuration='malaria')
        self.dacControlWidget = widgets.DACControWidget(self.microcontroller)
        self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
        self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)
        if ENABLE_TRACKING:
            self.trackingControlWidget = widgets.TrackingControllerWidget(self.trackingController,self.configurationManager,show_configurations=TRACKING_SHOW_MICROSCOPE_CONFIGURATIONS)
        self.multiPointWidget = widgets.MultiPointWidget(self.multipointController,self.configurationManager)
        self.multiPointWidget2 = widgets.MultiPointWidget2(self.navigationController,self.navigationViewer,self.multipointController,self.configurationManager)

        self.recordTabWidget = QTabWidget()
        if ENABLE_TRACKING:
            self.recordTabWidget.addTab(self.trackingControlWidget, "Tracking")
        self.recordTabWidget.addTab(self.multiPointWidget, "Multipoint Acquisition")
        self.recordTabWidget.addTab(self.multiPointWidget2, "Flexible Multipoint")
        self.recordTabWidget.addTab(self.recordingControlWidget, "Simple Recording")

        # layout widgets
        layout = QVBoxLayout() #layout = QStackedLayout()
        layout.addWidget(self.cameraSettingWidget)
        #self.objectivesWidget.setFixedHeight(100)
        layout.addWidget(self.liveControlWidget)
        layout.addWidget(self.navigationWidget)
        if SHOW_DAC_CONTROL:
            layout.addWidget(self.dacControlWidget)
        layout.addWidget(self.autofocusWidget)
        layout.addWidget(self.recordTabWidget)
        layout.addWidget(self.navigationViewer)
        layout.addWidget(self.objectivesWidget)
        layout.addStretch()

        # transfer the layout to the central widget
        self.centralWidget = QWidget()
        self.centralWidget.setLayout(layout)
        # self.centralWidget.setFixedSize(self.centralWidget.minimumSize())
        # self.centralWidget.setFixedWidth(self.centralWidget.minimumWidth())
        # self.centralWidget.setMaximumWidth(self.centralWidget.minimumWidth())
        self.centralWidget.setFixedWidth(self.centralWidget.minimumSizeHint().width())

        if SINGLE_WINDOW:
            dock_display = dock.Dock('Image Display', autoOrientation = False)
            dock_display.showTitleBar()
            dock_display.addWidget(self.imageDisplayTabs)
            dock_display.setStretch(x=100,y=None)
            dock_controlPanel = dock.Dock('Controls', autoOrientation = False)
            # dock_controlPanel.showTitleBar()
            dock_controlPanel.addWidget(self.centralWidget)
            dock_controlPanel.setStretch(x=1,y=None)
            dock_controlPanel.setFixedWidth(dock_controlPanel.minimumSizeHint().width())
            main_dockArea = dock.DockArea()
            main_dockArea.addDock(dock_display)
            main_dockArea.addDock(dock_controlPanel,'right')
            self.setCentralWidget(main_dockArea)
            desktopWidget = QDesktopWidget()
            height_min = 0.9*desktopWidget.height()
            width_min = 0.96*desktopWidget.width()
            self.setMinimumSize(int(width_min),int(height_min))
        else:
            self.setCentralWidget(self.centralWidget)
            self.tabbedImageDisplayWindow = QMainWindow()
            self.tabbedImageDisplayWindow.setCentralWidget(self.imageDisplayTabs)
            self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() | Qt.CustomizeWindowHint)
            self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() & ~Qt.WindowCloseButtonHint)
            desktopWidget = QDesktopWidget()
            width = 0.96*desktopWidget.height()
            height = width
            self.tabbedImageDisplayWindow.setFixedSize(width,height)
            self.tabbedImageDisplayWindow.show()

        # make connections
        self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
        self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
        self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
        # self.streamHandler.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
        self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
        self.navigationController.xPos.connect(lambda x:self.navigationWidget.label_Xpos.setText("{:.2f}".format(x)))
        self.navigationController.yPos.connect(lambda x:self.navigationWidget.label_Ypos.setText("{:.2f}".format(x)))
        self.navigationController.zPos.connect(lambda x:self.navigationWidget.label_Zpos.setText("{:.2f}".format(x)))
        if ENABLE_TRACKING:
            self.navigationController.signal_joystick_button_pressed.connect(self.trackingControlWidget.slot_joystick_button_pressed)
        else:
            self.navigationController.signal_joystick_button_pressed.connect(self.autofocusController.autofocus)
        self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
        self.multipointController.image_to_display.connect(self.imageDisplayWindow.display_image)
        self.multipointController.signal_current_configuration.connect(self.liveControlWidget.set_microscope_mode)
        self.multipointController.image_to_display_multi.connect(self.imageArrayDisplayWindow.display_image)

        self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
        self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
        self.liveControlWidget.update_camera_settings()

        self.slidePositionController.signal_slide_loading_position_reached.connect(self.navigationWidget.slot_slide_loading_position_reached)
        self.slidePositionController.signal_slide_loading_position_reached.connect(self.multiPointWidget.disable_the_start_aquisition_button)
        self.slidePositionController.signal_slide_scanning_position_reached.connect(self.navigationWidget.slot_slide_scanning_position_reached)
        self.slidePositionController.signal_slide_scanning_position_reached.connect(self.multiPointWidget.enable_the_start_aquisition_button)
        self.slidePositionController.signal_clear_slide.connect(self.navigationViewer.clear_slide)

        self.navigationController.xyPos.connect(self.navigationViewer.update_current_location)
        self.multipointController.signal_register_current_fov.connect(self.navigationViewer.register_fov)

        self.imageDisplayWindow.image_click_coordinates.connect(self.navigationController.move_from_click)
        self.navigationController.move_to_cached_position()

    def closeEvent(self, event):
        self.navigationController.cache_current_position()
        event.accept()
        # self.softwareTriggerGenerator.stop() @@@ => 
        self.navigationController.home()
        self.liveController.stop_live()
        self.camera.close()
        self.imageSaver.close()
        self.imageDisplay.close()
        if not SINGLE_WINDOW:
            self.imageDisplayWindow.close()
            self.imageArrayDisplayWindow.close()
            self.tabbedImageDisplayWindow.close()
        self.microcontroller.close()

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.camera_TIS as camera_tis
import control.core as core
import control.microcontroller as microcontroller

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		self.camera_1 = camera.Camera()
		self.camera_2 = camera_tis.Camera(sn=48910098)
		self.microcontroller = microcontroller.Microcontroller_Simulation()
		
		self.streamHandler_1 = core.StreamHandler()
		self.streamHandler_2 = core.StreamHandler()
		self.liveController_1 = core.LiveController(self.camera_1,self.microcontroller)
		self.liveController_2 = core.LiveController(self.camera_2,self.microcontroller)
		self.navigationController = core.NavigationController(self.microcontroller)
		self.autofocusController = core.AutoFocusController(self.camera_1,self.navigationController,self.liveController_1)
		self.trackingController = core.TrackingController(self.microcontroller,self.navigationController)
		self.imageSaver_1 = core.ImageSaver()
		self.imageSaver_2 = core.ImageSaver()
		self.imageDisplay_1 = core.ImageDisplay()
		self.imageDisplay_2 = core.ImageDisplay()

		'''
		# thread
		self.thread_multiPoint = QThread()
		self.thread_multiPoint.start()
		self.multipointController.moveToThread(self.thread_multiPoint)
		'''

		# open the camera
		# camera start streaming
		self.camera_1.open()
		self.camera_1.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera_1.set_callback(self.streamHandler_1.on_new_frame)
		self.camera_1.enable_callback()

		self.camera_2.open()
		self.camera_2.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera_2.set_callback(self.streamHandler_2.on_new_frame)
		self.camera_2.enable_callback()

		# load widgets
		self.cameraSettingWidget_1 = widgets.CameraSettingsWidget(self.camera_1,self.liveController_1)
		self.liveControlWidget_1 = widgets.LiveControlWidget(self.streamHandler_1,self.liveController_1)
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
		self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
		self.recordingControlWidget_1 = widgets.RecordingWidget(self.streamHandler_1,self.imageSaver_1)
		self.trackingControlWidget = widgets.TrackingControllerWidget(self.streamHandler_1,self.trackingController)

		self.cameraSettingWidget_2 = widgets.CameraSettingsWidget(self.camera_2,self.liveController_2)
		self.liveControlWidget_2 = widgets.LiveControlWidget(self.streamHandler_2,self.liveController_2)
		self.recordingControlWidget_2 = widgets.RecordingWidget(self.streamHandler_2,self.imageSaver_2)
		
		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget_1,0,0)
		layout.addWidget(self.liveControlWidget_1,1,0)
		layout.addWidget(self.navigationWidget,2,0)
		layout.addWidget(self.autofocusWidget,3,0)
		layout.addWidget(self.recordingControlWidget_1,4,0)
		
		layout.addWidget(self.cameraSettingWidget_2,5,0)
		layout.addWidget(self.liveControlWidget_2,6,0)
		layout.addWidget(self.recordingControlWidget_2,7,0)

		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# load window
		self.imageDisplayWindow_1 = core.ImageDisplayWindow()
		self.imageDisplayWindow_1.show()
		self.imageDisplayWindow_2 = core.ImageDisplayWindow()
		self.imageDisplayWindow_2.show()

		# make connections
		self.streamHandler_1.signal_new_frame_received.connect(self.liveController_1.on_new_frame)
		self.streamHandler_1.image_to_display.connect(self.imageDisplay_1.enqueue)
		self.streamHandler_1.packet_image_to_write.connect(self.imageSaver_1.enqueue)
		self.streamHandler_1.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
		self.imageDisplay_1.image_to_display.connect(self.imageDisplayWindow_1.display_image) # may connect streamHandler directly to imageDisplayWindow

		self.streamHandler_2.signal_new_frame_received.connect(self.liveController_2.on_new_frame)
		self.streamHandler_2.image_to_display.connect(self.imageDisplay_2.enqueue)
		self.streamHandler_2.packet_image_to_write.connect(self.imageSaver_2.enqueue)
		self.imageDisplay_2.image_to_display.connect(self.imageDisplayWindow_2.display_image) # may connect streamHandler directly to imageDisplayWindow
		
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)
		self.autofocusController.image_to_display.connect(self.imageDisplayWindow_1.display_image)


	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.liveController_1.stop_live()
		self.camera_1.close()
		self.imageSaver_1.close()
		self.imageDisplay_1.close()
		self.imageDisplayWindow_1.close()
		self.liveController_2.stop_live()
		self.camera_2.close()
		self.imageSaver_2.close()
		self.imageDisplay_2.close()
		self.imageDisplayWindow_2.close()

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

import control.utils as utils
from control._def import *

import time
import numpy as np
import cv2

class DisplacementMeasurementController(QObject):

    signal_readings = Signal(list)
    signal_plots = Signal(np.ndarray,np.ndarray)

    def __init__(self, x_offset = 0, y_offset = 0, x_scaling = 1, y_scaling = 1, N_average=1, N=10000):

        QObject.__init__(self)
        self.x_offset = x_offset
        self.y_offset = y_offset
        self.x_scaling = x_scaling
        self.y_scaling = y_scaling
        self.N_average = N_average
        self.N = N # length of array to emit
        self.t_array = np.array([])
        self.x_array = np.array([])
        self.y_array = np.array([])

    def update_measurement(self,image):

        t = time.time()

        if len(image.shape)==3:
            image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)

        h,w = image.shape
        x,y = np.meshgrid(range(w),range(h))
        I = image.astype(float)
        I = I - np.amin(I)
        I[I/np.amax(I)<0.2] = 0
        x = np.sum(x*I)/np.sum(I)
        y = np.sum(y*I)/np.sum(I)
        
        x = x - self.x_offset
        y = y - self.y_offset
        x = x*self.x_scaling
        y = y*self.y_scaling

        self.t_array = np.append(self.t_array,t)
        self.x_array = np.append(self.x_array,x)
        self.y_array = np.append(self.y_array,y)

        self.signal_plots.emit(self.t_array[-self.N:], np.vstack((self.x_array[-self.N:],self.y_array[-self.N:])))
        self.signal_readings.emit([np.mean(self.x_array[-self.N_average:]),np.mean(self.y_array[-self.N_average:])])

    def update_settings(self,x_offset,y_offset,x_scaling,y_scaling,N_average,N):
        self.N = N
        self.N_average = N_average
        self.x_offset = x_offset
        self.y_offset = y_offset
        self.x_scaling = x_scaling
        self.y_scaling = y_scaling
# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

import control.utils as utils
from control._def import *
import control.tracking as tracking

from queue import Queue
from threading import Thread, Lock
import time
import numpy as np
import pyqtgraph as pg
import cv2
from datetime import datetime

from lxml import etree as ET
from pathlib import Path
import control.utils_config as utils_config


class StreamHandler(QObject):

    image_to_display = Signal(np.ndarray)
    packet_image_to_write = Signal(np.ndarray, int, float)
    packet_image_for_tracking = Signal(np.ndarray, int, float)
    packet_image_for_array_display = Signal(np.ndarray, int)
    signal_new_frame_received = Signal()

    def __init__(self,crop_width=Acquisition.CROP_WIDTH,crop_height=Acquisition.CROP_HEIGHT,display_resolution_scaling=0.5):
        QObject.__init__(self)
        self.fps_display = 1
        self.fps_save = 1
        self.fps_track = 1
        self.timestamp_last_display = 0
        self.timestamp_last_save = 0
        self.timestamp_last_track = 0

        self.crop_width = crop_width
        self.crop_height = crop_height
        self.display_resolution_scaling = display_resolution_scaling

        self.save_image_flag = False
        self.track_flag = False
        self.handler_busy = False

        # for fps measurement
        self.timestamp_last = 0
        self.counter = 0
        self.fps_real = 0

    def start_recording(self):
        self.save_image_flag = True

    def stop_recording(self):
        self.save_image_flag = False

    def start_tracking(self):
        self.tracking_flag = True

    def stop_tracking(self):
        self.tracking_flag = False

    def set_display_fps(self,fps):
        self.fps_display = fps

    def set_save_fps(self,fps):
        self.fps_save = fps

    def set_crop(self,crop_width,height):
        self.crop_width = crop_width
        self.crop_height = crop_height

    def set_display_resolution_scaling(self, display_resolution_scaling):
        self.display_resolution_scaling = display_resolution_scaling/100
        print(self.display_resolution_scaling)

    def on_new_frame(self, camera):

        camera.image_locked = True
        self.handler_busy = True
        self.signal_new_frame_received.emit() # self.liveController.turn_off_illumination()

        # measure real fps
        timestamp_now = round(time.time())
        if timestamp_now == self.timestamp_last:
            self.counter = self.counter+1
        else:
            self.timestamp_last = timestamp_now
            self.fps_real = self.counter
            self.counter = 0
            print('real camera fps is ' + str(self.fps_real))

        # crop image
        image_cropped = utils.crop_image(camera.current_frame,self.crop_width,self.crop_height)
        image_cropped = np.squeeze(image_cropped)

        # send image to display
        time_now = time.time()
        if time_now-self.timestamp_last_display >= 1/self.fps_display:
            # self.image_to_display.emit(cv2.resize(image_cropped,(round(self.crop_width*self.display_resolution_scaling), round(self.crop_height*self.display_resolution_scaling)),cv2.INTER_LINEAR))
            self.image_to_display.emit(utils.crop_image(image_cropped,round(self.crop_width*self.display_resolution_scaling), round(self.crop_height*self.display_resolution_scaling)))
            self.timestamp_last_display = time_now

        # send image to array display
        self.packet_image_for_array_display.emit(image_cropped,(camera.frame_ID - camera.frame_ID_offset_hardware_trigger - 1) % VOLUMETRIC_IMAGING.NUM_PLANES_PER_VOLUME)

        # send image to write
        if self.save_image_flag and time_now-self.timestamp_last_save >= 1/self.fps_save:
            if camera.is_color:
                image_cropped = cv2.cvtColor(image_cropped,cv2.COLOR_RGB2BGR)
            self.packet_image_to_write.emit(image_cropped,camera.frame_ID,camera.timestamp)
            self.timestamp_last_save = time_now

        # send image to track
        if self.track_flag and time_now-self.timestamp_last_track >= 1/self.fps_track:
            # track is a blocking operation - it needs to be
            # @@@ will cropping before emitting the signal lead to speedup?
            self.packet_image_for_tracking.emit(image_cropped,camera.frame_ID,camera.timestamp)
            self.timestamp_last_track = time_now

        self.handler_busy = False
        camera.image_locked = False


class ImageArrayDisplayWindow(QMainWindow):

    def __init__(self, window_title=''):
        super().__init__()
        self.setWindowTitle(window_title)
        self.setWindowFlags(self.windowFlags() | Qt.CustomizeWindowHint)
        self.setWindowFlags(self.windowFlags() & ~Qt.WindowCloseButtonHint)
        self.widget = QWidget()

        # interpret image data as row-major instead of col-major
        pg.setConfigOptions(imageAxisOrder='row-major')

        self.sub_windows = []
        for i in range(9):
            self.sub_windows.append(pg.GraphicsLayoutWidget())
            self.sub_windows[i].view = self.sub_windows[i].addViewBox(enableMouse=True)
            self.sub_windows[i].img = pg.ImageItem(border='w')
            self.sub_windows[i].view.setAspectLocked(True)
            self.sub_windows[i].view.addItem(self.sub_windows[i].img)

        ## Layout
        layout = QGridLayout()
        layout.addWidget(self.sub_windows[0], 0, 0)
        layout.addWidget(self.sub_windows[1], 0, 1)
        layout.addWidget(self.sub_windows[2], 0, 2)
        layout.addWidget(self.sub_windows[3], 1, 0) 
        layout.addWidget(self.sub_windows[4], 1, 1) 
        layout.addWidget(self.sub_windows[5], 1, 2) 
        layout.addWidget(self.sub_windows[6], 2, 0) 
        layout.addWidget(self.sub_windows[7], 2, 1) 
        layout.addWidget(self.sub_windows[8], 2, 2) 
        self.widget.setLayout(layout)
        self.setCentralWidget(self.widget)

        # set window size
        desktopWidget = QDesktopWidget();
        width = min(desktopWidget.height()*0.9,1000) #@@@TO MOVE@@@#
        height = width
        self.setFixedSize(width,height)

    def display_image(self,image,i):
        if i < 9:
            self.sub_windows[i].img.setImage(image,autoLevels=False)
            self.sub_windows[i].view.autoRange(padding=0)

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

import locale

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

import pyqtgraph as pg

import pandas as pd
import napari

from napari.utils.colormaps import Colormap, AVAILABLE_COLORMAPS
import re
import cv2

from datetime import datetime

from control._def import *

class WrapperWindow(QMainWindow):
    def __init__(self, content_widget, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.setCentralWidget(content_widget)
        self.hide()

    def closeEvent(self, event):
        self.hide()
        event.ignore()

    def closeForReal(self, event):
        super().closeEvent(event)

class CollapsibleGroupBox(QGroupBox):
    def __init__(self, title):
        super(CollapsibleGroupBox,self).__init__(title)
        self.setCheckable(True)
        self.setChecked(True)
        self.higher_layout = QVBoxLayout()
        self.content = QVBoxLayout()
        #self.content.setAlignment(Qt.AlignTop)
        self.content_widget = QWidget()
        self.content_widget.setLayout(self.content)
        self.higher_layout.addWidget(self.content_widget)
        self.setLayout(self.higher_layout)
        self.toggled.connect(self.toggle_content)

    def toggle_content(self,state):
        self.content_widget.setVisible(state)

class ConfigEditorForAcquisitions(QDialog):
    def __init__(self, configManager, only_z_offset=True):
        super().__init__()

        self.config = configManager
        
        self.only_z_offset=only_z_offset

        self.scroll_area = QScrollArea()
        self.scroll_area.setWidgetResizable(True)
        self.scroll_area_widget = QWidget()
        self.scroll_area_layout = QVBoxLayout()
        self.scroll_area_widget.setLayout(self.scroll_area_layout)
        self.scroll_area.setWidget(self.scroll_area_widget)

        self.save_config_button = QPushButton("Save Config")
        self.save_config_button.clicked.connect(self.save_config)
        self.save_to_file_button = QPushButton("Save to File")
        self.save_to_file_button.clicked.connect(self.save_to_file)
        self.load_config_button = QPushButton("Load Config from File")
        self.load_config_button.clicked.connect(lambda: self.load_config_from_file(None))

        layout = QVBoxLayout()
        layout.addWidget(self.scroll_area)
        layout.addWidget(self.save_config_button)
        layout.addWidget(self.save_to_file_button)
        layout.addWidget(self.load_config_button)

        self.config_value_widgets = {}

        self.setLayout(layout)
        self.setWindowTitle("Configuration Editor")
        self.init_ui(only_z_offset)

    def init_ui(self, only_z_offset=None):
        if only_z_offset is None:
            only_z_offset = self.only_z_offset
        self.groups = {}
        for section in self.config.configurations:
            if not only_z_offset:
                group_box = CollapsibleGroupBox(section.name)
            else:
                group_box = QGroupBox(section.name)

            group_layout = QVBoxLayout()

            section_value_widgets = {}

            self.groups[str(section.id)] = group_box

            for option in section.__dict__.keys():
                if option.startswith('_') and option.endswith('_options'):
                    continue
                if option == 'id':
                    continue
                if only_z_offset and option != 'z_offset':
                    continue
                option_value = str(getattr(section, option))
                option_name = QLabel(option)
                option_layout = QHBoxLayout()
                option_layout.addWidget(option_name)
                if f'_{option}_options' in list(section.__dict__.keys()):
                    option_value_list = getattr(section,f'_{option}_options')
                    values = option_value_list.strip('[]').split(',')
                    for i in range(len(values)):
                        values[i] = values[i].strip()
                    if option_value not in values:
                        values.append(option_value)
                    combo_box = QComboBox()
                    combo_box.addItems(values)
                    combo_box.setCurrentText(option_value)
                    option_layout.addWidget(combo_box)
                    section_value_widgets[option] = combo_box
                else:
                    option_input = QLineEdit(option_value)
                    option_layout.addWidget(option_input)
                    section_value_widgets[option] = option_input
                group_layout.addLayout(option_layout)

            self.config_value_widgets[str(section.id)] = section_value_widgets
            if not only_z_offset:
                group_box.content.addLayout(group_layout)
            else:
                group_box.setLayout(group_layout)

            self.scroll_area_layout.addWidget(group_box)

    def save_config(self):
        for section in self.config.configurations:
            for option in section.__dict__.keys():
                if option.startswith("_") and option.endswith("_options"):
                    continue
                old_val = getattr(section,option)
                if option == 'id':
                    continue
                elif option == 'camera_sn':
                    option_name_in_xml = 'CameraSN'
                else:
                    option_name_in_xml = option.replace("_"," ").title().replace(" ","")
                try:
                    widget = self.config_value_widgets[str(section.id)][option]
                except KeyError:
                    continue
                if type(widget) is QLineEdit:
                    self.config.update_configuration(section.id, option_name_in_xml, widget.text())
                else:
                    self.config.update_configuration(section.id, option_name_in_xml, widget.currentText())
        self.config.configurations = []
        self.config.read_configurations()

    def save_to_file(self):
        self.save_config()
        file_path, _ = QFileDialog.getSaveFileName(self, "Save Acquisition Config File", '', "XML Files (*.xml);;All Files (*)")
        if file_path:
            self.config.write_configuration(file_path)

    def load_config_from_file(self,only_z_offset=None):
        file_path, _ = QFileDialog.getOpenFileName(self, "Load Acquisition Config File", '', "XML Files (*.xml);;All Files (*)")
        if file_path:
            self.config.config_filename = file_path
            self.config.configurations = []
            self.config.read_configurations()
            # Clear and re-initialize the UI
            self.scroll_area_widget.deleteLater()
            self.scroll_area_widget = QWidget()
            self.scroll_area_layout = QVBoxLayout()
            self.scroll_area_widget.setLayout(self.scroll_area_layout)
            self.scroll_area.setWidget(self.scroll_area_widget)
            self.init_ui(only_z_offset)



class ConfigEditor(QDialog):
    def __init__(self, config):
        super().__init__()

        self.config = config

        self.scroll_area = QScrollArea()
        self.scroll_area.setWidgetResizable(True)
        self.scroll_area_widget = QWidget()
        self.scroll_area_layout = QVBoxLayout()
        self.scroll_area_widget.setLayout(self.scroll_area_layout)
        self.scroll_area.setWidget(self.scroll_area_widget)

        self.save_config_button = QPushButton("Save Config")
        self.save_config_button.clicked.connect(self.save_config)
        self.save_to_file_button = QPushButton("Save to File")
        self.save_to_file_button.clicked.connect(self.save_to_file)
        self.load_config_button = QPushButton("Load Config from File")
        self.load_config_button.clicked.connect(self.load_config_from_file)

        layout = QVBoxLayout()
        layout.addWidget(self.scroll_area)
        layout.addWidget(self.save_config_button)
        layout.addWidget(self.save_to_file_button)
        layout.addWidget(self.load_config_button)

        self.config_value_widgets = {}

        self.setLayout(layout)
        self.setWindowTitle("Configuration Editor")
        self.init_ui()

    def init_ui(self):
        self.groups = {}
        for section in self.config.sections():
            group_box = CollapsibleGroupBox(section)
            group_layout = QVBoxLayout()

            section_value_widgets = {}

            self.groups[section] = group_box

            for option in self.config.options(section):
                if option.startswith('_') and option.endswith('_options'):
                    continue 
                option_value = self.config.get(section, option)
                option_name = QLabel(option)
                option_layout = QHBoxLayout()
                option_layout.addWidget(option_name)
                if f'_{option}_options' in self.config.options(section):
                    option_value_list = self.config.get(section,f'_{option}_options')
                    values = option_value_list.strip('[]').split(',')
                    for i in range(len(values)):
                        values[i] = values[i].strip()
                    if option_value not in values:
                        values.append(option_value)
                    combo_box = QComboBox()
                    combo_box.addItems(values)
                    combo_box.setCurrentText(option_value)
                    option_layout.addWidget(combo_box)
                    section_value_widgets[option] = combo_box
                else:
                    option_input = QLineEdit(option_value)
                    option_layout.addWidget(option_input)
                    section_value_widgets[option] = option_input
                group_layout.addLayout(option_layout)

            self.config_value_widgets[section] = section_value_widgets
            group_box.content.addLayout(group_layout)
            self.scroll_area_layout.addWidget(group_box)

    def save_config(self):
        for section in self.config.sections():
            for option in self.config.options(section):
                if option.startswith("_") and option.endswith("_options"):
                    continue
                old_val = self.config.get(section, option)
                widget = self.config_value_widgets[section][option]
                if type(widget) is QLineEdit:
                    self.config.set(section, option, widget.text())
                else:
                    self.config.set(section, option, widget.currentText())
                if old_val != self.config.get(section,option):
                    print(self.config.get(section,option))

    def save_to_file(self):
        self.save_config()
        file_path, _ = QFileDialog.getSaveFileName(self, "Save Config File", '', "INI Files (*.ini);;All Files (*)")
        if file_path:
            with open(file_path, 'w') as configfile:
                self.config.write(configfile)

    def load_config_from_file(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Load Config File", '', "INI Files (*.ini);;All Files (*)")
        if file_path:
            self.config.read(file_path)
            # Clear and re-initialize the UI
            self.scroll_area_widget.deleteLater()
            self.scroll_area_widget = QWidget()
            self.scroll_area_layout = QVBoxLayout()
            self.scroll_area_widget.setLayout(self.scroll_area_layout)
            self.scroll_area.setWidget(self.scroll_area_widget)
            self.init_ui()


class ConfigEditorBackwardsCompatible(ConfigEditor):
    def __init__(self, config, original_filepath, main_window):
        super().__init__(config)
        self.original_filepath = original_filepath
        self.main_window = main_window
        
        self.apply_exit_button = QPushButton("Apply and Exit")
        self.apply_exit_button.clicked.connect(self.apply_and_exit)

        self.layout().addWidget(self.apply_exit_button)

    def apply_and_exit(self):
        self.save_config()
        with open(self.original_filepath, 'w') as configfile:
            self.config.write(configfile)
        try:
            self.main_window.close()
        except:
            pass
        self.close()

class SpinningDiskConfocalWidget(QWidget):
    def __init__(self, xlight, config_manager=None):
        super(SpinningDiskConfocalWidget,self).__init__()
        
        self.config_manager = config_manager

        self.xlight = xlight

        self.init_ui()
        
        self.dropdown_emission_filter.setCurrentText(str(self.xlight.get_emission_filter()))
        self.dropdown_dichroic.setCurrentText(str(self.xlight.get_dichroic()))

        self.dropdown_emission_filter.currentIndexChanged.connect(self.set_emission_filter)
        self.dropdown_dichroic.currentIndexChanged.connect(self.set_dichroic)
        
        self.disk_position_state = self.xlight.get_disk_position()        

        if self.disk_position_state == 1:
            self.btn_toggle_widefield.setText("Switch to Widefield")

        if self.config_manager is not None:
            if self.disk_position_state ==1:
                self.config_manager.config_filename = "confocal_configurations.xml"
            else:
                self.config_manager.config_filename = "widefield_configurations.xml"
            self.config_manager.configurations = []    
            self.config_manager.read_configurations()
        
        self.btn_toggle_widefield.clicked.connect(self.toggle_disk_position)

        self.btn_toggle_motor.clicked.connect(self.toggle_motor)

    def init_ui(self):
        
        emissionFilterLayout = QHBoxLayout()
        emissionFilterLayout.addWidget(QLabel("Emission Filter Position"))

        self.dropdown_emission_filter = QComboBox(self)
        self.dropdown_emission_filter.addItems([str(i+1) for i in range(8)])

        emissionFilterLayout.addWidget(self.dropdown_emission_filter)
        

        dichroicLayout = QHBoxLayout()
        dichroicLayout.addWidget(QLabel("Dichroic Position"))

        self.dropdown_dichroic = QComboBox(self)
        self.dropdown_dichroic.addItems([str(i+1) for i in range(5)])

        dichroicLayout.addWidget(self.dropdown_dichroic)

        dropdownLayout = QVBoxLayout()

        dropdownLayout.addLayout(dichroicLayout)
        dropdownLayout.addLayout(emissionFilterLayout)
        dropdownLayout.addStretch()
        

        self.btn_toggle_widefield = QPushButton("Switch to Confocal")

        self.btn_toggle_motor = QPushButton("Disk Motor On")
        self.btn_toggle_motor.setCheckable(True)

        layout = QVBoxLayout(self)
        layout.addWidget(self.btn_toggle_motor)

        layout.addWidget(self.btn_toggle_widefield)
        layout.addLayout(dropdownLayout)
        self.setLayout(layout)

    def disable_all_buttons(self):
        self.dropdown_emission_filter.setEnabled(False)
        self.dropdown_dichroic.setEnabled(False)
        self.btn_toggle_widefield.setEnabled(False)
        self.btn_toggle_motor.setEnabled(False)

    def enable_all_buttons(self):
        self.dropdown_emission_filter.setEnabled(True)
        self.dropdown_dichroic.setEnabled(True)
        self.btn_toggle_widefield.setEnabled(True)
        self.btn_toggle_motor.setEnabled(True)

    def toggle_disk_position(self):
        self.disable_all_buttons()
        if self.disk_position_state==1:
            self.disk_position_state = self.xlight.set_disk_position(0)
            self.btn_toggle_widefield.setText("Switch to Confocal")
        else:
            self.disk_position_state = self.xlight.set_disk_position(1)
            self.btn_toggle_widefield.setText("Switch to Widefield")
        if self.config_manager is not None:
            if self.disk_position_state ==1:
                self.config_manager.config_filename = "confocal_configurations.xml"
            else:
                self.config_manager.config_filename = "widefield_configurations.xml"
            self.config_manager.configurations = []    
            self.config_manager.read_configurations()
        self.enable_all_buttons()

    def toggle_motor(self):
        self.disable_all_buttons()
        if self.btn_toggle_motor.isChecked():
            self.xlight.set_disk_motor_state(True)
        else:
            self.xlight.set_disk_motor_state(False)
        self.enable_all_buttons()

    def set_emission_filter(self, index):
        self.disable_all_buttons()
        selected_pos = self.dropdown_emission_filter.currentText()
        self.xlight.set_emission_filter(selected_pos)
        self.enable_all_buttons()
    
    def set_dichroic(self, index):
        self.disable_all_buttons()
        selected_pos = self.dropdown_dichroic.currentText()
        self.xlight.set_dichroic(selected_pos)
        self.enable_all_buttons()
  
class ObjectivesWidget(QWidget):
    def __init__(self, objective_store):
        super(ObjectivesWidget, self).__init__()

        self.objectiveStore = objective_store
    
        self.init_ui()

        self.dropdown.setCurrentText(self.objectiveStore.current_objective)

    def init_ui(self):
        # Dropdown for selecting keys
        self.dropdown = QComboBox(self)
        self.dropdown.addItems(self.objectiveStore.objectives_dict.keys())
        self.dropdown.currentIndexChanged.connect(self.display_objective)

        # TextBrowser to display key-value pairs
        #self.text_browser = QTextBrowser(self)
        # Layout
        dropdownLayout = QHBoxLayout()
        dropdownLabel = QLabel("Objectives:")
        dropdownLayout.addWidget(dropdownLabel)
        dropdownLayout.addWidget(self.dropdown)
        #textLayout = QHBoxLayout()
        #textLayout.addWidget(self.text_browser)
        layout = QVBoxLayout(self)
        layout.addLayout(dropdownLayout)
        #layout.addLayout(textLayout)

    def display_objective(self, index):
        selected_key = self.dropdown.currentText()
        objective_data = self.objectiveStore.objectives_dict.get(selected_key, {})
        #text = "\n".join([f"{key}: {value}" for key, value in objective_data.items()])
        self.objectiveStore.current_objective = selected_key
        #self.text_browser.setPlainText(text)

class FocusMapWidget(QWidget):

    def __init__(self, autofocusController, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.autofocusController = autofocusController
        self.init_ui()

    def init_ui(self):
        self.btn_add_to_focusmap = QPushButton("Add to focus map")
        self.btn_enable_focusmap = QPushButton("Enable focus map")
        self.btn_clear_focusmap = QPushButton("Clear focus map")
        self.fmap_coord_1 = QLabel("Focus Map Point 1: (xxx,yyy,zzz)")
        self.fmap_coord_2 = QLabel("Focus Map Point 2: (xxx,yyy,zzz)")
        self.fmap_coord_3 = QLabel("Focus Map Point 3: (xxx,yyy,zzz)")
        layout = QVBoxLayout()
        layout.addWidget(self.fmap_coord_1)
        layout.addWidget(self.fmap_coord_2)
        layout.addWidget(self.fmap_coord_3)

        button_layout = QHBoxLayout()
        button_layout.addWidget(self.btn_add_to_focusmap)
        button_layout.addWidget(self.btn_clear_focusmap)

        layout.addLayout(button_layout)
        
        layout.addWidget(self.btn_enable_focusmap)

        self.setLayout(layout)

        self.btn_add_to_focusmap.clicked.connect(self.add_to_focusmap)
        self.btn_enable_focusmap.clicked.connect(self.enable_focusmap)
        self.btn_clear_focusmap.clicked.connect(self.clear_focusmap)

    def disable_all_buttons(self):
        self.btn_add_to_focusmap.setEnabled(False)
        self.btn_enable_focusmap.setEnabled(False)
        self.btn_clear_focusmap.setEnabled(False)

    def enable_all_buttons(self):
        self.btn_add_to_focusmap.setEnabled(True)
        self.btn_enable_focusmap.setEnabled(True)
        self.btn_clear_focusmap.setEnabled(True)

    def clear_focusmap(self):
        self.disable_all_buttons()
        self.autofocusController.clear_focus_map()
        self.update_focusmap_display()
        self.btn_enable_focusmap.setText("Enable focus map")
        self.enable_all_buttons()

    def update_focusmap_display(self):
        self.fmap_coord_1.setText("Focus Map Point 1: (xxx,yyy,zzz)")
        self.fmap_coord_2.setText("Focus Map Point 2: (xxx,yyy,zzz)")
        self.fmap_coord_3.setText("Focus Map Point 3: (xxx,yyy,zzz)")
        try:
            x,y,z = self.autofocusController.focus_map_coords[0]
            self.fmap_coord_1.setText(f"Focus Map Point 1: ({x:.3f},{y:.3f},{z:.3f})")
        except IndexError:
            pass
        try:
            x,y,z = self.autofocusController.focus_map_coords[1]
            self.fmap_coord_2.setText(f"Focus Map Point 2: ({x:.3f},{y:.3f},{z:.3f})")
        except IndexError:
            pass
        try:
            x,y,z = self.autofocusController.focus_map_coords[2]
            self.fmap_coord_3.setText(f"Focus Map Point 3: ({x:.3f},{y:.3f},{z:.3f})")
        except IndexError:
            pass



    def enable_focusmap(self):
        self.disable_all_buttons()
        if self.autofocusController.use_focus_map == False:
            self.autofocusController.set_focus_map_use(True)
        else:
            self.autofocusController.set_focus_map_use(False)
        if self.autofocusController.use_focus_map:
            self.btn_enable_focusmap.setText("Disable focus map")
        else:
            self.btn_enable_focusmap.setText("Enable focus map")
        self.enable_all_buttons()

    def add_to_focusmap(self):
        self.disable_all_buttons()
        try:
            self.autofocusController.add_current_coords_to_focus_map()
        except ValueError:
            pass
        self.update_focusmap_display()
        self.enable_all_buttons()

class CameraSettingsWidget(QFrame):

    def __init__(self, camera, include_gain_exposure_time = False, include_camera_temperature_setting = False, include_camera_auto_wb_setting = False, main=None, *args, **kwargs):

        super().__init__(*args, **kwargs)
        self.camera = camera
        self.add_components(include_gain_exposure_time,include_camera_temperature_setting,include_camera_auto_wb_setting)        
        # set frame style
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self,include_gain_exposure_time,include_camera_temperature_setting,include_camera_auto_wb_setting):

        # add buttons and input fields
        self.entry_exposureTime = QDoubleSpinBox()
        self.entry_exposureTime.setMinimum(self.camera.EXPOSURE_TIME_MS_MIN) 
        self.entry_exposureTime.setMaximum(self.camera.EXPOSURE_TIME_MS_MAX) 
        self.entry_exposureTime.setSingleStep(1)
        self.entry_exposureTime.setValue(20)
        self.camera.set_exposure_time(20)

        self.entry_analogGain = QDoubleSpinBox()
        self.entry_analogGain.setMinimum(self.camera.GAIN_MIN) 
        self.entry_analogGain.setMaximum(self.camera.GAIN_MAX) 
        self.entry_analogGain.setSingleStep(self.camera.GAIN_STEP)
        self.entry_analogGain.setValue(0)
        self.camera.set_analog_gain(0)

        self.dropdown_pixelFormat = QComboBox()
        self.dropdown_pixelFormat.addItems(['MONO8','MONO12','MONO14','MONO16','BAYER_RG8','BAYER_RG12'])
        if self.camera.pixel_format is not None:
            self.dropdown_pixelFormat.setCurrentText(self.camera.pixel_format)
        else:
            print("setting camera's default pixel format")
            self.camera.set_pixel_format(DEFAULT_PIXEL_FORMAT)
            self.dropdown_pixelFormat.setCurrentText(DEFAULT_PIXEL_FORMAT)
        # to do: load and save pixel format in configurations

        self.entry_ROI_offset_x = QSpinBox()
        self.entry_ROI_offset_x.setValue(self.camera.OffsetX)
        self.entry_ROI_offset_x.setSingleStep(8)
        self.entry_ROI_offset_x.setFixedWidth(60)
        self.entry_ROI_offset_x.setMinimum(0)
        self.entry_ROI_offset_x.setMaximum(self.camera.WidthMax)
        self.entry_ROI_offset_x.setKeyboardTracking(False)
        self.entry_ROI_offset_y = QSpinBox()
        self.entry_ROI_offset_y.setValue(self.camera.OffsetY)
        self.entry_ROI_offset_y.setSingleStep(8)
        self.entry_ROI_offset_y.setFixedWidth(60)
        self.entry_ROI_offset_y.setMinimum(0)
        self.entry_ROI_offset_y.setMaximum(self.camera.HeightMax)
        self.entry_ROI_offset_y.setKeyboardTracking(False)
        self.entry_ROI_width = QSpinBox()
        self.entry_ROI_width.setMinimum(16)
        self.entry_ROI_width.setMaximum(self.camera.WidthMax)
        self.entry_ROI_width.setValue(self.camera.Width)
        self.entry_ROI_width.setSingleStep(8)
        self.entry_ROI_width.setFixedWidth(60)
        self.entry_ROI_width.setKeyboardTracking(False)
        self.entry_ROI_height = QSpinBox()
        self.entry_ROI_height.setSingleStep(8)
        self.entry_ROI_height.setMinimum(16)
        self.entry_ROI_height.setMaximum(self.camera.HeightMax)
        self.entry_ROI_height.setValue(self.camera.Height)
        self.entry_ROI_height.setFixedWidth(60)
        self.entry_ROI_height.setKeyboardTracking(False)
        self.entry_temperature = QDoubleSpinBox()
        self.entry_temperature.setMaximum(25)
        self.entry_temperature.setMinimum(-50)
        self.entry_temperature.setDecimals(1)
        self.label_temperature_measured = QLabel()
        # self.label_temperature_measured.setNum(0)
        self.label_temperature_measured.setFrameStyle(QFrame.Panel | QFrame.Sunken)

        # connection
        self.entry_exposureTime.valueChanged.connect(self.camera.set_exposure_time)
        self.entry_analogGain.valueChanged.connect(self.camera.set_analog_gain)
        self.dropdown_pixelFormat.currentTextChanged.connect(self.camera.set_pixel_format)
        self.entry_ROI_offset_x.valueChanged.connect(self.set_ROI_offset)
        self.entry_ROI_offset_y.valueChanged.connect(self.set_ROI_offset)
        self.entry_ROI_height.valueChanged.connect(self.set_Height)
        self.entry_ROI_width.valueChanged.connect(self.set_Width)

        # layout
        grid_ctrl = QGridLayout()
        if include_gain_exposure_time:
            grid_ctrl.addWidget(QLabel('Exposure Time (ms)'), 0,0)
            grid_ctrl.addWidget(self.entry_exposureTime, 0,1)
            grid_ctrl.addWidget(QLabel('Analog Gain'), 1,0)
            grid_ctrl.addWidget(self.entry_analogGain, 1,1)
        grid_ctrl.addWidget(QLabel('Pixel Format'), 2,0)
        grid_ctrl.addWidget(self.dropdown_pixelFormat, 2,1)
        try:
            current_res = self.camera.resolution
            current_res_string = "x".join([str(current_res[0]),str(current_res[1])])
            res_options = [f"{res[0]}x{res[1]}" for res in self.camera.res_list]
            self.dropdown_res = QComboBox()
            self.dropdown_res.addItems(res_options)
            self.dropdown_res.setCurrentText(current_res_string)

            self.dropdown_res.currentTextChanged.connect(self.change_full_res)
            grid_ctrl.addWidget(QLabel("Full Resolution"), 2,2)
            grid_ctrl.addWidget(self.dropdown_res, 2,3)
        except AttributeError:
            pass
        if include_camera_temperature_setting:
            grid_ctrl.addWidget(QLabel('Set Temperature (C)'),3,0)
            grid_ctrl.addWidget(self.entry_temperature,3,1)
            grid_ctrl.addWidget(QLabel('Actual Temperature (C)'),3,2)
            grid_ctrl.addWidget(self.label_temperature_measured,3,3)
            try:
                self.entry_temperature.valueChanged.connect(self.set_temperature)
                self.camera.set_temperature_reading_callback(self.update_measured_temperature)
            except AttributeError:
                pass

        hbox1 = QHBoxLayout()
        hbox1.addWidget(QLabel('ROI'))
        hbox1.addStretch()
        hbox1.addWidget(QLabel('height'))
        hbox1.addWidget(self.entry_ROI_height)
        hbox1.addWidget(QLabel('width'))
        hbox1.addWidget(self.entry_ROI_width)
        
        hbox1.addWidget(QLabel('offset y'))
        hbox1.addWidget(self.entry_ROI_offset_y)
        hbox1.addWidget(QLabel('offset x'))
        hbox1.addWidget(self.entry_ROI_offset_x)

        if include_camera_auto_wb_setting:
            is_color = False
            try:
                is_color = self.camera.get_is_color()
            except AttributeError:
                pass

            if is_color is True:
                grid_camera_setting_wb = QGridLayout()

                # auto white balance 
                self.btn_auto_wb = QPushButton('Auto White Balance')
                self.btn_auto_wb.setCheckable(True)
                self.btn_auto_wb.setChecked(False)
                self.btn_auto_wb.clicked.connect(self.toggle_auto_wb)
                print(self.camera.get_balance_white_auto())
                grid_camera_setting_wb.addWidget(self.btn_auto_wb,0,0)

        self.grid = QGridLayout()
        self.grid.addLayout(grid_ctrl,0,0)
        self.grid.addLayout(hbox1,1,0)
        if include_camera_auto_wb_setting:
            is_color = False
            try:
                is_color = self.camera.get_is_color()
            except AttributeError:
                pass
            if is_color is True:
                self.grid.addLayout(grid_camera_setting_wb,2,0)

        self.grid.setRowStretch(self.grid.rowCount(), 1)
        self.setLayout(self.grid)

    def toggle_auto_wb(self,pressed):
        # 0: OFF  1:CONTINUOUS  2:ONCE
        if pressed:
            self.camera.set_balance_white_auto(1)
        else:
            self.camera.set_balance_white_auto(0)

    def set_exposure_time(self,exposure_time):
        self.entry_exposureTime.setValue(exposure_time)

    def set_analog_gain(self,analog_gain):
        self.entry_analogGain.setValue(analog_gain)

    def set_Width(self):
        width = int(self.entry_ROI_width.value()//8)*8
        self.entry_ROI_width.blockSignals(True)
        self.entry_ROI_width.setValue(width)
        self.entry_ROI_width.blockSignals(False)
        offset_x = (self.camera.WidthMax - self.entry_ROI_width.value())/2
        offset_x = int(offset_x//8)*8
        self.entry_ROI_offset_x.blockSignals(True)
        self.entry_ROI_offset_x.setValue(offset_x)
        self.entry_ROI_offset_x.blockSignals(False)
        self.camera.set_ROI(self.entry_ROI_offset_x.value(),self.entry_ROI_offset_y.value(),self.entry_ROI_width.value(),self.entry_ROI_height.value())

    def set_Height(self):
        height = int(self.entry_ROI_height.value()//8)*8
        self.entry_ROI_height.blockSignals(True)
        self.entry_ROI_height.setValue(height)
        self.entry_ROI_height.blockSignals(False)
        offset_y = (self.camera.HeightMax - self.entry_ROI_height.value())/2
        offset_y = int(offset_y//8)*8
        self.entry_ROI_offset_y.blockSignals(True)
        self.entry_ROI_offset_y.setValue(offset_y)
        self.entry_ROI_offset_y.blockSignals(False)
        self.camera.set_ROI(self.entry_ROI_offset_x.value(),self.entry_ROI_offset_y.value(),self.entry_ROI_width.value(),self.entry_ROI_height.value())

    def set_ROI_offset(self):
    	self.camera.set_ROI(self.entry_ROI_offset_x.value(),self.entry_ROI_offset_y.value(),self.entry_ROI_width.value(),self.entry_ROI_height.value())

    def set_temperature(self):
        try:
            self.camera.set_temperature(float(self.entry_temperature.value()))
        except AttributeError:
            pass

    def update_measured_temperature(self,temperature):
        self.label_temperature_measured.setNum(temperature)

    def change_full_res(self, index):
        res_strings = self.dropdown_res.currentText().split("x")
        res_x = int(res_strings[0])
        res_y = int(res_strings[1])
        self.camera.set_resolution(res_x,res_y)
        self.entry_ROI_offset_x.blockSignals(True)
        self.entry_ROI_offset_y.blockSignals(True)
        self.entry_ROI_height.blockSignals(True)
        self.entry_ROI_width.blockSignals(True)

        self.entry_ROI_height.setMaximum(self.camera.HeightMax)
        self.entry_ROI_width.setMaximum(self.camera.WidthMax)

        self.entry_ROI_offset_x.setMaximum(self.camera.WidthMax)
        self.entry_ROI_offset_y.setMaximum(self.camera.HeightMax)
        
        self.entry_ROI_offset_x.setValue(int(8*self.camera.OffsetX//8))
        self.entry_ROI_offset_y.setValue(int(8*self.camera.OffsetY//8))
        self.entry_ROI_height.setValue(int(8*self.camera.Height//8))
        self.entry_ROI_width.setValue(int(8*self.camera.Width//8))

        self.entry_ROI_offset_x.blockSignals(False)
        self.entry_ROI_offset_y.blockSignals(False)
        self.entry_ROI_height.blockSignals(False)
        self.entry_ROI_width.blockSignals(False)


class LiveControlWidget(QFrame):
    signal_newExposureTime = Signal(float)
    signal_newAnalogGain = Signal(float)
    signal_autoLevelSetting = Signal(bool)
    def __init__(self, streamHandler, liveController, configurationManager=None, show_trigger_options=True, show_display_options=True, show_autolevel = False, autolevel=False, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.liveController = liveController
        self.streamHandler = streamHandler
        self.configurationManager = configurationManager
        self.fps_trigger = 10
        self.fps_display = 10
        self.liveController.set_trigger_fps(self.fps_trigger)
        self.streamHandler.set_display_fps(self.fps_display)
        
        self.triggerMode = TriggerMode.SOFTWARE
        # note that this references the object in self.configurationManager.configurations
        self.currentConfiguration = self.configurationManager.configurations[0]

        self.add_components(show_trigger_options,show_display_options,show_autolevel,autolevel)
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)
        self.update_microscope_mode_by_name(self.currentConfiguration.name)

        self.is_switching_mode = False # flag used to prevent from settings being set by twice - from both mode change slot and value change slot; another way is to use blockSignals(True)

    def add_components(self,show_trigger_options,show_display_options,show_autolevel,autolevel):
        # line 0: trigger mode
        self.triggerMode = None
        self.dropdown_triggerManu = QComboBox()
        self.dropdown_triggerManu.addItems([TriggerMode.SOFTWARE,TriggerMode.HARDWARE,TriggerMode.CONTINUOUS])

        # line 1: fps
        self.entry_triggerFPS = QDoubleSpinBox()
        self.entry_triggerFPS.setMinimum(0.02) 
        self.entry_triggerFPS.setMaximum(1000) 
        self.entry_triggerFPS.setSingleStep(1)
        self.entry_triggerFPS.setValue(self.fps_trigger)

        # line 2: choose microscope mode / toggle live mode 
        self.dropdown_modeSelection = QComboBox()
        for microscope_configuration in self.configurationManager.configurations:
            self.dropdown_modeSelection.addItems([microscope_configuration.name])
        self.dropdown_modeSelection.setCurrentText(self.currentConfiguration.name)

        self.btn_live = QPushButton("Live")
        self.btn_live.setCheckable(True)
        self.btn_live.setChecked(False)
        self.btn_live.setDefault(False)

        # line 3: exposure time and analog gain associated with the current mode
        self.entry_exposureTime = QDoubleSpinBox()
        self.entry_exposureTime.setMinimum(self.liveController.camera.EXPOSURE_TIME_MS_MIN) 
        self.entry_exposureTime.setMaximum(self.liveController.camera.EXPOSURE_TIME_MS_MAX) 
        self.entry_exposureTime.setSingleStep(1)
        self.entry_exposureTime.setValue(0)

        self.entry_analogGain = QDoubleSpinBox()
        self.entry_analogGain = QDoubleSpinBox()
        self.entry_analogGain.setMinimum(0) 
        self.entry_analogGain.setMaximum(24) 
        self.entry_analogGain.setSingleStep(0.1)
        self.entry_analogGain.setValue(0)

        self.slider_illuminationIntensity = QSlider(Qt.Horizontal)
        self.slider_illuminationIntensity.setTickPosition(QSlider.TicksBelow)
        self.slider_illuminationIntensity.setMinimum(0)
        self.slider_illuminationIntensity.setMaximum(100)
        self.slider_illuminationIntensity.setValue(100)
        self.slider_illuminationIntensity.setSingleStep(1)

        self.entry_illuminationIntensity = QDoubleSpinBox()
        self.entry_illuminationIntensity.setMinimum(0) 
        self.entry_illuminationIntensity.setMaximum(100) 
        self.entry_illuminationIntensity.setSingleStep(1)
        self.entry_illuminationIntensity.setValue(100)

        # line 4: display fps and resolution scaling
        self.entry_displayFPS = QDoubleSpinBox()
        self.entry_displayFPS.setMinimum(1) 
        self.entry_displayFPS.setMaximum(240) 
        self.entry_displayFPS.setSingleStep(1)
        self.entry_displayFPS.setValue(self.fps_display)

        self.slider_resolutionScaling = QSlider(Qt.Horizontal)
        self.slider_resolutionScaling.setTickPosition(QSlider.TicksBelow)
        self.slider_resolutionScaling.setMinimum(10)
        self.slider_resolutionScaling.setMaximum(100)
        self.slider_resolutionScaling.setValue(DEFAULT_DISPLAY_CROP)
        self.slider_resolutionScaling.setSingleStep(10)

        # autolevel
        self.btn_autolevel = QPushButton('Autolevel')
        self.btn_autolevel.setCheckable(True)
        self.btn_autolevel.setChecked(autolevel)
        
        # connections
        self.entry_triggerFPS.valueChanged.connect(self.liveController.set_trigger_fps)
        self.entry_displayFPS.valueChanged.connect(self.streamHandler.set_display_fps)
        self.slider_resolutionScaling.valueChanged.connect(self.streamHandler.set_display_resolution_scaling)
        self.slider_resolutionScaling.valueChanged.connect(self.liveController.set_display_resolution_scaling)
        self.dropdown_modeSelection.currentTextChanged.connect(self.update_microscope_mode_by_name)
        self.dropdown_triggerManu.currentIndexChanged.connect(self.update_trigger_mode)
        self.btn_live.clicked.connect(self.toggle_live)
        self.entry_exposureTime.valueChanged.connect(self.update_config_exposure_time)
        self.entry_analogGain.valueChanged.connect(self.update_config_analog_gain)
        self.entry_illuminationIntensity.valueChanged.connect(self.update_config_illumination_intensity)
        self.entry_illuminationIntensity.valueChanged.connect(lambda x: self.slider_illuminationIntensity.setValue(int(x)))
        self.slider_illuminationIntensity.valueChanged.connect(self.entry_illuminationIntensity.setValue)
        self.btn_autolevel.clicked.connect(self.signal_autoLevelSetting.emit)

        # layout
        grid_line0 = QGridLayout()
        grid_line0.addWidget(QLabel('Trigger Mode'), 0,0)
        grid_line0.addWidget(self.dropdown_triggerManu, 0,1)
        grid_line0.addWidget(QLabel('Trigger FPS'), 0,2)
        grid_line0.addWidget(self.entry_triggerFPS, 0,3)

        grid_line1 = QGridLayout()
        grid_line1.addWidget(QLabel('Microscope Configuration'), 0,0)
        grid_line1.addWidget(self.dropdown_modeSelection, 0,1)
        grid_line1.addWidget(self.btn_live, 0,2)

        grid_line2 = QGridLayout()
        grid_line2.addWidget(QLabel('Exposure Time (ms)'), 0,0)
        grid_line2.addWidget(self.entry_exposureTime, 0,1)
        grid_line2.addWidget(QLabel('Analog Gain'), 0,2)
        grid_line2.addWidget(self.entry_analogGain, 0,3)

        grid_line4 = QGridLayout()
        grid_line4.addWidget(QLabel('Illumination'), 0,0)
        grid_line4.addWidget(self.slider_illuminationIntensity, 0,1)
        grid_line4.addWidget(self.entry_illuminationIntensity, 0,2)

        grid_line3 = QGridLayout()
        grid_line3.addWidget(QLabel('Display FPS'), 0,0)
        grid_line3.addWidget(self.entry_displayFPS, 0,1)
        grid_line3.addWidget(QLabel('Display Resolution'), 0,2)
        grid_line3.addWidget(self.slider_resolutionScaling,0,3)
        if show_autolevel:
            grid_line3.addWidget(self.btn_autolevel,0,4)

        self.grid = QVBoxLayout()
        if show_trigger_options:
            self.grid.addLayout(grid_line0)
        self.grid.addLayout(grid_line1)
        self.grid.addLayout(grid_line2)
        self.grid.addLayout(grid_line4)
        if show_display_options:
            self.grid.addLayout(grid_line3)
        self.grid.addStretch()
        self.setLayout(self.grid)

    def toggle_live(self,pressed):
        if pressed:
            self.liveController.start_live()
        else:
            self.liveController.stop_live()

    def update_camera_settings(self):
        self.signal_newAnalogGain.emit(self.entry_analogGain.value())
        self.signal_newExposureTime.emit(self.entry_exposureTime.value())

    def update_microscope_mode_by_name(self,current_microscope_mode_name):
        self.is_switching_mode = True
        # identify the mode selected (note that this references the object in self.configurationManager.configurations)
        self.currentConfiguration = next((config for config in self.configurationManager.configurations if config.name == current_microscope_mode_name), None)
        # update the microscope to the current configuration
        self.liveController.set_microscope_mode(self.currentConfiguration)
        # update the exposure time and analog gain settings according to the selected configuration
        self.entry_exposureTime.setValue(self.currentConfiguration.exposure_time)
        self.entry_analogGain.setValue(self.currentConfiguration.analog_gain)
        self.entry_illuminationIntensity.setValue(self.currentConfiguration.illumination_intensity)
        self.is_switching_mode = False

    def update_trigger_mode(self):
        self.liveController.set_trigger_mode(self.dropdown_triggerManu.currentText())

    def update_config_exposure_time(self,new_value):
        if self.is_switching_mode == False:
            self.currentConfiguration.exposure_time = new_value
            self.configurationManager.update_configuration(self.currentConfiguration.id,'ExposureTime',new_value)
            self.signal_newExposureTime.emit(new_value)

    def update_config_analog_gain(self,new_value):
        if self.is_switching_mode == False:
            self.currentConfiguration.analog_gain = new_value
            self.configurationManager.update_configuration(self.currentConfiguration.id,'AnalogGain',new_value)
            self.signal_newAnalogGain.emit(new_value)

    def update_config_illumination_intensity(self,new_value):
        if self.is_switching_mode == False:
            self.currentConfiguration.illumination_intensity = new_value
            self.configurationManager.update_configuration(self.currentConfiguration.id,'IlluminationIntensity',new_value)
            self.liveController.set_illumination(self.currentConfiguration.illumination_source, self.currentConfiguration.illumination_intensity)

    def set_microscope_mode(self,config):
        # self.liveController.set_microscope_mode(config)
        self.dropdown_modeSelection.setCurrentText(config.name)

    def set_trigger_mode(self,trigger_mode):
        self.dropdown_triggerManu.setCurrentText(trigger_mode)
        self.liveController.set_trigger_mode(self.dropdown_triggerManu.currentText())

class PiezoWidget(QFrame):
    def __init__(self, navigationController, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.add_components()
        self.navigationController = navigationController

    def add_components(self):
        # Row 1: Slider and Double Spin Box for direct control
        self.slider = QSlider(Qt.Horizontal, self)
        self.slider.setMinimum(0)
        self.slider.setMaximum(OBJECTIVE_PIEZO_RANGE_UM)  # Assuming maximum position is 300 um
        self.spinBox = QDoubleSpinBox(self)

        self.spinBox.setRange(0.0, OBJECTIVE_PIEZO_RANGE_UM)  # Range set from 0 to 300 um
        self.spinBox.setDecimals(0)
        self.spinBox.setSingleStep(1)  # Small step for fine control

        hbox1 = QHBoxLayout()
        hbox1.addWidget(self.slider)
        hbox1.addWidget(self.spinBox)

        # Row 2: Increment Double Spin Box, Move Up and Move Down Buttons
        self.increment_spinBox = QDoubleSpinBox(self)
        self.increment_spinBox.setRange(0.0, 100.0)  # Range for increment, adjust as needed
        self.increment_spinBox.setDecimals(0)
        self.increment_spinBox.setSingleStep(1)
        self.increment_spinBox.setValue(1.0)  # Set default increment to 1 um
        self.move_up_btn = QPushButton("Move Up", self)
        self.move_down_btn = QPushButton("Move Down", self)

        hbox2 = QHBoxLayout()
        hbox2.addWidget(self.increment_spinBox)
        hbox2.addWidget(self.move_up_btn)
        hbox2.addWidget(self.move_down_btn)

        # Row 3: Home Button
        self.home_btn = QPushButton("Home to " + str(OBJECTIVE_PIEZO_HOME_UM) + " um", self)

        hbox3 = QHBoxLayout()
        hbox3.addWidget(self.home_btn)

        # Vertical Layout to include all HBoxes
        vbox = QVBoxLayout()
        vbox.addLayout(hbox1)
        vbox.addLayout(hbox2)
        vbox.addLayout(hbox3)

        self.setLayout(vbox)

        # Connect signals and slots
        self.slider.valueChanged.connect(self.update_spinBox_from_slider)
        self.spinBox.valueChanged.connect(self.update_slider_from_spinBox)
        self.move_up_btn.clicked.connect(lambda: self.adjust_position(True))
        self.move_down_btn.clicked.connect(lambda: self.adjust_position(False))
        self.home_btn.clicked.connect(self.home)

    def update_spinBox_from_slider(self, value):
        self.spinBox.setValue(float(value))
        displacement_um = float(self.spinBox.value())
        dac = int(65535 * (displacement_um / OBJECTIVE_PIEZO_RANGE_UM))
        self.navigationController.microcontroller.analog_write_onboard_DAC(7, dac)

    def update_slider_from_spinBox(self, value):
        self.slider.setValue(int(value))

    def adjust_position(self, up):
        increment = self.increment_spinBox.value()
        current_position = self.spinBox.value()
        if up:
            new_position = current_position + increment
        else:
            new_position = current_position - increment
        self.spinBox.setValue(new_position)

    def home(self):
        self.spinBox.setValue(OBJECTIVE_PIEZO_HOME_UM)

    def update_displacement_um_display(self, displacement):
        self.spinBox.blockSignals(True)
        self.slider.blockSignals(True)
        self.spinBox.setValue(displacement)
        self.slider.setValue(int(displacement))
        self.spinBox.blockSignals(False)
        self.slider.blockSignals(False)

class RecordingWidget(QFrame):
    def __init__(self, streamHandler, imageSaver, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.imageSaver = imageSaver # for saving path control
        self.streamHandler = streamHandler
        self.base_path_is_set = False
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        self.btn_setSavingDir = QPushButton('Browse')
        self.btn_setSavingDir.setDefault(False)
        self.btn_setSavingDir.setIcon(QIcon('icon/folder.png'))
        
        self.lineEdit_savingDir = QLineEdit()
        self.lineEdit_savingDir.setReadOnly(True)
        self.lineEdit_savingDir.setText('Choose a base saving directory')

        self.lineEdit_savingDir.setText(DEFAULT_SAVING_PATH)
        self.imageSaver.set_base_path(DEFAULT_SAVING_PATH)

        self.lineEdit_experimentID = QLineEdit()

        self.entry_saveFPS = QDoubleSpinBox()
        self.entry_saveFPS.setMinimum(0.02) 
        self.entry_saveFPS.setMaximum(1000) 
        self.entry_saveFPS.setSingleStep(1)
        self.entry_saveFPS.setValue(1)
        self.streamHandler.set_save_fps(1)

        self.entry_timeLimit = QSpinBox()
        self.entry_timeLimit.setMinimum(-1) 
        self.entry_timeLimit.setMaximum(60*60*24*30) 
        self.entry_timeLimit.setSingleStep(1)
        self.entry_timeLimit.setValue(-1)

        self.btn_record = QPushButton("Record")
        self.btn_record.setCheckable(True)
        self.btn_record.setChecked(False)
        self.btn_record.setDefault(False)

        grid_line1 = QGridLayout()
        grid_line1.addWidget(QLabel('Saving Path'))
        grid_line1.addWidget(self.lineEdit_savingDir, 0,1)
        grid_line1.addWidget(self.btn_setSavingDir, 0,2)

        grid_line2 = QGridLayout()
        grid_line2.addWidget(QLabel('Experiment ID'), 0,0)
        grid_line2.addWidget(self.lineEdit_experimentID,0,1)

        grid_line3 = QGridLayout()
        grid_line3.addWidget(QLabel('Saving FPS'), 0,0)
        grid_line3.addWidget(self.entry_saveFPS, 0,1)
        grid_line3.addWidget(QLabel('Time Limit (s)'), 0,2)
        grid_line3.addWidget(self.entry_timeLimit, 0,3)
        grid_line3.addWidget(self.btn_record, 0,4)

        self.grid = QGridLayout()
        self.grid.addLayout(grid_line1,0,0)
        self.grid.addLayout(grid_line2,1,0)
        self.grid.addLayout(grid_line3,2,0)
        self.setLayout(self.grid)

        # add and display a timer - to be implemented
        # self.timer = QTimer()

        # connections
        self.btn_setSavingDir.clicked.connect(self.set_saving_dir)
        self.btn_record.clicked.connect(self.toggle_recording)
        self.entry_saveFPS.valueChanged.connect(self.streamHandler.set_save_fps)
        self.entry_timeLimit.valueChanged.connect(self.imageSaver.set_recording_time_limit)
        self.imageSaver.stop_recording.connect(self.stop_recording)

    def set_saving_dir(self):
        dialog = QFileDialog()
        save_dir_base = dialog.getExistingDirectory(None, "Select Folder")
        self.imageSaver.set_base_path(save_dir_base)
        self.lineEdit_savingDir.setText(save_dir_base)
        self.base_path_is_set = True

    def toggle_recording(self,pressed):
        if self.base_path_is_set == False:
            self.btn_record.setChecked(False)
            msg = QMessageBox()
            msg.setText("Please choose base saving directory first")
            msg.exec_()
            return
        if pressed:
            self.lineEdit_experimentID.setEnabled(False)
            self.btn_setSavingDir.setEnabled(False)
            self.imageSaver.start_new_experiment(self.lineEdit_experimentID.text())
            self.streamHandler.start_recording()
        else:
            self.streamHandler.stop_recording()
            self.lineEdit_experimentID.setEnabled(True)
            self.btn_setSavingDir.setEnabled(True)

    # stop_recording can be called by imageSaver
    def stop_recording(self):
        self.lineEdit_experimentID.setEnabled(True)
        self.btn_record.setChecked(False)
        self.streamHandler.stop_recording()
        self.btn_setSavingDir.setEnabled(True)

class NavigationWidget(QFrame):
    def __init__(self, navigationController, slidePositionController=None, main=None, widget_configuration = 'full', *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.navigationController = navigationController
        self.slidePositionController = slidePositionController
        self.widget_configuration = widget_configuration
        self.slide_position = None
        self.flag_click_to_move = False
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        self.label_Xpos = QLabel()
        self.label_Xpos.setNum(0)
        self.label_Xpos.setFrameStyle(QFrame.Panel | QFrame.Sunken)
        self.entry_dX = QDoubleSpinBox()
        self.entry_dX.setMinimum(0) 
        self.entry_dX.setMaximum(25) 
        self.entry_dX.setSingleStep(0.2)
        self.entry_dX.setValue(0)
        self.entry_dX.setDecimals(3)
        self.entry_dX.setKeyboardTracking(False)
        self.btn_moveX_forward = QPushButton('Forward')
        self.btn_moveX_forward.setDefault(False)
        self.btn_moveX_backward = QPushButton('Backward')
        self.btn_moveX_backward.setDefault(False)

        self.btn_home_X = QPushButton('Home X')
        self.btn_home_X.setDefault(False)
        self.btn_home_X.setEnabled(HOMING_ENABLED_X)
        self.btn_zero_X = QPushButton('Zero X')
        self.btn_zero_X.setDefault(False)
     
        self.checkbox_clickToMove = QCheckBox('Click to move')
        self.checkbox_clickToMove.setChecked(False)

        self.label_Ypos = QLabel()
        self.label_Ypos.setNum(0)
        self.label_Ypos.setFrameStyle(QFrame.Panel | QFrame.Sunken)
        self.entry_dY = QDoubleSpinBox()
        self.entry_dY.setMinimum(0)
        self.entry_dY.setMaximum(25)
        self.entry_dY.setSingleStep(0.2)
        self.entry_dY.setValue(0)
        self.entry_dY.setDecimals(3)
        self.entry_dY.setKeyboardTracking(False)
        self.btn_moveY_forward = QPushButton('Forward')
        self.btn_moveY_forward.setDefault(False)
        self.btn_moveY_backward = QPushButton('Backward')
        self.btn_moveY_backward.setDefault(False)

        self.btn_home_Y = QPushButton('Home Y')
        self.btn_home_Y.setDefault(False)
        self.btn_home_Y.setEnabled(HOMING_ENABLED_Y)
        self.btn_zero_Y = QPushButton('Zero Y')
        self.btn_zero_Y.setDefault(False)

        self.label_Zpos = QLabel()
        self.label_Zpos.setNum(0)
        self.label_Zpos.setFrameStyle(QFrame.Panel | QFrame.Sunken)
        self.entry_dZ = QDoubleSpinBox()
        self.entry_dZ.setMinimum(0) 
        self.entry_dZ.setMaximum(1000) 
        self.entry_dZ.setSingleStep(0.2)
        self.entry_dZ.setValue(0)
        self.entry_dZ.setDecimals(3)
        self.entry_dZ.setKeyboardTracking(False)
        self.btn_moveZ_forward = QPushButton('Forward')
        self.btn_moveZ_forward.setDefault(False)
        self.btn_moveZ_backward = QPushButton('Backward')
        self.btn_moveZ_backward.setDefault(False)

        self.btn_home_Z = QPushButton('Home Z')
        self.btn_home_Z.setDefault(False)
        self.btn_home_Z.setEnabled(HOMING_ENABLED_Z)
        self.btn_zero_Z = QPushButton('Zero Z')
        self.btn_zero_Z.setDefault(False)

        self.btn_load_slide = QPushButton('To Slide Loading Position')
        
        grid_line0 = QGridLayout()
        grid_line0.addWidget(QLabel('X (mm)'), 0,0)
        grid_line0.addWidget(self.label_Xpos, 0,1)
        grid_line0.addWidget(self.entry_dX, 0,2)
        grid_line0.addWidget(self.btn_moveX_forward, 0,3)
        grid_line0.addWidget(self.btn_moveX_backward, 0,4)
        
        grid_line1 = QGridLayout()
        grid_line1.addWidget(QLabel('Y (mm)'), 0,0)
        grid_line1.addWidget(self.label_Ypos, 0,1)
        grid_line1.addWidget(self.entry_dY, 0,2)
        grid_line1.addWidget(self.btn_moveY_forward, 0,3)
        grid_line1.addWidget(self.btn_moveY_backward, 0,4)

        grid_line2 = QGridLayout()
        grid_line2.addWidget(QLabel('Z (um)'), 0,0)
        grid_line2.addWidget(self.label_Zpos, 0,1)
        grid_line2.addWidget(self.entry_dZ, 0,2)
        grid_line2.addWidget(self.btn_moveZ_forward, 0,3)
        grid_line2.addWidget(self.btn_moveZ_backward, 0,4)
        
        grid_line3 = QHBoxLayout()

        grid_line3_buttons = QGridLayout()
        if self.widget_configuration == 'full':
            grid_line3_buttons.addWidget(self.btn_zero_X, 0,3)
            grid_line3_buttons.addWidget(self.btn_zero_Y, 0,4)
            grid_line3_buttons.addWidget(self.btn_zero_Z, 0,5)
            grid_line3_buttons.addWidget(self.btn_home_X, 0,0)
            grid_line3_buttons.addWidget(self.btn_home_Y, 0,1)
            grid_line3_buttons.addWidget(self.btn_home_Z, 0,2)
        elif self.widget_configuration == 'malaria':
            grid_line3_buttons.addWidget(self.btn_load_slide, 0,0,1,2)
            grid_line3_buttons.addWidget(self.btn_home_Z, 0,2,1,1)
            grid_line3_buttons.addWidget(self.btn_zero_Z, 0,3,1,1)
        elif self.widget_configuration == '384 well plate':
            grid_line3_buttons.addWidget(self.btn_load_slide, 0,0,1,2)
            grid_line3_buttons.addWidget(self.btn_home_Z, 0,2,1,1)
            grid_line3_buttons.addWidget(self.btn_zero_Z, 0,3,1,1)
        elif self.widget_configuration == '96 well plate':
            grid_line3_buttons.addWidget(self.btn_load_slide, 0,0,1,2)
            grid_line3_buttons.addWidget(self.btn_home_Z, 0,2,1,1)
            grid_line3_buttons.addWidget(self.btn_zero_Z, 0,3,1,1)

        grid_line3.addLayout(grid_line3_buttons)

        grid_line3.addWidget(self.checkbox_clickToMove)
        

        self.grid = QGridLayout()
        self.grid.addLayout(grid_line0,0,0)
        self.grid.addLayout(grid_line1,1,0)
        self.grid.addLayout(grid_line2,2,0)
        self.grid.addLayout(grid_line3,3,0)
        self.setLayout(self.grid)

        self.entry_dX.valueChanged.connect(self.set_deltaX)
        self.entry_dY.valueChanged.connect(self.set_deltaY)
        self.entry_dZ.valueChanged.connect(self.set_deltaZ)

        self.btn_moveX_forward.clicked.connect(self.move_x_forward)
        self.btn_moveX_backward.clicked.connect(self.move_x_backward)
        self.btn_moveY_forward.clicked.connect(self.move_y_forward)
        self.btn_moveY_backward.clicked.connect(self.move_y_backward)
        self.btn_moveZ_forward.clicked.connect(self.move_z_forward)
        self.btn_moveZ_backward.clicked.connect(self.move_z_backward)

        self.btn_home_X.clicked.connect(self.home_x)
        self.btn_home_Y.clicked.connect(self.home_y)
        self.btn_home_Z.clicked.connect(self.home_z)
        self.btn_zero_X.clicked.connect(self.zero_x)
        self.btn_zero_Y.clicked.connect(self.zero_y)
        self.btn_zero_Z.clicked.connect(self.zero_z)

        self.checkbox_clickToMove.stateChanged.connect(self.navigationController.set_flag_click_to_move)

        self.btn_load_slide.clicked.connect(self.switch_position)
        self.btn_load_slide.setStyleSheet("background-color: #C2C2FF");

    def toggle_navigation_controls(self, started):
        if started:
            self.flag_click_to_move = self.navigationController.get_flag_click_to_move()
            self.setEnabled_all(False)
            self.checkbox_clickToMove.setChecked(False)
        else:
            self.setEnabled_all(True)
            self.checkbox_clickToMove.setChecked(self.flag_click_to_move)

    def setEnabled_all(self, enabled):
        self.checkbox_clickToMove.setEnabled(enabled)
        self.btn_home_X.setEnabled(enabled)
        self.btn_zero_X.setEnabled(enabled)
        self.btn_moveX_forward.setEnabled(enabled)
        self.btn_moveX_backward.setEnabled(enabled)
        self.btn_home_Y.setEnabled(enabled)
        self.btn_zero_Y.setEnabled(enabled)
        self.btn_moveY_forward.setEnabled(enabled)
        self.btn_moveY_backward.setEnabled(enabled)
        self.btn_home_Z.setEnabled(enabled)
        self.btn_zero_Z.setEnabled(enabled)
        self.btn_moveZ_forward.setEnabled(enabled)
        self.btn_moveZ_backward.setEnabled(enabled)
        self.btn_load_slide.setEnabled(enabled)

        
    def move_x_forward(self):
        self.navigationController.move_x(self.entry_dX.value())
    def move_x_backward(self):
        self.navigationController.move_x(-self.entry_dX.value())
    def move_y_forward(self):
        self.navigationController.move_y(self.entry_dY.value())
    def move_y_backward(self):
        self.navigationController.move_y(-self.entry_dY.value())
    def move_z_forward(self):
        self.navigationController.move_z(self.entry_dZ.value()/1000)
    def move_z_backward(self):
        self.navigationController.move_z(-self.entry_dZ.value()/1000) 

    def set_deltaX(self,value):
        mm_per_ustep = SCREW_PITCH_X_MM/(self.navigationController.x_microstepping*FULLSTEPS_PER_REV_X) # to implement a get_x_microstepping() in multipointController
        deltaX = round(value/mm_per_ustep)*mm_per_ustep
        self.entry_dX.setValue(deltaX)
    def set_deltaY(self,value):
        mm_per_ustep = SCREW_PITCH_Y_MM/(self.navigationController.y_microstepping*FULLSTEPS_PER_REV_Y)
        deltaY = round(value/mm_per_ustep)*mm_per_ustep
        self.entry_dY.setValue(deltaY)
    def set_deltaZ(self,value):
        mm_per_ustep = SCREW_PITCH_Z_MM/(self.navigationController.z_microstepping*FULLSTEPS_PER_REV_Z)
        deltaZ = round(value/1000/mm_per_ustep)*mm_per_ustep*1000
        self.entry_dZ.setValue(deltaZ)

    def home_x(self):
        msg = QMessageBox()
        msg.setIcon(QMessageBox.Information)
        msg.setText("Confirm your action")
        msg.setInformativeText("Click OK to run homing")
        msg.setWindowTitle("Confirmation")
        msg.setStandardButtons(QMessageBox.Ok | QMessageBox.Cancel)
        msg.setDefaultButton(QMessageBox.Cancel)
        retval = msg.exec_()
        if QMessageBox.Ok == retval:
            self.navigationController.home_x()

    def home_y(self):
        msg = QMessageBox()
        msg.setIcon(QMessageBox.Information)
        msg.setText("Confirm your action")
        msg.setInformativeText("Click OK to run homing")
        msg.setWindowTitle("Confirmation")
        msg.setStandardButtons(QMessageBox.Ok | QMessageBox.Cancel)
        msg.setDefaultButton(QMessageBox.Cancel)
        retval = msg.exec_()
        if QMessageBox.Ok == retval:
            self.navigationController.home_y()

    def home_z(self):
        msg = QMessageBox()
        msg.setIcon(QMessageBox.Information)
        msg.setText("Confirm your action")
        msg.setInformativeText("Click OK to run homing")
        msg.setWindowTitle("Confirmation")
        msg.setStandardButtons(QMessageBox.Ok | QMessageBox.Cancel)
        msg.setDefaultButton(QMessageBox.Cancel)
        retval = msg.exec_()
        if QMessageBox.Ok == retval:
            self.navigationController.home_z()

    def zero_x(self):
        self.navigationController.zero_x()

    def zero_y(self):
        self.navigationController.zero_y()

    def zero_z(self):
        self.navigationController.zero_z()

    def slot_slide_loading_position_reached(self):
        self.slide_position = 'loading'
        self.btn_load_slide.setStyleSheet("background-color: #C2FFC2");
        self.btn_load_slide.setText('To Scanning Position')
        self.btn_moveX_forward.setEnabled(False)
        self.btn_moveX_backward.setEnabled(False)
        self.btn_moveY_forward.setEnabled(False)
        self.btn_moveY_backward.setEnabled(False)
        self.btn_moveZ_forward.setEnabled(False)
        self.btn_moveZ_backward.setEnabled(False)
        self.btn_load_slide.setEnabled(True)

    def slot_slide_scanning_position_reached(self):
        self.slide_position = 'scanning'
        self.btn_load_slide.setStyleSheet("background-color: #C2C2FF");
        self.btn_load_slide.setText('To Loading Position')
        self.btn_moveX_forward.setEnabled(True)
        self.btn_moveX_backward.setEnabled(True)
        self.btn_moveY_forward.setEnabled(True)
        self.btn_moveY_backward.setEnabled(True)
        self.btn_moveZ_forward.setEnabled(True)
        self.btn_moveZ_backward.setEnabled(True)
        self.btn_load_slide.setEnabled(True)

    def switch_position(self):
        if self.slide_position != 'loading':
            self.slidePositionController.move_to_slide_loading_position()
        else:
            self.slidePositionController.move_to_slide_scanning_position()
        self.btn_load_slide.setEnabled(False)

class DACControWidget(QFrame):
    def __init__(self, microcontroller ,*args, **kwargs):
        super().__init__(*args, **kwargs)
        self.microcontroller = microcontroller
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        self.slider_DAC0 = QSlider(Qt.Horizontal)
        self.slider_DAC0.setTickPosition(QSlider.TicksBelow)
        self.slider_DAC0.setMinimum(0)
        self.slider_DAC0.setMaximum(100)
        self.slider_DAC0.setSingleStep(1)
        self.slider_DAC0.setValue(0)

        self.entry_DAC0 = QDoubleSpinBox()
        self.entry_DAC0.setMinimum(0) 
        self.entry_DAC0.setMaximum(100) 
        self.entry_DAC0.setSingleStep(0.1)
        self.entry_DAC0.setValue(0)
        self.entry_DAC0.setKeyboardTracking(False)

        self.slider_DAC1 = QSlider(Qt.Horizontal)
        self.slider_DAC1.setTickPosition(QSlider.TicksBelow)
        self.slider_DAC1.setMinimum(0)
        self.slider_DAC1.setMaximum(100)
        self.slider_DAC1.setValue(0)
        self.slider_DAC1.setSingleStep(1)

        self.entry_DAC1 = QDoubleSpinBox()
        self.entry_DAC1.setMinimum(0) 
        self.entry_DAC1.setMaximum(100) 
        self.entry_DAC1.setSingleStep(0.1)
        self.entry_DAC1.setValue(0)
        self.entry_DAC1.setKeyboardTracking(False)

        # connections
        self.entry_DAC0.valueChanged.connect(self.set_DAC0)
        self.entry_DAC0.valueChanged.connect(self.slider_DAC0.setValue)
        self.slider_DAC0.valueChanged.connect(self.entry_DAC0.setValue)
        self.entry_DAC1.valueChanged.connect(self.set_DAC1)
        self.entry_DAC1.valueChanged.connect(self.slider_DAC1.setValue)
        self.slider_DAC1.valueChanged.connect(self.entry_DAC1.setValue)

        # layout
        grid_line1 = QGridLayout()
        grid_line1.addWidget(QLabel('DAC0'), 0,0)
        grid_line1.addWidget(self.slider_DAC0, 0,1)
        grid_line1.addWidget(self.entry_DAC0, 0,2)
        grid_line1.addWidget(QLabel('DAC1'), 1,0)
        grid_line1.addWidget(self.slider_DAC1, 1,1)
        grid_line1.addWidget(self.entry_DAC1, 1,2)

        self.grid = QGridLayout()
        self.grid.addLayout(grid_line1,1,0)
        self.setLayout(self.grid)

    def set_DAC0(self,value):
        self.microcontroller.analog_write_onboard_DAC(0,int(value*65535/100))

    def set_DAC1(self,value):
        self.microcontroller.analog_write_onboard_DAC(1,int(value*65535/100))

class AutoFocusWidget(QFrame):
    def __init__(self, autofocusController, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.autofocusController = autofocusController
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        self.entry_delta = QDoubleSpinBox()
        self.entry_delta.setMinimum(0) 
        self.entry_delta.setMaximum(20) 
        self.entry_delta.setSingleStep(0.2)
        self.entry_delta.setDecimals(3)
        self.entry_delta.setValue(1.524)
        self.entry_delta.setKeyboardTracking(False)
        self.autofocusController.set_deltaZ(1.524)

        self.entry_N = QSpinBox()
        self.entry_N.setMinimum(3) 
        self.entry_N.setMaximum(20) 
        self.entry_N.setSingleStep(1)
        self.entry_N.setValue(10)
        self.entry_N.setKeyboardTracking(False)
        self.autofocusController.set_N(10)

        self.btn_autofocus = QPushButton('Autofocus')
        self.btn_autofocus.setDefault(False)
        self.btn_autofocus.setCheckable(True)
        self.btn_autofocus.setChecked(False)

        # layout
        grid_line0 = QGridLayout()
        grid_line0.addWidget(QLabel('delta Z (um)'), 0,0)
        grid_line0.addWidget(self.entry_delta, 0,1)
        grid_line0.addWidget(QLabel('N Z planes'), 0,2)
        grid_line0.addWidget(self.entry_N, 0,3)
        grid_line0.addWidget(self.btn_autofocus, 0,4)

        self.grid = QGridLayout()
        self.grid.addLayout(grid_line0,0,0)
        self.grid.setRowStretch(self.grid.rowCount(), 1)
        self.setLayout(self.grid)
        
        # connections
        self.btn_autofocus.clicked.connect(lambda : self.autofocusController.autofocus(False))
        self.entry_delta.valueChanged.connect(self.set_deltaZ)
        self.entry_N.valueChanged.connect(self.autofocusController.set_N)
        self.autofocusController.autofocusFinished.connect(self.autofocus_is_finished)

    def set_deltaZ(self,value):
        mm_per_ustep = SCREW_PITCH_Z_MM/(self.autofocusController.navigationController.z_microstepping*FULLSTEPS_PER_REV_Z)
        deltaZ = round(value/1000/mm_per_ustep)*mm_per_ustep*1000
        self.entry_delta.setValue(deltaZ)
        self.autofocusController.set_deltaZ(deltaZ)

    def autofocus_is_finished(self):
        self.btn_autofocus.setChecked(False)


class FilterControllerWidget(QFrame):
    def __init__(self, filterController, liveController, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.filterController = filterController
        self.liveController = liveController
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        self.comboBox = QComboBox()
        for i in range(1, 8):  # Assuming 7 filter positions
            self.comboBox.addItem(f"Position {i}")
        self.checkBox = QCheckBox("Disable filter wheel movement on changing Microscope Configuration", self)
            
        layout = QGridLayout()
        layout.addWidget(QLabel('Filter wheel position:'), 0,0)
        layout.addWidget(self.comboBox, 0,1)
        layout.addWidget(self.checkBox, 2,0)

        self.setLayout(layout)
        
        self.comboBox.currentIndexChanged.connect(self.on_selection_change)  # Connecting to selection change
        self.checkBox.stateChanged.connect(self.disable_movement_by_switching_channels)

    def on_selection_change(self, index):
        # The 'index' parameter is the new index of the combo box
        if index >= 0 and index <= 7:  # Making sure the index is valid
            self.filterController.set_emission_filter(index+1)

    def disable_movement_by_switching_channels(self, state):
        if state:
            self.liveController.enable_channel_auto_filter_switching = False
        else:
            self.liveController.enable_channel_auto_filter_switching = True


class StatsDisplayWidget(QFrame):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.initUI()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def initUI(self):
        self.layout = QVBoxLayout()
        self.table_widget = QTableWidget()
        self.table_widget.setColumnCount(2)
        self.table_widget.verticalHeader().hide()
        self.table_widget.horizontalHeader().hide()
        self.table_widget.horizontalHeader().setSectionResizeMode(QHeaderView.ResizeToContents)
        self.layout.addWidget(self.table_widget)
        self.setLayout(self.layout)

    def display_stats(self, stats):
        locale.setlocale(locale.LC_ALL, '')
        self.table_widget.setRowCount(len(stats))
        row = 0
        for key, value in stats.items():
            key_item = QTableWidgetItem(str(key))
            value_item = None
            try:
                value_item = QTableWidgetItem(f'{value:n}')
            except:
                value_item = QTableWidgetItem(str(value))
            self.table_widget.setItem(row,0,key_item)
            self.table_widget.setItem(row,1,value_item)
            row+=1


class MultiPointWidget(QFrame):

    signal_acquisition_started = Signal(bool)
    signal_acquisition_channels = Signal(list)
    signal_acquisition_shape = Signal(int, int, int, float, float, float)

    def __init__(self, multipointController, configurationManager = None, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.multipointController = multipointController
        self.configurationManager = configurationManager
        self.base_path_is_set = False
        self.well_selected = False
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):

        self.btn_setSavingDir = QPushButton('Browse')
        self.btn_setSavingDir.setDefault(False)
        self.btn_setSavingDir.setIcon(QIcon('icon/folder.png'))
        
        self.lineEdit_savingDir = QLineEdit()
        self.lineEdit_savingDir.setReadOnly(True)
        self.lineEdit_savingDir.setText('Choose a base saving directory')

        self.lineEdit_savingDir.setText(DEFAULT_SAVING_PATH)
        self.multipointController.set_base_path(DEFAULT_SAVING_PATH)
        self.base_path_is_set = True

        self.lineEdit_experimentID = QLineEdit()

        self.entry_deltaX = QDoubleSpinBox()
        self.entry_deltaX.setMinimum(0) 
        self.entry_deltaX.setMaximum(5) 
        self.entry_deltaX.setSingleStep(0.1)
        self.entry_deltaX.setValue(Acquisition.DX)
        self.entry_deltaX.setDecimals(3)
        self.entry_deltaX.setKeyboardTracking(False)

        self.entry_NX = QSpinBox()
        self.entry_NX.setMinimum(1) 
        self.entry_NX.setMaximum(50) 
        self.entry_NX.setSingleStep(1)
        self.entry_NX.setValue(Acquisition.NX)
        self.entry_NX.setKeyboardTracking(False)

        self.entry_deltaY = QDoubleSpinBox()
        self.entry_deltaY.setMinimum(0) 
        self.entry_deltaY.setMaximum(5) 
        self.entry_deltaY.setSingleStep(0.1)
        self.entry_deltaY.setValue(Acquisition.DX)
        self.entry_deltaY.setDecimals(3)
        self.entry_deltaY.setKeyboardTracking(False)
        
        self.entry_NY = QSpinBox()
        self.entry_NY.setMinimum(1) 
        self.entry_NY.setMaximum(50) 
        self.entry_NY.setSingleStep(1)
        self.entry_NY.setValue(Acquisition.NY)
        self.entry_NY.setKeyboardTracking(False)

        self.entry_deltaZ = QDoubleSpinBox()
        self.entry_deltaZ.setMinimum(0) 
        self.entry_deltaZ.setMaximum(1000) 
        self.entry_deltaZ.setSingleStep(0.2)
        self.entry_deltaZ.setValue(Acquisition.DZ)
        self.entry_deltaZ.setDecimals(3)
        self.entry_deltaZ.setKeyboardTracking(False)
        
        self.entry_NZ = QSpinBox()
        self.entry_NZ.setMinimum(1) 
        self.entry_NZ.setMaximum(2000) 
        self.entry_NZ.setSingleStep(1)
        self.entry_NZ.setValue(1)
        self.entry_NZ.setKeyboardTracking(False)
        
        self.entry_dt = QDoubleSpinBox()
        self.entry_dt.setMinimum(0) 
        self.entry_dt.setMaximum(12*3600) 
        self.entry_dt.setSingleStep(1)
        self.entry_dt.setValue(0)
        self.entry_dt.setKeyboardTracking(False)

        self.entry_Nt = QSpinBox()
        self.entry_Nt.setMinimum(1) 
        self.entry_Nt.setMaximum(50000)   # @@@ to be changed
        self.entry_Nt.setSingleStep(1)
        self.entry_Nt.setValue(1)
        self.entry_Nt.setKeyboardTracking(False)

        self.list_configurations = QListWidget()
        for microscope_configuration in self.configurationManager.configurations:
            self.list_configurations.addItems([microscope_configuration.name])
        self.list_configurations.setSelectionMode(QAbstractItemView.MultiSelection) # ref: https://doc.qt.io/qt-5/qabstractitemview.html#SelectionMode-enum

        self.checkbox_withAutofocus = QCheckBox('Contrast AF')
        self.checkbox_withAutofocus.setChecked(MULTIPOINT_AUTOFOCUS_ENABLE_BY_DEFAULT)
        self.multipointController.set_af_flag(MULTIPOINT_AUTOFOCUS_ENABLE_BY_DEFAULT)

        self.checkbox_genFocusMap = QCheckBox('Generate focus map')
        self.checkbox_genFocusMap.setChecked(False)

        self.checkbox_withReflectionAutofocus = QCheckBox('Reflection AF')
        self.checkbox_withReflectionAutofocus.setChecked(MULTIPOINT_REFLECTION_AUTOFOCUS_ENABLE_BY_DEFAULT)

        self.multipointController.set_reflection_af_flag(MULTIPOINT_REFLECTION_AUTOFOCUS_ENABLE_BY_DEFAULT)
        self.btn_startAcquisition = QPushButton('Start Acquisition')
        self.btn_startAcquisition.setStyleSheet("background-color: #C2C2FF");
        self.btn_startAcquisition.setCheckable(True)
        self.btn_startAcquisition.setChecked(False)

        # layout
        grid_line0 = QGridLayout()
        grid_line0.addWidget(QLabel('Saving Path'))
        grid_line0.addWidget(self.lineEdit_savingDir, 0,1)
        grid_line0.addWidget(self.btn_setSavingDir, 0,2)

        grid_line1 = QGridLayout()
        grid_line1.addWidget(QLabel('Experiment ID'), 0,0)
        grid_line1.addWidget(self.lineEdit_experimentID,0,1)

        grid_line2 = QGridLayout()
        grid_line2.addWidget(QLabel('dx (mm)'), 0,0)
        grid_line2.addWidget(self.entry_deltaX, 0,1)
        grid_line2.addWidget(QLabel('Nx'), 0,2)
        grid_line2.addWidget(self.entry_NX, 0,3)
        grid_line2.addWidget(QLabel('dy (mm)'), 0,4)
        grid_line2.addWidget(self.entry_deltaY, 0,5)
        grid_line2.addWidget(QLabel('Ny'), 0,6)
        grid_line2.addWidget(self.entry_NY, 0,7)

        grid_line2.addWidget(QLabel('dz (um)'), 1,0)
        grid_line2.addWidget(self.entry_deltaZ, 1,1)
        grid_line2.addWidget(QLabel('Nz'), 1,2)
        grid_line2.addWidget(self.entry_NZ, 1,3)
        grid_line2.addWidget(QLabel('dt (s)'), 1,4)
        grid_line2.addWidget(self.entry_dt, 1,5)
        grid_line2.addWidget(QLabel('Nt'), 1,6)
        grid_line2.addWidget(self.entry_Nt, 1,7)

        grid_af = QVBoxLayout()
        grid_af.addWidget(self.checkbox_withAutofocus)
        grid_af.addWidget(self.checkbox_genFocusMap)
        if SUPPORT_LASER_AUTOFOCUS:
            grid_af.addWidget(self.checkbox_withReflectionAutofocus)

        grid_line3 = QHBoxLayout()
        grid_line3.addWidget(self.list_configurations)
        # grid_line3.addWidget(self.checkbox_withAutofocus)
        grid_line3.addLayout(grid_af)
        grid_line3.addWidget(self.btn_startAcquisition)

        self.grid = QGridLayout()
        self.grid.addLayout(grid_line0,0,0)
        self.grid.addLayout(grid_line1,1,0)
        self.grid.addLayout(grid_line2,2,0)
        self.grid.addLayout(grid_line3,3,0)
        self.setLayout(self.grid)

        # add and display a timer - to be implemented
        # self.timer = QTimer()

        # connections
        self.entry_deltaX.valueChanged.connect(self.set_deltaX)
        self.entry_deltaY.valueChanged.connect(self.set_deltaY)
        self.entry_deltaZ.valueChanged.connect(self.set_deltaZ)
        self.entry_dt.valueChanged.connect(self.multipointController.set_deltat)
        self.entry_NX.valueChanged.connect(self.multipointController.set_NX)
        self.entry_NY.valueChanged.connect(self.multipointController.set_NY)
        self.entry_NZ.valueChanged.connect(self.multipointController.set_NZ)
        self.entry_Nt.valueChanged.connect(self.multipointController.set_Nt)
        self.checkbox_withAutofocus.stateChanged.connect(self.multipointController.set_af_flag)
        self.checkbox_withReflectionAutofocus.stateChanged.connect(self.multipointController.set_reflection_af_flag)
        self.checkbox_genFocusMap.stateChanged.connect(self.multipointController.set_gen_focus_map_flag)
        self.btn_setSavingDir.clicked.connect(self.set_saving_dir)
        self.btn_startAcquisition.clicked.connect(self.toggle_acquisition)
        self.multipointController.acquisitionFinished.connect(self.acquisition_is_finished)
        self.list_configurations.itemSelectionChanged.connect(self.emit_selected_channels)

    def set_deltaX(self,value):
        mm_per_ustep = SCREW_PITCH_X_MM/(self.multipointController.navigationController.x_microstepping*FULLSTEPS_PER_REV_X) # to implement a get_x_microstepping() in multipointController
        deltaX = round(value/mm_per_ustep)*mm_per_ustep
        self.entry_deltaX.setValue(deltaX)
        self.multipointController.set_deltaX(deltaX)

    def set_deltaY(self,value):
        mm_per_ustep = SCREW_PITCH_Y_MM/(self.multipointController.navigationController.y_microstepping*FULLSTEPS_PER_REV_Y)
        deltaY = round(value/mm_per_ustep)*mm_per_ustep
        self.entry_deltaY.setValue(deltaY)
        self.multipointController.set_deltaY(deltaY)

    def set_deltaZ(self,value):
        mm_per_ustep = SCREW_PITCH_Z_MM/(self.multipointController.navigationController.z_microstepping*FULLSTEPS_PER_REV_Z)
        deltaZ = round(value/1000/mm_per_ustep)*mm_per_ustep*1000
        self.entry_deltaZ.setValue(deltaZ)
        self.multipointController.set_deltaZ(deltaZ)

    def set_saving_dir(self):
        dialog = QFileDialog()
        save_dir_base = dialog.getExistingDirectory(None, "Select Folder")
        self.multipointController.set_base_path(save_dir_base)
        self.lineEdit_savingDir.setText(save_dir_base)
        self.base_path_is_set = True

    def set_well_selected(self, selected):
        self.well_selected = selected

    def emit_selected_channels(self):
        selected_channels = [item.text() for item in self.list_configurations.selectedItems()]
        self.signal_acquisition_channels.emit(selected_channels)

    def toggle_acquisition(self,pressed):
        if self.base_path_is_set == False:
            self.btn_startAcquisition.setChecked(False)
            msg = QMessageBox()
            msg.setText("Please choose base saving directory first")
            msg.exec_()
            return
        if IS_HCS and self.well_selected == False:
            self.btn_startAcquisition.setChecked(False)
            msg = QMessageBox()
            msg.setText("Please select a well to scan first")
            msg.exec_()
            return
        if not self.list_configurations.selectedItems(): # no channel selected
            self.btn_startAcquisition.setChecked(False)
            msg = QMessageBox()
            msg.setText("Please select at least one imaging channel first")
            msg.exec_()
            return
        if pressed:
            # @@@ to do: add a widgetManger to enable and disable widget 
            # @@@ to do: emit signal to widgetManager to disable other widgets
            self.setEnabled_all(False)
            self.multipointController.set_selected_configurations((item.text() for item in self.list_configurations.selectedItems()))
            self.multipointController.start_new_experiment(self.lineEdit_experimentID.text())
             # emit acquisition data
            self.signal_acquisition_started.emit(True)
            self.signal_acquisition_shape.emit(self.entry_NX.value(),
                                               self.entry_NY.value(),
                                               self.entry_NZ.value(),
                                               self.entry_deltaX.value(),
                                               self.entry_deltaY.value(),
                                               self.entry_deltaZ.value())
            # set parameters
            self.multipointController.set_deltaX(self.entry_deltaX.value())
            self.multipointController.set_deltaY(self.entry_deltaY.value())
            self.multipointController.set_deltaZ(self.entry_deltaZ.value())
            self.multipointController.set_deltat(self.entry_dt.value())
            self.multipointController.set_NX(self.entry_NX.value())
            self.multipointController.set_NY(self.entry_NY.value())
            self.multipointController.set_NZ(self.entry_NZ.value())
            self.multipointController.set_Nt(self.entry_Nt.value())
            self.multipointController.set_af_flag(self.checkbox_withAutofocus.isChecked())
            self.multipointController.set_reflection_af_flag(self.checkbox_withReflectionAutofocus.isChecked())
            self.multipointController.set_base_path(self.lineEdit_savingDir.text())
            self.multipointController.run_acquisition()
        else:
            self.multipointController.request_abort_aquisition()
            self.setEnabled_all(True)

    def acquisition_is_finished(self):
        self.signal_acquisition_started.emit(False)
        self.btn_startAcquisition.setChecked(False)
        self.setEnabled_all(True)

    def setEnabled_all(self,enabled,exclude_btn_startAcquisition=True):
        self.btn_setSavingDir.setEnabled(enabled)
        self.lineEdit_savingDir.setEnabled(enabled)
        self.lineEdit_experimentID.setEnabled(enabled)
        self.entry_deltaX.setEnabled(enabled)
        self.entry_NX.setEnabled(enabled)
        self.entry_deltaY.setEnabled(enabled)
        self.entry_NY.setEnabled(enabled)
        self.entry_deltaZ.setEnabled(enabled)
        self.entry_NZ.setEnabled(enabled)
        self.entry_dt.setEnabled(enabled)
        self.entry_Nt.setEnabled(enabled)
        self.list_configurations.setEnabled(enabled)
        self.checkbox_withAutofocus.setEnabled(enabled)
        self.checkbox_withReflectionAutofocus.setEnabled(enabled)
        self.checkbox_genFocusMap.setEnabled(enabled)
        if exclude_btn_startAcquisition is not True:
            self.btn_startAcquisition.setEnabled(enabled)

    def disable_the_start_aquisition_button(self):
        self.btn_startAcquisition.setEnabled(False)

    def enable_the_start_aquisition_button(self):
        self.btn_startAcquisition.setEnabled(True)

class MultiPointWidget2(QFrame):

    signal_acquisition_started = Signal(bool)
    signal_acquisition_channels = Signal(list)
    signal_acquisition_shape = Signal(int, int, int, float, float, float)
    signal_stitcher_widget = Signal(bool)

    def __init__(self, navigationController, navigationViewer, multipointController, configurationManager = None, main=None, scanCoordinates=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.last_used_locations = None
        self.last_used_location_ids = None
        self.multipointController = multipointController
        self.configurationManager = configurationManager
        self.navigationController = navigationController
        self.navigationViewer = navigationViewer
        self.scanCoordinates = scanCoordinates
        self.base_path_is_set = False
        self.location_list = np.empty((0, 3), dtype=float)
        self.location_ids = np.empty((0,), dtype=str)
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)
        self.acquisition_in_place=False

    def add_components(self):

        self.btn_setSavingDir = QPushButton('Browse')
        self.btn_setSavingDir.setDefault(False)
        self.btn_setSavingDir.setIcon(QIcon('icon/folder.png'))

        self.lineEdit_savingDir = QLineEdit()
        self.lineEdit_savingDir.setReadOnly(True)
        self.lineEdit_savingDir.setText('Choose a base saving directory')

        self.lineEdit_savingDir.setText(DEFAULT_SAVING_PATH)
        self.multipointController.set_base_path(DEFAULT_SAVING_PATH)
        self.base_path_is_set = True

        self.lineEdit_experimentID = QLineEdit()

        self.dropdown_location_list = QComboBox()
        self.btn_add = QPushButton('Add')
        self.btn_remove = QPushButton('Remove')
        self.btn_previous = QPushButton('Previous')
        self.btn_next = QPushButton('Next')
        self.btn_clear = QPushButton('Clear all')

        self.btn_load_last_executed = QPushButton('Prev Used Locations')

        self.btn_export_locations = QPushButton('Export Location List')
        self.btn_import_locations = QPushButton('Import Location List')

        # editable points table
        self.table_location_list = QTableWidget()
        self.table_location_list.setColumnCount(4)
        header_labels = ['x', 'y', 'z', 'ID']
        self.table_location_list.setHorizontalHeaderLabels(header_labels)
        self.btn_show_table_location_list = QPushButton('Show Location List')

        self.entry_deltaX = QDoubleSpinBox()
        self.entry_deltaX.setMinimum(0) 
        self.entry_deltaX.setMaximum(5) 
        self.entry_deltaX.setSingleStep(0.1)
        self.entry_deltaX.setValue(Acquisition.DX)
        self.entry_deltaX.setDecimals(3)
        self.entry_deltaX.setKeyboardTracking(False)

        self.entry_NX = QSpinBox()
        self.entry_NX.setMinimum(1)
        self.entry_NX.setMaximum(50)
        self.entry_NX.setSingleStep(1)
        self.entry_NX.setValue(1)
        self.entry_NX.setKeyboardTracking(False)

        self.entry_deltaY = QDoubleSpinBox()
        self.entry_deltaY.setMinimum(0)
        self.entry_deltaY.setMaximum(5)
        self.entry_deltaY.setSingleStep(0.1)
        self.entry_deltaY.setValue(Acquisition.DX)
        self.entry_deltaY.setDecimals(3)
        self.entry_deltaY.setKeyboardTracking(False)

        self.entry_NY = QSpinBox()
        self.entry_NY.setMinimum(1)
        self.entry_NY.setMaximum(50)
        self.entry_NY.setSingleStep(1)
        self.entry_NY.setValue(1)
        self.entry_NY.setKeyboardTracking(False)

        self.entry_deltaZ = QDoubleSpinBox()
        self.entry_deltaZ.setMinimum(0) 
        self.entry_deltaZ.setMaximum(1000)
        self.entry_deltaZ.setSingleStep(0.2)
        self.entry_deltaZ.setValue(Acquisition.DZ)
        self.entry_deltaZ.setDecimals(3)
        self.entry_deltaZ.setKeyboardTracking(False)
        
        self.entry_NZ = QSpinBox()
        self.entry_NZ.setMinimum(1)
        self.entry_NZ.setMaximum(2000)
        self.entry_NZ.setSingleStep(1)
        self.entry_NZ.setValue(1)
        self.entry_NZ.setKeyboardTracking(False)
        
        self.entry_dt = QDoubleSpinBox()
        self.entry_dt.setMinimum(0)
        self.entry_dt.setMaximum(12*3600)
        self.entry_dt.setSingleStep(1)
        self.entry_dt.setValue(0)
        self.entry_dt.setKeyboardTracking(False)

        self.entry_Nt = QSpinBox()
        self.entry_Nt.setMinimum(1)
        self.entry_Nt.setMaximum(50000)   # @@@ to be changed
        self.entry_Nt.setSingleStep(1)
        self.entry_Nt.setValue(1)
        self.entry_Nt.setKeyboardTracking(False)

        self.list_configurations = QListWidget()
        for microscope_configuration in self.configurationManager.configurations:
            self.list_configurations.addItems([microscope_configuration.name])
        self.list_configurations.setSelectionMode(QAbstractItemView.MultiSelection) # ref: https://doc.qt.io/qt-5/qabstractitemview.html#SelectionMode-enum

        self.checkbox_withAutofocus = QCheckBox('Contrast AF')
        self.checkbox_withAutofocus.setChecked(MULTIPOINT_AUTOFOCUS_ENABLE_BY_DEFAULT)
        self.multipointController.set_af_flag(MULTIPOINT_AUTOFOCUS_ENABLE_BY_DEFAULT)
        self.checkbox_withReflectionAutofocus = QCheckBox('Reflection AF')
        self.checkbox_withReflectionAutofocus.setChecked(MULTIPOINT_REFLECTION_AUTOFOCUS_ENABLE_BY_DEFAULT)
        self.multipointController.set_reflection_af_flag(MULTIPOINT_REFLECTION_AUTOFOCUS_ENABLE_BY_DEFAULT)
        self.btn_startAcquisition = QPushButton('Start Acquisition')
        self.btn_startAcquisition.setStyleSheet("background-color: #C2C2FF");
        self.btn_startAcquisition.setCheckable(True)
        self.btn_startAcquisition.setChecked(False)

        # layout
        grid_line0 = QGridLayout()
        grid_line0.addWidget(QLabel('Saving Path'))
        grid_line0.addWidget(self.lineEdit_savingDir, 0,1)
        grid_line0.addWidget(self.btn_setSavingDir, 0,2)
        grid_line0.addWidget(QLabel('ID'), 0,3)
        grid_line0.addWidget(self.lineEdit_experimentID,0,4)

        grid_line4 = QGridLayout()
        grid_line4.addWidget(QLabel('Location List'),0,0)
        grid_line4.addWidget(self.dropdown_location_list,0,1,1,2)
        grid_line4.addWidget(self.btn_clear,0,3)
        grid_line4.addWidget(self.btn_show_table_location_list,0,4)

        grid_line3point5 = QGridLayout()
        grid_line3point5.addWidget(self.btn_add,0,0)
        grid_line3point5.addWidget(self.btn_remove,0,1)
        grid_line3point5.addWidget(self.btn_next,0,2)
        grid_line3point5.addWidget(self.btn_previous,0,3)
        #grid_line3point5.addWidget(self.btn_load_last_executed,0,4)

        grid_line3point75 = QGridLayout()
        grid_line3point75.addWidget(self.btn_import_locations,0,0)
        grid_line3point75.addWidget(self.btn_export_locations,0,1)

        grid_line2 = QGridLayout()
        grid_line2.addWidget(QLabel('dx (mm)'), 0,0)
        grid_line2.addWidget(self.entry_deltaX, 0,1)
        grid_line2.addWidget(QLabel('Nx'), 0,2)
        grid_line2.addWidget(self.entry_NX, 0,3)
        grid_line2.addWidget(QLabel('dy (mm)'), 0,4)
        grid_line2.addWidget(self.entry_deltaY, 0,5)
        grid_line2.addWidget(QLabel('Ny'), 0,6)
        grid_line2.addWidget(self.entry_NY, 0,7)

        grid_line2.addWidget(QLabel('dz (um)'), 1,0)
        grid_line2.addWidget(self.entry_deltaZ, 1,1)
        grid_line2.addWidget(QLabel('Nz'), 1,2)
        grid_line2.addWidget(self.entry_NZ, 1,3)
        grid_line2.addWidget(QLabel('dt (s)'), 1,4)
        grid_line2.addWidget(self.entry_dt, 1,5)
        grid_line2.addWidget(QLabel('Nt'), 1,6)
        grid_line2.addWidget(self.entry_Nt, 1,7)

        grid_af = QVBoxLayout()
        grid_af.addWidget(self.checkbox_withAutofocus)
        if SUPPORT_LASER_AUTOFOCUS:
            grid_af.addWidget(self.checkbox_withReflectionAutofocus)

        grid_line3 = QHBoxLayout()
        grid_line3.addWidget(self.list_configurations)
        # grid_line3.addWidget(self.checkbox_withAutofocus)
        grid_line3.addLayout(grid_af)
        grid_line3.addWidget(self.btn_startAcquisition)

        self.grid = QGridLayout()
        self.grid.addLayout(grid_line0,0,0)
        # self.grid.addLayout(grid_line1,1,0)
        self.grid.addLayout(grid_line4,1,0)
        self.grid.addLayout(grid_line3point5,2,0)
        self.grid.addLayout(grid_line3point75,3,0)
        # self.grid.addLayout(grid_line5,2,0)
        self.grid.addLayout(grid_line2,4,0)
        self.grid.addLayout(grid_line3,5,0)
        self.setLayout(self.grid)

        # add and display a timer - to be implemented
        # self.timer = QTimer()

        # connections
        self.entry_deltaX.valueChanged.connect(self.set_deltaX)
        self.entry_deltaY.valueChanged.connect(self.set_deltaY)
        self.entry_deltaZ.valueChanged.connect(self.set_deltaZ)
        self.entry_dt.valueChanged.connect(self.multipointController.set_deltat)
        self.entry_NX.valueChanged.connect(self.multipointController.set_NX)
        self.entry_NY.valueChanged.connect(self.multipointController.set_NY)
        self.entry_NZ.valueChanged.connect(self.multipointController.set_NZ)
        self.entry_Nt.valueChanged.connect(self.multipointController.set_Nt)
        self.checkbox_withAutofocus.stateChanged.connect(self.multipointController.set_af_flag)
        self.checkbox_withReflectionAutofocus.stateChanged.connect(self.multipointController.set_reflection_af_flag)
        self.btn_setSavingDir.clicked.connect(self.set_saving_dir)
        self.btn_startAcquisition.clicked.connect(self.toggle_acquisition)
        self.multipointController.acquisitionFinished.connect(self.acquisition_is_finished)
        self.list_configurations.itemSelectionChanged.connect(self.emit_selected_channels)

        self.btn_add.clicked.connect(self.add_location)
        self.btn_remove.clicked.connect(self.remove_location)
        self.btn_previous.clicked.connect(self.previous)
        self.btn_next.clicked.connect(self.next)
        self.btn_clear.clicked.connect(self.clear)
        self.btn_load_last_executed.clicked.connect(self.load_last_used_locations)
        self.btn_export_locations.clicked.connect(self.export_location_list)
        self.btn_import_locations.clicked.connect(self.import_location_list)

        self.table_location_list.cellClicked.connect(self.cell_was_clicked)
        self.table_location_list.cellChanged.connect(self.cell_was_changed)
        self.btn_show_table_location_list.clicked.connect(self.table_location_list.show)

        self.dropdown_location_list.currentIndexChanged.connect(self.go_to)

        self.shortcut = QShortcut(QKeySequence(";"), self)
        self.shortcut.activated.connect(self.btn_add.click)

    def set_deltaX(self,value):
        mm_per_ustep = SCREW_PITCH_X_MM/(self.multipointController.navigationController.x_microstepping*FULLSTEPS_PER_REV_X) # to implement a get_x_microstepping() in multipointController
        deltaX = round(value/mm_per_ustep)*mm_per_ustep
        self.entry_deltaX.setValue(deltaX)
        self.multipointController.set_deltaX(deltaX)

    def set_deltaY(self,value):
        mm_per_ustep = SCREW_PITCH_Y_MM/(self.multipointController.navigationController.y_microstepping*FULLSTEPS_PER_REV_Y)
        deltaY = round(value/mm_per_ustep)*mm_per_ustep
        self.entry_deltaY.setValue(deltaY)
        self.multipointController.set_deltaY(deltaY)

    def set_deltaZ(self,value):
        mm_per_ustep = SCREW_PITCH_Z_MM/(self.multipointController.navigationController.z_microstepping*FULLSTEPS_PER_REV_Z)
        deltaZ = round(value/1000/mm_per_ustep)*mm_per_ustep*1000
        self.entry_deltaZ.setValue(deltaZ)
        self.multipointController.set_deltaZ(deltaZ)

    def set_saving_dir(self):
        dialog = QFileDialog()
        save_dir_base = dialog.getExistingDirectory(None, "Select Folder")
        self.multipointController.set_base_path(save_dir_base)
        self.lineEdit_savingDir.setText(save_dir_base)
        self.base_path_is_set = True

    def emit_selected_channels(self):
        selected_channels = [item.text() for item in self.list_configurations.selectedItems()]
        self.signal_acquisition_channels.emit(selected_channels)

    def toggle_acquisition(self,pressed):
        if self.base_path_is_set == False:
            self.btn_startAcquisition.setChecked(False)
            msg = QMessageBox()
            msg.setText("Please choose base saving directory first")
            msg.exec_()
            return
        if pressed:
            # @@@ to do: add a widgetManger to enable and disable widget 
            # @@@ to do: emit signal to widgetManager to disable other widgets

            # add the current location to the location list if the list is empty
            if len(self.location_list) == 0:
                self.add_location()
                self.acquisition_in_place =True
            self.setEnabled_all(False)
            self.multipointController.set_selected_configurations((item.text() for item in self.list_configurations.selectedItems()))
            self.multipointController.start_new_experiment(self.lineEdit_experimentID.text())
            self.signal_acquisition_started.emit(True)
            self.signal_acquisition_shape.emit(self.entry_NX.value(),
                                               self.entry_NY.value(),
                                               self.entry_NZ.value(),
                                               self.entry_deltaX.value(),
                                               self.entry_deltaY.value(),
                                               self.entry_deltaZ.value())
            # set parameters
            self.multipointController.set_deltaX(self.entry_deltaX.value())
            self.multipointController.set_deltaY(self.entry_deltaY.value())
            self.multipointController.set_deltaZ(self.entry_deltaZ.value())
            self.multipointController.set_deltat(self.entry_dt.value())
            self.multipointController.set_NX(self.entry_NX.value())
            self.multipointController.set_NY(self.entry_NY.value())
            self.multipointController.set_NZ(self.entry_NZ.value())
            self.multipointController.set_Nt(self.entry_Nt.value())
            self.multipointController.set_af_flag(self.checkbox_withAutofocus.isChecked())
            self.multipointController.set_reflection_af_flag(self.checkbox_withReflectionAutofocus.isChecked())
            self.multipointController.set_base_path(self.lineEdit_savingDir.text())
            self.multipointController.run_acquisition(self.location_list)
        else:
            self.multipointController.request_abort_aquisition()
            self.setEnabled_all(True)

    def load_last_used_locations(self):
        if self.last_used_locations is None or len(self.last_used_locations) == 0:
            return
        self.clear_only_location_list()

        for row, row_ind in zip(self.last_used_locations, self.last_used_location_ids):
            x = row[0]
            y = row[1]
            z = row[2]
            name = row_ind[0]
            if not np.any(np.all(self.location_list[:, :2] == [x, y], axis=1)):
                location_str = 'x: ' + str(round(x,3)) + ' mm, y: ' + str(round(y,3)) + ' mm, z: ' + str(round(1000*z,1)) + ' um'
                self.dropdown_location_list.addItem(location_str)
                self.location_list = np.vstack((self.location_list, [[x,y,z]]))
                self.location_ids = np.append(self.location_ids, name)
                self.table_location_list.insertRow(self.table_location_list.rowCount())
                self.table_location_list.setItem(self.table_location_list.rowCount()-1,0, QTableWidgetItem(str(round(x,3))))
                self.table_location_list.setItem(self.table_location_list.rowCount()-1,1, QTableWidgetItem(str(round(y,3))))
                self.table_location_list.setItem(self.table_location_list.rowCount()-1,2, QTableWidgetItem(str(round(z*1000,1))))
                self.table_location_list.setItem(self.table_location_list.rowCount()-1,3, QTableWidgetItem(name))
                index = self.dropdown_location_list.count() - 1
                self.dropdown_location_list.setCurrentIndex(index)
                print(self.location_list)
                self.navigationViewer.register_fov_to_image(x,y)
            else:
                print("Duplicate values not added based on x and y.")
                #to-do: update z coordinate



    def acquisition_is_finished(self):
        if not self.acquisition_in_place:
            self.last_used_locations = self.location_list.copy()
            self.last_used_location_ids = self.location_ids.copy()
        else:
            self.clear()
            self.acquisition_in_place = False
        self.signal_acquisition_started.emit(False)
        self.btn_startAcquisition.setChecked(False)
        self.setEnabled_all(True)

    def setEnabled_all(self,enabled,exclude_btn_startAcquisition=True):
        self.btn_setSavingDir.setEnabled(enabled)
        self.lineEdit_savingDir.setEnabled(enabled)
        self.lineEdit_experimentID.setEnabled(enabled)
        self.entry_deltaX.setEnabled(enabled)
        self.entry_NX.setEnabled(enabled)
        self.entry_deltaY.setEnabled(enabled)
        self.entry_NY.setEnabled(enabled)
        self.entry_deltaZ.setEnabled(enabled)
        self.entry_NZ.setEnabled(enabled)
        self.entry_dt.setEnabled(enabled)
        self.entry_Nt.setEnabled(enabled)
        self.list_configurations.setEnabled(enabled)
        self.checkbox_withAutofocus.setEnabled(enabled)
        self.checkbox_withReflectionAutofocus.setEnabled(enabled)
        if exclude_btn_startAcquisition is not True:
            self.btn_startAcquisition.setEnabled(enabled)

    def disable_the_start_aquisition_button(self):
        self.btn_startAcquisition.setEnabled(False)

    def enable_the_start_aquisition_button(self):
        self.btn_startAcquisition.setEnabled(True)

    def add_location(self):
        x = self.navigationController.x_pos_mm
        y = self.navigationController.y_pos_mm
        z = self.navigationController.z_pos_mm
        name = ''
        if self.scanCoordinates is not None:
            name = self.create_point_id()
        
        if not np.any(np.all(self.location_list[:, :2] == [x, y], axis=1)):
            location_str = 'x: ' + str(round(x,3)) + ' mm, y: ' + str(round(y,3)) + ' mm, z: ' + str(round(1000*z,1)) + ' um'
            self.dropdown_location_list.addItem(location_str)
            index = self.dropdown_location_list.count() - 1
            self.dropdown_location_list.setCurrentIndex(index)
            self.location_list = np.vstack((self.location_list, [[self.navigationController.x_pos_mm,self.navigationController.y_pos_mm,self.navigationController.z_pos_mm]]))
            print(self.location_list)
            self.location_ids = np.append(self.location_ids, name)
            self.table_location_list.insertRow(self.table_location_list.rowCount())
            self.table_location_list.setItem(self.table_location_list.rowCount()-1,0, QTableWidgetItem(str(round(x,3))))
            self.table_location_list.setItem(self.table_location_list.rowCount()-1,1, QTableWidgetItem(str(round(y,3))))
            self.table_location_list.setItem(self.table_location_list.rowCount()-1,2, QTableWidgetItem(str(round(1000*z,1))))
            self.table_location_list.setItem(self.table_location_list.rowCount()-1,3, QTableWidgetItem(name))
            self.navigationViewer.register_fov_to_image(x,y)
        else:
            print("Duplicate values not added based on x and y.")
            #to-do: update z coordinate

    def create_point_id(self):
        self.scanCoordinates.get_selected_wells()
        if len(self.scanCoordinates.name) == 0:
            print('Select a well first.')
            return None
        
        name = self.scanCoordinates.name[0]
        location_split_names = [int(x.split('-')[1]) for x in self.location_ids if x.split('-')[0] == name]
        if len(location_split_names) > 0:
            new_id = f'{name}-{np.max(location_split_names)+1}'
        else:
            new_id = f'{name}-0'
        return new_id

    def remove_location(self):
        index = self.dropdown_location_list.currentIndex()
        if index >=0:
            self.dropdown_location_list.removeItem(index)
            self.table_location_list.removeRow(index)
            x = self.location_list[index,0]
            y = self.location_list[index,1]
            z = self.location_list[index,2]
            self.navigationViewer.deregister_fov_to_image(x,y)
            self.location_list = np.delete(self.location_list, index, axis=0)
            self.location_ids = np.delete(self.location_ids, index, axis=0)
            if len(self.location_list) == 0:
                self.navigationViewer.clear_slide()
            print(self.location_list)

    def next(self):
        index = self.dropdown_location_list.currentIndex()
        max_index = self.dropdown_location_list.count() - 1
        index = min(index + 1, max_index)
        self.dropdown_location_list.setCurrentIndex(index)
        x = self.location_list[index,0]
        y = self.location_list[index,1]
        z = self.location_list[index,2]
        self.navigationController.move_x_to(x)
        self.navigationController.move_y_to(y)
        self.navigationController.move_z_to(z)

    def previous(self):
        index = self.dropdown_location_list.currentIndex()
        index = max(index - 1, 0)
        self.dropdown_location_list.setCurrentIndex(index)
        x = self.location_list[index,0]
        y = self.location_list[index,1]
        z = self.location_list[index,2]
        self.navigationController.move_x_to(x)
        self.navigationController.move_y_to(y)
        self.navigationController.move_z_to(z)

    def clear(self):
        self.location_list = np.empty((0, 3), dtype=float)
        self.location_ids = np.empty((0,), dtype=str)
        self.dropdown_location_list.clear()
        self.navigationViewer.clear_slide()
        self.table_location_list.setRowCount(0)

    def clear_only_location_list(self):
        self.location_list = np.empty((0,3),dtype=float)
        self.location_ids = np.empty((0,),dtype=str)
        self.dropdown_location_list.clear()
        self.table_location_list.setRowCount(0)

    def clear_only_location_list(self):
        self.location_list = np.empty((0,3),dtype=float)
        self.dropdown_location_list.clear()

    def go_to(self,index):
        if index != -1:
            if index < len(self.location_list): # to avoid giving errors when adding new points
                x = self.location_list[index,0]
                y = self.location_list[index,1]
                z = self.location_list[index,2]
                self.navigationController.move_x_to(x)
                self.navigationController.move_y_to(y)
                self.navigationController.move_z_to(z)
                self.table_location_list.selectRow(index)

    def cell_was_clicked(self,row,column):

        self.dropdown_location_list.setCurrentIndex(row)

    def cell_was_changed(self,row,column):
        x= self.location_list[row,0]
        y= self.location_list[row,1]
        self.navigationViewer.deregister_fov_to_image(x,y)
    
        val_edit = self.table_location_list.item(row,column).text()
        if column < 2:
            val_edit = float(val_edit)
            self.location_list[row,column] = val_edit
        elif column == 2:
            z = float(val_edit)/1000
            self.location_list[row,column] = z
        else:
            self.location_ids[row] = val_edit
        
        self.navigationViewer.register_fov_to_image(self.location_list[row,0], self.location_list[row,1])
        location_str = 'x: ' + str(round(self.location_list[row,0],3)) + ' mm, y: ' + str(round(self.location_list[row,1],3)) + ' mm, z: ' + str(1000*round(self.location_list[row,2],3)) + ' um'
        self.dropdown_location_list.setItemText(row, location_str)
        self.go_to(row)

    def keyPressEvent(self, event):
        if event.key() == Qt.Key_A and event.modifiers() == Qt.ControlModifier:
            self.add_location()
        else:
            super().keyPressEvent(event)

    def _update_z(self,index,z_mm):
        self.location_list[index,2] = z_mm
        location_str = 'x: ' + str(round(self.location_list[index,0],3)) + ' mm, y: ' + str(round(self.location_list[index,1],3)) + ' mm, z: ' + str(round(1000*z_mm,1)) + ' um'
        self.dropdown_location_list.setItemText(index, location_str)

    def export_location_list(self):
        file_path, _ = QFileDialog.getSaveFileName(self, "Export Location List", '', "CSV Files (*.csv);;All Files (*)")
        if file_path:
            location_list_df = pd.DataFrame(self.location_list,columns=['x (mm)','y (mm)', 'z (um)'])
            location_list_df['ID'] = self.location_ids
            location_list_df['i'] = 0
            location_list_df['j'] = 0
            location_list_df['k'] = 0
            location_list_df.to_csv(file_path,index=False,header=True)

    def import_location_list(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Import Location List", '', "CSV Files (*.csv);;All Files (*)")
        if file_path:
            location_list_df = pd.read_csv(file_path)
            location_list_df_relevant = None
            try:
                location_list_df_relevant = location_list_df[['x (mm)', 'y (mm)', 'z (um)']]
            except KeyError:
                print("Improperly formatted location list being imported")
                return
            if 'ID' in location_list_df.columns:
                location_list_df_relevant['ID'] = location_list_df['ID'].astype(str)
            else:
                location_list_df_relevant['ID'] = 'None'
            self.clear_only_location_list()
            for index, row in location_list_df_relevant.iterrows():
                x = row['x (mm)']
                y = row['y (mm)']
                z = row['z (um)']
                name = row['ID']
                if not np.any(np.all(self.location_list[:, :2] == [x, y], axis=1)):
                    location_str = 'x: ' + str(round(x,3)) + ' mm, y: ' + str(round(y,3)) + ' mm, z: ' + str(round(1000*z,1)) + ' um'
                    self.dropdown_location_list.addItem(location_str)
                    index = self.dropdown_location_list.count() - 1
                    self.dropdown_location_list.setCurrentIndex(index)
                    self.location_list = np.vstack((self.location_list, [[x,y,z]]))
                    self.location_ids = np.append(self.location_ids, name)
                    self.table_location_list.insertRow(self.table_location_list.rowCount())
                    self.table_location_list.setItem(self.table_location_list.rowCount()-1,0, QTableWidgetItem(str(round(x,3))))
                    self.table_location_list.setItem(self.table_location_list.rowCount()-1,1, QTableWidgetItem(str(round(y,3))))
                    self.table_location_list.setItem(self.table_location_list.rowCount()-1,2, QTableWidgetItem(str(round(1000*z,1))))
                    self.table_location_list.setItem(self.table_location_list.rowCount()-1,3, QTableWidgetItem(name))
                    self.navigationViewer.register_fov_to_image(x,y)
                else:
                    print("Duplicate values not added based on x and y.")
            print(self.location_list)


class StitcherWidget(QFrame):

    def __init__(self, configurationManager, *args, **kwargs): #multiPointWidget, multiPointWidget2,*args, **kwargs):
        super(StitcherWidget, self).__init__(*args, **kwargs)
        self.configurationManager = configurationManager
        #self.multiPointWidget = multiPointWidget
        #self.multiPointWidget2 = self.MultiPointWidget2
        self.output_path = ""
        self.contrast_limits = None

        self.setFrameStyle(QFrame.Panel | QFrame.Raised)  # Set frame style
        #self.layout = QGridLayout(self)  # Initialize layout with self as the parent
        self.layout = QVBoxLayout(self)
        self.topLayout = QHBoxLayout()
        self.colLayout1 = QVBoxLayout()
        self.colLayout2 = QVBoxLayout()


        # Apply flatfield correction checkbox
        self.applyFlatfieldCheck = QCheckBox("Apply Flatfield Correction")
        self.colLayout2.addWidget(self.applyFlatfieldCheck)

        # Output format dropdown
        self.outputFormatLabel = QLabel('Select Output Format:', self)
        self.outputFormatCombo = QComboBox(self)
        self.outputFormatCombo.addItem("OME-ZARR")
        self.outputFormatCombo.addItem("OME-TIFF")
        self.colLayout1.addWidget(self.outputFormatLabel)
        self.colLayout1.addWidget(self.outputFormatCombo)

        # Use registration checkbox
        self.useRegistrationCheck = QCheckBox("Use Registration")
        self.useRegistrationCheck.toggled.connect(self.onRegistrationCheck)
        self.colLayout2.addWidget(self.useRegistrationCheck)

        # Select Registartion Channel
        self.registrationChannelLabel = QLabel("Select Registration Channel:", self)
        self.registrationChannelLabel.setVisible(False)
        self.colLayout2.addWidget(self.registrationChannelLabel)
        self.registrationChannelCombo = QComboBox(self)
        #self.registrationChannelCombo.setEnabled(False)
        self.registrationChannelLabel.setVisible(False)
        self.registrationChannelCombo.setVisible(False)
        #for microscope_configuration in self.configurationManager.configurations:
        #    self.registrationChannelCombo.addItems([microscope_configuration.name])
        self.colLayout2.addWidget(self.registrationChannelCombo)
        ### todo: make sure selected channel is one of the selected modes (check if in multipointcontroller channels selected)
        
        self.topLayout.addLayout(self.colLayout1)
        self.topLayout.addLayout(self.colLayout2)
        self.layout.addLayout(self.topLayout)

        # Button to view output in Napari
        self.viewOutputButton = QPushButton("View Output in Napari")
        self.viewOutputButton.setEnabled(False)  # Initially disabled
        self.viewOutputButton.setVisible(False)
        self.viewOutputButton.clicked.connect(self.viewOutputNapari)
        self.layout.addWidget(self.viewOutputButton)

        # Progress bar
        self.progressBar = QProgressBar()
        self.layout.addWidget(self.progressBar)
        self.progressBar.setVisible(False)  # Initially hidden

        # Status label
        self.statusLabel = QLabel("Status: Image Acquisition")
        self.layout.addWidget(self.statusLabel)
        self.statusLabel.setVisible(False)

    def onRegistrationCheck(self, checked):
        #self.registrationChannelCombo.setEnabled(checked)
        self.registrationChannelLabel.setVisible(checked)
        self.registrationChannelCombo.setVisible(checked)
        if checked:
            self.colLayout2.removeWidget(self.applyFlatfieldCheck)
            self.colLayout1.insertWidget(0, self.applyFlatfieldCheck)
        else:
            self.colLayout1.removeWidget(self.applyFlatfieldCheck)
            self.colLayout2.insertWidget(0, self.applyFlatfieldCheck)

    def updateRegistrationChannels(self, selected_channels):
        self.registrationChannelCombo.clear()  # Clear existing items
        self.registrationChannelCombo.addItems(selected_channels)

    def gettingFlatfields(self):
        self.statusLabel.setText('Status: Calculating Flatfield Images...')
        self.viewOutputButton.setVisible(False)
        self.viewOutputButton.setStyleSheet("")
        self.progressBar.setValue(0)
        self.statusLabel.setVisible(True)
        self.progressBar.setVisible(True)

    def startingStitching(self):
        self.statusLabel.setText('Status: Stitching Acquisition Images...')
        self.viewOutputButton.setVisible(False)
        self.progressBar.setValue(0)
        self.statusLabel.setVisible(True)
        self.progressBar.setVisible(True)

    def updateProgressBar(self, value, total):
        self.progressBar.setMaximum(total)
        self.progressBar.setValue(value)
        self.progressBar.setVisible(True)

    def startingSaving(self):
        self.statusLabel.setText('Status: Saving Stitched Image...')
        self.progressBar.setRange(0, 0)  # indeterminate mode.
        self.statusLabel.setVisible(True)
        self.progressBar.setVisible(True)

    def finishedSaving(self, output_path, dtype):
        self.statusLabel.setVisible(False)
        self.progressBar.setVisible(False)
        self.viewOutputButton.setVisible(True)
        self.viewOutputButton.setStyleSheet("background-color: #C2C2FF")
        self.viewOutputButton.setEnabled(True)
        try: 
            self.viewOutputButton.clicked.disconnect()
        except TypeError:
            pass
        self.viewOutputButton.clicked.connect(self.viewOutputNapari)

        if np.issubdtype(dtype, np.integer):  # Check if dtype is an integer type
            contrast_limits = (np.iinfo(dtype).min, np.iinfo(dtype).max) 
        elif np.issubdtype(dtype, np.floating):  # floating point type
            contrast_limits = (0.0, 1.0)
        else:
            contrast_limits = None
            raise ValueError("Unsupported dtype")

        self.output_path = output_path
        self.contrast_limits = contrast_limits
        print("Stitching completed.")
        print(output_path)
        print(dtype)

    def viewOutputNapari(self):
        try:
            napari_viewer = napari.Viewer()
            if ".ome.zarr" in self.output_path:
                napari_viewer.open(self.output_path, plugin='napari-ome-zarr', contrast_limits=self.contrast_limits)
            else:
                napari_viewer.open(self.output_path, contrast_limits=self.contrast_limits)

            colors = ['gray', 'cyan', 'magma', 'green', 'red', 'blue', 'magenta', 'yellow',
                      'bop orange', 'bop blue', 'gray', 'magma', 'viridis', 'inferno'] #etc
            for i, layer in enumerate(napari_viewer.layers):
                #layer.contrast_limits = self.contrast_limits
                layer.colormap = colors[i]
            # napari.run()  # Start the Napari event loop
        except Exception as e:
            QMessageBox.critical(self, "Error Opening in Napari", str(e))


class NapariLiveWidget(QWidget):

    signal_coordinates_clicked = Signal(int, int, int, int)
    signal_layer_contrast_limits = Signal(str, float, float)

    def __init__(self, configurationManager, liveControlWidget, parent=None):
        super().__init__(parent)
        # Initialize placeholders for the acquisition parameters
        self.configurationManager = configurationManager
        self.liveControlWidget = liveControlWidget
        self.live_layer_name = ""
        self.image_width = 0
        self.image_height = 0
        self.dtype = np.uint8 
        self.channels = []
        self.init_live = False
        self.init_live_rgb = False
        self.contrast_limits = {}
        self.init_scale = False
        self.previous_scale = None
        self.previous_center = None
        self.last_was_autofocus = False

        # Initialize a napari Viewer without showing its standalone window.
        self.initNapariViewer()
        self.addNapariGrayclipColormap()

    def addNapariGrayclipColormap(self):
        if hasattr(napari.utils.colormaps.AVAILABLE_COLORMAPS, 'grayclip'):
            return
        grayclip = []
        for i in range(255):
            grayclip.append([i / 255, i / 255, i / 255])
        grayclip.append([1, 0, 0])
        napari.utils.colormaps.AVAILABLE_COLORMAPS['grayclip'] = napari.utils.Colormap(name='grayclip', colors=grayclip)

    def initNapariViewer(self):
        self.viewer = napari.Viewer(show=False)
        self.viewerWidget = self.viewer.window._qt_window
        self.viewer.dims.axis_labels = ['Y-axis', 'X-axis']
        self.layout = QVBoxLayout()
        self.layout.addWidget(self.viewerWidget)
        self.setLayout(self.layout)

    def initLiveLayer(self, channel, image_height, image_width, image_dtype, rgb=False):
        """Initializes the full canvas for each channel based on the acquisition parameters."""
        self.viewer.layers.clear()
        self.image_width = image_width
        self.image_height = image_height
        self.dtype = np.dtype(image_dtype)
        self.channels.append(channel)
        self.live_layer_name = channel
        contrast_limits = self.getContrastLimits()
        if rgb == True:
            canvas = np.zeros((image_height, image_width, 3), dtype=self.dtype)
        else:
            canvas = np.zeros((image_height, image_width), dtype=self.dtype)
        layer = self.viewer.add_image(canvas, name=channel, visible=True, rgb=rgb, colormap='grayclip',
                                      contrast_limits=contrast_limits, blending='additive')
        layer.mouse_double_click_callbacks.append(self.onDoubleClick)
        layer.events.contrast_limits.connect(self.signalContrastLimits)  # Connect to contrast limits event
        self.resetView()

    def updateLiveLayer(self, image, from_autofocus=False):
        """Updates the appropriate slice of the canvas with the new image data."""
        rgb = len(image.shape) >= 3
        if not rgb and not self.init_live:
            self.initLiveLayer("Live View", image.shape[0], image.shape[1], image.dtype, rgb)
            self.init_live = True
            self.init_live_rgb = False
            print("init live")
        elif rgb and not self.init_live_rgb:
            self.initLiveLayer("Live View", image.shape[0], image.shape[1], image.dtype, rgb)
            self.init_live_rgb = True
            self.init_live = False
            print("init live rgb")
        
        layer = self.viewer.layers["Live View"]
        layer.data = image

        if from_autofocus:
            if not self.last_was_autofocus:
                self.previous_scale = self.viewer.camera.zoom
                self.previous_center = self.viewer.camera.center
            self.resetView()
            self.last_was_autofocus = True
        else:
            if not self.init_scale:
                self.resetView()
                self.previous_scale = self.viewer.camera.zoom
                self.previous_center = self.viewer.camera.center
                self.init_scale = True

            if self.last_was_autofocus and self.previous_scale is not None:
                self.viewer.camera.zoom = self.previous_scale
                self.viewer.camera.center = self.previous_center
            self.last_was_autofocus = False

        curr_layer_name = self.liveControlWidget.dropdown_modeSelection.currentText()
        if self.live_layer_name != curr_layer_name:
            self.live_layer_name = curr_layer_name
            layer.contrast_limits = self.contrast_limits.get(self.live_layer_name, self.getContrastLimits())
        layer.refresh()

    def onDoubleClick(self, layer, event):
        """Handle double-click events and emit centered coordinates if within the data range."""
        coords = layer.world_to_data(event.position)
        layer_shape = layer.data.shape[0:2] if len(layer.data.shape) >= 3 else layer.data.shape

        if coords is not None and (0 <= int(coords[-1]) < layer_shape[-1] and (0 <= int(coords[-2]) < layer_shape[-2])):
            x_centered = int(coords[-1] - layer_shape[-1] / 2)
            y_centered = int(coords[-2] - layer_shape[-2] / 2)
            # Emit the centered coordinates and dimensions of the layer's data array
            self.signal_coordinates_clicked.emit(x_centered, y_centered, layer_shape[-1], layer_shape[-2])

    def signalContrastLimits(self, event):
        layer = event.source
        layer_name = self.liveControlWidget.dropdown_modeSelection.currentText()
        min_val, max_val = map(float, layer.contrast_limits)  # or use int if necessary
        self.signal_layer_contrast_limits.emit(layer_name, min_val, max_val)
        self.contrast_limits[layer_name] = min_val, max_val

    def saveContrastLimits(self, layer_name, min_val, max_val):
        self.contrast_limits[layer_name] = (min_val, max_val)

    def getContrastLimits(self):
        if np.issubdtype(self.dtype, np.integer):
            return (np.iinfo(self.dtype).min, np.iinfo(self.dtype).max)
        elif np.issubdtype(self.dtype, np.floating):
            return (0.0, 1.0)
        return None

    def resetView(self):
         self.viewer.reset_view()


class NapariMultiChannelWidget(QWidget):

    signal_layer_contrast_limits = Signal(str, float, float)

    def __init__(self, configurationManager, parent=None):
        super().__init__(parent)
        # Initialize placeholders for the acquisition parameters
        self.configurationManager = configurationManager
        self.image_width = 0
        self.image_height = 0
        self.dtype = np.uint8
        self.channels = []
        self.contrast_limits = {}
        self.pixel_size_um = 1
        self.layers_initialized = False
        self.viewer_scale_initialized = False
        self.grid_enabled = False
        # Initialize a napari Viewer without showing its standalone window.
        self.initNapariViewer()

    def initNapariViewer(self):
        self.viewer = napari.Viewer(show=False)
        if self.grid_enabled:
            self.viewer.grid.enabled = True
        self.viewer.dims.axis_labels = ['Z-axis', 'Y-axis', 'X-axis']
        self.viewerWidget = self.viewer.window._qt_window
        self.layout = QVBoxLayout()
        self.layout.addWidget(self.viewerWidget)
        self.setLayout(self.layout)
        
    def initLayersShape(self, Nx, Ny, Nz, dx, dy, dz):
        self.Nz = Nz

    def initChannels(self, channels):
        self.channels = channels

    def extractWavelength(self, name):
        # Split the string and find the wavelength number immediately after "Fluorescence"
        parts = name.split()
        if 'Fluorescence' in parts:
            index = parts.index('Fluorescence') + 1
            if index < len(parts):
                return parts[index].split()[0]  # Assuming '488 nm Ex' and taking '488'
        for color in ['R', 'G', 'B']:
            if color in parts or f"full_{color}" in parts:
                return color
        return None

    def generateColormap(self, channel_info):
        """Convert a HEX value to a normalized RGB tuple."""
        positions = [0, 1]
        c0 = (0, 0, 0)
        c1 = (((channel_info['hex'] >> 16) & 0xFF) / 255,  # Normalize the Red component
             ((channel_info['hex'] >> 8) & 0xFF) / 255,      # Normalize the Green component
             (channel_info['hex'] & 0xFF) / 255)             # Normalize the Blue component
        return Colormap(colors=[c0, c1], controls=[0, 1], name=channel_info['name'])

    def initLayers(self, image_height, image_width, image_dtype, rgb=False):
        """Initializes the full canvas for each channel based on the acquisition parameters."""
        self.viewer.layers.clear()
        self.image_width = image_width
        self.image_height = image_height
        self.dtype = np.dtype(image_dtype)
        self.layers_initialized = True

    def updateLayers(self, image, i, j, k, channel_name):
        """Updates the appropriate slice of the canvas with the new image data."""
        if not self.layers_initialized:
            self.initLayers(image.shape[0], image.shape[1], image.dtype)
 
        rgb = len(image.shape) == 3
        if channel_name not in self.viewer.layers:
            self.channels.append(channel_name)
            if rgb:
                color = None  # RGB images do not need a colormap
                canvas = np.zeros((self.Nz, self.image_height, self.image_width, 3), dtype=self.dtype)
            else:
                channel_info = CHANNEL_COLORS_MAP.get(self.extractWavelength(channel_name), {'hex': 0xFFFFFF, 'name': 'gray'})
                if channel_info['name'] in AVAILABLE_COLORMAPS:
                    color = AVAILABLE_COLORMAPS[channel_info['name']]
                else:
                    color = self.generateColormap(channel_info)
                canvas = np.zeros((self.Nz, self.image_height, self.image_width), dtype=self.dtype)
            
            limits = self.getContrastLimits(self.dtype)
            layer = self.viewer.add_image(canvas, name=channel_name, visible=True, rgb=rgb,
                                          colormap=color, contrast_limits=limits, blending='additive')
            layer.contrast_limits = self.contrast_limits.get(channel_name, limits)
            layer.events.contrast_limits.connect(self.signalContrastLimits)

            if not self.viewer_scale_initialized:
                self.resetView()
                self.viewer_scale_initialized = True

        layer = self.viewer.layers[channel_name]
        layer.data[k] = image
        layer.contrast_limits = self.contrast_limits.get(layer.name, self.getContrastLimits(self.dtype))
        self.viewer.dims.set_point(0, k)
        layer.refresh()

    def getContrastLimits(self, dtype):
        if np.issubdtype(dtype, np.integer):
            return (np.iinfo(dtype).min, np.iinfo(dtype).max)
        elif np.issubdtype(dtype, np.floating):
            return (0.0, 1.0)
        return None

    def signalContrastLimits(self, event):
        layer = event.source
        min_val, max_val = map(float, layer.contrast_limits)  # or use int if necessary
        self.signal_layer_contrast_limits.emit(layer.name, min_val, max_val)
        self.contrast_limits[layer.name] = min_val, max_val

    def saveContrastLimits(self, layer_name, min_val, max_val):
        self.contrast_limits[layer_name] = (min_val, max_val)

    def resetView(self):
        self.viewer.reset_view()
        for layer in self.viewer.layers:
            layer.refresh()


class NapariTiledDisplayWidget(QWidget):

    signal_coordinates_clicked = Signal(int, int, int, int, int, int, float, float)
    signal_layer_contrast_limits = Signal(str, float, float)

    def __init__(self, configurationManager, parent=None):
        super().__init__(parent)
        # Initialize placeholders for the acquisition parameters
        self.configurationManager = configurationManager
        self.downsample_factor = PRVIEW_DOWNSAMPLE_FACTOR
        self.image_width = 0
        self.image_height = 0
        self.dtype = np.uint8
        self.channels = []
        self.Nx = 1
        self.Ny = 1
        self.Nz = 1
        self.layers_initialized = False
        self.viewer_scale_initialized = False
        self.contrast_limits = {}
        self.initNapariViewer()

    def initNapariViewer(self):
        self.viewer = napari.Viewer(show=False) #, ndisplay=3)
        self.viewerWidget = self.viewer.window._qt_window
        self.viewer.dims.axis_labels = ['Z-axis', 'Y-axis', 'X-axis']
        self.layout = QVBoxLayout()
        self.layout.addWidget(self.viewerWidget)
        self.setLayout(self.layout)
        
    def initLayersShape(self, Nx, Ny, Nz, dx, dy, dz):
        self.Nx = Nx
        self.Ny = Ny
        self.Nz = Nz
        self.dx_mm = dx
        self.dy_mm = dy
        self.dz_um = dz

    def initChannels(self, channels):
        self.channels = channels

    def extractWavelength(self, name):
        # Split the string and find the wavelength number immediately after "Fluorescence"
        parts = name.split()
        if 'Fluorescence' in parts:
            index = parts.index('Fluorescence') + 1
            if index < len(parts):
                return parts[index].split()[0]  # Assuming '488 nm Ex' and taking '488'
        for color in ['R', 'G', 'B']:
            if color in parts or f"full_{color}" in parts:
                return color
        return None

    def generateColormap(self, channel_info):
        """Convert a HEX value to a normalized RGB tuple."""
        c0 = (0, 0, 0)
        c1 = (((channel_info['hex'] >> 16) & 0xFF) / 255,  # Normalize the Red component
             ((channel_info['hex'] >> 8) & 0xFF) / 255,      # Normalize the Green component
             (channel_info['hex'] & 0xFF) / 255)             # Normalize the Blue component
        return Colormap(colors=[c0, c1], controls=[0, 1], name=channel_info['name'])

    def initLayers(self, image_height, image_width, image_dtype):
        """Initializes the full canvas for each channel based on the acquisition parameters."""
        self.viewer.layers.clear()
        self.image_width = image_width // self.downsample_factor
        self.image_height = image_height // self.downsample_factor
        self.dtype = np.dtype(image_dtype)
        self.resetView()
        self.layers_initialized = True
        self.viewer_scale_initialized = False
        self.layers_initialized = True

    def updateLayers(self, image, i, j, k, channel_name):
        """Updates the appropriate slice of the canvas with the new image data."""
        rgb = len(image.shape) == 3  # Check if image is RGB based on shape
        if not self.layers_initialized:
           self.initLayers(image.shape[0], image.shape[1], image.dtype)
 
        if channel_name not in self.viewer.layers:
            self.channels.append(channel_name)
            if rgb:
                color = None  # No colormap for RGB images
                canvas = np.zeros((self.Nz, self.Ny * self.image_height, self.Nx * self.image_width, 3), dtype=self.dtype)
            else:
                channel_info = CHANNEL_COLORS_MAP.get(self.extractWavelength(channel_name), {'hex': 0xFFFFFF, 'name': 'gray'})
                if channel_info['name'] in AVAILABLE_COLORMAPS:
                    color = AVAILABLE_COLORMAPS[channel_info['name']]
                else:
                    color = self.generateColormap(channel_info)
                canvas = np.zeros((self.Nz, self.Ny * self.image_height, self.Nx * self.image_width), dtype=self.dtype)

            limits = self.getContrastLimits(self.dtype)
            layer = self.viewer.add_image(canvas, name=channel_name, visible=True, rgb=rgb, colormap=color, contrast_limits=limits, blending='additive')
            layer.contrast_limits = self.contrast_limits.get(channel_name, limits)
            layer.events.contrast_limits.connect(self.signalContrastLimits)
            layer.mouse_double_click_callbacks.append(self.onDoubleClick)

        image = cv2.resize(image, (self.image_width, self.image_height), interpolation=cv2.INTER_AREA)
        
        if not self.viewer_scale_initialized:
            self.resetView()
            self.viewer_scale_initialized = True
 
        layer = self.viewer.layers[channel_name]
        layer_data = layer.data
        y_slice = slice(i * self.image_height, (i + 1) * self.image_height)
        x_slice = slice(j * self.image_width, (j + 1) * self.image_width)
        if rgb:
            layer_data[k, y_slice, x_slice, :] = image
        else:
            layer_data[k, y_slice, x_slice] = image
        
        layer.data = layer_data
        self.viewer.dims.set_point(0, k)
        layer.refresh()

    def signalContrastLimits(self, event):
        layer = event.source
        min_val, max_val = map(float, layer.contrast_limits) 
        self.signal_layer_contrast_limits.emit(layer.name, min_val, max_val)
        self.contrast_limits[layer.name] = min_val, max_val

    def getContrastLimits(self, dtype):
        if np.issubdtype(dtype, np.integer):
            return (np.iinfo(dtype).min, np.iinfo(dtype).max)
        elif np.issubdtype(dtype, np.floating):
            return (0.0, 1.0)
        return None

    def saveContrastLimits(self, layer_name, min_val, max_val):
        self.contrast_limits[layer_name] = (min_val, max_val)

    def onDoubleClick(self, layer, event):
        """Handle double-click events and emit centered coordinates if within the data range."""
        coords = layer.world_to_data(event.position) 
        layer_shape = layer.data.shape[0:3] if len(layer.data.shape) >= 4 else layer.data.shape

        if coords is not None and (0 <= int(coords[-1]) < layer_shape[-1] and (0 <= int(coords[-2]) < layer_shape[-2])):
            x_centered = int(coords[-1] - layer_shape[-1] / 2)
            y_centered = int(coords[-2] - layer_shape[-2] / 2)
            # Emit the centered coordinates and dimensions of the layer's data array
            self.signal_coordinates_clicked.emit(x_centered, y_centered,
                                                 layer_shape[-1], layer_shape[-2],
                                                 self.Nx, self.Ny,
                                                 self.dx_mm, self.dy_mm)

    def resetView(self):
        self.viewer.reset_view()
        for layer in self.viewer.layers:
            layer.refresh()


class TrackingControllerWidget(QFrame):
    def __init__(self, trackingController, configurationManager, show_configurations = True, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.trackingController = trackingController
        self.configurationManager = configurationManager
        self.base_path_is_set = False
        self.add_components(show_configurations)
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self,show_configurations):
        self.btn_setSavingDir = QPushButton('Browse')
        self.btn_setSavingDir.setDefault(False)
        self.btn_setSavingDir.setIcon(QIcon('icon/folder.png'))
        self.lineEdit_savingDir = QLineEdit()
        self.lineEdit_savingDir.setReadOnly(True)
        self.lineEdit_savingDir.setText('Choose a base saving directory')
        self.lineEdit_savingDir.setText(DEFAULT_SAVING_PATH)
        self.trackingController.set_base_path(DEFAULT_SAVING_PATH)
        self.base_path_is_set = True

        self.lineEdit_experimentID = QLineEdit()

        self.dropdown_objective = QComboBox()
        self.dropdown_objective.addItems(list(OBJECTIVES.keys()))
        self.dropdown_objective.setCurrentText(DEFAULT_OBJECTIVE)

        self.dropdown_tracker = QComboBox()
        self.dropdown_tracker.addItems(TRACKERS)
        self.dropdown_tracker.setCurrentText(DEFAULT_TRACKER)

        self.entry_tracking_interval = QDoubleSpinBox()
        self.entry_tracking_interval.setMinimum(0) 
        self.entry_tracking_interval.setMaximum(30) 
        self.entry_tracking_interval.setSingleStep(0.5)
        self.entry_tracking_interval.setValue(0)

        self.list_configurations = QListWidget()
        for microscope_configuration in self.configurationManager.configurations:
            self.list_configurations.addItems([microscope_configuration.name])
        self.list_configurations.setSelectionMode(QAbstractItemView.MultiSelection) # ref: https://doc.qt.io/qt-5/qabstractitemview.html#SelectionMode-enum

        self.checkbox_withAutofocus = QCheckBox('With AF')
        self.checkbox_saveImages = QCheckBox('Save Images')
        self.btn_track = QPushButton('Start Tracking')
        self.btn_track.setCheckable(True)
        self.btn_track.setChecked(False)

        self.checkbox_enable_stage_tracking = QCheckBox(' Enable Stage Tracking')
        self.checkbox_enable_stage_tracking.setChecked(True)

        # layout
        grid_line0 = QGridLayout()
        tmp = QLabel('Saving Path')
        tmp.setFixedWidth(90)
        grid_line0.addWidget(tmp, 0,0)
        grid_line0.addWidget(self.lineEdit_savingDir, 0,1, 1,2)
        grid_line0.addWidget(self.btn_setSavingDir, 0,3)
        tmp = QLabel('Experiment ID')
        tmp.setFixedWidth(90)
        grid_line0.addWidget(tmp, 1,0)
        grid_line0.addWidget(self.lineEdit_experimentID, 1,1, 1,1)
        tmp = QLabel('Objective')
        tmp.setFixedWidth(90)
        grid_line0.addWidget(tmp,1,2)
        grid_line0.addWidget(self.dropdown_objective, 1,3)

        grid_line3 = QHBoxLayout()
        tmp = QLabel('Configurations')
        tmp.setFixedWidth(90)
        grid_line3.addWidget(tmp)
        grid_line3.addWidget(self.list_configurations)
        
        grid_line1 = QHBoxLayout()
        tmp = QLabel('Tracker')
        grid_line1.addWidget(tmp)
        grid_line1.addWidget(self.dropdown_tracker)
        tmp = QLabel('Tracking Interval (s)')
        grid_line1.addWidget(tmp)
        grid_line1.addWidget(self.entry_tracking_interval)
        grid_line1.addWidget(self.checkbox_withAutofocus)
        grid_line1.addWidget(self.checkbox_saveImages)

        grid_line4 = QGridLayout()
        grid_line4.addWidget(self.btn_track,0,0,1,3)
        grid_line4.addWidget(self.checkbox_enable_stage_tracking,0,4)

        self.grid = QVBoxLayout()
        self.grid.addLayout(grid_line0)
        if show_configurations:
            self.grid.addLayout(grid_line3)
        else:
            self.list_configurations.setCurrentRow(0) # select the first configuration
        self.grid.addLayout(grid_line1)        
        self.grid.addLayout(grid_line4)
        self.grid.addStretch()
        self.setLayout(self.grid)

        # connections - buttons, checkboxes, entries
        self.checkbox_enable_stage_tracking.stateChanged.connect(self.trackingController.toggle_stage_tracking)
        self.checkbox_withAutofocus.stateChanged.connect(self.trackingController.toggel_enable_af)
        self.checkbox_saveImages.stateChanged.connect(self.trackingController.toggel_save_images)
        self.entry_tracking_interval.valueChanged.connect(self.trackingController.set_tracking_time_interval)
        self.btn_setSavingDir.clicked.connect(self.set_saving_dir)
        self.btn_track.clicked.connect(self.toggle_acquisition)
        # connections - selections and entries
        self.dropdown_tracker.currentIndexChanged.connect(self.update_tracker)
        self.dropdown_objective.currentIndexChanged.connect(self.update_pixel_size)
        # controller to widget
        self.trackingController.signal_tracking_stopped.connect(self.slot_tracking_stopped)

        # run initialization functions
        self.update_pixel_size()
        self.trackingController.update_image_resizing_factor(1) # to add: image resizing slider

    def slot_joystick_button_pressed(self):
        self.btn_track.toggle()
        if self.btn_track.isChecked():
            if self.base_path_is_set == False:
                self.btn_track.setChecked(False)
                msg = QMessageBox()
                msg.setText("Please choose base saving directory first")
                msg.exec_()
                return
            self.setEnabled_all(False)
            self.trackingController.start_new_experiment(self.lineEdit_experimentID.text())
            self.trackingController.set_selected_configurations((item.text() for item in self.list_configurations.selectedItems()))
            self.trackingController.start_tracking()
        else:
            self.trackingController.stop_tracking()

    def slot_tracking_stopped(self):
        self.btn_track.setChecked(False)
        self.setEnabled_all(True)
        print('tracking stopped')

    def set_saving_dir(self):
        dialog = QFileDialog()
        save_dir_base = dialog.getExistingDirectory(None, "Select Folder")
        self.trackingController.set_base_path(save_dir_base)
        self.lineEdit_savingDir.setText(save_dir_base)
        self.base_path_is_set = True 

    def toggle_acquisition(self,pressed):
        if pressed:
            if self.base_path_is_set == False:
                self.btn_track.setChecked(False)
                msg = QMessageBox()
                msg.setText("Please choose base saving directory first")
                msg.exec_()
                return
            # @@@ to do: add a widgetManger to enable and disable widget 
            # @@@ to do: emit signal to widgetManager to disable other widgets
            self.setEnabled_all(False)
            self.trackingController.start_new_experiment(self.lineEdit_experimentID.text())
            self.trackingController.set_selected_configurations((item.text() for item in self.list_configurations.selectedItems()))
            self.trackingController.start_tracking()
        else:
            self.trackingController.stop_tracking()

    def setEnabled_all(self,enabled):
        self.btn_setSavingDir.setEnabled(enabled)
        self.lineEdit_savingDir.setEnabled(enabled)
        self.lineEdit_experimentID.setEnabled(enabled)
        self.dropdown_tracker
        self.dropdown_objective
        self.list_configurations.setEnabled(enabled)

    def update_tracker(self, index):
        self.trackingController.update_tracker_selection(self.dropdown_tracker.currentText())

    def update_pixel_size(self): 
        objective = self.dropdown_objective.currentText()
        self.trackingController.objective = objective
        # self.internal_state.data['Objective'] = self.objective
        pixel_size_um = CAMERA_PIXEL_SIZE_UM[CAMERA_SENSOR] / ( TUBE_LENS_MM/ (OBJECTIVES[objective]['tube_lens_f_mm']/OBJECTIVES[objective]['magnification']) )
        self.trackingController.update_pixel_size(pixel_size_um)
        print('pixel size is ' + str(pixel_size_um) + ' um')


    '''
        # connections
        self.checkbox_withAutofocus.stateChanged.connect(self.trackingController.set_af_flag)
        self.btn_setSavingDir.clicked.connect(self.set_saving_dir)
        self.btn_startAcquisition.clicked.connect(self.toggle_acquisition)
        self.trackingController.trackingStopped.connect(self.acquisition_is_finished)

    def set_saving_dir(self):
        dialog = QFileDialog()
        save_dir_base = dialog.getExistingDirectory(None, "Select Folder")
        self.plateReadingController.set_base_path(save_dir_base)
        self.lineEdit_savingDir.setText(save_dir_base)
        self.base_path_is_set = True

    def toggle_acquisition(self,pressed):
        if self.base_path_is_set == False:
            self.btn_startAcquisition.setChecked(False)
            msg = QMessageBox()
            msg.setText("Please choose base saving directory first")
            msg.exec_()
            return
        if pressed:
            # @@@ to do: add a widgetManger to enable and disable widget 
            # @@@ to do: emit signal to widgetManager to disable other widgets
            self.setEnabled_all(False)
            self.trackingController.start_new_experiment(self.lineEdit_experimentID.text())
            self.trackingController.set_selected_configurations((item.text() for item in self.list_configurations.selectedItems()))
            self.trackingController.set_selected_columns(list(map(int,[item.text() for item in self.list_columns.selectedItems()])))
            self.trackingController.run_acquisition()
        else:
            self.trackingController.stop_acquisition() # to implement
            pass

    def acquisition_is_finished(self):
        self.btn_startAcquisition.setChecked(False)
        self.setEnabled_all(True)

    def setEnabled_all(self,enabled,exclude_btn_startAcquisition=False):
        self.btn_setSavingDir.setEnabled(enabled)
        self.lineEdit_savingDir.setEnabled(enabled)
        self.lineEdit_experimentID.setEnabled(enabled)
        self.list_columns.setEnabled(enabled)
        self.list_configurations.setEnabled(enabled)
        self.checkbox_withAutofocus.setEnabled(enabled)
        if exclude_btn_startAcquisition is not True:
            self.btn_startAcquisition.setEnabled(enabled)
    '''

class PlateReaderAcquisitionWidget(QFrame):
    def __init__(self, plateReadingController, configurationManager = None, show_configurations = True, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.plateReadingController = plateReadingController
        self.configurationManager = configurationManager
        self.base_path_is_set = False
        self.add_components(show_configurations)
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self,show_configurations):
        self.btn_setSavingDir = QPushButton('Browse')
        self.btn_setSavingDir.setDefault(False)
        self.btn_setSavingDir.setIcon(QIcon('icon/folder.png'))
        self.lineEdit_savingDir = QLineEdit()
        self.lineEdit_savingDir.setReadOnly(True)
        self.lineEdit_savingDir.setText('Choose a base saving directory')
        self.lineEdit_savingDir.setText(DEFAULT_SAVING_PATH)
        self.plateReadingController.set_base_path(DEFAULT_SAVING_PATH)
        self.base_path_is_set = True

        self.lineEdit_experimentID = QLineEdit()

        self.list_columns = QListWidget()
        for i in range(PLATE_READER.NUMBER_OF_COLUMNS):
            self.list_columns.addItems([str(i+1)])
        self.list_columns.setSelectionMode(QAbstractItemView.MultiSelection) # ref: https://doc.qt.io/qt-5/qabstractitemview.html#SelectionMode-enum

        self.list_configurations = QListWidget()
        for microscope_configuration in self.configurationManager.configurations:
            self.list_configurations.addItems([microscope_configuration.name])
        self.list_configurations.setSelectionMode(QAbstractItemView.MultiSelection) # ref: https://doc.qt.io/qt-5/qabstractitemview.html#SelectionMode-enum

        self.checkbox_withAutofocus = QCheckBox('With AF')
        self.btn_startAcquisition = QPushButton('Start Acquisition')
        self.btn_startAcquisition.setCheckable(True)
        self.btn_startAcquisition.setChecked(False)

        self.btn_startAcquisition.setEnabled(False)

        # layout
        grid_line0 = QGridLayout()
        tmp = QLabel('Saving Path')
        tmp.setFixedWidth(90)
        grid_line0.addWidget(tmp)
        grid_line0.addWidget(self.lineEdit_savingDir, 0,1)
        grid_line0.addWidget(self.btn_setSavingDir, 0,2)

        grid_line1 = QGridLayout()
        tmp = QLabel('Sample ID')
        tmp.setFixedWidth(90)
        grid_line1.addWidget(tmp)
        grid_line1.addWidget(self.lineEdit_experimentID,0,1)

        grid_line2 = QGridLayout()
        tmp = QLabel('Columns')
        tmp.setFixedWidth(90)
        grid_line2.addWidget(tmp)
        grid_line2.addWidget(self.list_columns, 0,1)

        grid_line3 = QHBoxLayout()
        tmp = QLabel('Configurations')
        tmp.setFixedWidth(90)
        grid_line3.addWidget(tmp)
        grid_line3.addWidget(self.list_configurations)
        # grid_line3.addWidget(self.checkbox_withAutofocus)

        self.grid = QGridLayout()
        self.grid.addLayout(grid_line0,0,0)
        self.grid.addLayout(grid_line1,1,0)
        self.grid.addLayout(grid_line2,2,0)
        if show_configurations:
            self.grid.addLayout(grid_line3,3,0)
        else:
            self.list_configurations.setCurrentRow(0) # select the first configuration
        self.grid.addWidget(self.btn_startAcquisition,4,0)
        self.setLayout(self.grid)

        # add and display a timer - to be implemented
        # self.timer = QTimer()

        # connections
        self.checkbox_withAutofocus.stateChanged.connect(self.plateReadingController.set_af_flag)
        self.btn_setSavingDir.clicked.connect(self.set_saving_dir)
        self.btn_startAcquisition.clicked.connect(self.toggle_acquisition)
        self.plateReadingController.acquisitionFinished.connect(self.acquisition_is_finished)

    def set_saving_dir(self):
        dialog = QFileDialog()
        save_dir_base = dialog.getExistingDirectory(None, "Select Folder")
        self.plateReadingController.set_base_path(save_dir_base)
        self.lineEdit_savingDir.setText(save_dir_base)
        self.base_path_is_set = True

    def toggle_acquisition(self,pressed):
        if self.base_path_is_set == False:
            self.btn_startAcquisition.setChecked(False)
            msg = QMessageBox()
            msg.setText("Please choose base saving directory first")
            msg.exec_()
            return
        if pressed:
            # @@@ to do: add a widgetManger to enable and disable widget 
            # @@@ to do: emit signal to widgetManager to disable other widgets
            self.setEnabled_all(False)
            self.plateReadingController.start_new_experiment(self.lineEdit_experimentID.text())
            self.plateReadingController.set_selected_configurations((item.text() for item in self.list_configurations.selectedItems()))
            self.plateReadingController.set_selected_columns(list(map(int,[item.text() for item in self.list_columns.selectedItems()])))
            self.plateReadingController.run_acquisition()
        else:
            self.plateReadingController.stop_acquisition() # to implement
            pass

    def acquisition_is_finished(self):
        self.btn_startAcquisition.setChecked(False)
        self.setEnabled_all(True)

    def setEnabled_all(self,enabled,exclude_btn_startAcquisition=False):
        self.btn_setSavingDir.setEnabled(enabled)
        self.lineEdit_savingDir.setEnabled(enabled)
        self.lineEdit_experimentID.setEnabled(enabled)
        self.list_columns.setEnabled(enabled)
        self.list_configurations.setEnabled(enabled)
        self.checkbox_withAutofocus.setEnabled(enabled)
        self.checkbox_withReflectionAutofocus.setEnabled(enabled)
        if exclude_btn_startAcquisition is not True:
            self.btn_startAcquisition.setEnabled(enabled)

    def slot_homing_complete(self):
        self.btn_startAcquisition.setEnabled(True)
    
class PlateReaderNavigationWidget(QFrame):
    def __init__(self, plateReaderNavigationController, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)
        self.plateReaderNavigationController = plateReaderNavigationController

    def add_components(self):
        self.dropdown_column = QComboBox()
        self.dropdown_column.addItems([''])
        self.dropdown_column.addItems([str(i+1) for i in range(PLATE_READER.NUMBER_OF_COLUMNS)])
        self.dropdown_row = QComboBox()
        self.dropdown_row.addItems([''])
        self.dropdown_row.addItems([chr(i) for i in range(ord('A'),ord('A')+PLATE_READER.NUMBER_OF_ROWS)])
        self.btn_moveto = QPushButton("Move To")
        self.btn_home = QPushButton('Home')
        self.label_current_location = QLabel()
        self.label_current_location.setFrameStyle(QFrame.Panel | QFrame.Sunken)
        self.label_current_location.setFixedWidth(50)

        self.dropdown_column.setEnabled(False)
        self.dropdown_row.setEnabled(False)
        self.btn_moveto.setEnabled(False)
        
        # layout
        grid_line0 = QHBoxLayout()
        # tmp = QLabel('Saving Path')
        # tmp.setFixedWidth(90)
        grid_line0.addWidget(self.btn_home)
        grid_line0.addWidget(QLabel('Column'))
        grid_line0.addWidget(self.dropdown_column)
        grid_line0.addWidget(QLabel('Row'))
        grid_line0.addWidget(self.dropdown_row)
        grid_line0.addWidget(self.btn_moveto)
        grid_line0.addStretch()
        grid_line0.addWidget(self.label_current_location)

        self.grid = QGridLayout()
        self.grid.addLayout(grid_line0,0,0)
        self.setLayout(self.grid)

        self.btn_home.clicked.connect(self.home)
        self.btn_moveto.clicked.connect(self.move)

    def home(self):
        msg = QMessageBox()
        msg.setIcon(QMessageBox.Information)
        msg.setText("Confirm your action")
        msg.setInformativeText("Click OK to run homing")
        msg.setWindowTitle("Confirmation")
        msg.setStandardButtons(QMessageBox.Ok | QMessageBox.Cancel)
        msg.setDefaultButton(QMessageBox.Cancel)
        retval = msg.exec_()
        if QMessageBox.Ok == retval:
            self.plateReaderNavigationController.home()

    def move(self):
        self.plateReaderNavigationController.moveto(self.dropdown_column.currentText(),self.dropdown_row.currentText())

    def slot_homing_complete(self):
        self.dropdown_column.setEnabled(True)
        self.dropdown_row.setEnabled(True)
        self.btn_moveto.setEnabled(True)

    def update_current_location(self,location_str):
        self.label_current_location.setText(location_str)
        row = location_str[0]
        column = location_str[1:]
        self.dropdown_row.setCurrentText(row)
        self.dropdown_column.setCurrentText(column)


class TriggerControlWidget(QFrame):
    # for synchronized trigger 
    signal_toggle_live = Signal(bool)
    signal_trigger_mode = Signal(str)
    signal_trigger_fps = Signal(float)

    def __init__(self, microcontroller2):
        super().__init__()
        self.fps_trigger = 10
        self.fps_display = 10
        self.microcontroller2 = microcontroller2
        self.triggerMode = TriggerMode.SOFTWARE
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        # line 0: trigger mode
        self.triggerMode = None
        self.dropdown_triggerManu = QComboBox()
        self.dropdown_triggerManu.addItems([TriggerMode.SOFTWARE,TriggerMode.HARDWARE])

        # line 1: fps
        self.entry_triggerFPS = QDoubleSpinBox()
        self.entry_triggerFPS.setMinimum(0.02) 
        self.entry_triggerFPS.setMaximum(1000) 
        self.entry_triggerFPS.setSingleStep(1)
        self.entry_triggerFPS.setValue(self.fps_trigger)

        self.btn_live = QPushButton("Live")
        self.btn_live.setCheckable(True)
        self.btn_live.setChecked(False)
        self.btn_live.setDefault(False)

        # connections
        self.dropdown_triggerManu.currentIndexChanged.connect(self.update_trigger_mode)
        self.btn_live.clicked.connect(self.toggle_live)
        self.entry_triggerFPS.valueChanged.connect(self.update_trigger_fps)

        # inititialization
        self.microcontroller2.set_camera_trigger_frequency(self.fps_trigger)

        # layout
        grid_line0 = QGridLayout()
        grid_line0.addWidget(QLabel('Trigger Mode'), 0,0)
        grid_line0.addWidget(self.dropdown_triggerManu, 0,1)
        grid_line0.addWidget(QLabel('Trigger FPS'), 0,2)
        grid_line0.addWidget(self.entry_triggerFPS, 0,3)
        grid_line0.addWidget(self.btn_live, 1,0,1,4)
        self.setLayout(grid_line0)

    def toggle_live(self,pressed):
        self.signal_toggle_live.emit(pressed)
        if pressed:
            self.microcontroller2.start_camera_trigger()
        else:
            self.microcontroller2.stop_camera_trigger()

    def update_trigger_mode(self):
        self.signal_trigger_mode.emit(self.dropdown_triggerManu.currentText())

    def update_trigger_fps(self,fps):
        self.fps_trigger = fps
        self.signal_trigger_fps.emit(fps)
        self.microcontroller2.set_camera_trigger_frequency(self.fps_trigger)

class MultiCameraRecordingWidget(QFrame):
    def __init__(self, streamHandler, imageSaver, channels, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.imageSaver = imageSaver # for saving path control
        self.streamHandler = streamHandler
        self.channels = channels
        self.base_path_is_set = False
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        self.btn_setSavingDir = QPushButton('Browse')
        self.btn_setSavingDir.setDefault(False)
        self.btn_setSavingDir.setIcon(QIcon('icon/folder.png'))
        
        self.lineEdit_savingDir = QLineEdit()
        self.lineEdit_savingDir.setReadOnly(True)
        self.lineEdit_savingDir.setText('Choose a base saving directory')

        self.lineEdit_experimentID = QLineEdit()

        self.entry_saveFPS = QDoubleSpinBox()
        self.entry_saveFPS.setMinimum(0.02) 
        self.entry_saveFPS.setMaximum(1000) 
        self.entry_saveFPS.setSingleStep(1)
        self.entry_saveFPS.setValue(1)
        for channel in self.channels:
            self.streamHandler[channel].set_save_fps(1)

        self.entry_timeLimit = QSpinBox()
        self.entry_timeLimit.setMinimum(-1) 
        self.entry_timeLimit.setMaximum(60*60*24*30) 
        self.entry_timeLimit.setSingleStep(1)
        self.entry_timeLimit.setValue(-1)

        self.btn_record = QPushButton("Record")
        self.btn_record.setCheckable(True)
        self.btn_record.setChecked(False)
        self.btn_record.setDefault(False)

        grid_line1 = QGridLayout()
        grid_line1.addWidget(QLabel('Saving Path'))
        grid_line1.addWidget(self.lineEdit_savingDir, 0,1)
        grid_line1.addWidget(self.btn_setSavingDir, 0,2)

        grid_line2 = QGridLayout()
        grid_line2.addWidget(QLabel('Experiment ID'), 0,0)
        grid_line2.addWidget(self.lineEdit_experimentID,0,1)

        grid_line3 = QGridLayout()
        grid_line3.addWidget(QLabel('Saving FPS'), 0,0)
        grid_line3.addWidget(self.entry_saveFPS, 0,1)
        grid_line3.addWidget(QLabel('Time Limit (s)'), 0,2)
        grid_line3.addWidget(self.entry_timeLimit, 0,3)
        grid_line3.addWidget(self.btn_record, 0,4)

        self.grid = QGridLayout()
        self.grid.addLayout(grid_line1,0,0)
        self.grid.addLayout(grid_line2,1,0)
        self.grid.addLayout(grid_line3,2,0)
        self.setLayout(self.grid)

        # add and display a timer - to be implemented
        # self.timer = QTimer()

        # connections
        self.btn_setSavingDir.clicked.connect(self.set_saving_dir)
        self.btn_record.clicked.connect(self.toggle_recording)
        for channel in self.channels:
            self.entry_saveFPS.valueChanged.connect(self.streamHandler[channel].set_save_fps)
            self.entry_timeLimit.valueChanged.connect(self.imageSaver[channel].set_recording_time_limit)
            self.imageSaver[channel].stop_recording.connect(self.stop_recording)

    def set_saving_dir(self):
        dialog = QFileDialog()
        save_dir_base = dialog.getExistingDirectory(None, "Select Folder")
        for channel in self.channels:
            self.imageSaver[channel].set_base_path(save_dir_base)
        self.lineEdit_savingDir.setText(save_dir_base)
        self.save_dir_base = save_dir_base
        self.base_path_is_set = True

    def toggle_recording(self,pressed):
        if self.base_path_is_set == False:
            self.btn_record.setChecked(False)
            msg = QMessageBox()
            msg.setText("Please choose base saving directory first")
            msg.exec_()
            return
        if pressed:
            self.lineEdit_experimentID.setEnabled(False)
            self.btn_setSavingDir.setEnabled(False)
            experiment_ID = self.lineEdit_experimentID.text()
            experiment_ID = experiment_ID + '_' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S.%f')
            os.mkdir(os.path.join(self.save_dir_base,experiment_ID))
            for channel in self.channels:
                self.imageSaver[channel].start_new_experiment(os.path.join(experiment_ID,channel),add_timestamp=False)
                self.streamHandler[channel].start_recording()
        else:
            for channel in self.channels:
                self.streamHandler[channel].stop_recording()
            self.lineEdit_experimentID.setEnabled(True)
            self.btn_setSavingDir.setEnabled(True)

    # stop_recording can be called by imageSaver
    def stop_recording(self):
        self.lineEdit_experimentID.setEnabled(True)
        self.btn_record.setChecked(False)
        for channel in self.channels:
            self.streamHandler[channel].stop_recording()
        self.btn_setSavingDir.setEnabled(True)

class WaveformDisplay(QFrame):

    def __init__(self, N=1000, include_x=True, include_y=True, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.N = N
        self.include_x = include_x
        self.include_y = include_y
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        self.plotWidget = {}
        self.plotWidget['X'] = PlotWidget('X', N=self.N, add_legend=True)
        self.plotWidget['Y'] = PlotWidget('X', N=self.N, add_legend=True)

        layout = QGridLayout() #layout = QStackedLayout()
        if self.include_x:
            layout.addWidget(self.plotWidget['X'],0,0)
        if self.include_y:
            layout.addWidget(self.plotWidget['Y'],1,0)
        self.setLayout(layout)

    def plot(self,time,data):
        if self.include_x:
            self.plotWidget['X'].plot(time,data[0,:],'X',color=(255,255,255),clear=True)
        if self.include_y:
            self.plotWidget['Y'].plot(time,data[1,:],'Y',color=(255,255,255),clear=True)

    def update_N(self,N):
        self.N = N
        self.plotWidget['X'].update_N(N)
        self.plotWidget['Y'].update_N(N)

class PlotWidget(pg.GraphicsLayoutWidget):
    
    def __init__(self, title='', N = 1000, parent=None,add_legend=False):
        super().__init__(parent)
        self.plotWidget = self.addPlot(title = '', axisItems = {'bottom': pg.DateAxisItem()})
        if add_legend:
            self.plotWidget.addLegend()
        self.N = N
    
    def plot(self,x,y,label,color,clear=False):
        self.plotWidget.plot(x[-self.N:],y[-self.N:],pen=pg.mkPen(color=color,width=2),name=label,clear=clear)

    def update_N(self,N):
        self.N = N

class DisplacementMeasurementWidget(QFrame):
    def __init__(self, displacementMeasurementController, waveformDisplay, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.displacementMeasurementController = displacementMeasurementController
        self.waveformDisplay = waveformDisplay
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        self.entry_x_offset = QDoubleSpinBox()
        self.entry_x_offset.setMinimum(0) 
        self.entry_x_offset.setMaximum(3000) 
        self.entry_x_offset.setSingleStep(0.2)
        self.entry_x_offset.setDecimals(3)
        self.entry_x_offset.setValue(0)
        self.entry_x_offset.setKeyboardTracking(False)

        self.entry_y_offset = QDoubleSpinBox()
        self.entry_y_offset.setMinimum(0) 
        self.entry_y_offset.setMaximum(3000) 
        self.entry_y_offset.setSingleStep(0.2)
        self.entry_y_offset.setDecimals(3)
        self.entry_y_offset.setValue(0)
        self.entry_y_offset.setKeyboardTracking(False)

        self.entry_x_scaling = QDoubleSpinBox()
        self.entry_x_scaling.setMinimum(-100) 
        self.entry_x_scaling.setMaximum(100) 
        self.entry_x_scaling.setSingleStep(0.1)
        self.entry_x_scaling.setDecimals(3)
        self.entry_x_scaling.setValue(1)
        self.entry_x_scaling.setKeyboardTracking(False)

        self.entry_y_scaling = QDoubleSpinBox()
        self.entry_y_scaling.setMinimum(-100) 
        self.entry_y_scaling.setMaximum(100) 
        self.entry_y_scaling.setSingleStep(0.1)
        self.entry_y_scaling.setDecimals(3)
        self.entry_y_scaling.setValue(1)
        self.entry_y_scaling.setKeyboardTracking(False)

        self.entry_N_average = QSpinBox()
        self.entry_N_average.setMinimum(1) 
        self.entry_N_average.setMaximum(25) 
        self.entry_N_average.setSingleStep(1)
        self.entry_N_average.setValue(1)
        self.entry_N_average.setKeyboardTracking(False)

        self.entry_N = QSpinBox()
        self.entry_N.setMinimum(1) 
        self.entry_N.setMaximum(5000) 
        self.entry_N.setSingleStep(1)
        self.entry_N.setValue(1000)
        self.entry_N.setKeyboardTracking(False)

        self.reading_x = QLabel()
        self.reading_x.setNum(0)
        self.reading_x.setFrameStyle(QFrame.Panel | QFrame.Sunken)

        self.reading_y = QLabel()
        self.reading_y.setNum(0)
        self.reading_y.setFrameStyle(QFrame.Panel | QFrame.Sunken)

        # layout
        grid_line0 = QGridLayout()
        grid_line0.addWidget(QLabel('x offset'), 0,0)
        grid_line0.addWidget(self.entry_x_offset, 0,1)
        grid_line0.addWidget(QLabel('x scaling'), 0,2)
        grid_line0.addWidget(self.entry_x_scaling, 0,3)
        grid_line0.addWidget(QLabel('y offset'), 0,4)
        grid_line0.addWidget(self.entry_y_offset, 0,5)
        grid_line0.addWidget(QLabel('y scaling'), 0,6)
        grid_line0.addWidget(self.entry_y_scaling, 0,7)
        
        grid_line1 = QGridLayout()
        grid_line1.addWidget(QLabel('d from x'), 0,0)
        grid_line1.addWidget(self.reading_x, 0,1)
        grid_line1.addWidget(QLabel('d from y'), 0,2)
        grid_line1.addWidget(self.reading_y, 0,3)
        grid_line1.addWidget(QLabel('N average'), 0,4)
        grid_line1.addWidget(self.entry_N_average, 0,5)
        grid_line1.addWidget(QLabel('N'), 0,6)
        grid_line1.addWidget(self.entry_N, 0,7)

        self.grid = QGridLayout()
        self.grid.addLayout(grid_line0,0,0)
        self.grid.addLayout(grid_line1,1,0)
        self.setLayout(self.grid)
        
        # connections
        self.entry_x_offset.valueChanged.connect(self.update_settings)
        self.entry_y_offset.valueChanged.connect(self.update_settings)
        self.entry_x_scaling.valueChanged.connect(self.update_settings)
        self.entry_y_scaling.valueChanged.connect(self.update_settings)
        self.entry_N_average.valueChanged.connect(self.update_settings)
        self.entry_N.valueChanged.connect(self.update_settings)
        self.entry_N.valueChanged.connect(self.update_waveformDisplay_N)

    def update_settings(self,new_value):
        print('update settings')
        self.displacementMeasurementController.update_settings(self.entry_x_offset.value(),self.entry_y_offset.value(),self.entry_x_scaling.value(),self.entry_y_scaling.value(),self.entry_N_average.value(),self.entry_N.value())
    
    def update_waveformDisplay_N(self,N):    
        self.waveformDisplay.update_N(N)

    def display_readings(self,readings):
        self.reading_x.setText("{:.2f}".format(readings[0]))
        self.reading_y.setText("{:.2f}".format(readings[1]))

class LaserAutofocusControlWidget(QFrame):
    def __init__(self, laserAutofocusController, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.laserAutofocusController = laserAutofocusController
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        self.btn_initialize = QPushButton("Initialize")
        self.btn_initialize.setCheckable(False)
        self.btn_initialize.setChecked(False)
        self.btn_initialize.setDefault(False)

        self.btn_set_reference = QPushButton("Set as reference plane")
        self.btn_set_reference.setCheckable(False)
        self.btn_set_reference.setChecked(False)
        self.btn_set_reference.setDefault(False)
        if not self.laserAutofocusController.is_initialized:
            self.btn_set_reference.setEnabled(False)

        self.label_displacement = QLabel()
        self.label_displacement.setFrameStyle(QFrame.Panel | QFrame.Sunken)

        self.btn_measure_displacement = QPushButton("Measure displacement")
        self.btn_measure_displacement.setCheckable(False)
        self.btn_measure_displacement.setChecked(False)
        self.btn_measure_displacement.setDefault(False)
        if not self.laserAutofocusController.is_initialized:
            self.btn_measure_displacement.setEnabled(False)

        self.entry_target = QDoubleSpinBox()
        self.entry_target.setMinimum(-100)
        self.entry_target.setMaximum(100)
        self.entry_target.setSingleStep(0.01)
        self.entry_target.setDecimals(2)
        self.entry_target.setValue(0)
        self.entry_target.setKeyboardTracking(False)

        self.btn_move_to_target = QPushButton("Move to target")
        self.btn_move_to_target.setCheckable(False)
        self.btn_move_to_target.setChecked(False)
        self.btn_move_to_target.setDefault(False)
        if not self.laserAutofocusController.is_initialized:
            self.btn_move_to_target.setEnabled(False)
        
        self.grid = QGridLayout()
        self.grid.addWidget(self.btn_initialize,0,0,1,3)
        self.grid.addWidget(self.btn_set_reference,1,0,1,3)
        self.grid.addWidget(QLabel('Displacement (um)'),2,0)
        self.grid.addWidget(self.label_displacement,2,1)
        self.grid.addWidget(self.btn_measure_displacement,2,2)
        self.grid.addWidget(QLabel('Target (um)'),3,0)
        self.grid.addWidget(self.entry_target,3,1)
        self.grid.addWidget(self.btn_move_to_target,3,2)
        self.grid.setRowStretch(self.grid.rowCount(), 1)

        self.setLayout(self.grid)

        # make connections
        self.btn_initialize.clicked.connect(self.init_controller)
        self.btn_set_reference.clicked.connect(self.laserAutofocusController.set_reference)
        self.btn_measure_displacement.clicked.connect(self.laserAutofocusController.measure_displacement)
        self.btn_move_to_target.clicked.connect(self.move_to_target)
        self.laserAutofocusController.signal_displacement_um.connect(self.label_displacement.setNum)

    def init_controller(self):
        self.laserAutofocusController.initialize_auto()
        if self.laserAutofocusController.is_initialized:
            self.btn_set_reference.setEnabled(True)
            self.btn_measure_displacement.setEnabled(True)
            self.btn_move_to_target.setEnabled(True)

    def move_to_target(self,target_um):
        self.laserAutofocusController.move_to_target(self.entry_target.value())


class WellSelectionWidget(QTableWidget):

    signal_wellSelected = Signal(bool)
    signal_wellSelectedPos = Signal(float,float)

    def __init__(self, format_, *args):

        if format_ == 6:
            self.rows = 2
            self.columns = 3
            self.spacing_mm = 39.2
        elif format_ == 12:
            self.rows = 3
            self.columns = 4
            self.spacing_mm = 26
        elif format_ == 24:
            self.rows = 4
            self.columns = 6
            self.spacing_mm = 18
        elif format_ == 96:
            self.rows = 8
            self.columns = 12
            self.spacing_mm = 9
        elif format_ == 384:
            self.rows = 16
            self.columns = 24
            self.spacing_mm = 4.5
        elif format_ == 1536:
            self.rows = 32
            self.columns = 48
            self.spacing_mm = 2.25

        self.format = format_

        QTableWidget.__init__(self, self.rows, self.columns, *args)
        self.setData()
        self.resizeColumnsToContents()
        self.resizeRowsToContents()
        self.setEditTriggers(QTableWidget.NoEditTriggers)
        self.cellDoubleClicked.connect(self.onDoubleClick)
        self.cellClicked.connect(self.onSingleClick)
        self.itemSelectionChanged.connect(self.get_selected_cells)

        # size
        self.verticalHeader().setSectionResizeMode(QHeaderView.Fixed)
        self.verticalHeader().setDefaultSectionSize(int(5*self.spacing_mm))
        self.horizontalHeader().setSectionResizeMode(QHeaderView.Fixed)
        self.horizontalHeader().setMinimumSectionSize(int(5*self.spacing_mm))

        self.setSizePolicy(QSizePolicy.Minimum,QSizePolicy.Minimum)
        self.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        self.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        self.resizeColumnsToContents()
        self.setFixedSize(self.horizontalHeader().length() + 
                   self.verticalHeader().width(),
                   self.verticalHeader().length() + 
                   self.horizontalHeader().height())

    def setData(self): 
        '''
        # cells
        for i in range(16):
            for j in range(24):
                newitem = QTableWidgetItem( chr(ord('A')+i) + str(j) )
                self.setItem(i, j, newitem)
        '''
        # row header
        row_headers = []
        for i in range(16):
            row_headers.append(chr(ord('A')+i))
        self.setVerticalHeaderLabels(row_headers)

        # make the outer cells not selectable if using 96 and 384 well plates
        if self.format == 384:
            if NUMBER_OF_SKIP == 1:
                for i in range(self.rows):
                    item = QTableWidgetItem()
                    item.setFlags(item.flags() & ~Qt.ItemIsSelectable)
                    self.setItem(i,0,item)
                    item = QTableWidgetItem()
                    item.setFlags(item.flags() & ~Qt.ItemIsSelectable)
                    self.setItem(i,self.columns-1,item)
                for j in range(self.columns):
                    item = QTableWidgetItem()
                    item.setFlags(item.flags() & ~Qt.ItemIsSelectable)
                    self.setItem(0,j,item)
                    item = QTableWidgetItem()
                    item.setFlags(item.flags() & ~Qt.ItemIsSelectable)
                    self.setItem(self.rows-1,j,item)
        elif self.format == 96:
            if NUMBER_OF_SKIP == 1:
                for i in range(self.rows):
                    item = QTableWidgetItem()
                    item.setFlags(item.flags() & ~Qt.ItemIsSelectable)
                    self.setItem(i,0,item)
                    item = QTableWidgetItem()
                    item.setFlags(item.flags() & ~Qt.ItemIsSelectable)
                    self.setItem(i,self.columns-1,item)
                for j in range(self.columns):
                    item = QTableWidgetItem()
                    item.setFlags(item.flags() & ~Qt.ItemIsSelectable)
                    self.setItem(0,j,item)
                    item = QTableWidgetItem()
                    item.setFlags(item.flags() & ~Qt.ItemIsSelectable)
                    self.setItem(self.rows-1,j,item)


    def onDoubleClick(self,row,col):
        print("double click well", row, col)
        if (row >= 0 + NUMBER_OF_SKIP and row <= self.rows-1-NUMBER_OF_SKIP ) and ( col >= 0 + NUMBER_OF_SKIP and col <= self.columns-1-NUMBER_OF_SKIP ):
            self.signal_wellSelected.emit(True)
            x_mm = col*WELL_SPACING_MM + A1_X_MM + WELLPLATE_OFFSET_X_mm
            y_mm = row*WELL_SPACING_MM + A1_Y_MM + WELLPLATE_OFFSET_Y_mm
            self.signal_wellSelectedPos.emit(x_mm,y_mm)
        else:
            self.signal_wellSelected.emit(False)
 
    def onSingleClick(self,row,col):
        print("single click well", row, col)
        if (row >= 0 + NUMBER_OF_SKIP and row <= self.rows-1-NUMBER_OF_SKIP ) and ( col >= 0 + NUMBER_OF_SKIP and col <= self.columns-1-NUMBER_OF_SKIP ):
            self.signal_wellSelected.emit(True)
        else:
            self.signal_wellSelected.emit(False)
            
    def get_selected_cells(self):
        print("getting selected wells...")
        list_of_selected_cells = []
        for index in self.selectedIndexes():
            row, col = index.row(), index.column()
            # Check if the cell is within the allowed bounds
            if (row >= 0 + NUMBER_OF_SKIP and row <= self.rows - 1 - NUMBER_OF_SKIP) and \
               (col >= 0 + NUMBER_OF_SKIP and col <= self.columns - 1 - NUMBER_OF_SKIP):
                list_of_selected_cells.append((row, col))
        
        if not list_of_selected_cells:
            self.signal_wellSelected.emit(False)
        else:
            print("wells:",list_of_selected_cells)
            self.signal_wellSelected.emit(True)
        return(list_of_selected_cells)


from PyQt5.QtWidgets import QApplication, QWidget, QPushButton, QLineEdit, QLabel, QHBoxLayout, QVBoxLayout, QGridLayout
from PyQt5.QtGui import QPixmap, QPainter, QColor
import re
import sys

class Well1536SelectionWidget(QWidget):

    signal_wellSelectedPos = Signal(float,float)

    def __init__(self):
        super().__init__()
        self.selected_cells = {}  # Dictionary to keep track of selected cells and their colors
        self.current_cell = None  # To track the current (green) cell
        self.rows = 32
        self.columns = 48
        self.spacing_mm = 2.25
        self.initUI()

    def initUI(self):
        self.setWindowTitle('1536 Well Plate')
        self.setGeometry(100, 100, 550, 400)

        self.a = 10

        self.image = QPixmap(48*self.a, 32*self.a)
        self.image.fill(QColor('white'))
        self.label = QLabel()
        self.label.setPixmap(self.image)

        self.cell_input = QLineEdit(self)
        go_button = QPushButton('Go to well', self)
        go_button.clicked.connect(self.go_to_cell)

        self.selection_input = QLineEdit(self)
        select_button = QPushButton('Select wells', self)
        select_button.clicked.connect(self.select_cells)

        layout = QGridLayout()

        layout.addWidget(self.label,0,0,3,1)

        layout.addWidget(QLabel("Well Navigation"),1,1)
        layout.addWidget(self.cell_input,1,2)
        layout.addWidget(go_button,1,3)

        layout.addWidget(QLabel("Well Selection"),2,1)
        layout.addWidget(self.selection_input,2,2)
        layout.addWidget(select_button,2,3)

        self.setLayout(layout)

    def redraw_wells(self):
        self.image.fill(QColor('white'))  # Clear the pixmap first
        painter = QPainter(self.image)
        painter.setPen(QColor('white'))
        # Draw selected cells in red
        for (row, col), color in self.selected_cells.items():
            painter.setBrush(QColor(color))
            painter.drawRect(col * self.a, row * self.a, self.a, self.a)
        # Draw current cell in green
        if self.current_cell:
            painter.setBrush(QColor('#ff7f0e'))
            row, col = self.current_cell
            painter.drawRect(col * self.a, row * self.a, self.a, self.a)
        painter.end()
        self.label.setPixmap(self.image)

    def go_to_cell(self):
        cell_desc = self.cell_input.text().strip()
        match = re.match(r'([A-Za-z]+)(\d+)', cell_desc)
        if match:
            row_part, col_part = match.groups()
            row_index = self.row_to_index(row_part)
            col_index = int(col_part) - 1
            self.current_cell = (row_index, col_index)  # Update the current cell
            self.redraw_wells()  # Redraw with the new current cell
            x_mm = col_index*WELL_SPACING_MM + A1_X_MM + WELLPLATE_OFFSET_X_mm
            y_mm = row_index*WELL_SPACING_MM + A1_Y_MM + WELLPLATE_OFFSET_Y_mm
            self.signal_wellSelectedPos.emit(x_mm,y_mm)

    def select_cells(self):
        # first clear selection
        self.selected_cells = {}

        pattern = r'([A-Za-z]+)(\d+):?([A-Za-z]*)(\d*)'
        cell_descriptions = self.selection_input.text().split(',')
        for desc in cell_descriptions:
            match = re.match(pattern, desc.strip())
            if match:
                start_row, start_col, end_row, end_col = match.groups()
                start_row_index = self.row_to_index(start_row)
                start_col_index = int(start_col) - 1

                if end_row and end_col:  # It's a range
                    end_row_index = self.row_to_index(end_row)
                    end_col_index = int(end_col) - 1
                    for row in range(min(start_row_index, end_row_index), max(start_row_index, end_row_index) + 1):
                        for col in range(min(start_col_index, end_col_index), max(start_col_index, end_col_index) + 1):
                            self.selected_cells[(row, col)] = '#1f77b4'
                else:  # It's a single cell
                    self.selected_cells[(start_row_index, start_col_index)] = '#1f77b4'
        self.redraw_wells()

    def row_to_index(self, row):
        index = 0
        for char in row:
            index = index * 26 + (ord(char.upper()) - ord('A') + 1)
        return index - 1

    def get_selected_cells(self):
        list_of_selected_cells = list(self.selected_cells.keys())
        return(list_of_selected_cells)

class LedMatrixSettingsDialog(QDialog):
    def __init__(self,led_array):
        self.led_array = led_array
        super().__init__()
        self.setWindowTitle("LED Matrix Settings")

        self.layout = QVBoxLayout()

        # Add QDoubleSpinBox for LED intensity (0-1)
        self.NA_spinbox = QDoubleSpinBox()
        self.NA_spinbox.setRange(0, 1)
        self.NA_spinbox.setSingleStep(0.01)
        self.NA_spinbox.setValue(self.led_array.NA)

        NA_layout = QHBoxLayout()
        NA_layout.addWidget(QLabel("NA"))
        NA_layout.addWidget(self.NA_spinbox)

        self.layout.addLayout(NA_layout)
        self.setLayout(self.layout)

        # add ok/cancel buttons
        self.button_box = QDialogButtonBox(QDialogButtonBox.Ok | QDialogButtonBox.Cancel)
        self.button_box.accepted.connect(self.accept)
        self.button_box.rejected.connect(self.reject)
        self.layout.addWidget(self.button_box)

        self.button_box.accepted.connect(self.update_NA)

    def update_NA(self):
        self.led_array.set_NA(self.NA_spinbox.value())

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

import pandas as pd
import numpy as np
import time
import cv2
from control._def import *
import control.utils as utils

def multipoint_custom_script_entry(multiPointWorker,time_point,current_path,coordinate_id,coordiante_name,i,j):
    
    print( 'in custom script; t ' + str(multiPointWorker.time_point) + ', location ' + coordiante_name + ': ' +  str(i) + '_' + str(j) )

    # autofocus

    # if z location is included in the scan coordinates
    if multiPointWorker.use_scan_coordinates and multiPointWorker.scan_coordinates_mm.shape[1] == 3 :

        if multiPointWorker.do_autofocus:
            
            # autofocus for every FOV in the first scan and update the coordinates
            if multiPointWorker.time_point == 0:

                configuration_name_AF = MULTIPOINT_AUTOFOCUS_CHANNEL
                config_AF = next((config for config in multiPointWorker.configurationManager.configurations if config.name == configuration_name_AF))
                multiPointWorker.signal_current_configuration.emit(config_AF)
                multiPointWorker.autofocusController.autofocus()
                multiPointWorker.autofocusController.wait_till_autofocus_has_completed()
                multiPointWorker.scan_coordinates_mm[coordinate_id,2] = multiPointWorker.navigationController.z_pos_mm

            # in subsequent scans, autofocus at the first FOV and offset the rest
            else:

                if coordinate_id == 0:

                    z0 = multiPointWorker.scan_coordinates_mm[0,2]
                    configuration_name_AF = MULTIPOINT_AUTOFOCUS_CHANNEL
                    config_AF = next((config for config in multiPointWorker.configurationManager.configurations if config.name == configuration_name_AF))
                    multiPointWorker.signal_current_configuration.emit(config_AF)
                    multiPointWorker.autofocusController.autofocus()
                    multiPointWorker.autofocusController.wait_till_autofocus_has_completed()
                    multiPointWorker.scan_coordinates_mm[0,2] = multiPointWorker.navigationController.z_pos_mm
                    offset = multiPointWorker.scan_coordinates_mm[0,2] - z0
                    print('offset is ' + str(offset))
                    multiPointWorker.scan_coordinates_mm[1:,2] = multiPointWorker.scan_coordinates_mm[1:,2] + offset

                else:

                    pass


    # if z location is not included in the scan coordinates
    else:
        if multiPointWorker.do_reflection_af == False:
            # perform AF only if when not taking z stack or doing z stack from center
            if ( (multiPointWorker.NZ == 1) or Z_STACKING_CONFIG == 'FROM CENTER' ) and (multiPointWorker.do_autofocus) and (multiPointWorker.FOV_counter%Acquisition.NUMBER_OF_FOVS_PER_AF==0):
            # temporary: replace the above line with the line below to AF every FOV
            # if (multiPointWorker.NZ == 1) and (multiPointWorker.do_autofocus):
                configuration_name_AF = MULTIPOINT_AUTOFOCUS_CHANNEL
                config_AF = next((config for config in multiPointWorker.configurationManager.configurations if config.name == configuration_name_AF))
                multiPointWorker.signal_current_configuration.emit(config_AF)
                multiPointWorker.autofocusController.autofocus()
                multiPointWorker.autofocusController.wait_till_autofocus_has_completed()
        else:
           # initialize laser autofocus
            if multiPointWorker.reflection_af_initialized==False:
                # initialize the reflection AF
                multiPointWorker.microscope.laserAutofocusController.initialize_auto()
                multiPointWorker.reflection_af_initialized = True
                # do contrast AF for the first FOV
                if multiPointWorker.do_autofocus and ( (multiPointWorker.NZ == 1) or Z_STACKING_CONFIG == 'FROM CENTER' ) :
                    configuration_name_AF = MULTIPOINT_AUTOFOCUS_CHANNEL
                    config_AF = next((config for config in multiPointWorker.configurationManager.configurations if config.name == configuration_name_AF))
                    multiPointWorker.signal_current_configuration.emit(config_AF)
                    multiPointWorker.autofocusController.autofocus()
                    multiPointWorker.autofocusController.wait_till_autofocus_has_completed()
                # set the current plane as reference
                multiPointWorker.microscope.laserAutofocusController.set_reference()
            else:
                multiPointWorker.microscope.laserAutofocusController.move_to_target(0)
                multiPointWorker.microscope.laserAutofocusController.move_to_target(0) # for stepper in open loop mode, repeat the operation to counter backlash 

    if (multiPointWorker.NZ > 1):
        # move to bottom of the z stack
        if Z_STACKING_CONFIG == 'FROM CENTER':
            multiPointWorker.navigationController.move_z_usteps(-multiPointWorker.deltaZ_usteps*round((multiPointWorker.NZ-1)/2))
            multiPointWorker.wait_till_operation_is_completed()
            time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)
        # maneuver for achiving uniform step size and repeatability when using open-loop control
        multiPointWorker.navigationController.move_z_usteps(-160)
        multiPointWorker.wait_till_operation_is_completed()
        multiPointWorker.navigationController.move_z_usteps(160)
        multiPointWorker.wait_till_operation_is_completed()
        time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)

    # z-stack
    for k in range(multiPointWorker.NZ):
        
        file_ID = coordiante_name + str(i) + '_' + str(j if multiPointWorker.x_scan_direction==1 else multiPointWorker.NX-1-j) + '_' + str(k)
        # metadata = dict(x = multiPointWorker.navigationController.x_pos_mm, y = multiPointWorker.navigationController.y_pos_mm, z = multiPointWorker.navigationController.z_pos_mm)
        # metadata = json.dumps(metadata)

        # iterate through selected modes
        for config in multiPointWorker.selected_configurations:

            if 'USB Spectrometer' not in config.name:

                if time_point%10 != 0:

                    if 'Fluorescence' in config.name:
                        # only do fluorescence every 10th timepoint
                        continue

                # update the current configuration
                multiPointWorker.signal_current_configuration.emit(config)
                multiPointWorker.wait_till_operation_is_completed()
                # trigger acquisition (including turning on the illumination)
                if multiPointWorker.liveController.trigger_mode == TriggerMode.SOFTWARE:
                    multiPointWorker.liveController.turn_on_illumination()
                    multiPointWorker.wait_till_operation_is_completed()
                    multiPointWorker.camera.send_trigger()
                elif multiPointWorker.liveController.trigger_mode == TriggerMode.HARDWARE:
                    multiPointWorker.microcontroller.send_hardware_trigger(control_illumination=True,illumination_on_time_us=multiPointWorker.camera.exposure_time*1000)
                # read camera frame
                image = multiPointWorker.camera.read_frame()
                if image is None:
                    print('multiPointWorker.camera.read_frame() returned None')
                    continue
                # tunr of the illumination if using software trigger
                if multiPointWorker.liveController.trigger_mode == TriggerMode.SOFTWARE:
                    multiPointWorker.liveController.turn_off_illumination()
                # process the image -  @@@ to move to camera
                image = utils.crop_image(image,multiPointWorker.crop_width,multiPointWorker.crop_height)
                image = utils.rotate_and_flip_image(image,rotate_image_angle=multiPointWorker.camera.rotate_image_angle,flip_image=multiPointWorker.camera.flip_image)
                # multiPointWorker.image_to_display.emit(cv2.resize(image,(round(multiPointWorker.crop_width*multiPointWorker.display_resolution_scaling), round(multiPointWorker.crop_height*multiPointWorker.display_resolution_scaling)),cv2.INTER_LINEAR))
                image_to_display = utils.crop_image(image,round(multiPointWorker.crop_width*multiPointWorker.display_resolution_scaling), round(multiPointWorker.crop_height*multiPointWorker.display_resolution_scaling))
                multiPointWorker.image_to_display.emit(image_to_display)
                multiPointWorker.image_to_display_multi.emit(image_to_display,config.illumination_source)
                if image.dtype == np.uint16:
                    saving_path = os.path.join(current_path, file_ID + '_' + str(config.name).replace(' ','_') + '.tiff')
                    if multiPointWorker.camera.is_color:
                        if 'BF LED matrix' in config.name:
                            if MULTIPOINT_BF_SAVING_OPTION == 'RGB2GRAY':
                                image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)
                            elif MULTIPOINT_BF_SAVING_OPTION == 'Green Channel Only':
                                image = image[:,:,1]
                    iio.imwrite(saving_path,image)
                else:
                    saving_path = os.path.join(current_path, file_ID + '_' + str(config.name).replace(' ','_') + '.' + Acquisition.IMAGE_FORMAT)
                    if multiPointWorker.camera.is_color:
                        if 'BF LED matrix' in config.name:
                            if MULTIPOINT_BF_SAVING_OPTION == 'Raw':
                                image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)
                            elif MULTIPOINT_BF_SAVING_OPTION == 'RGB2GRAY':
                                image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)
                            elif MULTIPOINT_BF_SAVING_OPTION == 'Green Channel Only':
                                image = image[:,:,1]
                        else:
                            image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)
                    cv2.imwrite(saving_path,image)
                QApplication.processEvents()
            
            else:

                if multiPointWorker.usb_spectrometer != None:
                    for l in range(N_SPECTRUM_PER_POINT):
                        data = multiPointWorker.usb_spectrometer.read_spectrum()
                        multiPointWorker.spectrum_to_display.emit(data)
                        saving_path = os.path.join(current_path, file_ID + '_' + str(config.name).replace(' ','_') + '_' + str(l) + '.csv')
                        np.savetxt(saving_path,data,delimiter=',')

        # add the coordinate of the current location
        new_row = pd.DataFrame({'i':[i],'j':[multiPointWorker.NX-1-j],'k':[k],
                                'x (mm)':[multiPointWorker.navigationController.x_pos_mm],
                                'y (mm)':[multiPointWorker.navigationController.y_pos_mm],
                                'z (um)':[multiPointWorker.navigationController.z_pos_mm*1000]},
                                )
        multiPointWorker.coordinates_pd = pd.concat([multiPointWorker.coordinates_pd, new_row], ignore_index=True)

        # register the current fov in the navigationViewer 
        multiPointWorker.signal_register_current_fov.emit(multiPointWorker.navigationController.x_pos_mm,multiPointWorker.navigationController.y_pos_mm)

        # check if the acquisition should be aborted
        if multiPointWorker.multiPointController.abort_acqusition_requested:
            multiPointWorker.liveController.turn_off_illumination()
            multiPointWorker.navigationController.move_x_usteps(-multiPointWorker.dx_usteps)
            multiPointWorker.wait_till_operation_is_completed()
            multiPointWorker.navigationController.move_y_usteps(-multiPointWorker.dy_usteps)
            multiPointWorker.wait_till_operation_is_completed()
            if multiPointWorker.navigationController.get_pid_control_flag(2) is False:
                _usteps_to_clear_backlash = max(160,20*multiPointWorker.navigationController.z_microstepping)
                multiPointWorker.navigationController.move_z_usteps(-multiPointWorker.dz_usteps-_usteps_to_clear_backlash)
                multiPointWorker.wait_till_operation_is_completed()
                multiPointWorker.navigationController.move_z_usteps(_usteps_to_clear_backlash)
                multiPointWorker.wait_till_operation_is_completed()
            else:
                multiPointWorker.navigationController.move_z_usteps(-multiPointWorker.dz_usteps)
                multiPointWorker.wait_till_operation_is_completed()

            multiPointWorker.coordinates_pd.to_csv(os.path.join(current_path,'coordinates.csv'),index=False,header=True)
            multiPointWorker.navigationController.enable_joystick_button_action = True
            return

        if multiPointWorker.NZ > 1:
            # move z
            if k < multiPointWorker.NZ - 1:
                multiPointWorker.navigationController.move_z_usteps(multiPointWorker.deltaZ_usteps)
                multiPointWorker.wait_till_operation_is_completed()
                time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)
                multiPointWorker.dz_usteps = multiPointWorker.dz_usteps + multiPointWorker.deltaZ_usteps
    
    if multiPointWorker.NZ > 1:
        # move z back
        if Z_STACKING_CONFIG == 'FROM CENTER':
            if multiPointWorker.navigationController.get_pid_control_flag(2) is False:
                _usteps_to_clear_backlash = max(160,20*multiPointWorker.navigationController.z_microstepping)
                multiPointWorker.navigationController.move_z_usteps( -multiPointWorker.deltaZ_usteps*(multiPointWorker.NZ-1) + multiPointWorker.deltaZ_usteps*round((multiPointWorker.NZ-1)/2) - _usteps_to_clear_backlash)
                multiPointWorker.wait_till_operation_is_completed()
                multiPointWorker.navigationController.move_z_usteps(_usteps_to_clear_backlash)
                multiPointWorker.wait_till_operation_is_completed()
            else:
                multiPointWorker.navigationController.move_z_usteps( -multiPointWorker.deltaZ_usteps*(multiPointWorker.NZ-1) + multiPointWorker.deltaZ_usteps*round((multiPointWorker.NZ-1)/2) )
                multiPointWorker.wait_till_operation_is_completed()

            multiPointWorker.dz_usteps = multiPointWorker.dz_usteps - multiPointWorker.deltaZ_usteps*(multiPointWorker.NZ-1) + multiPointWorker.deltaZ_usteps*round((multiPointWorker.NZ-1)/2)
        else:
            if multiPointWorker.navigationController.get_pid_control_flag(2) is False:
                _usteps_to_clear_backlash = max(160,20*multiPointWorker.navigationController.z_microstepping)
                multiPointWorker.navigationController.move_z_usteps(-multiPointWorker.deltaZ_usteps*(multiPointWorker.NZ-1) - _usteps_to_clear_backlash)
                multiPointWorker.wait_till_operation_is_completed()
                multiPointWorker.navigationController.move_z_usteps(_usteps_to_clear_backlash)
                multiPointWorker.wait_till_operation_is_completed()
            else:
                multiPointWorker.navigationController.move_z_usteps(-multiPointWorker.deltaZ_usteps*(multiPointWorker.NZ-1))
                multiPointWorker.wait_till_operation_is_completed()

            multiPointWorker.dz_usteps = multiPointWorker.dz_usteps - multiPointWorker.deltaZ_usteps*(multiPointWorker.NZ-1)

    # update FOV counter
    multiPointWorker.FOV_counter = multiPointWorker.FOV_counter + 1

# set QT_API environment variable
import os 
import sys
import time
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

from control._def import *

# app specific libraries
import control.widgets as widgets
import control.ImSwitch.napariViewerWidget as napariViewerWidget
import serial


if CAMERA_TYPE == "Toupcam":
    try:
        import control.camera_toupcam as camera
    except:
        print("Problem importing Toupcam, defaulting to default camera")
        import control.camera as camera
elif CAMERA_TYPE == "FLIR":
    try:
        import control.camera_flir as camera
    except:
        print("Problem importing FLIR camera, defaulting to default camera")
        import control.camera as camera
else:
    import control.camera as camera

if FOCUS_CAMERA_TYPE == "Toupcam":
    try:
        import control.camera_toupcam as camera_fc
    except:
        print("Problem importing Toupcam for focus, defaulting to default camera")
        import control.camera as camera_fc
elif FOCUS_CAMERA_TYPE == "FLIR":
    try:
        import control.camera_flir as camera_fc
    except:
        print("Problem importing FLIR camera for focus, defaulting to default camera")
        import control.camera as camera_fc
else:
    import control.camera as camera_fc



import control.core as core
import control.microcontroller as microcontroller

import control.serial_peripherals as serial_peripherals

if SUPPORT_LASER_AUTOFOCUS:
    import control.core_displacement_measurement as core_displacement_measurement

import pyqtgraph.dockarea as dock
import time

SINGLE_WINDOW = True # set to False if use separate windows for display and control

class OctopiGUI(QMainWindow):

    # variables
    fps_software_trigger = 100

    def __init__(self, is_simulation = False, *args, **kwargs):
        super().__init__(*args, **kwargs)

        # load objects
        if is_simulation:
            if ENABLE_SPINNING_DISK_CONFOCAL:
                self.xlight = serial_peripherals.XLight_Simulation()
            if ENABLE_NL5:
                import control.NL5 as NL5
                self.nl5 = NL5.NL5_Simulation()
            if ENABLE_CELLX:
                self.cellx = serial_peripherals.CellX_Simulation()
            if SUPPORT_LASER_AUTOFOCUS:
                self.camera_focus = camera_fc.Camera_Simulation()
            self.camera = camera.Camera_Simulation(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
            self.camera.set_pixel_format(DEFAULT_PIXEL_FORMAT)

            if USE_ZABER_EMISSION_FILTER_WHEEL:
                self.emission_filter_wheel = serial_peripherals.FilterController_Simulation(115200, 8, serial.PARITY_NONE, serial.STOPBITS_ONE)

            self.microcontroller = microcontroller.Microcontroller_Simulation()
        else:
            if ENABLE_SPINNING_DISK_CONFOCAL:
                self.xlight = serial_peripherals.XLight(XLIGHT_SERIAL_NUMBER,XLIGHT_SLEEP_TIME_FOR_WHEEL)
            if ENABLE_NL5:
                print('initializing NL5 ...')
                import control.NL5 as NL5
                self.nl5 = NL5.NL5()
                print('NL5 initialized')
            if ENABLE_CELLX:
                print('initializing CellX ...')
                self.cellx = serial_peripherals.CellX(CELLX_SN)
                for channel in [1,2,3,4]:
                    self.cellx.set_modulation(channel,CELLX_MODULATION)
                    self.cellx.turn_on(channel)
                print('CellX initialized')
            if USE_LDI_SERIAL_CONTROL:
                print('initializing LDI ...')
                self.ldi = serial_peripherals.LDI()
                self.ldi.run()
                print('LDI initialized')
            if SUPPORT_LASER_AUTOFOCUS:
                sn_camera_focus = camera_fc.get_sn_by_model(FOCUS_CAMERA_MODEL)
                self.camera_focus = camera_fc.Camera(sn=sn_camera_focus)
                self.camera_focus.open()
                self.camera_focus.set_pixel_format('MONO8')
            sn_camera_main = camera.get_sn_by_model(MAIN_CAMERA_MODEL)
            self.camera = camera.Camera(sn=sn_camera_main,rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
            self.camera.open()
            self.camera.set_pixel_format(DEFAULT_PIXEL_FORMAT) # bug: comment out for confocal?

            if USE_ZABER_EMISSION_FILTER_WHEEL:
                self.emission_filter_wheel = serial_peripherals.FilterController(FILTER_CONTROLLER_SERIAL_NUMBER, 115200, 8, serial.PARITY_NONE, serial.STOPBITS_ONE)

            self.microcontroller = microcontroller.Microcontroller(version=CONTROLLER_VERSION,sn=CONTROLLER_SN)

        if USE_ZABER_EMISSION_FILTER_WHEEL:
            self.emission_filter_wheel.do_homing()

        # reset the MCU
        self.microcontroller.reset()
        time.sleep(0.5)

        # reinitialize motor drivers and DAC (in particular for V2.1 driver board where PG is not functional)
        self.microcontroller.initialize_drivers()
        time.sleep(0.5)

        # configure the actuators
        self.microcontroller.configure_actuators()

        print('load channel_configurations.xml')
        self.configurationManager = core.ConfigurationManager(filename='./channel_configurations.xml')
        self.objectiveStore = core.ObjectiveStore() # todo: add widget to select/save objective save
        self.streamHandler = core.StreamHandler(display_resolution_scaling=DEFAULT_DISPLAY_CROP/100)
        self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager,parent=self)
        self.navigationController = core.NavigationController(self.microcontroller, parent=self)
        self.slidePositionController = core.SlidePositionController(self.navigationController,self.liveController,is_for_wellplate=True)
        self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
        self.scanCoordinates = core.ScanCoordinates()
        self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController,self.configurationManager,scanCoordinates=self.scanCoordinates,parent=self)
        if ENABLE_TRACKING:
            self.trackingController = core.TrackingController(self.camera,self.microcontroller,self.navigationController,self.configurationManager,self.liveController,self.autofocusController,self.imageDisplayWindow)
        self.imageSaver = core.ImageSaver()
        self.imageDisplay = core.ImageDisplay()
        self.navigationViewer = core.NavigationViewer(sample=str(WELLPLATE_FORMAT)+' well plate')

        # retract the objective
        self.navigationController.home_z()
        # wait for the operation to finish
        t0 = time.time()
        while self.microcontroller.is_busy():
            time.sleep(0.005)
            if time.time() - t0 > 10:
                print('z homing timeout, the program will exit')
                sys.exit(1)
        print('objective retracted')

        # set encoder arguments
        # set axis pid control enable
        # only ENABLE_PID_X and HAS_ENCODER_X are both enable, can be enable to PID
        if HAS_ENCODER_X == True:
            self.navigationController.set_axis_PID_arguments(0, PID_P_X, PID_I_X, PID_D_X)
            self.navigationController.configure_encoder(0, (SCREW_PITCH_X_MM * 1000) / ENCODER_RESOLUTION_UM_X, ENCODER_FLIP_DIR_X)
            self.navigationController.set_pid_control_enable(0, ENABLE_PID_X)
        if HAS_ENCODER_Y == True:
            self.navigationController.set_axis_PID_arguments(1, PID_P_Y, PID_I_Y, PID_D_Y)
            self.navigationController.configure_encoder(1, (SCREW_PITCH_Y_MM * 1000) / ENCODER_RESOLUTION_UM_Y, ENCODER_FLIP_DIR_Y)
            self.navigationController.set_pid_control_enable(1, ENABLE_PID_Y)
        if HAS_ENCODER_Z == True:
            self.navigationController.set_axis_PID_arguments(2, PID_P_Z, PID_I_Z, PID_D_Z)
            self.navigationController.configure_encoder(2, (SCREW_PITCH_Z_MM * 1000) / ENCODER_RESOLUTION_UM_Z, ENCODER_FLIP_DIR_Z)
            self.navigationController.set_pid_control_enable(2, ENABLE_PID_Z)
        time.sleep(0.5)

        self.navigationController.set_z_limit_pos_mm(SOFTWARE_POS_LIMIT.Z_POSITIVE)
        self.navigationController.set_z_limit_neg_mm(SOFTWARE_POS_LIMIT.Z_NEGATIVE)

        # home XY, set zero and set software limit
        print('home xy')
        timestamp_start = time.time()
        # x needs to be at > + 20 mm when homing y
        self.navigationController.move_x(20) # to-do: add blocking code
        while self.microcontroller.is_busy():
            time.sleep(0.005)
        # home y
        self.navigationController.home_y()
        t0 = time.time()
        while self.microcontroller.is_busy():
            time.sleep(0.005)
            if time.time() - t0 > 10:
                print('y homing timeout, the program will exit')
                sys.exit(1)
        self.navigationController.zero_y()
        # home x
        self.navigationController.home_x()
        t0 = time.time()
        while self.microcontroller.is_busy():
            time.sleep(0.005)
            if time.time() - t0 > 10:
                print('x homing timeout, the program will exit')
                sys.exit(1)
        self.navigationController.zero_x()
        self.slidePositionController.homing_done = True

        if USE_ZABER_EMISSION_FILTER_WHEEL:
            self.emission_filter_wheel.wait_homing_finish()

        self.navigationController.set_x_limit_pos_mm(SOFTWARE_POS_LIMIT.X_POSITIVE)
        self.navigationController.set_x_limit_neg_mm(SOFTWARE_POS_LIMIT.X_NEGATIVE)
        self.navigationController.set_y_limit_pos_mm(SOFTWARE_POS_LIMIT.Y_POSITIVE)
        self.navigationController.set_y_limit_neg_mm(SOFTWARE_POS_LIMIT.Y_NEGATIVE)
        self.navigationController.set_z_limit_pos_mm(SOFTWARE_POS_LIMIT.Z_POSITIVE)

        # move to scanning position
        self.navigationController.move_x(20)
        while self.microcontroller.is_busy():
            time.sleep(0.005)
        self.navigationController.move_y(20)
        while self.microcontroller.is_busy():
            time.sleep(0.005)

        # set piezo arguments
        if ENABLE_OBJECTIVE_PIEZO is True:
            if OBJECTIVE_PIEZO_CONTROL_VOLTAGE_RANGE == 5:
                OUTPUT_GAINS.CHANNEL7_GAIN = True
            else:
                OUTPUT_GAINS.CHANNEL7_GAIN = False

        # set output's gains
        div = 1 if OUTPUT_GAINS.REFDIV is True else 0
        gains  = OUTPUT_GAINS.CHANNEL0_GAIN << 0 
        gains += OUTPUT_GAINS.CHANNEL1_GAIN << 1 
        gains += OUTPUT_GAINS.CHANNEL2_GAIN << 2 
        gains += OUTPUT_GAINS.CHANNEL3_GAIN << 3 
        gains += OUTPUT_GAINS.CHANNEL4_GAIN << 4 
        gains += OUTPUT_GAINS.CHANNEL5_GAIN << 5 
        gains += OUTPUT_GAINS.CHANNEL6_GAIN << 6 
        gains += OUTPUT_GAINS.CHANNEL7_GAIN << 7 
        self.microcontroller.configure_dac80508_refdiv_and_gain(div, gains)

        # set illumination intensity factor
        global ILLUMINATION_INTENSITY_FACTOR
        self.microcontroller.set_dac80508_scaling_factor_for_illumination(ILLUMINATION_INTENSITY_FACTOR)

        # open the camera
        # camera start streaming
        # self.camera.set_reverse_x(CAMERA_REVERSE_X) # these are not implemented for the cameras in use
        # self.camera.set_reverse_y(CAMERA_REVERSE_Y) # these are not implemented for the cameras in use
        self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
        self.camera.set_callback(self.streamHandler.on_new_frame)
        self.camera.enable_callback()

        # load widgets
        if ENABLE_SPINNING_DISK_CONFOCAL:
            self.spinningDiskConfocalWidget = widgets.SpinningDiskConfocalWidget(self.xlight, self.configurationManager)
        if ENABLE_NL5:
            import control.NL5Widget as NL5Widget
            self.nl5Wdiget = NL5Widget.NL5Widget(self.nl5)

        if CAMERA_TYPE == "Toupcam":
            self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera, include_gain_exposure_time=False, include_camera_temperature_setting = True, include_camera_auto_wb_setting = False)
        else:
            self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera, include_gain_exposure_time=False, include_camera_temperature_setting = False, include_camera_auto_wb_setting = True)
        self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager,show_display_options=True,show_autolevel=True,autolevel=True)
        self.navigationWidget = widgets.NavigationWidget(self.navigationController,self.slidePositionController,widget_configuration='384 well plate')
        self.dacControlWidget = widgets.DACControWidget(self.microcontroller)
        self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
        if USE_ZABER_EMISSION_FILTER_WHEEL:
            self.filterControllerWidget = widgets.FilterControllerWidget(self.emission_filter_wheel, self.liveController)
        self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)
        if ENABLE_TRACKING:
            self.trackingControlWidget = widgets.TrackingControllerWidget(self.trackingController,self.configurationManager,show_configurations=TRACKING_SHOW_MICROSCOPE_CONFIGURATIONS)
        self.multiPointWidget = widgets.MultiPointWidget(self.multipointController,self.configurationManager)
        self.multiPointWidget2 = widgets.MultiPointWidget2(self.navigationController,self.navigationViewer,self.multipointController,self.configurationManager,scanCoordinates=None) # =self.scanCoordinates
        self.piezoWidget = widgets.PiezoWidget(self.navigationController)
        
        if WELLPLATE_FORMAT != 1536:
            self.wellSelectionWidget = widgets.WellSelectionWidget(WELLPLATE_FORMAT)
        else:
            self.wellSelectionWidget = widgets.Well1536SelectionWidget()
        self.scanCoordinates.add_well_selector(self.wellSelectionWidget)

        # image display tabs
        self.imageDisplayTabs = QTabWidget()

        if USE_NAPARI_FOR_LIVE_VIEW:
            self.napariLiveWidget = widgets.NapariLiveWidget(self.configurationManager, self.liveControlWidget)
            self.imageDisplayTabs.addTab(self.napariLiveWidget, "Live View")
        else:
            if ENABLE_TRACKING:
                self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True)
                self.imageDisplayWindow.show_ROI_selector()
            else:
                self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True,show_LUT=True,autoLevels=True)
            self.imageDisplayTabs.addTab(self.imageDisplayWindow.widget, "Live View")

        if USE_NAPARI_FOR_MULTIPOINT:
            self.napariMultiChannelWidget = widgets.NapariMultiChannelWidget(self.configurationManager)
            # self.napariMultiChannelWidget.set_pixel_size_um(3.76*2/60)  
            # ^ for 60x, IMX571, 2x2 binning, to change to using objective and camera config
            self.imageDisplayTabs.addTab(self.napariMultiChannelWidget, "Multichannel Acquisition")
        else:
            self.imageArrayDisplayWindow = core.ImageArrayDisplayWindow()
            self.imageDisplayTabs.addTab(self.imageArrayDisplayWindow.widget, "Multichannel Acquisition")

        if SHOW_TILED_PREVIEW:
            if USE_NAPARI_FOR_TILED_DISPLAY:
                self.napariTiledDisplayWidget = widgets.NapariTiledDisplayWidget(self.configurationManager)
                self.imageDisplayTabs.addTab(self.napariTiledDisplayWidget, "Tiled Preview")
            else:
                self.imageDisplayWindow_scan_preview = core.ImageDisplayWindow(draw_crosshairs=True) 
                self.imageDisplayTabs.addTab(self.imageDisplayWindow_scan_preview.widget, "Tiled Preview")

        # acquisition tabs
        self.recordTabWidget = QTabWidget()
        self.recordTabWidget.addTab(self.multiPointWidget, "Multipoint (Wellplate)")
        if ENABLE_FLEXIBLE_MULTIPOINT:
            self.recordTabWidget.addTab(self.multiPointWidget2, "Flexible Multipoint")
        if ENABLE_SPINNING_DISK_CONFOCAL:
            self.recordTabWidget.addTab(self.spinningDiskConfocalWidget,"Spinning Disk Confocal")
        if ENABLE_TRACKING:
            self.recordTabWidget.addTab(self.trackingControlWidget, "Tracking")
        self.recordTabWidget.addTab(self.recordingControlWidget, "Simple Recording")

        self.microscopeControlTabWidget = QTabWidget()
        self.microscopeControlTabWidget.addTab(self.navigationWidget,"Stages")
        if ENABLE_OBJECTIVE_PIEZO:
            self.microscopeControlTabWidget.addTab(self.piezoWidget,"Piezo")
        self.microscopeControlTabWidget.addTab(self.cameraSettingWidget,'Camera')
        self.microscopeControlTabWidget.addTab(self.autofocusWidget,"Contrast AF")
        if USE_ZABER_EMISSION_FILTER_WHEEL:
            self.microscopeControlTabWidget.addTab(self.filterControllerWidget,"Filter")

        # layout widgets
        layout = QVBoxLayout() #layout = QStackedLayout()
        #layout.addWidget(self.cameraSettingWidget)
        layout.addWidget(self.liveControlWidget)
        layout.addWidget(self.microscopeControlTabWidget)
        if SHOW_DAC_CONTROL:
            layout.addWidget(self.dacControlWidget)
        layout.addWidget(self.recordTabWidget)
        layout.addWidget(self.navigationViewer)
        layout.addStretch()

        # transfer the layout to the central widget
        self.centralWidget = QWidget()
        self.centralWidget.setLayout(layout)
        # self.centralWidget.setFixedSize(self.centralWidget.minimumSize())
        # self.centralWidget.setFixedWidth(self.centralWidget.minimumWidth())
        # self.centralWidget.setMaximumWidth(self.centralWidget.minimumWidth())
        self.centralWidget.setFixedWidth(self.centralWidget.minimumSizeHint().width())

        if SINGLE_WINDOW:
            dock_display = dock.Dock('Image Display', autoOrientation = False)
            dock_display.showTitleBar()
            dock_display.addWidget(self.imageDisplayTabs)
            dock_display.setStretch(x=100,y=100)
            self.dock_wellSelection = dock.Dock('Well Selector', autoOrientation = False)
            self.dock_wellSelection.showTitleBar()
            self.dock_wellSelection.addWidget(self.wellSelectionWidget)
            #self.dock_wellSelection.addWidget(self.wellFormatWidget) # todo: add widget to select wellplate format
            self.dock_wellSelection.setFixedHeight(self.dock_wellSelection.minimumSizeHint().height())
            dock_controlPanel = dock.Dock('Controls', autoOrientation = False)
            # dock_controlPanel.showTitleBar()
            dock_controlPanel.addWidget(self.centralWidget)
            dock_controlPanel.setStretch(x=1,y=None)
            dock_controlPanel.setFixedWidth(dock_controlPanel.minimumSizeHint().width())
            main_dockArea = dock.DockArea()
            main_dockArea.addDock(dock_display)
            main_dockArea.addDock(self.dock_wellSelection,'bottom')
            main_dockArea.addDock(dock_controlPanel,'right')
            self.setCentralWidget(main_dockArea)
            desktopWidget = QDesktopWidget()
            height_min = 0.9*desktopWidget.height()
            width_min = 0.96*desktopWidget.width()
            self.setMinimumSize(int(width_min),int(height_min))
        else:
            self.setCentralWidget(self.centralWidget)
            self.tabbedImageDisplayWindow = QMainWindow()
            self.tabbedImageDisplayWindow.setCentralWidget(self.imageDisplayTabs)
            self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() | Qt.CustomizeWindowHint)
            self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() & ~Qt.WindowCloseButtonHint)
            desktopWidget = QDesktopWidget()
            width = 0.96*desktopWidget.height()
            height = width
            self.tabbedImageDisplayWindow.setFixedSize(width,height)
            self.tabbedImageDisplayWindow.show()

        '''
        try:
            self.cswWindow = widgets.WrapperWindow(self.cameraSettingWidget)
        except AttributeError:
            pass

        try:
            self.cswfcWindow = widgets.WrapperWindow(self.cameraSettingWidget_focus_camera)
        except AttributeError:
            pass
        '''

        # make connections
        self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)          
        self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
        # self.streamHandler.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
        self.navigationController.xPos.connect(lambda x:self.navigationWidget.label_Xpos.setText("{:.2f}".format(x)))
        self.navigationController.yPos.connect(lambda x:self.navigationWidget.label_Ypos.setText("{:.2f}".format(x)))
        self.navigationController.zPos.connect(lambda x:self.navigationWidget.label_Zpos.setText("{:.2f}".format(x)))
        if ENABLE_TRACKING:
            self.navigationController.signal_joystick_button_pressed.connect(self.trackingControlWidget.slot_joystick_button_pressed)
        else:
            self.navigationController.signal_joystick_button_pressed.connect(self.autofocusController.autofocus)

        self.multiPointWidget.signal_acquisition_started.connect(self.navigationWidget.toggle_navigation_controls)
        self.multiPointWidget.signal_acquisition_started.connect(self.toggleAcquisitionStart)
        if ENABLE_FLEXIBLE_MULTIPOINT:
            self.recordTabWidget.currentChanged.connect(self.onTabChanged)
            self.multiPointWidget2.signal_acquisition_started.connect(self.navigationWidget.toggle_navigation_controls)
            self.multiPointWidget2.signal_acquisition_started.connect(self.toggleAcquisitionStart)

        self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
        self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
        self.liveControlWidget.update_camera_settings()

        # load vs scan position switching
        self.slidePositionController.signal_slide_loading_position_reached.connect(self.navigationWidget.slot_slide_loading_position_reached)
        self.slidePositionController.signal_slide_loading_position_reached.connect(self.multiPointWidget.disable_the_start_aquisition_button)
        self.slidePositionController.signal_slide_scanning_position_reached.connect(self.navigationWidget.slot_slide_scanning_position_reached)
        self.slidePositionController.signal_slide_scanning_position_reached.connect(self.multiPointWidget.enable_the_start_aquisition_button)
        self.slidePositionController.signal_clear_slide.connect(self.navigationViewer.clear_slide)

        # display the FOV in the viewer
        self.navigationController.xyPos.connect(self.navigationViewer.update_current_location)
        self.multipointController.signal_register_current_fov.connect(self.navigationViewer.register_fov)
        self.multipointController.signal_current_configuration.connect(self.liveControlWidget.set_microscope_mode)
        self.multipointController.signal_z_piezo_um.connect(self.piezoWidget.update_displacement_um_display)

        if USE_NAPARI_FOR_LIVE_VIEW:
            self.autofocusController.image_to_display.connect(lambda image: self.napariLiveWidget.updateLiveLayer(image, from_autofocus=True))
            self.streamHandler.image_to_display.connect(lambda image: self.napariLiveWidget.updateLiveLayer(image, from_autofocus=False))
            self.multipointController.image_to_display.connect(lambda image: self.napariLiveWidget.updateLiveLayer(image, from_autofocus=False))
            self.napariLiveWidget.signal_coordinates_clicked.connect(self.navigationController.move_from_click)
        else:
            self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
            self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
            self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
            self.multipointController.image_to_display.connect(self.imageDisplayWindow.display_image)
            self.liveControlWidget.signal_autoLevelSetting.connect(self.imageDisplayWindow.set_autolevel) # todo: replicate for napari (autolevel)
            self.imageDisplayWindow.image_click_coordinates.connect(self.navigationController.move_from_click)
        
        if USE_NAPARI_FOR_MULTIPOINT:    
            self.multiPointWidget.signal_acquisition_channels.connect(self.napariMultiChannelWidget.initChannels)
            self.multiPointWidget.signal_acquisition_shape.connect(self.napariMultiChannelWidget.initLayersShape)
            if ENABLE_FLEXIBLE_MULTIPOINT:
                self.multiPointWidget2.signal_acquisition_channels.connect(self.napariMultiChannelWidget.initChannels)
                self.multiPointWidget2.signal_acquisition_shape.connect(self.napariMultiChannelWidget.initLayersShape)
            self.multipointController.napari_layers_init.connect(self.napariMultiChannelWidget.initLayers)
            self.multipointController.napari_layers_update.connect(self.napariMultiChannelWidget.updateLayers)
            if USE_NAPARI_FOR_LIVE_VIEW:
                self.napariMultiChannelWidget.signal_layer_contrast_limits.connect(self.napariLiveWidget.saveContrastLimits)
                self.napariLiveWidget.signal_layer_contrast_limits.connect(self.napariMultiChannelWidget.saveContrastLimits)
        else:
            self.multipointController.image_to_display_multi.connect(self.imageArrayDisplayWindow.display_image)

        if SHOW_TILED_PREVIEW:
            if USE_NAPARI_FOR_TILED_DISPLAY:
                self.multiPointWidget.signal_acquisition_channels.connect(self.napariTiledDisplayWidget.initChannels)
                self.multiPointWidget.signal_acquisition_shape.connect(self.napariTiledDisplayWidget.initLayersShape)
                if ENABLE_FLEXIBLE_MULTIPOINT:
                    self.multiPointWidget2.signal_acquisition_channels.connect(self.napariTiledDisplayWidget.initChannels)
                    self.multiPointWidget2.signal_acquisition_shape.connect(self.napariTiledDisplayWidget.initLayersShape)
                self.multipointController.napari_layers_init.connect(self.napariTiledDisplayWidget.initLayers)
                self.multipointController.napari_layers_update.connect(self.napariTiledDisplayWidget.updateLayers)
                self.napariTiledDisplayWidget.signal_coordinates_clicked.connect(self.navigationController.scan_preview_move_from_click)
                if USE_NAPARI_FOR_LIVE_VIEW:
                    self.napariTiledDisplayWidget.signal_layer_contrast_limits.connect(self.napariLiveWidget.saveContrastLimits)
                    self.napariLiveWidget.signal_layer_contrast_limits.connect(self.napariTiledDisplayWidget.saveContrastLimits)
                if USE_NAPARI_FOR_MULTIPOINT:
                    self.napariTiledDisplayWidget.signal_layer_contrast_limits.connect(self.napariMultiChannelWidget.saveContrastLimits)
                    self.napariMultiChannelWidget.signal_layer_contrast_limits.connect(self.napariTiledDisplayWidget.saveContrastLimits)
            else:
                self.multipointController.image_to_display_tiled_preview.connect(self.imageDisplayWindow_scan_preview.display_image)
                self.imageDisplayWindow_scan_preview.image_click_coordinates.connect(self.navigationController.scan_preview_move_from_click)

        # (double) click to move to a well
        self.wellSelectionWidget.signal_wellSelectedPos.connect(self.navigationController.move_to)
        self.wellSelectionWidget.signal_wellSelected.connect(self.multiPointWidget.set_well_selected)

        # camera
        self.camera.set_callback(self.streamHandler.on_new_frame)

        # laser autofocus
        if SUPPORT_LASER_AUTOFOCUS:

            # controllers
            self.configurationManager_focus_camera = core.ConfigurationManager(filename='./focus_camera_configurations.xml')
            self.streamHandler_focus_camera = core.StreamHandler()
            self.liveController_focus_camera = core.LiveController(self.camera_focus,self.microcontroller,self.configurationManager_focus_camera,self,control_illumination=False,for_displacement_measurement=True)
            self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController,self.configurationManager,scanCoordinates=self.scanCoordinates,parent=self)
            self.imageDisplayWindow_focus = core.ImageDisplayWindow(draw_crosshairs=True)
            self.displacementMeasurementController = core_displacement_measurement.DisplacementMeasurementController()
            self.laserAutofocusController = core.LaserAutofocusController(self.microcontroller,self.camera_focus,self.liveController_focus_camera,self.navigationController,has_two_interfaces=HAS_TWO_INTERFACES,use_glass_top=USE_GLASS_TOP,look_for_cache=False)

            # camera
            self.camera_focus.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
            self.camera_focus.set_callback(self.streamHandler_focus_camera.on_new_frame)
            self.camera_focus.enable_callback()
            self.camera_focus.start_streaming()

            # widgets
            if FOCUS_CAMERA_TYPE == "Toupcam":
                self.cameraSettingWidget_focus_camera = widgets.CameraSettingsWidget(self.camera_focus, include_gain_exposure_time = False, include_camera_temperature_setting = True, include_camera_auto_wb_setting = False)
            else:
                self.cameraSettingWidget_focus_camera = widgets.CameraSettingsWidget(self.camera_focus, include_gain_exposure_time = False, include_camera_temperature_setting = False, include_camera_auto_wb_setting = True)

            self.liveControlWidget_focus_camera = widgets.LiveControlWidget(self.streamHandler_focus_camera,self.liveController_focus_camera,self.configurationManager_focus_camera,show_display_options=True)
            self.waveformDisplay = widgets.WaveformDisplay(N=1000,include_x=True,include_y=False)
            self.displacementMeasurementWidget = widgets.DisplacementMeasurementWidget(self.displacementMeasurementController,self.waveformDisplay)
            self.laserAutofocusControlWidget = widgets.LaserAutofocusControlWidget(self.laserAutofocusController)

            self.microscopeControlTabWidget.addTab(self.laserAutofocusControlWidget, "Laser AF")

            dock_laserfocus_image_display = dock.Dock('Focus Camera Image Display', autoOrientation = False)
            dock_laserfocus_image_display.showTitleBar()
            dock_laserfocus_image_display.addWidget(self.imageDisplayWindow_focus.widget)
            dock_laserfocus_image_display.setStretch(x=100,y=100)

            dock_laserfocus_liveController = dock.Dock('Focus Camera Controller', autoOrientation = False)
            dock_laserfocus_liveController.showTitleBar()
            dock_laserfocus_liveController.addWidget(self.liveControlWidget_focus_camera)
            dock_laserfocus_liveController.setStretch(x=100,y=100)
            # dock_laserfocus_liveController.setFixedHeight(self.liveControlWidget_focus_camera.minimumSizeHint().height())
            dock_laserfocus_liveController.setFixedWidth(self.liveControlWidget_focus_camera.minimumSizeHint().width())

            dock_waveform = dock.Dock('Displacement Measurement', autoOrientation = False)
            dock_waveform.showTitleBar()
            dock_waveform.addWidget(self.waveformDisplay)
            dock_waveform.setStretch(x=100,y=40)

            dock_displayMeasurement =  dock.Dock('Displacement Measurement Control', autoOrientation = False)
            dock_displayMeasurement.showTitleBar()
            dock_displayMeasurement.addWidget(self.displacementMeasurementWidget)
            dock_displayMeasurement.setStretch(x=100,y=40)
            dock_displayMeasurement.setFixedWidth(self.displacementMeasurementWidget.minimumSizeHint().width())

            laserfocus_dockArea = dock.DockArea()
            laserfocus_dockArea.addDock(dock_laserfocus_image_display)
            laserfocus_dockArea.addDock(dock_laserfocus_liveController,'right',relativeTo=dock_laserfocus_image_display)
            if SHOW_LEGACY_DISPLACEMENT_MEASUREMENT_WINDOWS:
                laserfocus_dockArea.addDock(dock_waveform,'bottom',relativeTo=dock_laserfocus_liveController)
                laserfocus_dockArea.addDock(dock_displayMeasurement,'bottom',relativeTo=dock_waveform)

            self.imageDisplayTabs.addTab(laserfocus_dockArea,"Laser-Based Focus")

            # connections
            self.liveControlWidget_focus_camera.signal_newExposureTime.connect(self.cameraSettingWidget_focus_camera.set_exposure_time)
            self.liveControlWidget_focus_camera.signal_newAnalogGain.connect(self.cameraSettingWidget_focus_camera.set_analog_gain)
            self.liveControlWidget_focus_camera.update_camera_settings()

            self.streamHandler_focus_camera.signal_new_frame_received.connect(self.liveController_focus_camera.on_new_frame)
            self.streamHandler_focus_camera.image_to_display.connect(self.imageDisplayWindow_focus.display_image)

            self.streamHandler_focus_camera.image_to_display.connect(self.displacementMeasurementController.update_measurement)
            self.displacementMeasurementController.signal_plots.connect(self.waveformDisplay.plot)
            self.displacementMeasurementController.signal_readings.connect(self.displacementMeasurementWidget.display_readings)
            self.laserAutofocusController.image_to_display.connect(self.imageDisplayWindow_focus.display_image)

        # widget for confocal
        if ENABLE_SPINNING_DISK_CONFOCAL:
                self.microscopeControlTabWidget.addTab(self.spinningDiskConfocalWidget,"Confocal")
        if ENABLE_NL5:
            self.microscopeControlTabWidget.addTab(self.nl5Wdiget,"Confocal")

        self.navigationController.move_to_cached_position()

        # Create the menu bar
        menubar = self.menuBar()
        # Add the "Settings" menu
        settings_menu = menubar.addMenu("Settings")
        if SUPPORT_SCIMICROSCOPY_LED_ARRAY:
            # Add the "LED Matrix" action
            led_matrix_action = QAction("LED Matrix", self)
            led_matrix_action.triggered.connect(self.openLedMatrixSettings)
            settings_menu.addAction(led_matrix_action)

    def openLedMatrixSettings(self):
        if SUPPORT_SCIMICROSCOPY_LED_ARRAY:
            dialog = widgets.LedMatrixSettingsDialog(self.liveController.led_array) # to move led_arry outside liveController
            dialog.exec_()

    def onTabChanged(self, index):
        acquisitionWidget = self.recordTabWidget.widget(index)
        self.toggleWellSelector(index)
        acquisitionWidget.emit_selected_channels()

    def toggleWellSelector(self, close):
        self.dock_wellSelection.setVisible(not close)

    def toggleAcquisitionStart(self, acquisition_started):
        current_index = self.recordTabWidget.currentIndex()
        for index in range(self.recordTabWidget.count()):
            self.recordTabWidget.setTabEnabled(index, not acquisition_started or index == current_index)
        if current_index == 0:
            self.dock_wellSelection.setVisible(not acquisition_started)

    def closeEvent(self, event):
        self.navigationController.cache_current_position()

        if USE_ZABER_EMISSION_FILTER_WHEEL:
            self.emission_filter_wheel.set_emission_filter('1')

        # move the objective to a defined position upon exit
        self.navigationController.move_x(0.1) # temporary bug fix - move_x needs to be called before move_x_to if the stage has been moved by the joystick
        while self.microcontroller.is_busy():
            time.sleep(0.005)
        self.navigationController.move_x_to(30)
        while self.microcontroller.is_busy():
            time.sleep(0.005)
        self.navigationController.move_y(0.1) # temporary bug fix - move_y needs to be called before move_y_to if the stage has been moved by the joystick
        while self.microcontroller.is_busy():
            time.sleep(0.005)
        self.navigationController.move_y_to(30)
        while self.microcontroller.is_busy():
            time.sleep(0.005)

        self.navigationController.turnoff_axis_pid_control()

        self.liveController.stop_live()
        self.camera.stop_streaming()
        self.camera.close()
        if ENABLE_CELLX:
            for channel in [1,2,3,4]:
                self.cellx.turn_off(channel)
            self.cellx.close()

        self.imageSaver.close()
        self.imageDisplay.close()
        if not SINGLE_WINDOW:
            self.imageDisplayWindow.close()
            self.imageArrayDisplayWindow.close()
            self.tabbedImageDisplayWindow.close()
        if SUPPORT_LASER_AUTOFOCUS:
            self.liveController_focus_camera.stop_live()
            self.camera_focus.close()
            self.imageDisplayWindow_focus.close()
        self.microcontroller.close()

        try:
            self.cswWindow.closeForReal(event)
        except AttributeError:
            pass

        try:
            self.cswfcWindow.closeForReal(event)
        except AttributeError:
            pass

        event.accept()

import os
import sys
import glob
import numpy as np
from pathlib import Path
from configparser import ConfigParser
import json

def conf_attribute_reader(string_value):
    """
    :brief: standardized way for reading config entries
    that are strings, in priority order
    None -> bool -> dict/list (via json) -> int -> float -> string
    REMEMBER TO ENCLOSE PROPERTY NAMES IN LISTS/DICTS IN
    DOUBLE QUOTES
    """
    actualvalue = str(string_value).strip()
    try:
        if str(actualvalue) == "None":
            return None
    except:
        pass
    try:
        if str(actualvalue) == "True" or str(actualvalue) == "true":
            return True
        if str(actualvalue) == "False" or str(actualvalue) == "false":
            return False
    except:
        pass
    try:
        actualvalue = json.loads(actualvalue)
    except:
        try:
            actualvalue = int(str(actualvalue))
        except:
            try:
                actualvalue = float(actualvalue)
            except:
                actualvalue = str(actualvalue)
    return actualvalue


def populate_class_from_dict(myclass, options):
    """
    :brief: helper function to establish a compatibility
        layer between new way of storing config and current
        way of accessing it. assumes all class attributes are
        all-uppercase, and pattern-matches attributes in
        priority order dict/list (json) -> -> int -> float-> string
    REMEMBER TO ENCLOSE PROPERTY NAMES IN LISTS IN DOUBLE QUOTES
    """
    for key, value in options:
        if key.startswith('_') and key.endswith('options'):
            continue
        actualkey = key.upper()
        actualvalue = conf_attribute_reader(value)
        setattr(myclass, actualkey, actualvalue)

class TriggerMode:
    SOFTWARE = 'Software Trigger'
    HARDWARE = 'Hardware Trigger'
    CONTINUOUS = 'Continuous Acqusition'

class Acquisition:
    CROP_WIDTH = 3000
    CROP_HEIGHT = 3000
    NUMBER_OF_FOVS_PER_AF = 3
    IMAGE_FORMAT = 'bmp'
    IMAGE_DISPLAY_SCALING_FACTOR = 0.3
    DX = 0.9
    DY = 0.9
    DZ = 1.5
    NX = 1
    NY = 1

class PosUpdate:
    INTERVAL_MS = 25

class MicrocontrollerDef:
    MSG_LENGTH = 24
    CMD_LENGTH = 8
    N_BYTES_POS = 4

class Microcontroller2Def:
    MSG_LENGTH = 4
    CMD_LENGTH = 8
    N_BYTES_POS = 4

USE_SEPARATE_MCU_FOR_DAC = False

class MCU_PINS:
    PWM1 = 5
    PWM2 = 4
    PWM3 = 22
    PWM4 = 3
    PWM5 = 23
    PWM6 = 2
    PWM7 = 1
    PWM9 = 6
    PWM10 = 7
    PWM11 = 8
    PWM12 = 9
    PWM13 = 10
    PWM14 = 15
    PWM15 = 24
    PWM16 = 25
    AF_LASER = 15

class CMD_SET:
    MOVE_X = 0
    MOVE_Y = 1
    MOVE_Z = 2
    MOVE_THETA = 3
    HOME_OR_ZERO = 5
    TURN_ON_ILLUMINATION = 10
    TURN_OFF_ILLUMINATION = 11
    SET_ILLUMINATION = 12
    SET_ILLUMINATION_LED_MATRIX = 13
    ACK_JOYSTICK_BUTTON_PRESSED = 14
    ANALOG_WRITE_ONBOARD_DAC = 15
    SET_DAC80508_REFDIV_GAIN = 16
    SET_ILLUMINATION_INTENSITY_FACTOR = 17
    MOVETO_X = 6
    MOVETO_Y = 7
    MOVETO_Z = 8
    SET_LIM = 9
    SET_LIM_SWITCH_POLARITY = 20
    CONFIGURE_STEPPER_DRIVER = 21
    SET_MAX_VELOCITY_ACCELERATION = 22
    SET_LEAD_SCREW_PITCH = 23
    SET_OFFSET_VELOCITY = 24
    CONFIGURE_STAGE_PID = 25
    ENABLE_STAGE_PID = 26
    DISABLE_STAGE_PID = 27
    SET_HOME_SAFETY_MERGIN = 28
    SET_PID_ARGUMENTS = 29
    SEND_HARDWARE_TRIGGER = 30
    SET_STROBE_DELAY = 31
    SET_PIN_LEVEL = 41
    INITIALIZE = 254
    RESET = 255

class CMD_SET2:
    ANALOG_WRITE_DAC8050X = 0
    SET_CAMERA_TRIGGER_FREQUENCY = 1
    START_CAMERA_TRIGGERING = 2
    STOP_CAMERA_TRIGGERING = 3

BIT_POS_JOYSTICK_BUTTON = 0
BIT_POS_SWITCH = 1

class HOME_OR_ZERO:
    HOME_NEGATIVE = 1 # motor moves along the negative direction (MCU coordinates)
    HOME_POSITIVE = 0 # motor moves along the negative direction (MCU coordinates)
    ZERO = 2

class AXIS:
    X = 0
    Y = 1
    Z = 2
    THETA = 3
    XY = 4

class LIMIT_CODE:
    X_POSITIVE = 0
    X_NEGATIVE = 1
    Y_POSITIVE = 2
    Y_NEGATIVE = 3
    Z_POSITIVE = 4
    Z_NEGATIVE = 5

class LIMIT_SWITCH_POLARITY:
    ACTIVE_LOW = 0
    ACTIVE_HIGH = 1
    DISABLED = 2
    X_HOME= 1
    Y_HOME= 1
    Z_HOME= 2


class ILLUMINATION_CODE:
    ILLUMINATION_SOURCE_LED_ARRAY_FULL = 0;
    ILLUMINATION_SOURCE_LED_ARRAY_LEFT_HALF = 1
    ILLUMINATION_SOURCE_LED_ARRAY_RIGHT_HALF = 2
    ILLUMINATION_SOURCE_LED_ARRAY_LEFTB_RIGHTR = 3
    ILLUMINATION_SOURCE_LED_ARRAY_LOW_NA = 4;
    ILLUMINATION_SOURCE_LED_ARRAY_LEFT_DOT = 5;
    ILLUMINATION_SOURCE_LED_ARRAY_RIGHT_DOT = 6;
    ILLUMINATION_SOURCE_LED_EXTERNAL_FET = 20
    ILLUMINATION_SOURCE_405NM = 11
    ILLUMINATION_SOURCE_488NM = 12
    ILLUMINATION_SOURCE_638NM = 13
    ILLUMINATION_SOURCE_561NM = 14
    ILLUMINATION_SOURCE_730NM = 15

class VOLUMETRIC_IMAGING:
    NUM_PLANES_PER_VOLUME = 20

class CMD_EXECUTION_STATUS:
    COMPLETED_WITHOUT_ERRORS = 0
    IN_PROGRESS = 1
    CMD_CHECKSUM_ERROR = 2
    CMD_INVALID = 3
    CMD_EXECUTION_ERROR = 4
    ERROR_CODE_EMPTYING_THE_FLUDIIC_LINE_FAILED = 100

class CAMERA_CONFIG:
    ROI_OFFSET_X_DEFAULT = 0
    ROI_OFFSET_Y_DEFAULT = 0
    ROI_WIDTH_DEFAULT = 3104
    ROI_HEIGHT_DEFAULT = 2084

###########################################################
#### machine specific configurations - to be overridden ###
###########################################################
ROTATE_IMAGE_ANGLE = None
FLIP_IMAGE = None # 'Horizontal', 'Vertical', 'Both'

CAMERA_REVERSE_X = False
CAMERA_REVERSE_Y = False

DEFAULT_TRIGGER_MODE = TriggerMode.SOFTWARE

# note: XY are the in-plane axes, Z is the focus axis

# change the following so that "backward" is "backward" - towards the single sided hall effect sensor
STAGE_MOVEMENT_SIGN_X = -1
STAGE_MOVEMENT_SIGN_Y = 1
STAGE_MOVEMENT_SIGN_Z = -1
STAGE_MOVEMENT_SIGN_THETA = 1

STAGE_POS_SIGN_X = STAGE_MOVEMENT_SIGN_X
STAGE_POS_SIGN_Y = STAGE_MOVEMENT_SIGN_Y
STAGE_POS_SIGN_Z = STAGE_MOVEMENT_SIGN_Z
STAGE_POS_SIGN_THETA = STAGE_MOVEMENT_SIGN_THETA

TRACKING_MOVEMENT_SIGN_X = 1
TRACKING_MOVEMENT_SIGN_Y = 1
TRACKING_MOVEMENT_SIGN_Z = 1
TRACKING_MOVEMENT_SIGN_THETA = 1

USE_ENCODER_X = False
USE_ENCODER_Y = False
USE_ENCODER_Z = False
USE_ENCODER_THETA = False

ENCODER_POS_SIGN_X = 1
ENCODER_POS_SIGN_Y = 1
ENCODER_POS_SIGN_Z = 1
ENCODER_POS_SIGN_THETA = 1

ENCODER_STEP_SIZE_X_MM = 100e-6
ENCODER_STEP_SIZE_Y_MM = 100e-6
ENCODER_STEP_SIZE_Z_MM = 100e-6
ENCODER_STEP_SIZE_THETA = 1

FULLSTEPS_PER_REV_X = 200
FULLSTEPS_PER_REV_Y = 200
FULLSTEPS_PER_REV_Z = 200
FULLSTEPS_PER_REV_THETA = 200

# beginning of actuator specific configurations

SCREW_PITCH_X_MM = 1
SCREW_PITCH_Y_MM = 1
SCREW_PITCH_Z_MM = 0.012*25.4

MICROSTEPPING_DEFAULT_X = 8
MICROSTEPPING_DEFAULT_Y = 8
MICROSTEPPING_DEFAULT_Z = 8
MICROSTEPPING_DEFAULT_THETA = 8 # not used, to be removed

X_MOTOR_RMS_CURRENT_mA = 490
Y_MOTOR_RMS_CURRENT_mA = 490
Z_MOTOR_RMS_CURRENT_mA = 490

X_MOTOR_I_HOLD = 0.5
Y_MOTOR_I_HOLD = 0.5
Z_MOTOR_I_HOLD = 0.5

MAX_VELOCITY_X_mm = 25
MAX_VELOCITY_Y_mm = 25
MAX_VELOCITY_Z_mm = 2

MAX_ACCELERATION_X_mm = 500
MAX_ACCELERATION_Y_mm = 500
MAX_ACCELERATION_Z_mm = 20

# config encoder arguments
HAS_ENCODER_X = False
HAS_ENCODER_Y = False
HAS_ENCODER_Z = False

# enable PID control
ENABLE_PID_X  = False
ENABLE_PID_Y  = False
ENABLE_PID_Z  = False

# PID arguments
PID_P_X = int(1<<12)
PID_I_X = int(0)
PID_D_X = int(0)

PID_P_Y = int(1<<12)
PID_I_Y = int(0)
PID_D_Y = int(0)

PID_P_Z = int(1<<12)
PID_I_Z = int(0)
PID_D_Z = int(1)

# flip direction True or False
ENCODER_FLIP_DIR_X = True
ENCODER_FLIP_DIR_Y = True
ENCODER_FLIP_DIR_Z = True

# distance for each count (um)
ENCODER_RESOLUTION_UM_X = 0.05
ENCODER_RESOLUTION_UM_Y = 0.05
ENCODER_RESOLUTION_UM_Z = 0.1

# end of actuator specific configurations

SCAN_STABILIZATION_TIME_MS_X = 160
SCAN_STABILIZATION_TIME_MS_Y = 160
SCAN_STABILIZATION_TIME_MS_Z = 20
HOMING_ENABLED_X = True
HOMING_ENABLED_Y = True
HOMING_ENABLED_Z = False

SLEEP_TIME_S = 0.005

LED_MATRIX_R_FACTOR = 0
LED_MATRIX_G_FACTOR = 0
LED_MATRIX_B_FACTOR = 1

DEFAULT_SAVING_PATH = str(Path.home()) + "/Downloads"

DEFAULT_PIXEL_FORMAT = 'MONO12'

class PLATE_READER:
    NUMBER_OF_ROWS = 8
    NUMBER_OF_COLUMNS = 12
    ROW_SPACING_MM = 9
    COLUMN_SPACING_MM = 9
    OFFSET_COLUMN_1_MM = 20
    OFFSET_ROW_A_MM = 20

DEFAULT_DISPLAY_CROP = 100 # value ranges from 1 to 100 - image display crop size 

CAMERA_PIXEL_SIZE_UM = {'IMX290':2.9,'IMX178':2.4,'IMX226':1.85,'IMX250':3.45,'IMX252':3.45,'IMX273':3.45,'IMX264':3.45,'IMX265':3.45,'IMX571':3.76,'PYTHON300':4.8}
OBJECTIVES = {'2x':{'magnification':2, 'NA':0.10, 'tube_lens_f_mm':180}, 
                '4x':{'magnification':4, 'NA':0.13, 'tube_lens_f_mm':180}, 
                '10x':{'magnification':10, 'NA':0.25, 'tube_lens_f_mm':180}, 
                '10x (Mitutoyo)':{'magnification':10, 'NA':0.25, 'tube_lens_f_mm':200},
                '20x (Boli)':{'magnification':20, 'NA':0.4, 'tube_lens_f_mm':180}, 
                '20x (Nikon)':{'magnification':20, 'NA':0.45, 'tube_lens_f_mm':200},
                '20x':{'magnification':20, 'NA':0.4, 'tube_lens_f_mm':180}, 
                '40x':{'magnification':40, 'NA':0.6, 'tube_lens_f_mm':180}}
TUBE_LENS_MM = 50
CAMERA_SENSOR = 'IMX226'
DEFAULT_OBJECTIVE = '10x (Mitutoyo)'
TRACKERS = ['csrt', 'kcf', 'mil', 'tld', 'medianflow','mosse','daSiamRPN']
DEFAULT_TRACKER = 'csrt'

ENABLE_TRACKING = False
TRACKING_SHOW_MICROSCOPE_CONFIGURATIONS = False # set to true when doing multimodal acquisition
if ENABLE_TRACKING:
    DEFAULT_DISPLAY_CROP = 100

class AF:
    STOP_THRESHOLD = 0.85
    CROP_WIDTH = 800
    CROP_HEIGHT = 800

class Tracking:
    SEARCH_AREA_RATIO = 10 #@@@ check
    CROPPED_IMG_RATIO = 10 #@@@ check
    BBOX_SCALE_FACTOR = 1.2
    DEFAULT_TRACKER = "csrt"
    INIT_METHODS = ["roi"]
    DEFAULT_INIT_METHOD = "roi"

SHOW_DAC_CONTROL = False

class SLIDE_POSITION:
    LOADING_X_MM = 30
    LOADING_Y_MM = 55
    SCANNING_X_MM = 3
    SCANNING_Y_MM = 3

class OUTPUT_GAINS:
    REFDIV = False
    CHANNEL0_GAIN = False
    CHANNEL1_GAIN = False
    CHANNEL2_GAIN = False
    CHANNEL3_GAIN = False
    CHANNEL4_GAIN = False
    CHANNEL5_GAIN = False
    CHANNEL6_GAIN = False
    CHANNEL7_GAIN = True

SLIDE_POTISION_SWITCHING_TIMEOUT_LIMIT_S = 10
SLIDE_POTISION_SWITCHING_HOME_EVERYTIME = False

class SOFTWARE_POS_LIMIT:
    X_POSITIVE = 56
    X_NEGATIVE = -0.5
    Y_POSITIVE = 56
    Y_NEGATIVE = -0.5
    Z_POSITIVE = 6
    Z_NEGATIVE = 0.05

SHOW_AUTOLEVEL_BTN = False
AUTOLEVEL_DEFAULT_SETTING = False

MULTIPOINT_AUTOFOCUS_CHANNEL = 'BF LED matrix full'
# MULTIPOINT_AUTOFOCUS_CHANNEL = 'BF LED matrix left half'
MULTIPOINT_AUTOFOCUS_ENABLE_BY_DEFAULT = True
MULTIPOINT_BF_SAVING_OPTION = 'Raw'
# MULTIPOINT_BF_SAVING_OPTION = 'RGB2GRAY'
# MULTIPOINT_BF_SAVING_OPTION = 'Green Channel Only'

DEFAULT_MULTIPOINT_NX=1
DEFAULT_MULTIPOINT_NY=1

ENABLE_FLEXIBLE_MULTIPOINT = False

CAMERA_SN = {'ch 1':'SN1','ch 2': 'SN2'} # for multiple cameras, to be overwritten in the configuration file

ENABLE_STROBE_OUTPUT = False

Z_STACKING_CONFIG = 'FROM BOTTOM' # 'FROM BOTTOM', 'FROM TOP'

# plate format
WELLPLATE_FORMAT = 384

# for 384 well plate
DEFAULT_Z_POS_MM = 2
NUMBER_OF_SKIP_384 = 1
A1_X_MM_384_WELLPLATE = 12.05
A1_Y_MM_384_WELLPLATE = 9.05
WELL_SPACING_MM_384_WELLPLATE = 4.5
WELL_SIZE_MM_384_WELLPLATE = 3.3
# B1 upper left corner in piexel: x = 124, y = 141
# B1 upper left corner in mm: x = 12.13 mm - 3.3 mm/2, y = 8.99 mm + 4.5 mm - 3.3 mm/2
# B2 upper left corner in pixel: x = 177, y = 141

WELLPLATE_OFFSET_X_mm = 0 # x offset adjustment for using different plates
WELLPLATE_OFFSET_Y_mm = 0 # y offset adjustment for using different plates

# for USB spectrometer
N_SPECTRUM_PER_POINT = 5

# focus measure operator
FOCUS_MEASURE_OPERATOR = 'LAPE' # 'GLVA' # LAPE has worked well for bright field images; GLVA works well for darkfield/fluorescence

# controller version
CONTROLLER_VERSION = 'Arduino Due' # 'Teensy'

#How to read Spinnaker nodemaps, options are INDIVIDUAL or VALUE
CHOSEN_READ = 'INDIVIDUAL'

# laser autofocus
SUPPORT_LASER_AUTOFOCUS = False
MAIN_CAMERA_MODEL = 'MER2-1220-32U3M'
FOCUS_CAMERA_MODEL = 'MER2-630-60U3M'
FOCUS_CAMERA_EXPOSURE_TIME_MS = 2
FOCUS_CAMERA_ANALOG_GAIN = 0
LASER_AF_AVERAGING_N = 5
LASER_AF_DISPLAY_SPOT_IMAGE = True
LASER_AF_CROP_WIDTH = 1536
LASER_AF_CROP_HEIGHT = 256
HAS_TWO_INTERFACES = True
USE_GLASS_TOP = True
SHOW_LEGACY_DISPLACEMENT_MEASUREMENT_WINDOWS = False

MULTIPOINT_REFLECTION_AUTOFOCUS_ENABLE_BY_DEFAULT = False

RUN_CUSTOM_MULTIPOINT = False

RETRACT_OBJECTIVE_BEFORE_MOVING_TO_LOADING_POSITION = True
OBJECTIVE_RETRACTED_POS_MM = 0.1

CLASSIFICATION_MODEL_PATH ="/home/cephla/Documents/tmp/model_perf_r34_b32.pt"
SEGMENTATION_MODEL_PATH = "/home/cephla/Documents/tmp/model_segmentation_1073_9.pth"
CLASSIFICATION_TEST_MODE=False

USE_TRT_SEGMENTATION=False
SEGMENTATION_CROP=1500

DISP_TH_DURING_MULTIPOINT=0.95
SORT_DURING_MULTIPOINT = False

DO_FLUORESCENCE_RTP = False

ENABLE_SPINNING_DISK_CONFOCAL=False

INVERTED_OBJECTIVE = False

ILLUMINATION_INTENSITY_FACTOR = 0.6

CAMERA_TYPE="Default"

FOCUS_CAMERA_TYPE="Default"

# Spinning disk confocal integration
ENABLE_SPINNING_DISK_CONFOCAL = False
USE_LDI_SERIAL_CONTROL = False

XLIGHT_EMISSION_FILTER_MAPPING = {405:1,470:2,555:3,640:4,730:5}
XLIGHT_SERIAL_NUMBER = "B00031BE"
XLIGHT_SLEEP_TIME_FOR_WHEEL = 0.25
XLIGHT_VALIDATE_WHEEL_POS = False

# Confocal.nl NL5 integration
ENABLE_NL5 = False
ENABLE_CELLX = False
CELLX_SN = None
CELLX_MODULATION = 'EXT Digital'
NL5_USE_AOUT = False
NL5_USE_DOUT = True
NL5_TRIGGER_PIN = 2
NL5_WAVENLENGTH_MAP = {
    405: 1,
    470: 2, 488: 2,
    545: 3, 555: 3, 561: 3,
    637: 4, 638: 4, 640: 4
}

# Laser AF characterization mode
LASER_AF_CHARACTERIZATION_MODE=False

# Napari integration
USE_NAPARI_FOR_LIVE_VIEW = False
USE_NAPARI_FOR_MULTIPOINT = True
USE_NAPARI_FOR_TILED_DISPLAY = True

# Controller SN (needed when using multiple teensy-based connections)
CONTROLLER_SN = None

# Sci microscopy
SUPPORT_SCIMICROSCOPY_LED_ARRAY = False
SCIMICROSCOPY_LED_ARRAY_SN = None
SCIMICROSCOPY_LED_ARRAY_DISTANCE = 50
SCIMICROSCOPY_LED_ARRAY_DEFAULT_NA = 0.8
SCIMICROSCOPY_LED_ARRAY_DEFAULT_COLOR = [1,1,1]
SCIMICROSCOPY_LED_ARRAY_TURN_ON_DELAY = 0.03 # time to wait before trigger the camera (in seconds)

# Tiled preview
SHOW_TILED_PREVIEW = True
PRVIEW_DOWNSAMPLE_FACTOR = 5

# Stitcher
ENABLE_STITCHER = False
IS_HCS = True
FULL_REGISTRATION = False
STITCH_COMPLETE_ACQUISITION = False
CHANNEL_COLORS_MAP = {
    '405':      {'hex': 0x3300FF, 'name': 'blue'},
    '488':      {'hex': 0x1FFF00, 'name': 'green'},
    '561':      {'hex': 0xFFCF00, 'name': 'yellow'},
    '638':      {'hex': 0xFF0000, 'name': 'red'},
    '730':      {'hex': 0x770000, 'name': 'dark red'},
    'R':        {'hex': 0xFF0000, 'name': 'red'},
    'G':        {'hex': 0x1FFF00, 'name': 'green'},
    'B':        {'hex': 0x3300FF, 'name': 'blue'}
}

# Emission filter wheel
USE_ZABER_EMISSION_FILTER_WHEEL = False
# need redefine it with real USB device serial number
FILTER_CONTROLLER_SERIAL_NUMBER = 'A10NG007' 

##########################################################
#### start of loading machine specific configurations ####
##########################################################
CACHED_CONFIG_FILE_PATH = None

# Piezo configuration items
ENABLE_OBJECTIVE_PIEZO = True
# the value of OBJECTIVE_PIEZO_CONTROL_VOLTAGE_RANGE is 2.5 or 5
OBJECTIVE_PIEZO_CONTROL_VOLTAGE_RANGE = 5
OBJECTIVE_PIEZO_RANGE_UM = 300
OBJECTIVE_PIEZO_HOME_UM = 20

MULTIPOINT_USE_PIEZO_FOR_ZSTACKS = True
MULTIPOINT_PIEZO_DELAY_MS = 20
MULTIPOINT_PIEZO_UPDATE_DISPLAY = True

AWB_RATIOS_R = 1.375
AWB_RATIOS_G = 1
AWB_RATIOS_B = 1.4141

try:
    with open("cache/config_file_path.txt", 'r') as file:
        for line in file:
            CACHED_CONFIG_FILE_PATH = line
            break
except FileNotFoundError:
    CACHED_CONFIG_FILE_PATH = None

config_files = glob.glob('.' + '/' + 'configuration*.ini')
if config_files:
    if len(config_files) > 1:
        if CACHED_CONFIG_FILE_PATH in config_files:
            print('defaulting to last cached config file at '+CACHED_CONFIG_FILE_PATH)
            config_files = [CACHED_CONFIG_FILE_PATH]
        else:
            print('multiple machine configuration files found, the program will exit')
            sys.exit(1)
    print('load machine-specific configuration')
    #exec(open(config_files[0]).read())
    cfp = ConfigParser()
    cfp.read(config_files[0])
    var_items = list(locals().keys())
    for var_name in var_items:
        if type(locals()[var_name]) is type:
            continue
        varnamelower = var_name.lower()
        if varnamelower not in cfp.options("GENERAL"):
            continue
        value = cfp.get("GENERAL",varnamelower)
        actualvalue = conf_attribute_reader(value)
        locals()[var_name] = actualvalue
    for classkey in var_items:
        myclass = None
        classkeyupper = classkey.upper()
        pop_items = None
        try:
            pop_items = cfp.items(classkeyupper)
        except:
            continue
        if type(locals()[classkey]) is not type:
            continue
        myclass = locals()[classkey]
        populate_class_from_dict(myclass,pop_items)
    with open("cache/config_file_path.txt", 'w') as file:
        file.write(config_files[0])
    CACHED_CONFIG_FILE_PATH = config_files[0]
else:
    print('configuration*.ini file not found, defaulting to legacy configuration')
    config_files = glob.glob('.' + '/' + 'configuration*.txt')
    if config_files:
        if len(config_files) > 1:
            print('multiple machine configuration files found, the program will exit')
            sys.exit(1)
        print('load machine-specific configuration')
        exec(open(config_files[0]).read())
    else:
        print('machine-specific configuration not present, the program will exit')
        sys.exit(1)
##########################################################
##### end of loading machine specific configurations #####
##########################################################

# objective piezo
if ENABLE_OBJECTIVE_PIEZO == False:
    MULTIPOINT_USE_PIEZO_FOR_ZSTACKS = False

# saving path
if not (DEFAULT_SAVING_PATH.startswith(str(Path.home()))):
    DEFAULT_SAVING_PATH = str(Path.home())+"/"+DEFAULT_SAVING_PATH.strip("/")

# limit switch
X_HOME_SWITCH_POLARITY = LIMIT_SWITCH_POLARITY.X_HOME
Y_HOME_SWITCH_POLARITY = LIMIT_SWITCH_POLARITY.Y_HOME
Z_HOME_SWITCH_POLARITY = LIMIT_SWITCH_POLARITY.Z_HOME

# home safety margin with (um) unit
X_HOME_SAFETY_MARGIN_UM = 50
Y_HOME_SAFETY_MARGIN_UM = 50
Z_HOME_SAFETY_MARGIN_UM = 600 

if ENABLE_TRACKING:
    DEFAULT_DISPLAY_CROP = Tracking.DEFAULT_DISPLAY_CROP

if WELLPLATE_FORMAT == 384:
    WELL_SIZE_MM = 3.3
    WELL_SPACING_MM = 4.5
    NUMBER_OF_SKIP = 1
    A1_X_MM = 12.05     # measured stage position - to update
    A1_Y_MM = 9.05      # measured stage position - to update
    A1_X_PIXEL = 144    # coordinate on the png
    A1_Y_PIXEL = 108    # coordinate on the png
elif WELLPLATE_FORMAT == 96:
    NUMBER_OF_SKIP = 0
    WELL_SIZE_MM = 6.21
    WELL_SPACING_MM = 9
    A1_X_MM = 14.3      # measured stage position - to update
    A1_Y_MM = 11.36     # measured stage position - to update
    A1_X_PIXEL = 171    # coordinate on the png
    A1_Y_PIXEL = 138    # coordinate on the png
elif WELLPLATE_FORMAT == 24:
    NUMBER_OF_SKIP = 0
    WELL_SIZE_MM = 15.54
    WELL_SPACING_MM = 19.3
    A1_X_MM = 17.05     # measured stage position - to update
    A1_Y_MM = 13.67     # measured stage position - to update
    A1_X_PIXEL = 144    # coordinate on the png - to update
    A1_Y_PIXEL = 108    # coordinate on the png - to update
elif WELLPLATE_FORMAT == 12:
    NUMBER_OF_SKIP = 0
    WELL_SIZE_MM = 22.05
    WELL_SPACING_MM = 26
    A1_X_MM = 24.75     # measured stage position - to update
    A1_Y_MM = 16.86     # measured stage position - to update
    A1_X_PIXEL = 297    # coordinate on the png
    A1_Y_PIXEL = 209    # coordinate on the png
elif WELLPLATE_FORMAT == 6:
    NUMBER_OF_SKIP = 0
    WELL_SIZE_MM = 34.94
    WELL_SPACING_MM = 39.2
    A1_X_MM = 24.55     # measured stage position - to update
    A1_Y_MM = 23.01     # measured stage position - to update
    A1_X_PIXEL = 297    # coordinate on the png - to update
    A1_Y_PIXEL = 209    # coordinate on the png - to update
elif WELLPLATE_FORMAT == 1536:
    NUMBER_OF_SKIP = 0
    WELL_SIZE_MM = 1.5
    WELL_SPACING_MM = 2.25
    A1_X_MM = 11.0      # measured stage position - to update
    A1_Y_MM = 7.86      # measured stage position - to update
    A1_X_PIXEL = 144    # coordinate on the png - to update
    A1_Y_PIXEL = 108    # coordinate on the png - to update

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

import control.utils as utils
from control._def import *
import control.tracking as tracking

from queue import Queue
from threading import Thread, Lock
import time
import numpy as np
import pyqtgraph as pg
import cv2
from datetime import datetime

from lxml import etree as ET
from pathlib import Path
import control.utils_config as utils_config

import math
import json
import pandas as pd

class SpectrumStreamHandler(QObject):

    spectrum_to_display = Signal(np.ndarray)
    spectrum_to_write = Signal(np.ndarray)
    signal_new_spectrum_received = Signal()

    def __init__(self):
        QObject.__init__(self)
        self.fps_display = 30
        self.fps_save = 1
        self.timestamp_last_display = 0
        self.timestamp_last_save = 0

        self.save_spectrum_flag = False

        # for fps measurement
        self.timestamp_last = 0
        self.counter = 0
        self.fps_real = 0

    def start_recording(self):
        self.save_spectrum_flag = True

    def stop_recording(self):
        self.save_spectrum_flag = False

    def set_display_fps(self,fps):
        self.fps_display = fps

    def set_save_fps(self,fps):
        self.fps_save = fps

    def on_new_measurement(self, data):
        self.signal_new_spectrum_received.emit()
        # measure real fps
        timestamp_now = round(time.time())
        if timestamp_now == self.timestamp_last:
            self.counter = self.counter+1
        else:
            self.timestamp_last = timestamp_now
            self.fps_real = self.counter
            self.counter = 0
            print('real spectrometer fps is ' + str(self.fps_real))
        # send image to display
        time_now = time.time()
        if time_now-self.timestamp_last_display >= 1/self.fps_display:
            self.spectrum_to_display.emit(data)
            self.timestamp_last_display = time_now
        # send image to write
        if self.save_spectrum_flag and time_now-self.timestamp_last_save >= 1/self.fps_save:
            self.spectrum_to_write.emit(data)
            self.timestamp_last_save = time_now

class SpectrumSaver(QObject):

    stop_recording = Signal()

    def __init__(self):
        QObject.__init__(self)
        self.base_path = './'
        self.experiment_ID = ''
        self.max_num_file_per_folder = 1000
        self.queue = Queue(10) # max 10 items in the queue
        self.stop_signal_received = False
        self.thread = Thread(target=self.process_queue)
        self.thread.start()
        self.counter = 0
        self.recording_start_time = 0
        self.recording_time_limit = -1

    def process_queue(self):
        while True:
            # stop the thread if stop signal is received
            if self.stop_signal_received:
                return
            # process the queue
            try:
                data = self.queue.get(timeout=0.1)
                folder_ID = int(self.counter/self.max_num_file_per_folder)
                file_ID = int(self.counter%self.max_num_file_per_folder)
                # create a new folder
                if file_ID == 0:
                    os.mkdir(os.path.join(self.base_path,self.experiment_ID,str(folder_ID)))

                saving_path = os.path.join(self.base_path,self.experiment_ID,str(folder_ID),str(file_ID) + '.csv')
                np.savetxt(saving_path,data,delimiter=',')

                self.counter = self.counter + 1
                self.queue.task_done()
            except:
                pass
                            
    def enqueue(self,data):
        try:
            self.queue.put_nowait(data)
            if ( self.recording_time_limit>0 ) and ( time.time()-self.recording_start_time >= self.recording_time_limit ):
                self.stop_recording.emit()
            # when using self.queue.put(str_), program can be slowed down despite multithreading because of the block and the GIL
        except:
            print('imageSaver queue is full, image discarded')

    def set_base_path(self,path):
        self.base_path = path

    def set_recording_time_limit(self,time_limit):
        self.recording_time_limit = time_limit

    def start_new_experiment(self,experiment_ID,add_timestamp=True):
        if add_timestamp:
            # generate unique experiment ID
            self.experiment_ID = experiment_ID + '_spectrum_' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S.%f')
        else:
            self.experiment_ID = experiment_ID
        self.recording_start_time = time.time()
        # create a new folder
        try:
            os.mkdir(os.path.join(self.base_path,self.experiment_ID))
            # to do: save configuration
        except:
            pass
        # reset the counter
        self.counter = 0

    def close(self):
        self.queue.join()
        self.stop_signal_received = True
        self.thread.join()

# set QT_API environment variable
import os 
from pathlib import Path
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.core_platereader as core_platereader
import control.microcontroller as microcontroller

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, is_simulation = False, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		if is_simulation:
			self.camera = camera.Camera_Simulation()
			self.microcontroller = microcontroller.Microcontroller_Simulation()
		else:
			self.camera = camera.Camera()
			self.microcontroller = microcontroller.Microcontroller()
		
		self.configurationManager = core.ConfigurationManager(filename=str(Path.home()) + "/configurations_platereader.xml")
		self.streamHandler = core.StreamHandler()
		self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
		self.navigationController = core.NavigationController(self.microcontroller)
		self.plateReaderNavigationController = core.PlateReaderNavigationController(self.microcontroller)
		self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
		self.plateReadingController = core_platereader.PlateReadingController(self.camera,self.plateReaderNavigationController,self.liveController,self.autofocusController,self.configurationManager)
		self.imageSaver = core.ImageSaver()

		# open the camera
		# camera start streaming
		self.camera.open()
		self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera.set_callback(self.streamHandler.on_new_frame)
		self.camera.enable_callback()

		# load widgets
		self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,include_gain_exposure_time=False)
		self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager,show_trigger_options=False,show_display_options=False)
		self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
		self.plateReaderAcquisitionWidget = widgets.PlateReaderAcquisitionWidget(self.plateReadingController,self.configurationManager,show_configurations=False)
		self.plateReaderNavigationWidget = widgets.PlateReaderNavigationWidget(self.plateReaderNavigationController)

		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		#layout.addWidget(self.cameraSettingWidget,0,0)
		layout.addWidget(self.liveControlWidget,1,0)
		layout.addWidget(self.plateReaderNavigationWidget,2,0)
		layout.addWidget(self.autofocusWidget,3,0)
		layout.addWidget(self.plateReaderAcquisitionWidget,4,0)
		
		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# load window
		self.imageDisplayWindow = core.ImageDisplayWindow()
		self.imageDisplayWindow.show()

		# make connections
		self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
		self.streamHandler.image_to_display.connect(self.imageDisplayWindow.display_image)
		self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
		# self.plateReaderNavigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		# self.plateReaderNavigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		# self.plateReaderNavigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)
		self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
		# self.plateReadingController.image_to_display.connect(self.imageDisplayWindow.display_image)
		self.plateReadingController.signal_current_configuration.connect(self.liveControlWidget.set_microscope_mode)
		self.plateReadingController.image_to_display.connect(self.imageDisplayWindow.display_image)
		self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
		self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
		self.liveControlWidget.update_camera_settings()

		self.microcontroller.set_callback(self.plateReaderNavigationController.update_pos)
		self.plateReaderNavigationController.signal_homing_complete.connect(self.plateReaderNavigationWidget.slot_homing_complete)
		self.plateReaderNavigationController.signal_homing_complete.connect(self.plateReaderAcquisitionWidget.slot_homing_complete)
		self.plateReaderNavigationController.signal_current_well.connect(self.plateReaderNavigationWidget.update_current_location)

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		# self.plateReaderNavigationController.home()
		self.liveController.stop_live()
		self.camera.close()
		self.imageSaver.close()
		self.imageDisplayWindow.close()
		self.microcontroller.close()
import cv2
from numpy import std, square, mean
import numpy as np
from scipy.ndimage import label

def crop_image(image,crop_width,crop_height):
    image_height = image.shape[0]
    image_width = image.shape[1]
    roi_left = int(max(image_width/2 - crop_width/2,0))
    roi_right = int(min(image_width/2 + crop_width/2,image_width))
    roi_top = int(max(image_height/2 - crop_height/2,0))
    roi_bottom = int(min(image_height/2 + crop_height/2,image_height))
    image_cropped = image[roi_top:roi_bottom,roi_left:roi_right]
    return image_cropped

def calculate_focus_measure(image,method='LAPE'):
    if len(image.shape) == 3:
        image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY) # optional
    if method == 'LAPE':
        if image.dtype == np.uint16:
            lap = cv2.Laplacian(image,cv2.CV_32F)
        else:
            lap = cv2.Laplacian(image,cv2.CV_16S)
        focus_measure = mean(square(lap))
    elif method == 'GLVA':
        focus_measure = np.std(image,axis=None)# GLVA
    else:
        focus_measure = np.std(image,axis=None)# GLVA
    return focus_measure

def unsigned_to_signed(unsigned_array,N):
    signed = 0
    for i in range(N):
        signed = signed + int(unsigned_array[i])*(256**(N-1-i))
    signed = signed - (256**N)/2
    return signed

def rotate_and_flip_image(image,rotate_image_angle,flip_image):
    ret_image = image.copy()
    if(rotate_image_angle != 0):
        '''
            # ROTATE_90_CLOCKWISE
            # ROTATE_90_COUNTERCLOCKWISE
        '''
        if(rotate_image_angle == 90):
            ret_image = cv2.rotate(ret_image,cv2.ROTATE_90_CLOCKWISE)
        elif(rotate_image_angle == -90):
            ret_image = cv2.rotate(ret_image,cv2.ROTATE_90_COUNTERCLOCKWISE)
        elif(rotate_image_angle == 180):
            ret_image = cv2.rotate(ret_image,cv2.ROTATE_180)

    if(flip_image is not None):
        '''
            flipcode = 0: flip vertically
            flipcode > 0: flip horizontally
            flipcode < 0: flip vertically and horizontally
        '''
        if(flip_image == 'Vertical'):
            ret_image = cv2.flip(ret_image, 0)
        elif(flip_image == 'Horizontal'):
            ret_image = cv2.flip(ret_image, 1)
        elif(flip_image == 'Both'):
            ret_image = cv2.flip(ret_image, -1)

    return ret_image

def generate_dpc(im_left, im_right):
    # Normalize the images
    im_left = im_left.astype(float)/255
    im_right = im_right.astype(float)/255
    # differential phase contrast calculation
    im_dpc = 0.5 + np.divide(im_left-im_right, im_left+im_right)
    # take care of errors
    im_dpc[im_dpc < 0] = 0
    im_dpc[im_dpc > 1] = 1
    im_dpc[np.isnan(im_dpc)] = 0

    im_dpc = (im_dpc * 255).astype(np.uint8)

    return im_dpc

def colorize_mask(mask):
    # Label the detected objects
    labeled_mask, ___ = label(mask)
    # Color them
    colored_mask = np.array((labeled_mask * 83) % 255, dtype=np.uint8)
    colored_mask = cv2.applyColorMap(colored_mask, cv2.COLORMAP_HSV)
    # make sure background is black
    colored_mask[labeled_mask == 0] = 0
    return colored_mask

def colorize_mask_get_counts(mask):
    # Label the detected objects
    labeled_mask, no_cells = label(mask)
    # Color them
    colored_mask = np.array((labeled_mask * 83) % 255, dtype=np.uint8)
    colored_mask = cv2.applyColorMap(colored_mask, cv2.COLORMAP_HSV)
    # make sure background is black
    colored_mask[labeled_mask == 0] = 0
    return colored_mask, no_cells

def overlay_mask_dpc(color_mask, im_dpc):
    # Overlay the colored mask and DPC image
    # make DPC 3-channel
    im_dpc = np.stack([im_dpc]*3, axis=2)
    return (0.75*im_dpc + 0.25*color_mask).astype(np.uint8)
    
def centerCrop(image, crop_sz):
    center = image.shape
    x = int(center[1]/2 - crop_sz/2)
    y = int(center[0]/2 - crop_sz/2)
    cropped = image[y:y+crop_sz, x:x+crop_sz]
    
    return cropped

def interpolate_plane(triple1, triple2, triple3, point):
    """
    Given 3 triples triple1-3 of coordinates (x,y,z)
    and a pair of coordinates (x,y), linearly interpolates
    the z-value at (x,y).
    """
    # Unpack points
    x1, y1, z1 = triple1
    x2, y2, z2 = triple2
    x3, y3, z3 = triple3

    x,y = point
    # Calculate barycentric coordinates
    detT = (y2 - y3) * (x1 - x3) + (x3 - x2) * (y1 - y3)
    if detT == 0:
        raise ValueError("Your 3 x-y coordinates are linear")
    alpha = ((y2 - y3) * (x - x3) + (x3 - x2) * (y - y3)) / detT
    beta = ((y3 - y1) * (x - x3) + (x1 - x3) * (y - y3)) / detT
    gamma = 1 - alpha - beta

    # Interpolate z-coordinate
    z = alpha * z1 + beta * z2 + gamma * z3

    return z


import argparse
import cv2
import time
import numpy as np
import threading
try:
    import seabreeze as sb
    import seabreeze.spectrometers
except:
    print('seabreeze import error')

# installation: $ pip3 install seabreeze
# installation: $ seabreeze_os_setup

from control._def import *

class Spectrometer(object):

    def __init__(self,sn=None):
        if sn == None:
            self.spectrometer = sb.spectrometers.Spectrometer.from_first_available()
        else:
            self.spectrometer = sb.spectrometers.Spectrometer.Spectrometer.from_serial_number(sn)

        self.new_data_callback_external = None

        self.streaming_started = False
        self.streaming_paused = False
        self.stop_streaming = False
        self.is_reading_spectrum = False

        self.thread_streaming = threading.Thread(target=self.stream, daemon=True)

    def set_integration_time_ms(self,integration_time_ms):
        self.spectrometer.integration_time_micros(int(1000*integration_time_ms))

    def read_spectrum(self,correct_dark_counts=False,correct_nonlinearity=False):
        self.is_reading_spectrum = True
        data = self.spectrometer.spectrum(correct_dark_counts,correct_nonlinearity)
        self.is_reading_spectrum = False
        return data

    def set_callback(self,function):
        self.new_data_callback_external = function

    def start_streaming(self):
        if self.streaming_started == False:
            self.streaming_started = True
            self.streaming_paused = False
            self.thread_streaming.start()
        else:
            self.streaming_paused = False

    def pause_streaming(self):
        self.streaming_paused = True

    def resume_streaming(self):
        self.streaming_paused = False

    def stream(self):
        while self.stop_streaming == False:
            if self.streaming_paused:
                time.sleep(0.05)
                continue
            # avoid conflict
            while self.is_reading_spectrum:
                time.sleep(0.05)
            if self.new_data_callback_external != None:
                self.new_data_callback_external(self.read_spectrum())

    def close(self):
        if self.streaming_started:
            self.stop_streaming = True
            self.thread_streaming.join()
        self.spectrometer.close()

class Spectrometer_Simulation(object):
    
    def __init__(self,sn=None):
        self.new_data_callback_external = None
        self.streaming_started = False
        self.stop_streaming = False
        self.streaming_paused = False
        self.is_reading_spectrum = False
        self.thread_streaming = threading.Thread(target=self.stream, daemon=True)

    def set_integration_time_us(self,integration_time_us):
        pass

    def read_spectrum(self,correct_dark_counts=False,correct_nonlinearity=False):
        N = 4096
        wavelength = np.linspace(400,1100,N)
        intensity = np.random.randint(0,65536,N)
        return np.stack((wavelength,intensity))
    
    def set_callback(self,function):
        self.new_data_callback_external = function

    def start_streaming(self):
        if self.streaming_started == False:
            self.streaming_started = True
            self.streaming_paused = False
            self.thread_streaming.start()
        else:
            self.streaming_paused = False

    def pause_streaming(self):
        self.streaming_paused = True

    def resume_streaming(self):
        self.streaming_paused = False

    def stream(self):
        while self.stop_streaming == False:
            if self.streaming_paused:
                time.sleep(0.05)
                continue
            # avoid conflict
            while self.is_reading_spectrum:
                time.sleep(0.05)
            if self.new_data_callback_external != None:
                print('read spectrum...')
                self.new_data_callback_external(self.read_spectrum())

    def close(self):
        if self.streaming_started:
            self.stop_streaming = True
            self.thread_streaming.join()
import platform
import serial
import serial.tools.list_ports
import time
import numpy as np
import threading

from control._def import *

from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# temporary
class Microcontroller2():
    def __init__(self):
        self.serial = None
        self.platform_name = platform.system()
        self.tx_buffer_length = Microcontroller2Def.CMD_LENGTH
        self.rx_buffer_length = Microcontroller2Def.MSG_LENGTH

        self._cmd_id = 0
        self._cmd_id_mcu = None # command id of mcu's last received command 
        self._cmd_execution_status = None
        self.mcu_cmd_execution_in_progress = False
        self.last_command = None
        self.timeout_counter = 0

        controller_ports = [ p.device for p in serial.tools.list_ports.comports() if p.manufacturer == 'Teensyduino']
        if not controller_ports:
            raise IOError("No Teensy Found")
        self.serial = serial.Serial(controller_ports[0],2000000)
        print('Teensy connected')

        '''
        self.new_packet_callback_external = None
        self.terminate_reading_received_packet_thread = False
        self.thread_read_received_packet = threading.Thread(target=self.read_received_packet, daemon=True)
        self.thread_read_received_packet.start()
        '''

    def close(self):
        self.serial.close()

    def analog_write_DAC8050x(self,dac,value):
        print('write DAC ' + str(dac) + ': ' + str(value))
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET2.ANALOG_WRITE_DAC8050X
        cmd[2] = dac
        cmd[3] = (value >> 8) & 0xff
        cmd[4] = value & 0xff
        self.send_command(cmd)

    def set_camera_trigger_frequency(self,frequency):
        trigger_interval_us = int((1/frequency)*1000000*1000);
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET2.SET_CAMERA_TRIGGER_FREQUENCY
        cmd[2] = (trigger_interval_us >> 24) & 0xff
        cmd[3] = (trigger_interval_us >> 16) & 0xff
        cmd[4] = (trigger_interval_us >> 8) & 0xff
        cmd[5] = trigger_interval_us & 0xff
        self.send_command(cmd) 

    def start_camera_trigger(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET2.START_CAMERA_TRIGGERING
        self.send_command(cmd) 

    def stop_camera_trigger(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET2.STOP_CAMERA_TRIGGERING
        self.send_command(cmd) 
    
    def send_command(self,command):
        self._cmd_id = (self._cmd_id + 1)%256
        command[0] = self._cmd_id
        # command[self.tx_buffer_length-1] = self._calculate_CRC(command)
        self.serial.write(command)
        self.mcu_cmd_execution_in_progress = True
        self.last_command = command
        self.timeout_counter = 0

    def read_received_packet(self):
        while self.terminate_reading_received_packet_thread == False:
            # wait to receive data
            if self.serial.in_waiting==0:
                continue
            if self.serial.in_waiting % self.rx_buffer_length != 0:
                continue
            
            # get rid of old data
            num_bytes_in_rx_buffer = self.serial.in_waiting
            if num_bytes_in_rx_buffer > self.rx_buffer_length:
                # print('getting rid of old data')
                for i in range(num_bytes_in_rx_buffer-self.rx_buffer_length):
                    self.serial.read()
            
            # read the buffer
            msg=[]
            for i in range(self.rx_buffer_length):
                msg.append(ord(self.serial.read()))

            # parse the message
            '''
            - command ID (1 byte)
            - execution status (1 byte)
            - CRC (1 byte)
            '''
            self._cmd_id_mcu = msg[0]
            self._cmd_execution_status = msg[1]
            if (self._cmd_id_mcu == self._cmd_id) and (self._cmd_execution_status == CMD_EXECUTION_STATUS.COMPLETED_WITHOUT_ERRORS):
                if self.mcu_cmd_execution_in_progress == True:
                    self.mcu_cmd_execution_in_progress = False
                    print('   mcu command ' + str(self._cmd_id) + ' complete')
                elif self._cmd_id_mcu != self._cmd_id and self.last_command != None:
                    self.timeout_counter = self.timeout_counter + 1
                    if self.timeout_counter > 10:
                        self.resend_last_command()
                        print('      *** resend the last command')
            # print('command id ' + str(self._cmd_id) + '; mcu command ' + str(self._cmd_id_mcu) + ' status: ' + str(msg[1]) )

            if self.new_packet_callback_external is not None:
                self.new_packet_callback_external(self)

    def is_busy(self):
        return self.mcu_cmd_execution_in_progress

    def set_callback(self,function):
        self.new_packet_callback_external = function

    def _int_to_payload(self,signed_int,number_of_bytes):
        if signed_int >= 0:
            payload = signed_int
        else:
            payload = 2**(8*number_of_bytes) + signed_int # find two's completement
        return payload

    def _payload_to_int(self,payload,number_of_bytes):
        signed = 0
        for i in range(number_of_bytes):
            signed = signed + int(payload[i])*(256**(number_of_bytes-1-i))
        if signed >= 256**number_of_bytes/2:
            signed = signed - 256**number_of_bytes
        return signed

class Microcontroller2_Simulation():
    def __init__(self,parent=None):
        self.serial = None
        self.platform_name = platform.system()
        self.tx_buffer_length = MicrocontrollerDef.CMD_LENGTH
        self.rx_buffer_length = MicrocontrollerDef.MSG_LENGTH

        self._cmd_id = 0
        self._cmd_id_mcu = None # command id of mcu's last received command 
        self._cmd_execution_status = None
        self.mcu_cmd_execution_in_progress = False

         # for simulation
        self.timestamp_last_command = time.time() # for simulation only
        self._mcu_cmd_execution_status = None
        self.timer_update_command_execution_status = QTimer()
        self.timer_update_command_execution_status.timeout.connect(self._simulation_update_cmd_execution_status)

        '''
        self.new_packet_callback_external = None
        self.terminate_reading_received_packet_thread = False
        self.thread_read_received_packet = threading.Thread(target=self.read_received_packet, daemon=True)
        self.thread_read_received_packet.start()
        '''

    def close(self):
        self.terminate_reading_received_packet_thread = True
        self.thread_read_received_packet.join()

    def analog_write_DAC8050x(self,dac,value):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET2.ANALOG_WRITE_DAC8050X
        cmd[2] = dac
        cmd[3] = (value >> 8) & 0xff
        cmd[4] = value & 0xff
        self.send_command(cmd)

    def set_camera_trigger_frequency(self,frequency):
        trigger_interval_us = int((1/frequency)*1000000);
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET2.SET_CAMERA_TRIGGER_FREQUENCY
        cmd[2] = (trigger_interval_us >> 24) & 0xff
        cmd[3] = (trigger_interval_us >> 16) & 0xff
        cmd[4] = (trigger_interval_us >> 8) & 0xff
        cmd[5] = trigger_interval_us & 0xff
        self.send_command(cmd) 

    def start_camera_trigger(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET2.START_CAMERA_TRIGGERING
        self.send_command(cmd) 

    def stop_camera_trigger(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET2.STOP_CAMERA_TRIGGERING
        self.send_command(cmd) 

    def read_received_packet(self):
        while self.terminate_reading_received_packet_thread == False:
            # only for simulation - update the command execution status
            if time.time() - self.timestamp_last_command > 0.05: # in the simulation, assume all the operation takes 0.05s to complete
                if self._mcu_cmd_execution_status !=  CMD_EXECUTION_STATUS.COMPLETED_WITHOUT_ERRORS:
                    self._mcu_cmd_execution_status = CMD_EXECUTION_STATUS.COMPLETED_WITHOUT_ERRORS
                    print('   mcu command ' + str(self._cmd_id) + ' complete')

            # read and parse message
            msg=[]
            for i in range(self.rx_buffer_length):
                msg.append(0)

            msg[0] = self._cmd_id
            msg[1] = self._mcu_cmd_execution_status

            self._cmd_id_mcu = msg[0]
            self._cmd_execution_status = msg[1]
            if (self._cmd_id_mcu == self._cmd_id) and (self._cmd_execution_status == CMD_EXECUTION_STATUS.COMPLETED_WITHOUT_ERRORS):
                self.mcu_cmd_execution_in_progress = False
            # print('mcu_cmd_execution_in_progress: ' + str(self.mcu_cmd_execution_in_progress))
            
            if self.new_packet_callback_external is not None:
                self.new_packet_callback_external(self)

            time.sleep(0.005) # simulate MCU packet transmission interval
    
    def set_callback(self,function):
        self.new_packet_callback_external = function

    def is_busy(self):
        return self.mcu_cmd_execution_in_progress

    def send_command(self,command):
        self._cmd_id = (self._cmd_id + 1)%256
        command[0] = self._cmd_id
        # command[self.tx_buffer_length-1] = self._calculate_CRC(command)
        self.mcu_cmd_execution_in_progress = True
        # for simulation
        self._mcu_cmd_execution_status = CMD_EXECUTION_STATUS.IN_PROGRESS
        # self.timer_update_command_execution_status.setInterval(2000)
        # self.timer_update_command_execution_status.start()
        # print('start timer')
        # timer cannot be started from another thread
        self.timestamp_last_command = time.time()

    def _simulation_update_cmd_execution_status(self):
        # print('simulation - MCU command execution finished')
        # self._mcu_cmd_execution_status = CMD_EXECUTION_STATUS.COMPLETED_WITHOUT_ERRORS
        # self.timer_update_command_execution_status.stop()
        pass # timer cannot be started from another thread
import argparse
import cv2
import time
import numpy as np
try:
    import control.gxipy as gx
except:
    print('gxipy import error')

from control._def import *

def get_sn_by_model(model_name):
    try:
        device_manager = gx.DeviceManager()
        device_num, device_info_list = device_manager.update_device_list()
    except:
        device_num = 0
    if device_num > 0:
        for i in range(device_num):
            if device_info_list[i]['model_name'] == model_name:
                return device_info_list[i]['sn']
    return None # return None if no device with the specified model_name is connected

class Camera(object):

    def __init__(self,sn=None,is_global_shutter=False,rotate_image_angle=None,flip_image=None):

        # many to be purged
        self.sn = sn
        self.is_global_shutter = is_global_shutter
        self.device_manager = gx.DeviceManager()
        self.device_info_list = None
        self.device_index = 0
        self.camera = None
        self.is_color = None
        self.gamma_lut = None
        self.contrast_lut = None
        self.color_correction_param = None

        self.rotate_image_angle = rotate_image_angle
        self.flip_image = flip_image

        self.exposure_time = 1 # unit: ms
        self.analog_gain = 0
        self.frame_ID = -1
        self.frame_ID_software = -1
        self.frame_ID_offset_hardware_trigger = 0
        self.timestamp = 0

        self.image_locked = False
        self.current_frame = None

        self.callback_is_enabled = False
        self.is_streaming = False

        self.GAIN_MAX = 24
        self.GAIN_MIN = 0
        self.GAIN_STEP = 1
        self.EXPOSURE_TIME_MS_MIN = 0.01
        self.EXPOSURE_TIME_MS_MAX = 4000

        self.trigger_mode = None
        self.pixel_size_byte = 1

        # below are values for IMX226 (MER2-1220-32U3M) - to make configurable 
        self.row_period_us = 10
        self.row_numbers = 3036
        self.exposure_delay_us_8bit = 650
        self.exposure_delay_us = self.exposure_delay_us_8bit*self.pixel_size_byte
        self.strobe_delay_us = self.exposure_delay_us + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1)

        self.pixel_format = None # use the default pixel format

        self.is_live = False # this determines whether a new frame received will be handled in the streamHandler
        # mainly for discarding the last frame received after stop_live() is called, where illumination is being turned off during exposure

    def open(self,index=0):
        (device_num, self.device_info_list) = self.device_manager.update_device_list()
        if device_num == 0:
            raise RuntimeError('Could not find any USB camera devices!')
        if self.sn is None:
            self.device_index = index
            self.camera = self.device_manager.open_device_by_index(index + 1)
        else:
            self.camera = self.device_manager.open_device_by_sn(self.sn)
        self.is_color = self.camera.PixelColorFilter.is_implemented()
        # self._update_image_improvement_params()
        # self.camera.register_capture_callback(self,self._on_frame_callback)
        if self.is_color:
            # self.set_wb_ratios(self.get_awb_ratios())
            print(self.get_awb_ratios())
            # self.set_wb_ratios(1.28125,1.0,2.9453125)
            # self.set_wb_ratios(2,1,2)
            self.set_wb_ratios(AWB_RATIOS_R, AWB_RATIOS_G, AWB_RATIOS_B)

        # temporary
        self.camera.AcquisitionFrameRate.set(1000)
        self.camera.AcquisitionFrameRateMode.set(gx.GxSwitchEntry.ON)

        # turn off device link throughput limit
        self.camera.DeviceLinkThroughputLimitMode.set(gx.GxSwitchEntry.OFF)

        # get sensor parameters
        self.Width = self.camera.Width.get()
        self.Height = self.camera.Height.get()
        self.WidthMax = self.camera.WidthMax.get()
        self.HeightMax = self.camera.HeightMax.get()
        self.OffsetX = self.camera.OffsetX.get()
        self.OffsetY = self.camera.OffsetY.get()

    def set_callback(self,function):
        self.new_image_callback_external = function

    def enable_callback(self):
        if self.callback_is_enabled == False:
            # stop streaming
            if self.is_streaming:
                was_streaming = True
                self.stop_streaming()
            else:
                was_streaming = False
            # enable callback
            user_param = None
            self.camera.register_capture_callback(user_param,self._on_frame_callback)
            self.callback_is_enabled = True
            # resume streaming if it was on
            if was_streaming:
                self.start_streaming()
            self.callback_is_enabled = True
        else:
            pass

    def disable_callback(self):
        if self.callback_is_enabled == True:
            # stop streaming
            if self.is_streaming:
                was_streaming = True
                self.stop_streaming()
            else:
                was_streaming = False
            # disable call back
            self.camera.unregister_capture_callback()
            self.callback_is_enabled = False
            # resume streaming if it was on
            if was_streaming:
                self.start_streaming()
        else:
            pass

    def open_by_sn(self,sn):
        (device_num, self.device_info_list) = self.device_manager.update_device_list()
        if device_num == 0:
            raise RuntimeError('Could not find any USB camera devices!')
        self.camera = self.device_manager.open_device_by_sn(sn)
        self.is_color = self.camera.PixelColorFilter.is_implemented()
        self._update_image_improvement_params()

        '''
        if self.is_color is True:
            self.camera.register_capture_callback(_on_color_frame_callback)
        else:
            self.camera.register_capture_callback(_on_frame_callback)
        '''

    def close(self):
        self.camera.close_device()
        self.device_info_list = None
        self.camera = None
        self.is_color = None
        self.gamma_lut = None
        self.contrast_lut = None
        self.color_correction_param = None
        self.last_raw_image = None
        self.last_converted_image = None
        self.last_numpy_image = None

    def set_exposure_time(self,exposure_time):
        use_strobe = (self.trigger_mode == TriggerMode.HARDWARE) # true if using hardware trigger
        if use_strobe == False or self.is_global_shutter:
            self.exposure_time = exposure_time
            self.camera.ExposureTime.set(exposure_time * 1000)
        else:
            # set the camera exposure time such that the active exposure time (illumination on time) is the desired value
            self.exposure_time = exposure_time
            # add an additional 500 us so that the illumination can fully turn off before rows start to end exposure
            camera_exposure_time = self.exposure_delay_us + self.exposure_time*1000 + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1) + 500 # add an additional 500 us so that the illumination can fully turn off before rows start to end exposure
            self.camera.ExposureTime.set(camera_exposure_time)

    def update_camera_exposure_time(self):
        use_strobe = (self.trigger_mode == TriggerMode.HARDWARE) # true if using hardware trigger
        if use_strobe == False or self.is_global_shutter:
            self.camera.ExposureTime.set(self.exposure_time * 1000)
        else:
            camera_exposure_time = self.exposure_delay_us + self.exposure_time*1000 + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1) + 500 # add an additional 500 us so that the illumination can fully turn off before rows start to end exposure
            self.camera.ExposureTime.set(camera_exposure_time)

    def set_analog_gain(self,analog_gain):
        self.analog_gain = analog_gain
        self.camera.Gain.set(analog_gain)

    def get_awb_ratios(self):
        self.camera.BalanceWhiteAuto.set(2)
        self.camera.BalanceRatioSelector.set(0)
        awb_r = self.camera.BalanceRatio.get()
        self.camera.BalanceRatioSelector.set(1)
        awb_g = self.camera.BalanceRatio.get()
        self.camera.BalanceRatioSelector.set(2)
        awb_b = self.camera.BalanceRatio.get()
        return (awb_r, awb_g, awb_b)

    def set_wb_ratios(self, wb_r=None, wb_g=None, wb_b=None):
        self.camera.BalanceWhiteAuto.set(0)
        if wb_r is not None:
            self.camera.BalanceRatioSelector.set(0)
            awb_r = self.camera.BalanceRatio.set(wb_r)
        if wb_g is not None:
            self.camera.BalanceRatioSelector.set(1)
            awb_g = self.camera.BalanceRatio.set(wb_g)
        if wb_b is not None:
            self.camera.BalanceRatioSelector.set(2)
            awb_b = self.camera.BalanceRatio.set(wb_b)

    def set_balance_white_auto(self, value):
        if value in [0, 1, 2]:
            if self.camera.BalanceWhiteAuto.is_implemented():
                if self.camera.BalanceWhiteAuto.is_writable():
                    self.camera.BalanceWhiteAuto.set(value)

    def get_balance_white_auto(self):
        if self.camera.BalanceWhiteAuto.is_implemented():
            if self.camera.BalanceWhiteAuto.is_readable():
                return self.camera.BalanceWhiteAuto.get()

    def get_is_color(self):
        return self.is_color

    def set_reverse_x(self,value):
        self.camera.ReverseX.set(value)

    def set_reverse_y(self,value):
        self.camera.ReverseY.set(value)

    def start_streaming(self):
        self.camera.stream_on()
        self.is_streaming = True

    def stop_streaming(self):
        self.camera.stream_off()
        self.is_streaming = False

    def set_pixel_format(self,pixel_format):
        if self.is_streaming == True:
            was_streaming = True
            self.stop_streaming()
        else:
            was_streaming = False

        if self.camera.PixelFormat.is_implemented() and self.camera.PixelFormat.is_writable():
            if pixel_format == 'MONO8':
                self.camera.PixelFormat.set(gx.GxPixelFormatEntry.MONO8)
                self.pixel_size_byte = 1
            if pixel_format == 'MONO10':
                self.camera.PixelFormat.set(gx.GxPixelFormatEntry.MONO10)
                self.pixel_size_byte = 1
            if pixel_format == 'MONO12':
                self.camera.PixelFormat.set(gx.GxPixelFormatEntry.MONO12)
                self.pixel_size_byte = 2
            if pixel_format == 'MONO14':
                self.camera.PixelFormat.set(gx.GxPixelFormatEntry.MONO14)
                self.pixel_size_byte = 2
            if pixel_format == 'MONO16':
                self.camera.PixelFormat.set(gx.GxPixelFormatEntry.MONO16)
                self.pixel_size_byte = 2
            if pixel_format == 'BAYER_RG8':
                self.camera.PixelFormat.set(gx.GxPixelFormatEntry.BAYER_RG8)
                self.pixel_size_byte = 1
            if pixel_format == 'BAYER_RG12':
                self.camera.PixelFormat.set(gx.GxPixelFormatEntry.BAYER_RG12)
                self.pixel_size_byte = 2
            self.pixel_format = pixel_format
        else:
            print("pixel format is not implemented or not writable")

        if was_streaming:
           self.start_streaming()

        # update the exposure delay and strobe delay
        self.exposure_delay_us = self.exposure_delay_us_8bit*self.pixel_size_byte
        self.strobe_delay_us = self.exposure_delay_us + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1)

    def set_continuous_acquisition(self):
        self.camera.TriggerMode.set(gx.GxSwitchEntry.OFF)
        self.trigger_mode = TriggerMode.CONTINUOUS
        self.update_camera_exposure_time()

    def set_software_triggered_acquisition(self):
        self.camera.TriggerMode.set(gx.GxSwitchEntry.ON)
        self.camera.TriggerSource.set(gx.GxTriggerSourceEntry.SOFTWARE)
        self.trigger_mode = TriggerMode.SOFTWARE
        self.update_camera_exposure_time()

    def set_hardware_triggered_acquisition(self):
        self.camera.TriggerMode.set(gx.GxSwitchEntry.ON)
        self.camera.TriggerSource.set(gx.GxTriggerSourceEntry.LINE2) # LINE0 requires 7 mA min
        # self.camera.TriggerSource.set(gx.GxTriggerActivationEntry.RISING_EDGE)
        self.frame_ID_offset_hardware_trigger = None
        self.trigger_mode = TriggerMode.HARDWARE
        self.update_camera_exposure_time()

    def send_trigger(self):
        if self.is_streaming:
            self.camera.TriggerSoftware.send_command()
        else:
        	print('trigger not sent - camera is not streaming')

    def read_frame(self):
        raw_image = self.camera.data_stream[self.device_index].get_image()
        if self.is_color:
            rgb_image = raw_image.convert("RGB")
            numpy_image = rgb_image.get_numpy_array()
            if self.pixel_format == 'BAYER_RG12':
                numpy_image = numpy_image << 4
        else:
            numpy_image = raw_image.get_numpy_array()
            if self.pixel_format == 'MONO12':
                numpy_image = numpy_image << 4
        # self.current_frame = numpy_image
        return numpy_image

    def _on_frame_callback(self, user_param, raw_image):
        if raw_image is None:
            print("Getting image failed.")
            return
        if raw_image.get_status() != 0:
            print("Got an incomplete frame")
            return
        if self.image_locked:
            print('last image is still being processed, a frame is dropped')
            return
        if self.is_color:
            rgb_image = raw_image.convert("RGB")
            numpy_image = rgb_image.get_numpy_array()
            if self.pixel_format == 'BAYER_RG12':
                numpy_image = numpy_image << 4
        else:
            numpy_image = raw_image.get_numpy_array()
            if self.pixel_format == 'MONO12':
                numpy_image = numpy_image << 4
        if numpy_image is None:
            return
        self.current_frame = numpy_image
        self.frame_ID_software = self.frame_ID_software + 1
        self.frame_ID = raw_image.get_frame_id()
        if self.trigger_mode == TriggerMode.HARDWARE:
            if self.frame_ID_offset_hardware_trigger == None:
                self.frame_ID_offset_hardware_trigger = self.frame_ID
            self.frame_ID = self.frame_ID - self.frame_ID_offset_hardware_trigger
        self.timestamp = time.time()
        self.new_image_callback_external(self)

        # self.frameID = self.frameID + 1
        # print(self.frameID)
    
    def set_ROI(self,offset_x=None,offset_y=None,width=None,height=None):

        # stop streaming if streaming is on
        if self.is_streaming == True:
            was_streaming = True
            self.stop_streaming()
        else:
            was_streaming = False

        if width is not None:
            self.Width = width
            # update the camera setting
            if self.camera.Width.is_implemented() and self.camera.Width.is_writable():
                self.camera.Width.set(self.Width)
            else:
                print("Width is not implemented or not writable")

        if height is not None:
            self.Height = height
            # update the camera setting
            if self.camera.Height.is_implemented() and self.camera.Height.is_writable():
                self.camera.Height.set(self.Height)
            else:
                print("Height is not implemented or not writable")

        if offset_x is not None:
            self.OffsetX = offset_x
            # update the camera setting
            if self.camera.OffsetX.is_implemented() and self.camera.OffsetX.is_writable():
                self.camera.OffsetX.set(self.OffsetX)
            else:
                print("OffsetX is not implemented or not writable")

        if offset_y is not None:
            self.OffsetY = offset_y
            # update the camera setting
            if self.camera.OffsetY.is_implemented() and self.camera.OffsetY.is_writable():
                self.camera.OffsetY.set(self.OffsetY)
            else:
                print("OffsetY is not implemented or not writable")

        # restart streaming if it was previously on
        if was_streaming == True:
            self.start_streaming()

    def reset_camera_acquisition_counter(self):
        if self.camera.CounterEventSource.is_implemented() and self.camera.CounterEventSource.is_writable():
            self.camera.CounterEventSource.set(gx.GxCounterEventSourceEntry.LINE2)
        else:
            print("CounterEventSource is not implemented or not writable")

        if self.camera.CounterReset.is_implemented():
            self.camera.CounterReset.send_command()
        else:
            print("CounterReset is not implemented")

    def set_line3_to_strobe(self):
        # self.camera.StrobeSwitch.set(gx.GxSwitchEntry.ON)
        self.camera.LineSelector.set(gx.GxLineSelectorEntry.LINE3)
        self.camera.LineMode.set(gx.GxLineModeEntry.OUTPUT)
        self.camera.LineSource.set(gx.GxLineSourceEntry.STROBE)

    def set_line3_to_exposure_active(self):
        # self.camera.StrobeSwitch.set(gx.GxSwitchEntry.ON)
        self.camera.LineSelector.set(gx.GxLineSelectorEntry.LINE3)
        self.camera.LineMode.set(gx.GxLineModeEntry.OUTPUT)
        self.camera.LineSource.set(gx.GxLineSourceEntry.EXPOSURE_ACTIVE)

class Camera_Simulation(object):
    
    def __init__(self,sn=None,is_global_shutter=False,rotate_image_angle=None,flip_image=None):
        # many to be purged
        self.sn = sn
        self.is_global_shutter = is_global_shutter
        self.device_info_list = None
        self.device_index = 0
        self.camera = None
        self.is_color = None
        self.gamma_lut = None
        self.contrast_lut = None
        self.color_correction_param = None

        self.rotate_image_angle = rotate_image_angle
        self.flip_image = flip_image

        self.exposure_time = 0
        self.analog_gain = 0
        self.frame_ID = 0
        self.frame_ID_software = -1
        self.frame_ID_offset_hardware_trigger = 0
        self.timestamp = 0

        self.image_locked = False
        self.current_frame = None

        self.callback_is_enabled = False
        self.is_streaming = False

        self.GAIN_MAX = 24
        self.GAIN_MIN = 0
        self.GAIN_STEP = 1
        self.EXPOSURE_TIME_MS_MIN = 0.01
        self.EXPOSURE_TIME_MS_MAX = 4000

        self.trigger_mode = None
        self.pixel_size_byte = 1

        # below are values for IMX226 (MER2-1220-32U3M) - to make configurable 
        self.row_period_us = 10
        self.row_numbers = 3036
        self.exposure_delay_us_8bit = 650
        self.exposure_delay_us = self.exposure_delay_us_8bit*self.pixel_size_byte
        self.strobe_delay_us = self.exposure_delay_us + self.row_period_us*self.pixel_size_byte*(self.row_numbers-1)

        self.pixel_format = 'MONO8'

        self.is_live = False

        self.Width = 3000
        self.Height = 3000
        self.WidthMax = 4000
        self.HeightMax = 3000
        self.OffsetX = 0
        self.OffsetY = 0


    def open(self,index=0):
        pass

    def set_callback(self,function):
        self.new_image_callback_external = function

    def enable_callback(self):
        self.callback_is_enabled = True

    def disable_callback(self):
        self.callback_is_enabled = False

    def open_by_sn(self,sn):
        pass

    def close(self):
        pass

    def set_exposure_time(self,exposure_time):
        pass

    def update_camera_exposure_time(self):
        pass

    def set_analog_gain(self,analog_gain):
        pass

    def get_awb_ratios(self):
        pass

    def set_wb_ratios(self, wb_r=None, wb_g=None, wb_b=None):
        pass

    def set_balance_white_auto(self, value):
        pass

    def get_balance_white_auto(self):
        return 0

    def get_is_color(self):
        return False

    def start_streaming(self):
        self.frame_ID_software = 0

    def stop_streaming(self):
        pass

    def set_pixel_format(self,pixel_format):
        self.pixel_format = pixel_format
        print(pixel_format)
        self.frame_ID = 0

    def set_continuous_acquisition(self):
        pass

    def set_software_triggered_acquisition(self):
        pass

    def set_hardware_triggered_acquisition(self):
        pass

    def send_trigger(self):
        self.frame_ID = self.frame_ID + 1
        self.timestamp = time.time()
        if self.frame_ID == 1:
            if self.pixel_format == 'MONO8':
                self.current_frame = np.random.randint(255,size=(2000,2000),dtype=np.uint8)
                self.current_frame[901:1100,901:1100] = 200
            elif self.pixel_format == 'MONO12':
                self.current_frame = np.random.randint(4095,size=(2000,2000),dtype=np.uint16)
                self.current_frame[901:1100,901:1100] = 200*16
                self.current_frame = self.current_frame << 4
            elif self.pixel_format == 'MONO16':
                self.current_frame = np.random.randint(65535,size=(2000,2000),dtype=np.uint16)
                self.current_frame[901:1100,901:1100] = 200*256
        else:
            self.current_frame = np.roll(self.current_frame,10,axis=0)
            pass 
            # self.current_frame = np.random.randint(255,size=(768,1024),dtype=np.uint8)
        if self.new_image_callback_external is not None and self.callback_is_enabled:
            self.new_image_callback_external(self)

    def read_frame(self):
        return self.current_frame

    def _on_frame_callback(self, user_param, raw_image):
        pass

    def set_ROI(self,offset_x=None,offset_y=None,width=None,height=None):
        pass

    def reset_camera_acquisition_counter(self):
        pass

    def set_line3_to_strobe(self):
        pass

    def set_line3_to_exposure_active(self):
        pass

import control.RCM_API as RCM_API
import json

class NL5:
    
    def __init__(self):

        self.rcm = RCM_API.RCM_API()
        self.rcm.initialize_device(simulated=False)
        self.load_settings()

    def set_scan_amplitude(self,amplitude):
        self.scan_amplitude = amplitude
        self.rcm.set_float_parameter(self.rcm.AMPLITUDE_X,amplitude)

    def set_offset_x(self,offset_x):
        self.offset_x = offset_x
        self.rcm.set_float_parameter(self.rcm.OFFSET_SCAN_X,offset_x)

    def start_acquisition(self):
        ret = self.rcm.start_acquisition()

    def start_continuous_acquisition(self):
        self.rcm.start_acquisition()

    def stop_continuous_acquisition(self):
        self.rcm.stop_continuous_acquisition()

    def set_bypass(self, enabled):
        if enabled:
            self.rcm.set_bypass(1)
        else:
            self.rcm.set_bypass(0)

    def set_active_channel(self, channel):
        self.active_channel = channel
        for i in range(1, 5):
            self.rcm.set_integer_parameter(getattr(self.rcm, f'LASER_{i}_SELECTED'), 1 if i == channel else 0)

    def set_laser_power(self,channel,power):
        self.rcm.set_integer_parameter(getattr(self.rcm,f'LASER_{channel}_POWER'),power)

    def set_bypass_offset(self, offset):
        self.bypass_offset = offset
        self.rcm.set_float_parameter(self.rcm.BYPASS_OFFSET,offset)

    def set_line_speed(self,speed,save_setting=False):
        self.line_speed = speed
        self.rcm.set_integer_parameter(self.rcm.LINE_FREQUENCY,speed) # speed in mrad/s
        if save_setting:
            self.save_settings()

    def set_fov_x(self,fov_x):
        self.fov_x = fov_x
        self.rcm.set_integer_parameter(self.rcm.FIELD_OF_VIEW_X,fov_x)
        self.save_settings()

    def set_exposure_delay(self,exposure_delay_ms):
        self.exposure_delay_ms = exposure_delay_ms
        self.rcm.set_integer_parameter(self.rcm.EXPOSURE_DELAY,exposure_delay_ms)

    def load_settings(self):
        try:
            with open('NL5_settings.json', 'r') as file:
                settings = json.load(file)
                self.scan_amplitude = settings.get("scan_amplitude", 70.0)
                self.offset_x = settings.get("offset_x", 0.0)
                self.bypass_offset = settings.get("bypass_offset", 0.0)
                self.fov_x = settings.get("fov_x", 2048)
                self.exposure_delay_ms = settings.get("exposure_delay_ms", 30)
                self.line_speed = settings.get("line_speed", 3000)

        except FileNotFoundError:
            self.scan_amplitude = 70.0
            self.offset_x = 0.0
            self.bypass_offset = 0.0
            self.exposure_delay_ms = 30
            self.line_speed = 3000
            self.fov_x = 2048
    
    def save_settings(self):
        settings = {
            "scan_amplitude": self.scan_amplitude,
            "offset_x": self.offset_x,
            "bypass_offset": self.bypass_offset,
            "fov_x": self.fov_x,
            "exposure_delay_ms": self.exposure_delay_ms,
            "line_speed": self.line_speed
        }
        with open('NL5_settings.json', 'w') as file:
            json.dump(settings, file)


class NL5_Simulation:

    def __init__(self):
        self.load_settings()

    def set_scan_amplitude(self,amplitude):
        self.scan_amplitude = amplitude
        pass

    def set_offset_x(self,offset_x):
        self.offset_x = offset_x
        pass

    def start_acquisition(self):
        pass

    def start_continuous_acquisition(self):
        pass

    def stop_continuous_acquisition(self):
        pass

    def set_bypass(self, enabled):
        pass

    def set_active_channel(self, channel):
        pass

    def set_laser_power(self,channel,power):
        pass

    def set_bypass_offset(self, offset):
        self.bypass_offset = offset
        pass

    def set_line_speed(self,speed, save_setting = False):
        self.line_speed = speed
        if save_setting:
            self.save_settings()

    def set_fov_x(self,fov_x):
        self.fov_x = fov_x
        self.save_settings()

    def set_exposure_delay(self,exposure_delay_ms):
        self.exposure_delay_ms = exposure_delay_ms
        pass

    def load_settings(self):
        try:
            with open('NL5_settings.json', 'r') as file:
                settings = json.load(file)
                self.scan_amplitude = settings.get("scan_amplitude", 70.0)
                self.offset_x = settings.get("offset_x", 0.0)
                self.bypass_offset = settings.get("bypass_offset", 0.0)
                self.fov_x = settings.get("fov_x", 2048)
                self.exposure_delay_ms = settings.get("exposure_delay_ms", 30)
                self.line_speed = settings.get("line_speed", 3000)

        except FileNotFoundError:
            self.scan_amplitude = 70.0
            self.offset_x = 0.0
            self.bypass_offset = 0.0
            self.exposure_delay_ms = 30
            self.line_speed = 3000
            self.fov_x = 2048
    
    def save_settings(self):
        settings = {
            "scan_amplitude": self.scan_amplitude,
            "offset_x": self.offset_x,
            "bypass_offset": self.bypass_offset,
            "fov_x": self.fov_x,
            "exposure_delay_ms": self.exposure_delay_ms,
            "line_speed": self.line_speed
        }
        with open('NL5_settings.json', 'w') as file:
            json.dump(settings, file)
# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

import control.utils as utils
from control._def import *
import control.tracking as tracking
from control.core import *

from queue import Queue
from threading import Thread, Lock
import time
import numpy as np
import pyqtgraph as pg
import cv2
from datetime import datetime

from lxml import etree as ET
from pathlib import Path
import control.utils_config as utils_config

import math

class PlateReadingWorker(QObject):

    finished = Signal()
    image_to_display = Signal(np.ndarray)
    image_to_display_multi = Signal(np.ndarray,int)
    signal_current_configuration = Signal(Configuration)

    def __init__(self,plateReadingController):
        QObject.__init__(self)
        self.plateReadingController = plateReadingController

        self.camera = self.plateReadingController.camera
        self.microcontroller = self.plateReadingController.microcontroller
        self.plateReaderNavigationController = self.plateReadingController.plateReaderNavigationController
        self.liveController = self.plateReadingController.liveController
        self.autofocusController = self.plateReadingController.autofocusController
        self.configurationManager = self.plateReadingController.configurationManager
        self.NX = self.plateReadingController.NX
        self.NY = self.plateReadingController.NY
        self.NZ = self.plateReadingController.NZ
        self.Nt = self.plateReadingController.Nt
        self.deltaX = self.plateReadingController.deltaX
        self.deltaX_usteps = self.plateReadingController.deltaX_usteps
        self.deltaY = self.plateReadingController.deltaY
        self.deltaY_usteps = self.plateReadingController.deltaY_usteps
        self.deltaZ = self.plateReadingController.deltaZ
        self.deltaZ_usteps = self.plateReadingController.deltaZ_usteps
        self.dt = self.plateReadingController.deltat
        self.do_autofocus = self.plateReadingController.do_autofocus
        self.crop_width = self.plateReadingController.crop_width
        self.crop_height = self.plateReadingController.crop_height
        self.display_resolution_scaling = self.plateReadingController.display_resolution_scaling
        self.counter = self.plateReadingController.counter
        self.experiment_ID = self.plateReadingController.experiment_ID
        self.base_path = self.plateReadingController.base_path
        self.timestamp_acquisition_started = self.plateReadingController.timestamp_acquisition_started
        self.time_point = 0
        self.abort_acquisition_requested = False
        self.selected_configurations = self.plateReadingController.selected_configurations
        self.selected_columns = self.plateReadingController.selected_columns

    def run(self):
        self.abort_acquisition_requested = False
        self.plateReaderNavigationController.is_scanning = True
        while self.time_point < self.Nt and self.abort_acquisition_requested == False:
            # continous acquisition
            if self.dt == 0:
                self.run_single_time_point()
                self.time_point = self.time_point + 1
            # timed acquisition
            else:
                self.run_single_time_point()
                self.time_point = self.time_point + 1
                # check if the aquisition has taken longer than dt or integer multiples of dt, if so skip the next time point(s)
                while time.time() > self.timestamp_acquisition_started + self.time_point*self.dt:
                    print('skip time point ' + str(self.time_point+1))
                    self.time_point = self.time_point+1
                if self.time_point == self.Nt:
                    break # no waiting after taking the last time point
                # wait until it's time to do the next acquisition
                while time.time() < self.timestamp_acquisition_started + self.time_point*self.dt:
                    time.sleep(0.05)
        self.plateReaderNavigationController.is_scanning = False
        self.finished.emit()

    def wait_till_operation_is_completed(self):
        while self.microcontroller.is_busy():
            time.sleep(SLEEP_TIME_S)

    def run_single_time_point(self):
        self.FOV_counter = 0
        column_counter = 0
        print('multipoint acquisition - time point ' + str(self.time_point+1))
        
        # for each time point, create a new folder
        current_path = os.path.join(self.base_path,self.experiment_ID,str(self.time_point))
        os.mkdir(current_path)

        # run homing
        self.plateReaderNavigationController.home()
        self.wait_till_operation_is_completed()

        # row scan direction
        row_scan_direction = 1 # 1: A -> H, 0: H -> A

        # go through columns
        for column in self.selected_columns:
            
            # increament counter
            column_counter = column_counter + 1
            
            # move to the current column
            self.plateReaderNavigationController.moveto_column(column-1)
            self.wait_till_operation_is_completed()
            
            '''
            # row homing
            if column_counter > 1:
                self.plateReaderNavigationController.home_y()
                self.wait_till_operation_is_completed()
            '''
            
            # go through rows
            for row in range(PLATE_READER.NUMBER_OF_ROWS):

                if row_scan_direction == 0: # reverse scan:
                    row = PLATE_READER.NUMBER_OF_ROWS - 1 -row

                row_str = chr(ord('A')+row)
                file_ID = row_str + str(column)

                # move to the selected row
                self.plateReaderNavigationController.moveto_row(row)
                self.wait_till_operation_is_completed()
                time.sleep(SCAN_STABILIZATION_TIME_MS_Y/1000)
                
                # AF
                if (self.NZ == 1) and (self.do_autofocus) and (self.FOV_counter%Acquisition.NUMBER_OF_FOVS_PER_AF==0):
                    configuration_name_AF = 'BF LED matrix full'
                    config_AF = next((config for config in self.configurationManager.configurations if config.name == configuration_name_AF))
                    self.signal_current_configuration.emit(config_AF)
                    self.autofocusController.autofocus()
                    self.autofocusController.wait_till_autofocus_has_completed()

                # z stack
                for k in range(self.NZ):

                    if(self.NZ > 1):
                        # update file ID
                        file_ID = file_ID + '_' + str(k)
                        # maneuver for achiving uniform step size and repeatability when using open-loop control
                        self.plateReaderNavigationController.move_z_usteps(80)
                        self.wait_till_operation_is_completed()
                        self.plateReaderNavigationController.move_z_usteps(-80)
                        self.wait_till_operation_is_completed()
                        time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)

                    # iterate through selected modes
                    for config in self.selected_configurations:
                        self.signal_current_configuration.emit(config)
                        self.wait_till_operation_is_completed()
                        self.liveController.turn_on_illumination()
                        self.wait_till_operation_is_completed()
                        self.camera.send_trigger() 
                        image = self.camera.read_frame()
                        self.liveController.turn_off_illumination()
                        image = utils.crop_image(image,self.crop_width,self.crop_height)
                        saving_path = os.path.join(current_path, file_ID + '_' + str(config.name) + '.' + Acquisition.IMAGE_FORMAT)
                        # self.image_to_display.emit(cv2.resize(image,(round(self.crop_width*self.display_resolution_scaling), round(self.crop_height*self.display_resolution_scaling)),cv2.INTER_LINEAR))
                        # image_to_display = utils.crop_image(image,round(self.crop_width*self.liveController.display_resolution_scaling), round(self.crop_height*self.liveController.display_resolution_scaling))
                        image_to_display = utils.crop_image(image,round(self.crop_width), round(self.crop_height))
                        self.image_to_display.emit(image_to_display)
                        self.image_to_display_multi.emit(image_to_display,config.illumination_source)
                        if self.camera.is_color:
                            image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)
                        cv2.imwrite(saving_path,image)
                        QApplication.processEvents()

                    if(self.NZ > 1):
                        # move z
                        if k < self.NZ - 1:
                            self.plateReaderNavigationController.move_z_usteps(self.deltaZ_usteps)
                            self.wait_till_operation_is_completed()
                            time.sleep(SCAN_STABILIZATION_TIME_MS_Z/1000)

                if self.NZ > 1:
                    # move z back
                    self.plateReaderNavigationController.move_z_usteps(-self.deltaZ_usteps*(self.NZ-1))
                    self.wait_till_operation_is_completed()

                if self.abort_acquisition_requested:
                    return

            # update row scan direction
            row_scan_direction = 1 - row_scan_direction

class PlateReadingController(QObject):

    acquisitionFinished = Signal()
    image_to_display = Signal(np.ndarray)
    image_to_display_multi = Signal(np.ndarray,int)
    signal_current_configuration = Signal(Configuration)

    def __init__(self,camera,plateReaderNavigationController,liveController,autofocusController,configurationManager):
        QObject.__init__(self)

        self.camera = camera
        self.microcontroller = plateReaderNavigationController.microcontroller # to move to gui for transparency
        self.plateReaderNavigationController = plateReaderNavigationController
        self.liveController = liveController
        self.autofocusController = autofocusController
        self.configurationManager = configurationManager
        self.NX = 1
        self.NY = 1
        self.NZ = 1
        self.Nt = 1
        mm_per_ustep_X = SCREW_PITCH_X_MM/(self.plateReaderNavigationController.x_microstepping*FULLSTEPS_PER_REV_X)
        mm_per_ustep_Y = SCREW_PITCH_Y_MM/(self.plateReaderNavigationController.y_microstepping*FULLSTEPS_PER_REV_Y)
        mm_per_ustep_Z = SCREW_PITCH_Z_MM/(self.plateReaderNavigationController.z_microstepping*FULLSTEPS_PER_REV_Z)
        self.deltaX = Acquisition.DX
        self.deltaX_usteps = round(self.deltaX/mm_per_ustep_X)
        self.deltaY = Acquisition.DY
        self.deltaY_usteps = round(self.deltaY/mm_per_ustep_Y)
        self.deltaZ = Acquisition.DZ/1000
        self.deltaZ_usteps = round(self.deltaZ/mm_per_ustep_Z)
        self.deltat = 0
        self.do_autofocus = False
        self.crop_width = Acquisition.CROP_WIDTH
        self.crop_height = Acquisition.CROP_HEIGHT
        self.display_resolution_scaling = Acquisition.IMAGE_DISPLAY_SCALING_FACTOR
        self.counter = 0
        self.experiment_ID = None
        self.base_path = None
        self.selected_configurations = []
        self.selected_columns = []

    def set_NZ(self,N):
        self.NZ = N
    
    def set_Nt(self,N):
        self.Nt = N
    
    def set_deltaZ(self,delta_um):
        mm_per_ustep_Z = SCREW_PITCH_Z_MM/(self.plateReaderNavigationController.z_microstepping*FULLSTEPS_PER_REV_Z)
        self.deltaZ = delta_um/1000
        self.deltaZ_usteps = round((delta_um/1000)/mm_per_ustep_Z)
    
    def set_deltat(self,delta):
        self.deltat = delta
    
    def set_af_flag(self,flag):
        self.do_autofocus = flag

    def set_crop(self,crop_width,height):
        self.crop_width = crop_width
        self.crop_height = crop_height

    def set_base_path(self,path):
        self.base_path = path

    def start_new_experiment(self,experiment_ID): # @@@ to do: change name to prepare_folder_for_new_experiment
        # generate unique experiment ID
        self.experiment_ID = experiment_ID + '_' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S.%f')
        self.recording_start_time = time.time()
        # create a new folder
        try:
            os.mkdir(os.path.join(self.base_path,self.experiment_ID))
            self.configurationManager.write_configuration(os.path.join(self.base_path,self.experiment_ID)+"/configurations.xml") # save the configuration for the experiment
        except:
            pass

    def set_selected_configurations(self, selected_configurations_name):
        self.selected_configurations = []
        for configuration_name in selected_configurations_name:
            self.selected_configurations.append(next((config for config in self.configurationManager.configurations if config.name == configuration_name)))
    
    def set_selected_columns(self,selected_columns):
        selected_columns.sort()
        self.selected_columns = selected_columns

    def run_acquisition(self): # @@@ to do: change name to run_experiment
        print('start plate reading')
        # save the current microscope configuration
        self.configuration_before_running_multipoint = self.liveController.currentConfiguration
        # stop live
        if self.liveController.is_live:
            self.liveController.was_live_before_multipoint = True
            self.liveController.stop_live() # @@@ to do: also uncheck the live button
        else:
            self.liveController.was_live_before_multipoint = False
        # disable callback
        if self.camera.callback_is_enabled:
            self.camera.callback_was_enabled_before_multipoint = True
            self.camera.stop_streaming()
            self.camera.disable_callback()
            self.camera.start_streaming() # @@@ to do: absorb stop/start streaming into enable/disable callback - add a flag is_streaming to the camera class
        else:
            self.camera.callback_was_enabled_before_multipoint = False

        # run the acquisition
        self.timestamp_acquisition_started = time.time()
        # create a QThread object
        self.thread = QThread()
        # create a worker object
        self.plateReadingWorker = PlateReadingWorker(self)
        # move the worker to the thread
        self.plateReadingWorker.moveToThread(self.thread)
        # connect signals and slots
        self.thread.started.connect(self.plateReadingWorker.run)
        self.plateReadingWorker.finished.connect(self._on_acquisition_completed)
        self.plateReadingWorker.finished.connect(self.plateReadingWorker.deleteLater)
        self.plateReadingWorker.finished.connect(self.thread.quit)
        self.plateReadingWorker.image_to_display.connect(self.slot_image_to_display)
        self.plateReadingWorker.image_to_display_multi.connect(self.slot_image_to_display_multi)
        self.plateReadingWorker.signal_current_configuration.connect(self.slot_current_configuration,type=Qt.BlockingQueuedConnection)
        self.thread.finished.connect(self.thread.deleteLater)
        # start the thread
        self.thread.start()

    def stop_acquisition(self):
        self.plateReadingWorker.abort_acquisition_requested = True

    def _on_acquisition_completed(self):
        # restore the previous selected mode
        self.signal_current_configuration.emit(self.configuration_before_running_multipoint)

        # re-enable callback
        if self.camera.callback_was_enabled_before_multipoint:
            self.camera.stop_streaming()
            self.camera.enable_callback()
            self.camera.start_streaming()
            self.camera.callback_was_enabled_before_multipoint = False
        
        # re-enable live if it's previously on
        if self.liveController.was_live_before_multipoint:
            self.liveController.start_live()
        
        # emit the acquisition finished signal to enable the UI
        self.acquisitionFinished.emit()
        QApplication.processEvents()

    def slot_image_to_display(self,image):
        self.image_to_display.emit(image)

    def slot_image_to_display_multi(self,image,illumination_source):
        self.image_to_display_multi.emit(image,illumination_source)

    def slot_current_configuration(self,configuration):
        self.signal_current_configuration.emit(configuration)

#!/usr/bin/python
# -*- coding:utf-8 -*-
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-
#

GAMMA_MIN = 0.1
GAMMA_MAX = 10.0
CONTRAST_MIN = -50
CONTRAST_MAX = 100
UNSIGNED_INT_MAX = 0xFFFFFFFF
UNSIGNED_LONG_LONG_MAX = 0xFFFFFFFFFFFFFFFF


# frame state code
class GxFrameStatusList:
    SUCCESS = 0                 # Normal frame
    INCOMPLETE = -1             # Residual frame
    INVALID_IMAGE_INFO = -2     # invalid image info

    def __init__(self):
        pass


# Device type code
class GxDeviceClassList:
    UNKNOWN = 0                 # Unknown device type
    USB2 = 1                    # USB2.0 vision device
    GEV = 2                     # Gige vision device
    U3V = 3                     # USB3.0 vision device
    SMART = 4                   # Smart device

    def __init__(self):
        pass


class GxAccessMode:
    READONLY = 2                # Open the device in read-only mode
    CONTROL = 3                 # Open the device in controlled mode
    EXCLUSIVE = 4               # Open the device in exclusive mode

    def __init__(self):
        pass


class GxAccessStatus:
    UNKNOWN = 0                # The device's current status is unknown
    READWRITE = 1              # The device currently supports reading and writing
    READONLY = 2               # The device currently only supports reading
    NOACCESS = 3               # The device currently does neither support reading nor support writing

    def __init__(self):
        pass


class GxIPConfigureModeList:
    DHCP = 0x6                 # Enable the DHCP mode to allocate the IP address by the DHCP server
    LLA = 0x4                  # Enable the LLA mode to allocate the IP addresses
    STATIC_IP = 0x5            # Enable the static IP mode to configure the IP address
    DEFAULT = 0x7              # Enable the default mode to configure the IP address

    def __init__(self):
        pass


class GxPixelSizeEntry:
    BPP8 = 8
    BPP10 = 10
    BPP12 = 12
    BPP14 = 14
    BPP16 = 16
    BPP24 = 24
    BPP30 = 30
    BPP32 = 32
    BPP36 = 36
    BPP48 = 48
    BPP64 = 64

    def __init__(self):
        pass


class GxPixelColorFilterEntry:
    NONE = 0
    BAYER_RG = 1
    BAYER_GB = 2
    BAYER_GR = 3
    BAYER_BG = 4

    def __init__(self):
        pass


GX_PIXEL_MONO = 0x01000000
GX_PIXEL_COLOR = 0x02000000
GX_PIXEL_8BIT = 0x00080000
GX_PIXEL_10BIT = 0x000A0000
GX_PIXEL_12BIT = 0x000C0000
GX_PIXEL_16BIT = 0x00100000
GX_PIXEL_24BIT = 0x00180000
GX_PIXEL_30BIT = 0x001E0000
GX_PIXEL_32BIT = 0x00200000
GX_PIXEL_36BIT = 0x00240000
GX_PIXEL_48BIT = 0x00300000
GX_PIXEL_64BIT = 0x00400000


class GxPixelFormatEntry:
    UNDEFINED = 0
    MONO8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x0001)  # 0x1080001
    MONO8_SIGNED = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x0002)  # 0x1080002
    MONO10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0003)  # 0x1100003
    MONO12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0005)  # 0x1100005
    MONO14 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0025)  # 0x1100025
    MONO16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0007)  # 0x1100007
    BAYER_GR8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x0008)  # 0x1080008
    BAYER_RG8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x0009)  # 0x1080009
    BAYER_GB8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x000A)  # 0x108000A
    BAYER_BG8 = (GX_PIXEL_MONO | GX_PIXEL_8BIT | 0x000B)  # 0x108000B
    BAYER_GR10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x000C)  # 0x110000C
    BAYER_RG10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x000D)  # 0x110000D
    BAYER_GB10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x000E)  # 0x110000E
    BAYER_BG10 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x000F)  # 0x110000F
    BAYER_GR12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0010)  # 0x1100010
    BAYER_RG12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0011)  # 0x1100011
    BAYER_GB12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0012)  # 0x1100012
    BAYER_BG12 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0013)  # 0x1100013
    BAYER_GR16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x002E)  # 0x110002E
    BAYER_RG16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x002F)  # 0x110002F
    BAYER_GB16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0030)  # 0x1100030
    BAYER_BG16 = (GX_PIXEL_MONO | GX_PIXEL_16BIT | 0x0031)  # 0x1100031
    RGB8_PLANAR = (GX_PIXEL_COLOR | GX_PIXEL_24BIT | 0x0021)  # 0x2180021
    RGB10_PLANAR = (GX_PIXEL_COLOR | GX_PIXEL_48BIT | 0x0022)  # 0x2300022
    RGB12_PLANAR = (GX_PIXEL_COLOR | GX_PIXEL_48BIT | 0x0023)  # 0x2300023
    RGB16_PLANAR = (GX_PIXEL_COLOR | GX_PIXEL_48BIT | 0x0024)  # 0x2300024

    def __init__(self):
        pass


class GxAcquisitionModeEntry:
    SINGLE_FRAME = 0
    MULITI_FRAME = 1
    CONTINUOUS = 2

    def __init__(self):
        pass


class GxTriggerSourceEntry:
    SOFTWARE = 0
    LINE0 = 1
    LINE1 = 2
    LINE2 = 3
    LINE3 = 4

    def __init__(self):
        pass


class GxTriggerActivationEntry:
    FALLING_EDGE = 0
    RISING_EDGE = 1

    def __init__(self):
        pass


class GxExposureModeEntry:
    TIMED = 1
    TRIGGER_WIDTH = 2

    def __init__(self):
        pass


class GxUserOutputSelectorEntry:
    OUTPUT0 = 1
    OUTPUT1 = 2
    OUTPUT2 = 4

    def __init__(self):
        pass


class GxUserOutputModeEntry:
    STROBE = 0
    USER_DEFINED = 1

    def __init__(self):
        pass


class GxGainSelectorEntry:
    ALL = 0
    RED = 1
    GREEN = 2
    BLUE = 3

    def __init__(self):
        pass


class GxBlackLevelSelectEntry:
    ALL = 0
    RED = 1
    GREEN = 2
    BLUE = 3

    def __init__(self):
        pass


class GxBalanceRatioSelectorEntry:
    RED = 0
    GREEN = 1
    BLUE = 2

    def __init__(self):
        pass


class GxAALightEnvironmentEntry:
    NATURE_LIGHT = 0
    AC50HZ = 1
    AC60HZ = 2

    def __init__(self):
        pass


class GxUserSetEntry:
    DEFAULT = 0
    USER_SET0 = 1

    def __init__(self):
        pass


class GxAWBLampHouseEntry:
    ADAPTIVE = 0
    D65 = 1
    FLUORESCENCE = 2
    INCANDESCENT = 3
    D75 = 4
    D50 = 5
    U30 = 6

    def __init__(self):
        pass


class GxTestPatternEntry:
    OFF = 0
    GRAY_FRAME_RAMP_MOVING = 1
    SLANT_LINE_MOVING = 2
    VERTICAL_LINE_MOVING = 3
    SLANT_LINE = 6

    def __init__(self):
        pass


class GxTriggerSelectorEntry:
    FRAME_START = 1
    FRAME_BURST_START = 2

    def __init__(self):
        pass


class GxLineSelectorEntry:
    LINE0 = 0
    LINE1 = 1
    LINE2 = 2
    LINE3 = 3

    def __init__(self):
        pass


class GxLineModeEntry:
    INPUT = 0
    OUTPUT = 1

    def __init__(self):
        pass


class GxLineSourceEntry:
    OFF = 0
    STROBE = 1
    USER_OUTPUT0 = 2
    USER_OUTPUT1 = 3
    USER_OUTPUT2 = 4
    EXPOSURE_ACTIVE = 5
    FRAME_TRIGGER_WAIT = 6
    ACQUISITION_TRIGGER_WAIT = 7

    def __init__(self):
        pass


class GxEventSelectorEntry:
    EXPOSURE_END = 0x0004
    BLOCK_DISCARD = 0x9000
    EVENT_OVERRUN = 0x9001
    FRAME_START_OVER_TRIGGER = 0x9002
    BLOCK_NOT_EMPTY = 0x9003
    INTERNAL_ERROR = 0x9004

    def __init__(self):
        pass


class GxLutSelectorEntry:
    LUMINANCE = 0

    def __init__(self):
        pass


class GxTransferControlModeEntry:
    BASIC = 0
    USER_CONTROLED = 1

    def __init__(self):
        pass


class GxTransferOperationModeEntry:
    MULTI_BLOCK = 0

    def __init__(self):
        pass


class GxTestPatternGeneratorSelectorEntry:
    SENSOR = 0          # Sensor test pattern
    REGION0 = 1         # FPGA test pattern

    def __init__(self):
        pass


class GxChunkSelectorEntry:
    FRAME_ID = 1
    TIME_STAMP = 2

    def __init__(self):
        pass


class GxBinningHorizontalModeEntry:
    SUM = 0
    AVERAGE = 1

    def __init__(self):
        pass


class GxBinningVerticalModeEntry:
    SUM = 0
    AVERAGE = 1

    def __init__(self):
        pass


class GxAcquisitionStatusSelectorEntry:
    ACQUISITION_TRIGGER_WAIT = 0
    FRAME_TRIGGER_WAIT = 1

    def __init__(self):
        pass


class GxGammaModeEntry:
    SRGB = 0
    USER = 1

    def __init__(self):
        pass


class GxColorTransformationModeEntry:
    RGB_TO_RGB = 0
    USER = 1

    def __init__(self):
        pass


class GxColorTransformationValueSelectorEntry:
    GAIN00 = 0
    GAIN01 = 1
    GAIN02 = 2
    GAIN10 = 3
    GAIN11 = 4
    GAIN12 = 5
    GAIN20 = 6
    GAIN21 = 7
    GAIN22 = 8

    def __init__(self):
        pass


class GxAutoEntry:
    OFF = 0
    CONTINUOUS = 1
    ONCE = 2

    def __init__(self):
        pass


class GxSwitchEntry:
    OFF = 0
    ON = 1

    def __init__(self):
        pass


class GxRegionSendModeEntry:
    SINGLE_ROI = 0
    MULTI_ROI = 1

    def __init__(self):
        pass


class GxRegionSelectorEntry:
    REGION0 = 0
    REGION1 = 1
    REGION2 = 2
    REGION3 = 3
    REGION4 = 4
    REGION5 = 5
    REGION6 = 6
    REGION7 = 7

    def __init__(self):
        pass


# image interpolation method
class DxBayerConvertType:
    NEIGHBOUR = 0                           # Neighborhood average interpolation algorithm
    ADAPTIVE = 1                            # Edge adaptive interpolation algorithm
    NEIGHBOUR3 = 2                          # The neighborhood average interpolation algorithm for a larger region

    def __init__(self):
        pass


# image valid bit
class DxValidBit:
    BIT0_7 = 0              # bit 0~7
    BIT1_8 = 1              # bit 1~8
    BIT2_9 = 2              # bit 2~9
    BIT3_10 = 3             # bit 3~10
    BIT4_11 = 4             # bit 4~11

    def __init__(self):
        pass


# image mirror method
class DxImageMirrorMode:
    HORIZONTAL_MIRROR = 0                               # Horizontal mirror
    VERTICAL_MIRROR = 1                                 # Vertical mirror

    def __init__(self):
        pass

import platform
import serial
import sys
import serial.tools.list_ports
import time
import numpy as np
import threading
from crc import CrcCalculator, Crc8

from control._def import *

from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# add user to the dialout group to avoid the need to use sudo

# done (7/20/2021) - remove the time.sleep in all functions (except for __init__) to 
# make all callable functions nonblocking, instead, user should check use is_busy() to
# check if the microcontroller has finished executing the more recent command

# to do (7/28/2021) - add functions for configuring the stepper motors

class Microcontroller():    
    def __init__(self,version='Arduino Due',sn=None,parent=None):
        self.serial = None
        self.platform_name = platform.system()
        self.tx_buffer_length = MicrocontrollerDef.CMD_LENGTH
        self.rx_buffer_length = MicrocontrollerDef.MSG_LENGTH

        self._cmd_id = 0
        self._cmd_id_mcu = None # command id of mcu's last received command 
        self._cmd_execution_status = None
        self.mcu_cmd_execution_in_progress = False

        self.x_pos = 0 # unit: microstep or encoder resolution
        self.y_pos = 0 # unit: microstep or encoder resolution
        self.z_pos = 0 # unit: microstep or encoder resolution
        self.theta_pos = 0 # unit: microstep or encoder resolution
        self.button_and_switch_state = 0
        self.joystick_button_pressed = 0
        self.signal_joystick_button_pressed_event = False
        self.switch_state = 0

        self.last_command = None
        self.timeout_counter = 0
        self.last_command_timestamp = time.time()

        self.crc_calculator = CrcCalculator(Crc8.CCITT,table_based=True)
        self.retry = 0

        print('connecting to controller based on ' + version)

        if version =='Arduino Due':
            controller_ports = [p.device for p in serial.tools.list_ports.comports() if 'Arduino Due' == p.description] # autodetect - based on Deepak's code
        else:
            if sn is not None:
                controller_ports = [ p.device for p in serial.tools.list_ports.comports() if sn == p.serial_number]
            else:
                if sys.platform == 'win32':
                    controller_ports = [ p.device for p in serial.tools.list_ports.comports() if p.manufacturer == 'Microsoft']
                else:
                    controller_ports = [ p.device for p in serial.tools.list_ports.comports() if p.manufacturer == 'Teensyduino']

        if not controller_ports:
            raise IOError("no controller found")
        if len(controller_ports) > 1:
            print('multiple controller found - using the first')
        
        self.serial = serial.Serial(controller_ports[0],2000000)
        time.sleep(0.2)
        print('controller connected')

        self.new_packet_callback_external = None
        self.terminate_reading_received_packet_thread = False
        self.thread_read_received_packet = threading.Thread(target=self.read_received_packet, daemon=True)
        self.thread_read_received_packet.start()
        
    def close(self):
        self.terminate_reading_received_packet_thread = True
        self.thread_read_received_packet.join()
        self.serial.close()

    def reset(self):
        self._cmd_id = 0
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.RESET
        self.send_command(cmd)
        print('reset the microcontroller') # debug

    def initialize_drivers(self):
        self._cmd_id = 0
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.INITIALIZE
        self.send_command(cmd)
        print('initialize the drivers') # debug

    def turn_on_illumination(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.TURN_ON_ILLUMINATION
        self.send_command(cmd)

    def turn_off_illumination(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.TURN_OFF_ILLUMINATION
        self.send_command(cmd)

    def set_illumination(self,illumination_source,intensity,r=None,g=None,b=None):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_ILLUMINATION
        cmd[2] = illumination_source
        cmd[3] = int((intensity/100)*65535) >> 8
        cmd[4] = int((intensity/100)*65535) & 0xff
        self.send_command(cmd)

    def set_illumination_led_matrix(self,illumination_source,r,g,b):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_ILLUMINATION_LED_MATRIX
        cmd[2] = illumination_source
        cmd[3] = min(int(r*255),255)
        cmd[4] = min(int(g*255),255)
        cmd[5] = min(int(b*255),255)
        self.send_command(cmd)

    def send_hardware_trigger(self,control_illumination=False,illumination_on_time_us=0,trigger_output_ch=0):
        illumination_on_time_us = int(illumination_on_time_us)
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SEND_HARDWARE_TRIGGER
        cmd[2] = (control_illumination<<7) + trigger_output_ch # MSB: whether illumination is controlled
        cmd[3] = illumination_on_time_us >> 24
        cmd[4] = (illumination_on_time_us >> 16) & 0xff
        cmd[5] = (illumination_on_time_us >> 8) & 0xff
        cmd[6] = illumination_on_time_us & 0xff
        self.send_command(cmd)

    def set_strobe_delay_us(self, strobe_delay_us, camera_channel=0):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_STROBE_DELAY
        cmd[2] = camera_channel
        cmd[3] = strobe_delay_us >> 24
        cmd[4] = (strobe_delay_us >> 16) & 0xff
        cmd[5] = (strobe_delay_us >> 8) & 0xff
        cmd[6] = strobe_delay_us & 0xff
        self.send_command(cmd)

    '''
    def move_x(self,delta):
        direction = int((np.sign(delta)+1)/2)
        n_microsteps = abs(delta*Motion.STEPS_PER_MM_XY)
        if n_microsteps > 65535:
            n_microsteps = 65535
        cmd = bytearray(self.tx_buffer_length)
        cmd[0] = CMD_SET.MOVE_X
        cmd[1] = direction
        cmd[2] = int(n_microsteps) >> 8
        cmd[3] = int(n_microsteps) & 0xff
        self.serial.write(cmd)
    '''

    def move_x_usteps(self,usteps):
        direction = STAGE_MOVEMENT_SIGN_X*np.sign(usteps)
        n_microsteps_abs = abs(usteps)
        # if n_microsteps_abs exceed the max value that can be sent in one go
        while n_microsteps_abs >= (2**32)/2:
            n_microsteps_partial_abs = (2**32)/2 - 1
            n_microsteps_partial = direction*n_microsteps_partial_abs
            payload = self._int_to_payload(n_microsteps_partial,4)
            cmd = bytearray(self.tx_buffer_length)
            cmd[1] = CMD_SET.MOVE_X
            cmd[2] = payload >> 24
            cmd[3] = (payload >> 16) & 0xff
            cmd[4] = (payload >> 8) & 0xff
            cmd[5] = payload & 0xff
            self.send_command(cmd)
            # while self.mcu_cmd_execution_in_progress == True:
            #     time.sleep(self._motion_status_checking_interval)
            n_microsteps_abs = n_microsteps_abs - n_microsteps_partial_abs

        n_microsteps = direction*n_microsteps_abs
        payload = self._int_to_payload(n_microsteps,4)
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.MOVE_X
        cmd[2] = payload >> 24
        cmd[3] = (payload >> 16) & 0xff
        cmd[4] = (payload >> 8) & 0xff
        cmd[5] = payload & 0xff
        self.send_command(cmd)
        # while self.mcu_cmd_execution_in_progress == True:
        #     time.sleep(self._motion_status_checking_interval)

    def move_x_to_usteps(self,usteps):
        payload = self._int_to_payload(usteps,4)
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.MOVETO_X
        cmd[2] = payload >> 24
        cmd[3] = (payload >> 16) & 0xff
        cmd[4] = (payload >> 8) & 0xff
        cmd[5] = payload & 0xff
        self.send_command(cmd)

    '''
    def move_y(self,delta):
        direction = int((np.sign(delta)+1)/2)
        n_microsteps = abs(delta*Motion.STEPS_PER_MM_XY)
        if n_microsteps > 65535:
            n_microsteps = 65535
        cmd = bytearray(self.tx_buffer_length)
        cmd[0] = CMD_SET.MOVE_Y
        cmd[1] = direction
        cmd[2] = int(n_microsteps) >> 8
        cmd[3] = int(n_microsteps) & 0xff
        self.serial.write(cmd)
    '''

    def move_y_usteps(self,usteps):
        direction = STAGE_MOVEMENT_SIGN_Y*np.sign(usteps)
        n_microsteps_abs = abs(usteps)
        # if n_microsteps_abs exceed the max value that can be sent in one go
        while n_microsteps_abs >= (2**32)/2:
            n_microsteps_partial_abs = (2**32)/2 - 1
            n_microsteps_partial = direction*n_microsteps_partial_abs
            payload = self._int_to_payload(n_microsteps_partial,4)
            cmd = bytearray(self.tx_buffer_length)
            cmd[1] = CMD_SET.MOVE_Y
            cmd[2] = payload >> 24
            cmd[3] = (payload >> 16) & 0xff
            cmd[4] = (payload >> 8) & 0xff
            cmd[5] = payload & 0xff
            self.send_command(cmd)
            # while self.mcu_cmd_execution_in_progress == True:
            #     time.sleep(self._motion_status_checking_interval)
            n_microsteps_abs = n_microsteps_abs - n_microsteps_partial_abs

        n_microsteps = direction*n_microsteps_abs
        payload = self._int_to_payload(n_microsteps,4)
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.MOVE_Y
        cmd[2] = payload >> 24
        cmd[3] = (payload >> 16) & 0xff
        cmd[4] = (payload >> 8) & 0xff
        cmd[5] = payload & 0xff
        self.send_command(cmd)
        # while self.mcu_cmd_execution_in_progress == True:
        #     time.sleep(self._motion_status_checking_interval)
    
    def move_y_to_usteps(self,usteps):
        payload = self._int_to_payload(usteps,4)
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.MOVETO_Y
        cmd[2] = payload >> 24
        cmd[3] = (payload >> 16) & 0xff
        cmd[4] = (payload >> 8) & 0xff
        cmd[5] = payload & 0xff
        self.send_command(cmd)

    '''
    def move_z(self,delta):
        direction = int((np.sign(delta)+1)/2)
        n_microsteps = abs(delta*Motion.STEPS_PER_MM_Z)
        if n_microsteps > 65535:
            n_microsteps = 65535
        cmd = bytearray(self.tx_buffer_length)
        cmd[0] = CMD_SET.MOVE_Z
        cmd[1] = 1-direction
        cmd[2] = int(n_microsteps) >> 8
        cmd[3] = int(n_microsteps) & 0xff
        self.serial.write(cmd)
    '''

    def move_z_usteps(self,usteps):
        direction = STAGE_MOVEMENT_SIGN_Z*np.sign(usteps)
        n_microsteps_abs = abs(usteps)
        # if n_microsteps_abs exceed the max value that can be sent in one go
        while n_microsteps_abs >= (2**32)/2:
            n_microsteps_partial_abs = (2**32)/2 - 1
            n_microsteps_partial = direction*n_microsteps_partial_abs
            payload = self._int_to_payload(n_microsteps_partial,4)
            cmd = bytearray(self.tx_buffer_length)
            cmd[1] = CMD_SET.MOVE_Z
            cmd[2] = payload >> 24
            cmd[3] = (payload >> 16) & 0xff
            cmd[4] = (payload >> 8) & 0xff
            cmd[5] = payload & 0xff
            self.send_command(cmd)
            # while self.mcu_cmd_execution_in_progress == True:
            #     time.sleep(self._motion_status_checking_interval)
            n_microsteps_abs = n_microsteps_abs - n_microsteps_partial_abs

        n_microsteps = direction*n_microsteps_abs
        payload = self._int_to_payload(n_microsteps,4)
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.MOVE_Z
        cmd[2] = payload >> 24
        cmd[3] = (payload >> 16) & 0xff
        cmd[4] = (payload >> 8) & 0xff
        cmd[5] = payload & 0xff
        self.send_command(cmd)
        # while self.mcu_cmd_execution_in_progress == True:
        #     time.sleep(self._motion_status_checking_interval)

    def move_z_to_usteps(self,usteps):
        payload = self._int_to_payload(usteps,4)
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.MOVETO_Z
        cmd[2] = payload >> 24
        cmd[3] = (payload >> 16) & 0xff
        cmd[4] = (payload >> 8) & 0xff
        cmd[5] = payload & 0xff
        self.send_command(cmd)

    def move_theta_usteps(self,usteps):
        direction = STAGE_MOVEMENT_SIGN_THETA*np.sign(usteps)
        n_microsteps_abs = abs(usteps)
        # if n_microsteps_abs exceed the max value that can be sent in one go
        while n_microsteps_abs >= (2**32)/2:
            n_microsteps_partial_abs = (2**32)/2 - 1
            n_microsteps_partial = direction*n_microsteps_partial_abs
            payload = self._int_to_payload(n_microsteps_partial,4)
            cmd = bytearray(self.tx_buffer_length)
            cmd[1] = CMD_SET.MOVE_THETA
            cmd[2] = payload >> 24
            cmd[3] = (payload >> 16) & 0xff
            cmd[4] = (payload >> 8) & 0xff
            cmd[5] = payload & 0xff
            self.send_command(cmd)
            # while self.mcu_cmd_execution_in_progress == True:
            #     time.sleep(self._motion_status_checking_interval)
            n_microsteps_abs = n_microsteps_abs - n_microsteps_partial_abs

        n_microsteps = direction*n_microsteps_abs
        payload = self._int_to_payload(n_microsteps,4)
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.MOVE_THETA
        cmd[2] = payload >> 24
        cmd[3] = (payload >> 16) & 0xff
        cmd[4] = (payload >> 8) & 0xff
        cmd[5] = payload & 0xff
        self.send_command(cmd)
        # while self.mcu_cmd_execution_in_progress == True:
        #     time.sleep(self._motion_status_checking_interval)

    def set_off_set_velocity_x(self,off_set_velocity):
        # off_set_velocity is in mm/s
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_OFFSET_VELOCITY
        cmd[2] = AXIS.X
        off_set_velocity = off_set_velocity*1000000
        payload = self._int_to_payload(off_set_velocity,4)
        cmd[3] = payload >> 24
        cmd[4] = (payload >> 16) & 0xff
        cmd[5] = (payload >> 8) & 0xff
        cmd[6] = payload & 0xff
        self.send_command(cmd)

    def set_off_set_velocity_y(self,off_set_velocity):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_OFFSET_VELOCITY
        cmd[2] = AXIS.Y
        off_set_velocity = off_set_velocity*1000000
        payload = self._int_to_payload(off_set_velocity,4)
        cmd[3] = payload >> 24
        cmd[4] = (payload >> 16) & 0xff
        cmd[5] = (payload >> 8) & 0xff
        cmd[6] = payload & 0xff
        self.send_command(cmd)

    def home_x(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.HOME_OR_ZERO
        cmd[2] = AXIS.X
        cmd[3] = int((STAGE_MOVEMENT_SIGN_X+1)/2) # "move backward" if SIGN is 1, "move forward" if SIGN is -1
        self.send_command(cmd)
        # while self.mcu_cmd_execution_in_progress == True:
        #     time.sleep(self._motion_status_checking_interval)
        #     # to do: add timeout

    def home_y(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.HOME_OR_ZERO
        cmd[2] = AXIS.Y
        cmd[3] = int((STAGE_MOVEMENT_SIGN_Y+1)/2) # "move backward" if SIGN is 1, "move forward" if SIGN is -1
        self.send_command(cmd)
        # while self.mcu_cmd_execution_in_progress == True:
        #     sleep(self._motion_status_checking_interval)
        #     # to do: add timeout

    def home_z(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.HOME_OR_ZERO
        cmd[2] = AXIS.Z
        cmd[3] = int((STAGE_MOVEMENT_SIGN_Z+1)/2) # "move backward" if SIGN is 1, "move forward" if SIGN is -1
        self.send_command(cmd)
        # while self.mcu_cmd_execution_in_progress == True:
        #     time.sleep(self._motion_status_checking_interval)
        #     # to do: add timeout

    def home_theta(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.HOME_OR_ZERO
        cmd[2] = 3
        cmd[3] = int((STAGE_MOVEMENT_SIGN_THETA+1)/2) # "move backward" if SIGN is 1, "move forward" if SIGN is -1
        self.send_command(cmd)
        # while self.mcu_cmd_execution_in_progress == True:
        #     time.sleep(self._motion_status_checking_interval)
        #     # to do: add timeout

    def home_xy(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.HOME_OR_ZERO
        cmd[2] = AXIS.XY
        cmd[3] = int((STAGE_MOVEMENT_SIGN_X+1)/2) # "move backward" if SIGN is 1, "move forward" if SIGN is -1
        cmd[4] = int((STAGE_MOVEMENT_SIGN_Y+1)/2) # "move backward" if SIGN is 1, "move forward" if SIGN is -1
        self.send_command(cmd)

    def zero_x(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.HOME_OR_ZERO
        cmd[2] = AXIS.X
        cmd[3] = HOME_OR_ZERO.ZERO
        self.send_command(cmd)
        # while self.mcu_cmd_execution_in_progress == True:
        #     time.sleep(self._motion_status_checking_interval)
        #     # to do: add timeout

    def zero_y(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.HOME_OR_ZERO
        cmd[2] = AXIS.Y
        cmd[3] = HOME_OR_ZERO.ZERO
        self.send_command(cmd)
        # while self.mcu_cmd_execution_in_progress == True:
        #     sleep(self._motion_status_checking_interval)
        #     # to do: add timeout

    def zero_z(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.HOME_OR_ZERO
        cmd[2] = AXIS.Z
        cmd[3] = HOME_OR_ZERO.ZERO
        self.send_command(cmd)
        # while self.mcu_cmd_execution_in_progress == True:
        #     time.sleep(self._motion_status_checking_interval)
        #     # to do: add timeout

    def zero_theta(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.HOME_OR_ZERO
        cmd[2] = AXIS.THETA
        cmd[3] = HOME_OR_ZERO.ZERO
        self.send_command(cmd)
        # while self.mcu_cmd_execution_in_progress == True:
        #     time.sleep(self._motion_status_checking_interval)
        #     # to do: add timeout

    def configure_stage_pid(self, axis, transitions_per_revolution, flip_direction=False):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.CONFIGURE_STAGE_PID
        cmd[2] = axis
        cmd[3] = int(flip_direction)
        payload = self._int_to_payload(transitions_per_revolution,2)
        cmd[4] = (payload >> 8) & 0xff
        cmd[5] = payload & 0xff
        self.send_command(cmd)

    def turn_on_stage_pid(self, axis):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.ENABLE_STAGE_PID
        cmd[2] = axis
        self.send_command(cmd)

    def turn_off_stage_pid(self, axis):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.DISABLE_STAGE_PID
        cmd[2] = axis
        self.send_command(cmd)

    def set_pid_arguments(self, axis, pid_p, pid_i, pid_d):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_PID_ARGUMENTS
        cmd[2] = int(axis)

        cmd[3] = (int(pid_p) >> 8) & 0xff
        cmd[4] = int(pid_p) & 0xff

        cmd[5] = int(pid_i)
        cmd[6] = int(pid_d)
        self.send_command(cmd)

    def set_lim(self,limit_code,usteps):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_LIM
        cmd[2] = limit_code
        payload = self._int_to_payload(usteps,4)
        cmd[3] = payload >> 24
        cmd[4] = (payload >> 16) & 0xff
        cmd[5] = (payload >> 8) & 0xff
        cmd[6] = payload & 0xff
        self.send_command(cmd)

    def set_limit_switch_polarity(self,axis,polarity):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_LIM_SWITCH_POLARITY
        cmd[2] = axis
        cmd[3] = polarity
        self.send_command(cmd)

    def set_home_safety_margin(self, axis, margin):
        margin = abs(margin)
        if margin > 0xFFFF:
            margin = 0xFFFF
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_HOME_SAFETY_MERGIN
        cmd[2] = axis
        cmd[3] = (margin >> 8) & 0xff
        cmd[4] = (margin) & 0xff
        self.send_command(cmd)

    def configure_motor_driver(self,axis,microstepping,current_rms,I_hold):
        # current_rms in mA
        # I_hold 0.0-1.0
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.CONFIGURE_STEPPER_DRIVER
        cmd[2] = axis
        if microstepping == 1:
            cmd[3] = 0
        elif microstepping == 256:
            cmd[3] = 255 # max of uint8 is 255 - will be changed to 255 after received by the MCU
        else:
            cmd[3] = microstepping
        cmd[4] = current_rms >> 8
        cmd[5] = current_rms & 0xff
        cmd[6] = int(I_hold*255)
        self.send_command(cmd)

    def set_max_velocity_acceleration(self,axis,velocity,acceleration):
        # velocity: max 65535/100 mm/s
        # acceleration: max 65535/10 mm/s^2
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_MAX_VELOCITY_ACCELERATION
        cmd[2] = axis
        cmd[3] = int(velocity*100) >> 8
        cmd[4] = int(velocity*100) & 0xff
        cmd[5] = int(acceleration*10) >> 8
        cmd[6] = int(acceleration*10) & 0xff
        self.send_command(cmd)

    def set_leadscrew_pitch(self,axis,pitch_mm):
        # pitch: max 65535/1000 = 65.535 (mm)
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_LEAD_SCREW_PITCH
        cmd[2] = axis
        cmd[3] = int(pitch_mm*1000) >> 8
        cmd[4] = int(pitch_mm*1000) & 0xff
        self.send_command(cmd)

    def configure_actuators(self):
        # lead screw pitch
        self.set_leadscrew_pitch(AXIS.X,SCREW_PITCH_X_MM)
        self.wait_till_operation_is_completed()
        self.set_leadscrew_pitch(AXIS.Y,SCREW_PITCH_Y_MM)
        self.wait_till_operation_is_completed()
        self.set_leadscrew_pitch(AXIS.Z,SCREW_PITCH_Z_MM)
        self.wait_till_operation_is_completed()
        # stepper driver (microstepping,rms current and I_hold)
        self.configure_motor_driver(AXIS.X,MICROSTEPPING_DEFAULT_X,X_MOTOR_RMS_CURRENT_mA,X_MOTOR_I_HOLD)
        self.wait_till_operation_is_completed()
        self.configure_motor_driver(AXIS.Y,MICROSTEPPING_DEFAULT_Y,Y_MOTOR_RMS_CURRENT_mA,Y_MOTOR_I_HOLD)
        self.wait_till_operation_is_completed()
        self.configure_motor_driver(AXIS.Z,MICROSTEPPING_DEFAULT_Z,Z_MOTOR_RMS_CURRENT_mA,Z_MOTOR_I_HOLD)
        self.wait_till_operation_is_completed()
        # max velocity and acceleration
        self.set_max_velocity_acceleration(AXIS.X,MAX_VELOCITY_X_mm,MAX_ACCELERATION_X_mm)
        self.wait_till_operation_is_completed()
        self.set_max_velocity_acceleration(AXIS.Y,MAX_VELOCITY_Y_mm,MAX_ACCELERATION_Y_mm)
        self.wait_till_operation_is_completed()
        self.set_max_velocity_acceleration(AXIS.Z,MAX_VELOCITY_Z_mm,MAX_ACCELERATION_Z_mm)
        self.wait_till_operation_is_completed()
        # home switch
        self.set_limit_switch_polarity(AXIS.X,X_HOME_SWITCH_POLARITY)
        self.wait_till_operation_is_completed()
        self.set_limit_switch_polarity(AXIS.Y,Y_HOME_SWITCH_POLARITY)
        self.wait_till_operation_is_completed()
        self.set_limit_switch_polarity(AXIS.Z,Z_HOME_SWITCH_POLARITY)
        self.wait_till_operation_is_completed()
        # home safety margin
        self.set_home_safety_margin(AXIS.X, int(X_HOME_SAFETY_MARGIN_UM))
        self.wait_till_operation_is_completed()
        self.set_home_safety_margin(AXIS.Y, int(Y_HOME_SAFETY_MARGIN_UM))
        self.wait_till_operation_is_completed()
        self.set_home_safety_margin(AXIS.Z, int(Z_HOME_SAFETY_MARGIN_UM))
        self.wait_till_operation_is_completed()

    def ack_joystick_button_pressed(self):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.ACK_JOYSTICK_BUTTON_PRESSED
        self.send_command(cmd)

    def analog_write_onboard_DAC(self,dac,value):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.ANALOG_WRITE_ONBOARD_DAC
        cmd[2] = dac
        cmd[3] = (value >> 8) & 0xff
        cmd[4] = value & 0xff
        self.send_command(cmd)

    def configure_dac80508_refdiv_and_gain(self, div, gains):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_DAC80508_REFDIV_GAIN
        cmd[2] = div
        cmd[3] = gains
        self.send_command(cmd)

    def set_pin_level(self,pin,level):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_PIN_LEVEL
        cmd[2] = pin
        cmd[3] = level
        self.send_command(cmd)

    def turn_on_AF_laser(self):
        self.set_pin_level(MCU_PINS.AF_LASER,1)

    def turn_off_AF_laser(self):
        self.set_pin_level(MCU_PINS.AF_LASER,0)

    def send_command(self,command):
        self._cmd_id = (self._cmd_id + 1)%256
        command[0] = self._cmd_id
        command[-1] = self.crc_calculator.calculate_checksum(command[:-1])
        self.serial.write(command)
        self.mcu_cmd_execution_in_progress = True
        self.last_command = command
        self.timeout_counter = 0
        self.last_command_timestamp = time.time()
        self.retry = 0

    def resend_last_command(self):
        self.serial.write(self.last_command)
        self.mcu_cmd_execution_in_progress = True
        self.timeout_counter = 0
        self.retry = self.retry + 1

    def read_received_packet(self):
        while self.terminate_reading_received_packet_thread == False:
            # wait to receive data
            if self.serial.in_waiting==0:
                continue
            if self.serial.in_waiting % self.rx_buffer_length != 0:
                continue
            
            # get rid of old data
            num_bytes_in_rx_buffer = self.serial.in_waiting
            if num_bytes_in_rx_buffer > self.rx_buffer_length:
                # print('getting rid of old data')
                for i in range(num_bytes_in_rx_buffer-self.rx_buffer_length):
                    self.serial.read()
            
            # read the buffer
            msg=[]
            for i in range(self.rx_buffer_length):
                msg.append(ord(self.serial.read()))

            # parse the message
            '''
            - command ID (1 byte)
            - execution status (1 byte)
            - X pos (4 bytes)
            - Y pos (4 bytes)
            - Z pos (4 bytes)
            - Theta (4 bytes)
            - buttons and switches (1 byte)
            - reserved (4 bytes)
            - CRC (1 byte)
            '''
            self._cmd_id_mcu = msg[0]
            self._cmd_execution_status = msg[1]
            if (self._cmd_id_mcu == self._cmd_id) and (self._cmd_execution_status == CMD_EXECUTION_STATUS.COMPLETED_WITHOUT_ERRORS):
                if self.mcu_cmd_execution_in_progress == True:
                    self.mcu_cmd_execution_in_progress = False
                    print('   mcu command ' + str(self._cmd_id) + ' complete')
            elif self._cmd_id_mcu != self._cmd_id and time.time() - self.last_command_timestamp > 5 and self.last_command != None:
                self.timeout_counter = self.timeout_counter + 1
                if self.timeout_counter > 10:
                    self.resend_last_command()
                    print('      *** resend the last command')
            elif self._cmd_execution_status == CMD_EXECUTION_STATUS.CMD_CHECKSUM_ERROR:
                print('! cmd checksum error, resending command')
                if self.retry > 10:
                    print('!! resending command failed for more than 10 times, the program will exit')
                    sys.exit(1)
                else:
                    self.resend_last_command()
            # print('command id ' + str(self._cmd_id) + '; mcu command ' + str(self._cmd_id_mcu) + ' status: ' + str(msg[1]) )

            self.x_pos = self._payload_to_int(msg[2:6],MicrocontrollerDef.N_BYTES_POS) # unit: microstep or encoder resolution
            self.y_pos = self._payload_to_int(msg[6:10],MicrocontrollerDef.N_BYTES_POS) # unit: microstep or encoder resolution
            self.z_pos = self._payload_to_int(msg[10:14],MicrocontrollerDef.N_BYTES_POS) # unit: microstep or encoder resolution
            self.theta_pos = self._payload_to_int(msg[14:18],MicrocontrollerDef.N_BYTES_POS) # unit: microstep or encoder resolution

            self.button_and_switch_state = msg[18]
            # joystick button
            tmp = self.button_and_switch_state & (1 << BIT_POS_JOYSTICK_BUTTON)
            joystick_button_pressed = tmp > 0
            if self.joystick_button_pressed == False and joystick_button_pressed == True:
                self.signal_joystick_button_pressed_event = True
                self.ack_joystick_button_pressed()
            self.joystick_button_pressed = joystick_button_pressed
            # switch
            tmp = self.button_and_switch_state & (1 << BIT_POS_SWITCH)
            self.switch_state = tmp > 0

            if self.new_packet_callback_external is not None:
                self.new_packet_callback_external(self)

    def get_pos(self):
        return self.x_pos, self.y_pos, self.z_pos, self.theta_pos

    def get_button_and_switch_state(self):
        return self.button_and_switch_state

    def is_busy(self):
        return self.mcu_cmd_execution_in_progress

    def set_callback(self,function):
        self.new_packet_callback_external = function

    def wait_till_operation_is_completed(self, TIMEOUT_LIMIT_S=5):
        timestamp_start = time.time()
        while self.is_busy():
            time.sleep(0.02)
            if time.time() - timestamp_start > TIMEOUT_LIMIT_S:
                print('Error - microcontroller timeout, the program will exit')
                sys.exit(1)

    def _int_to_payload(self,signed_int,number_of_bytes):
        if signed_int >= 0:
            payload = signed_int
        else:
            payload = 2**(8*number_of_bytes) + signed_int # find two's completement
        return payload

    def _payload_to_int(self,payload,number_of_bytes):
        signed = 0
        for i in range(number_of_bytes):
            signed = signed + int(payload[i])*(256**(number_of_bytes-1-i))
        if signed >= 256**number_of_bytes/2:
            signed = signed - 256**number_of_bytes
        return signed
    
    def set_dac80508_scaling_factor_for_illumination(self, illumination_intensity_factor):
        if illumination_intensity_factor > 1:
            illumination_intensity_factor = 1

        if illumination_intensity_factor < 0:
            illumination_intensity_factor = 0.01

        factor = round(illumination_intensity_factor, 2) * 100
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_ILLUMINATION_INTENSITY_FACTOR
        cmd[2] = int(factor)
        self.send_command(cmd)

class Microcontroller_Simulation():
    def __init__(self,parent=None):
        self.serial = None
        self.platform_name = platform.system()
        self.tx_buffer_length = MicrocontrollerDef.CMD_LENGTH
        self.rx_buffer_length = MicrocontrollerDef.MSG_LENGTH

        self._cmd_id = 0
        self._cmd_id_mcu = None # command id of mcu's last received command 
        self._cmd_execution_status = None
        self.mcu_cmd_execution_in_progress = False

        self.x_pos = 0 # unit: microstep or encoder resolution
        self.y_pos = 0 # unit: microstep or encoder resolution
        self.z_pos = 0 # unit: microstep or encoder resolution
        self.theta_pos = 0 # unit: microstep or encoder resolution
        self.button_and_switch_state = 0
        self.joystick_button_pressed = 0
        self.signal_joystick_button_pressed_event = False
        self.switch_state = 0

         # for simulation
        self.timestamp_last_command = time.time() # for simulation only
        self._mcu_cmd_execution_status = None
        self.timer_update_command_execution_status = QTimer()
        self.timer_update_command_execution_status.timeout.connect(self._simulation_update_cmd_execution_status)

        self.new_packet_callback_external = None
        self.terminate_reading_received_packet_thread = False
        self.thread_read_received_packet = threading.Thread(target=self.read_received_packet, daemon=True)
        self.thread_read_received_packet.start()

        self.crc_calculator = CrcCalculator(Crc8.CCITT,table_based=True)

    def close(self):
        self.terminate_reading_received_packet_thread = True
        self.thread_read_received_packet.join()

    def reset(self):
        self._cmd_id = 0
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.RESET
        self.send_command(cmd)

    def initialize_drivers(self):
        self._cmd_id = 0
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.INITIALIZE
        self.send_command(cmd)
        print('initialize the drivers') # debug

    def move_x_usteps(self,usteps):
        self.x_pos = self.x_pos + STAGE_MOVEMENT_SIGN_X*usteps
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': move x')

    def move_x_to_usteps(self,usteps):
        self.x_pos = usteps
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': move x to')

    def move_y_usteps(self,usteps):
        self.y_pos = self.y_pos + STAGE_MOVEMENT_SIGN_Y*usteps
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': move y')

    def move_y_to_usteps(self,usteps):
        self.y_pos = usteps
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': move y to')

    def move_z_usteps(self,usteps):
        self.z_pos = self.z_pos + STAGE_MOVEMENT_SIGN_Z*usteps
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': move z')

    def move_z_to_usteps(self,usteps):
        self.z_pos = usteps
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': move z to')

    def move_theta_usteps(self,usteps):
        self.theta_pos = self.theta_pos + usteps
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)

    def home_x(self):
        self.x_pos = 0
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': home x')

    def home_y(self):
        self.y_pos = 0
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': home y')

    def home_z(self):
        self.z_pos = 0
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': home z')

    def home_xy(self):
        self.x_pos = 0
        self.y_pos = 0
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': home xy')

    def home_theta(self):
        self.theta_pos = 0
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)

    def zero_x(self):
        self.x_pos = 0
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': zero x')

    def zero_y(self):
        self.y_pos = 0
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': zero y')

    def zero_z(self):
        self.z_pos = 0
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': zero z')

    def zero_theta(self):
        self.theta_pos = 0
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)

    def configure_stage_pid(self, axis, transitions_per_revolution, flip_direction=False):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.CONFIGURE_STAGE_PID
        cmd[2] = axis
        cmd[3] = int(flip_direction)
        payload = self._int_to_payload(transitions_per_revolution,2)
        cmd[4] = (payload >> 8) & 0xff
        cmd[5] = payload & 0xff
        self.send_command(cmd)

    def turn_on_stage_pid(self, axis):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.ENABLE_STAGE_PID
        cmd[2] = axis
        self.send_command(cmd)

    def turn_off_stage_pid(self, axis):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.DISABLE_STAGE_PID
        cmd[2] = axis
        self.send_command(cmd)

    def set_pid_arguments(self, axis, pid_p, pid_i, pid_d):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_PID_ARGUMENTS
        cmd[2] = int(axis)

        cmd[3] = (int(pid_p) >> 8) & 0xff
        cmd[4] = int(pid_p) & 0xff

        cmd[5] = int(pid_i)
        cmd[6] = int(pid_d)
        self.send_command(cmd)

    def set_lim(self,limit_code,usteps):
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)

    def configure_motor_driver(self,axis,microstepping,current_rms,I_hold):
        # current_rms in mA
        # I_hold 0.0-1.0
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.CONFIGURE_STEPPER_DRIVER
        cmd[2] = axis
        if microstepping == 1:
            cmd[3] = 0
        elif microstepping == 256:
            cmd[3] = 255 # max of uint8 is 255 - will be changed to 255 after received by the MCU
        else:
            cmd[3] = microstepping
        cmd[4] = current_rms >> 8
        cmd[5] = current_rms & 0xff
        cmd[6] = int(I_hold*255)
        self.send_command(cmd)

    def set_max_velocity_acceleration(self,axis,velocity,acceleration):
        # velocity: max 65535/100 mm/s
        # acceleration: max 65535/10 mm/s^2
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_MAX_VELOCITY_ACCELERATION
        cmd[2] = axis
        cmd[3] = int(velocity*100) >> 8
        cmd[4] = int(velocity*100) & 0xff
        cmd[5] = int(acceleration*10) >> 8
        cmd[6] = int(acceleration*10) & 0xff
        self.send_command(cmd)

    def set_leadscrew_pitch(self,axis,pitch_mm):
        # pitch: max 65535/1000 = 65.535 (mm)
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_LEAD_SCREW_PITCH
        cmd[2] = axis
        cmd[3] = int(pitch_mm*1000) >> 8
        cmd[4] = int(pitch_mm*1000) & 0xff
        self.send_command(cmd)

    def set_limit_switch_polarity(self,axis,polarity):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_LIM_SWITCH_POLARITY
        cmd[2] = axis
        cmd[3] = polarity
        self.send_command(cmd)

    def set_home_safety_margin(self, axis, margin):
        margin = abs(margin)
        if margin > 0xFFFF:
            margin = 0xFFFF
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_HOME_SAFETY_MERGIN
        cmd[2] = axis
        cmd[3] = (margin >> 8) & 0xff
        cmd[4] = (margin) & 0xff
        self.send_command(cmd)

    def configure_actuators(self):
        # lead screw pitch
        self.set_leadscrew_pitch(AXIS.X,SCREW_PITCH_X_MM)
        self.wait_till_operation_is_completed()
        self.set_leadscrew_pitch(AXIS.Y,SCREW_PITCH_Y_MM)
        self.wait_till_operation_is_completed()
        self.set_leadscrew_pitch(AXIS.Z,SCREW_PITCH_Z_MM)
        self.wait_till_operation_is_completed()
        # stepper driver (microstepping,rms current and I_hold)
        self.configure_motor_driver(AXIS.X,MICROSTEPPING_DEFAULT_X,X_MOTOR_RMS_CURRENT_mA,X_MOTOR_I_HOLD)
        self.wait_till_operation_is_completed()
        self.configure_motor_driver(AXIS.Y,MICROSTEPPING_DEFAULT_Y,Y_MOTOR_RMS_CURRENT_mA,Y_MOTOR_I_HOLD)
        self.wait_till_operation_is_completed()
        self.configure_motor_driver(AXIS.Z,MICROSTEPPING_DEFAULT_Z,Z_MOTOR_RMS_CURRENT_mA,Z_MOTOR_I_HOLD)
        self.wait_till_operation_is_completed()
        # max velocity and acceleration
        self.set_max_velocity_acceleration(AXIS.X,MAX_VELOCITY_X_mm,MAX_ACCELERATION_X_mm)
        self.wait_till_operation_is_completed()
        self.set_max_velocity_acceleration(AXIS.Y,MAX_VELOCITY_Y_mm,MAX_ACCELERATION_Y_mm)
        self.wait_till_operation_is_completed()
        self.set_max_velocity_acceleration(AXIS.Z,MAX_VELOCITY_Z_mm,MAX_ACCELERATION_Z_mm)
        self.wait_till_operation_is_completed()
        # home switch
        self.set_limit_switch_polarity(AXIS.X,X_HOME_SWITCH_POLARITY)
        self.wait_till_operation_is_completed()
        self.set_limit_switch_polarity(AXIS.Y,Y_HOME_SWITCH_POLARITY)
        self.wait_till_operation_is_completed()
        self.set_limit_switch_polarity(AXIS.Z,Z_HOME_SWITCH_POLARITY)
        self.wait_till_operation_is_completed()
        # home safety margin
        self.set_home_safety_margin(AXIS.X, int(X_HOME_SAFETY_MARGIN_UM))
        self.wait_till_operation_is_completed()
        self.set_home_safety_margin(AXIS.Y, int(Y_HOME_SAFETY_MARGIN_UM))
        self.wait_till_operation_is_completed()
        self.set_home_safety_margin(AXIS.Z, int(Z_HOME_SAFETY_MARGIN_UM))
        self.wait_till_operation_is_completed()

    def analog_write_onboard_DAC(self,dac,value):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.ANALOG_WRITE_ONBOARD_DAC
        cmd[2] = dac
        cmd[3] = (value >> 8) & 0xff
        cmd[4] = value & 0xff
        self.send_command(cmd)

    def configure_dac80508_refdiv_and_gain(self, div, gains):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_DAC80508_REFDIV_GAIN
        cmd[2] = div
        cmd[3] = gains
        self.send_command(cmd)

    def read_received_packet(self):
        while self.terminate_reading_received_packet_thread == False:
            # only for simulation - update the command execution status
            if time.time() - self.timestamp_last_command > 0.05: # in the simulation, assume all the operation takes 0.05s to complete
                if self._mcu_cmd_execution_status !=  CMD_EXECUTION_STATUS.COMPLETED_WITHOUT_ERRORS:
                    self._mcu_cmd_execution_status = CMD_EXECUTION_STATUS.COMPLETED_WITHOUT_ERRORS
                    print('   mcu command ' + str(self._cmd_id) + ' complete')

            # read and parse message
            msg=[]
            for i in range(self.rx_buffer_length):
                msg.append(0)

            msg[0] = self._cmd_id
            msg[1] = self._mcu_cmd_execution_status

            self._cmd_id_mcu = msg[0]
            self._cmd_execution_status = msg[1]
            if (self._cmd_id_mcu == self._cmd_id) and (self._cmd_execution_status == CMD_EXECUTION_STATUS.COMPLETED_WITHOUT_ERRORS):
                self.mcu_cmd_execution_in_progress = False
            # print('mcu_cmd_execution_in_progress: ' + str(self.mcu_cmd_execution_in_progress))
            
            # self.x_pos = utils.unsigned_to_signed(msg[2:6],MicrocontrollerDef.N_BYTES_POS) # unit: microstep or encoder resolution
            # self.y_pos = utils.unsigned_to_signed(msg[6:10],MicrocontrollerDef.N_BYTES_POS) # unit: microstep or encoder resolution
            # self.z_pos = utils.unsigned_to_signed(msg[10:14],MicrocontrollerDef.N_BYTES_POS) # unit: microstep or encoder resolution
            # self.theta_pos = utils.unsigned_to_signed(msg[14:18],MicrocontrollerDef.N_BYTES_POS) # unit: microstep or encoder resolution
            
            self.button_and_switch_state = msg[18]

            if self.new_packet_callback_external is not None:
                self.new_packet_callback_external(self)

            time.sleep(0.005) # simulate MCU packet transmission interval

    def turn_on_illumination(self):
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': turn on illumination')

    def turn_off_illumination(self):
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': turn off illumination')

    def set_illumination(self,illumination_source,intensity):
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': set illumination')

    def set_illumination_led_matrix(self,illumination_source,r,g,b):
        cmd = bytearray(self.tx_buffer_length)
        self.send_command(cmd)
        print('   mcu command ' + str(self._cmd_id) + ': set illumination (led matrix)')

    def send_hardware_trigger(self,control_illumination=False,illumination_on_time_us=0,trigger_output_ch = 0):
        illumination_on_time_us = int(illumination_on_time_us)
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SEND_HARDWARE_TRIGGER
        cmd[2] = (control_illumination<<7) + trigger_output_ch # MSB: whether illumination is controlled
        cmd[3] = illumination_on_time_us >> 24
        cmd[4] = (illumination_on_time_us >> 16) & 0xff
        cmd[5] = (illumination_on_time_us >> 8) & 0xff
        cmd[6] = illumination_on_time_us & 0xff
        self.send_command(cmd)

    def set_strobe_delay_us(self, strobe_delay_us, camera_channel=0):
        print('set strobe delay')
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_STROBE_DELAY
        cmd[2] = camera_channel
        cmd[3] = strobe_delay_us >> 24
        cmd[4] = (strobe_delay_us >> 16) & 0xff
        cmd[5] = (strobe_delay_us >> 8) & 0xff
        cmd[6] = strobe_delay_us & 0xff
        self.send_command(cmd)

    def get_pos(self):
        return self.x_pos, self.y_pos, self.z_pos, self.theta_pos

    def get_button_and_switch_state(self):
        return self.button_and_switch_state

    def set_callback(self,function):
        self.new_packet_callback_external = function

    def is_busy(self):
        return self.mcu_cmd_execution_in_progress

    def set_pin_level(self,pin,level):
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_PIN_LEVEL
        cmd[2] = pin
        cmd[3] = level
        self.send_command(cmd)

    def turn_on_AF_laser(self):
        self.set_pin_level(MCU_PINS.AF_LASER,1)

    def turn_off_AF_laser(self):
        self.set_pin_level(MCU_PINS.AF_LASER,0)

    def send_command(self,command):
        self._cmd_id = (self._cmd_id + 1)%256
        command[0] = self._cmd_id
        command[-1] = self.crc_calculator.calculate_checksum(command[:-1])
        self.mcu_cmd_execution_in_progress = True
        # for simulation
        self._mcu_cmd_execution_status = CMD_EXECUTION_STATUS.IN_PROGRESS
        # self.timer_update_command_execution_status.setInterval(2000)
        # self.timer_update_command_execution_status.start()
        # print('start timer')
        # timer cannot be started from another thread
        self.timestamp_last_command = time.time()

    def _simulation_update_cmd_execution_status(self):
        # print('simulation - MCU command execution finished')
        # self._mcu_cmd_execution_status = CMD_EXECUTION_STATUS.COMPLETED_WITHOUT_ERRORS
        # self.timer_update_command_execution_status.stop()
        pass # timer cannot be started from another thread

    def wait_till_operation_is_completed(self, TIMEOUT_LIMIT_S=5):
        timestamp_start = time.time()
        while self.is_busy():
            time.sleep(0.02)
            if time.time() - timestamp_start > TIMEOUT_LIMIT_S:
                print('Error - microcontroller timeout, the program will exit')
                sys.exit(1)

    def set_dac80508_scaling_factor_for_illumination(self, illumination_intensity_factor):
        if illumination_intensity_factor > 1:
            illumination_intensity_factor = 1

        if illumination_intensity_factor < 0:
            illumination_intensity_factor = 0.01

        factor = illumination_intensity_factor * 100
        cmd = bytearray(self.tx_buffer_length)
        cmd[1] = CMD_SET.SET_ILLUMINATION_INTENSITY_FACTOR
        cmd[2] = int(factor)
        self.send_command(cmd)

﻿#!/usr/bin/python
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-
# -*- coding:utf-8 -*-

from ctypes import *
import sys


if sys.platform == 'linux2' or sys.platform == 'linux':
    try:
        dll = CDLL('/usr/lib/libgxiapi.so')
    except OSError:
        print("Cannot find libgxiapi.so.")
else:
    try:
        if (sys.version_info.major == 3 and sys.version_info.minor >= 8) or (sys.version_info.major > 3):
            dll = WinDLL('GxIAPI.dll', winmode=0)
        else:
            dll = WinDLL('GxIAPI.dll')
    except OSError:
        print('Cannot find GxIAPI.dll.')


# Error code
class GxStatusList:
    SUCCESS = 0	                # Success
    ERROR = -1                  # There is a unspecified internal error that is not expected to occur
    NOT_FOUND_TL = -2           # The TL library cannot be found
    NOT_FOUND_DEVICE = -3       # The device is not found
    OFFLINE = -4                # The current device is in a offline state
    INVALID_PARAMETER = -5      # Invalid parameter, Generally the pointer is NULL or the input IP and
                                # Other parameter formats are invalid
    INVALID_HANDLE = -6         # Invalid handle
    INVALID_CALL = -7           # The interface is invalid, which refers to software interface logic error
    INVALID_ACCESS = -8         # The function is currently inaccessible or the device access mode is incorrect
    NEED_MORE_BUFFER = -9       # The user request buffer is insufficient: the user input buffersize during
                                # the read operation is less than the actual need
    ERROR_TYPE = -10            # The type of FeatureID used by the user is incorrect,
                                # such as an integer interface using a floating-point function code
    OUT_OF_RANGE = -11          # The value written by the user is crossed
    NOT_IMPLEMENTED = -12       # This function is not currently supported
    NOT_INIT_API = -13          # There is no call to initialize the interface
    TIMEOUT = -14               # Timeout error
    REPEAT_OPENED = -1004       # The device has been opened

    def __init__(self):
        pass


class GxOpenMode:
    SN = 0	                   # Opens the device via a serial number
    IP = 1                     # Opens the device via an IP address
    MAC = 2                    # Opens the device via a MAC address
    INDEX = 3                  # Opens the device via a serial number(Start from 1)
    USER_ID = 4                # Opens the device via user defined ID

    def __init__(self):
        pass


class GxFrameMask:
    TYPE_MASK = 0xF0000000
    LEVEL_MASK = 0x0F000000
    
    def __init__(self):
        pass
    

class GxFeatureType:
    INT = 0x10000000            # Integer type
    FLOAT = 0X20000000          # Floating point type
    ENUM = 0x30000000           # Enum type
    BOOL = 0x40000000           # Boolean type
    STRING = 0x50000000         # String type
    BUFFER = 0x60000000         # Block data type
    COMMAND = 0x70000000        # Command type

    def __init__(self):
        pass


class GxFeatureLevel:
    REMOTE_DEV = 0x00000000     # RemoteDevice Layer
    TL = 0x01000000             # TL Layer
    IF = 0x02000000             # Interface Layer
    DEV = 0x03000000            # Device Layer
    DS = 0x04000000             # DataStream Layer

    def __init__(self):
        pass


class GxFeatureID:
    # ---------------Device Information Section---------------------------
    STRING_DEVICE_VENDOR_NAME = 0x50000000                 # The name of the device's vendor
    STRING_DEVICE_MODEL_NAME = 0x50000001                  # The model name of the device
    STRING_DEVICE_FIRMWARE_VERSION = 0x50000002            # The version of the device's firmware and software
    STRING_DEVICE_VERSION = 0x50000003                     # The version of the device
    STRING_DEVICE_SERIAL_NUMBER = 0x50000004               # A serial number for device
    STRING_FACTORY_SETTING_VERSION = 0x50000006            # The version of the device's Factory Setting
    STRING_DEVICE_USER_ID = 0x50000007                     # A user programmable string
    INT_DEVICE_LINK_SELECTOR = 0x10000008                  # Selects which Link of the device to control
    ENUM_DEVICE_LINK_THROUGHPUT_LIMIT_MODE = 0x30000009    # DeviceLinkThroughputLimit switch
    INT_DEVICE_LINK_THROUGHPUT_LIMIT = 0x1000000a          # Limits the maximum bandwidth of the data
    INT_DEVICE_LINK_CURRENT_THROUGHPUT = 0x1000000b        # Current bandwidth of the data
    COMMAND_DEVICE_RESET = 0x7000000c                      # Device reset
    INT_TIMESTAMP_TICK_FREQUENCY = 0x1000000d              # Timestamp tick frequency
    COMMAND_TIMESTAMP_LATCH = 0x7000000e                   # Timestamp latch
    COMMAND_TIMESTAMP_RESET = 0x7000000f                   # Timestamp reset
    COMMAND_TIMESTAMP_LATCH_RESET = 0x70000010             # Timestamp latch reset
    INT_TIMESTAMP_LATCH_VALUE = 0x10000011                 # The value of timestamp latch

    # ---------------ImageFormat Section----------------------------------
    INT_SENSOR_WIDTH = 0x100003e8                           # The actual width of the camera's sensor in pixels
    INT_SENSOR_HEIGHT = 0x100003e9                          # The actual height of the camera's sensor in pixels
    INT_WIDTH_MAX = 0x100003ea                              # Width max[read_only]
    INT_HEIGHT_MAX = 0x100003eb                             # Height max[read_only]
    INT_OFFSET_X = 0x100003ec                               # The X offset for the area of interest
    INT_OFFSET_Y = 0x100003ed                               # The Y offset for the area of interest
    INT_WIDTH = 0x100003ee                                  # the width of the area of interest in pixels
    INT_HEIGHT = 0x100003ef                                 # the height of the area of interest in pixels
    INT_BINNING_HORIZONTAL = 0x100003f0                     # Horizontal pixel Binning
    INT_BINNING_VERTICAL = 0x100003f1                       # Vertical pixel Binning
    INT_DECIMATION_HORIZONTAL = 0x100003f2                  # Horizontal pixel sampling
    INT_DECIMATION_VERTICAL = 0x100003f3                    # Vertical pixel sampling
    ENUM_PIXEL_SIZE = 0x300003f4                            # Pixel depth, Reference GxPixelSizeEntry
    ENUM_PIXEL_COLOR_FILTER = 0x300003f5                    # Bayer format, Reference GxPixelColorFilterEntry
    ENUM_PIXEL_FORMAT = 0x300003f6                          # Pixel format, Reference GxPixelFormatEntry
    BOOL_REVERSE_X = 0x400003f7                             # Horizontal flipping
    BOOL_REVERSE_Y = 0x400003f8                             # Vertical flipping
    ENUM_TEST_PATTERN = 0x300003f9                          # Test pattern, Reference GxTestPatternEntry
    ENUM_TEST_PATTERN_GENERATOR_SELECTOR = 0x300003fa       # The source of test pattern, reference GxTestPatternGeneratorSelectorEntry
    ENUM_REGION_SEND_MODE = 0x300003fb                      # ROI region output mode, reference GxRegionSendModeEntry
    ENUM_REGION_MODE = 0x300003fc                           # ROI region output switch
    ENUM_REGION_SELECTOR = 0x300003fd                       # ROI region select, reference GxRegionSelectorEntry
    INT_CENTER_WIDTH = 0x100003fe                           # Window width
    INT_CENTER_HEIGHT = 0x100003ff                          # Window height
    ENUM_BINNING_HORIZONTAL_MODE = 0x30000400               # Binning horizontal mode
    ENUM_BINNING_VERTICAL_MODE = 0x30000401                 # Binning vertical mode

    # ---------------TransportLayer Section-------------------------------
    INT_PAYLOAD_SIZE = 0x100007d0                           # Size of images in byte
    BOOL_GEV_CURRENT_IP_CONFIGURATION_LLA = 0x400007d1      # IP configuration by LLA.
    BOOL_GEV_CURRENT_IP_CONFIGURATION_DHCP = 0x400007d2     # IP configuration by DHCP
    BOOL_GEV_CURRENT_IP_CONFIGURATION_PERSISTENT_IP = 0x400007d3   # IP configuration by PersistentIP
    INT_ESTIMATED_BANDWIDTH = 0x100007d4                    # Estimated Bandwidth in Bps
    INT_GEV_HEARTBEAT_TIMEOUT = 0x100007d5                  # The heartbeat timeout in milliseconds
    INT_GEV_PACKET_SIZE = 0x100007d6                        # The packet size in bytes for each packet
    INT_GEV_PACKET_DELAY = 0x100007d7                       # A delay between the transmission of each packet
    INT_GEV_LINK_SPEED = 0x100007d8                         # The connection speed in Mbps

    # ---------------AcquisitionTrigger Section---------------------------
    ENUM_ACQUISITION_MODE = 0x30000bb8                      # The mode of acquisition, Reference: GxAcquisitionModeEntry
    COMMAND_ACQUISITION_START = 0x70000bb9                  # The command for starts the acquisition of images
    COMMAND_ACQUISITION_STOP = 0x70000bba                   # The command for stop the acquisition of images
    INT_ACQUISITION_SPEED_LEVEL = 0x10000bbb                # The level for acquisition speed
    INT_ACQUISITION_FRAME_COUNT = 0x10000bbc
    ENUM_TRIGGER_MODE = 0x30000bbd                          # Trigger mode, Reference:GxTriggerModeEntry
    COMMAND_TRIGGER_SOFTWARE = 0x70000bbe                   # The command for generates a software trigger signal
    ENUM_TRIGGER_ACTIVATION = 0x30000bbf                    # Trigger polarity, Reference GxTriggerActivationEntry
    ENUM_TRIGGER_SWITCH = 0x30000bc0                        # The switch of External trigger
    FLOAT_EXPOSURE_TIME = 0x20000bc1                        # Exposure time
    ENUM_EXPOSURE_AUTO = 0x30000bc2                         # Exposure auto
    FLOAT_TRIGGER_FILTER_RAISING = 0x20000bc3               # The Value of rising edge triggered filter
    FLOAT_TRIGGER_FILTER_FALLING = 0x20000bc4               # The Value of falling edge triggered filter
    ENUM_TRIGGER_SOURCE = 0x30000bc5                        # Trigger source, Reference GxTriggerSourceEntry
    ENUM_EXPOSURE_MODE = 0x30000bc6                         # Exposure mode, Reference GxExposureModeEntry
    ENUM_TRIGGER_SELECTOR = 0x30000bc7                      # Trigger type, Reference GxTriggerSelectorEntry
    FLOAT_TRIGGER_DELAY = 0x20000bc8                        # The trigger delay in microsecond
    ENUM_TRANSFER_CONTROL_MODE = 0x30000bc9                 # The control method for the transfers, Reference GxTransferControlModeEntry
    ENUM_TRANSFER_OPERATION_MODE = 0x30000bca               # The operation method for the transfers, Reference GxTransferOperationModeEntry
    COMMAND_TRANSFER_START = 0x70000bcb                     # Starts the streaming of data blocks out of the device
    INT_TRANSFER_BLOCK_COUNT = 0x10000bcc                   # The number of data Blocks that the device should stream before stopping
    BOOL_FRAME_STORE_COVER_ACTIVE = 0x40000bcd              # The switch for frame cover
    ENUM_ACQUISITION_FRAME_RATE_MODE = 0x30000bce           # The switch for Control frame rate
    FLOAT_ACQUISITION_FRAME_RATE = 0x20000bcf               # The value for Control frame rate
    FLOAT_CURRENT_ACQUISITION_FRAME_RATE = 0x20000bd0       # The maximum allowed frame acquisition rate
    ENUM_FIXED_PATTERN_NOISE_CORRECT_MODE = 0x30000bd1      # The switch of fixed pattern noise correct
    INT_ACQUISITION_BURST_FRAME_COUNT = 0x10000bd6          # The acquisition burst frame count
    ENUM_ACQUISITION_STATUS_SELECTOR = 0x30000bd7           # The selector of acquisition status
    BOOL_ACQUISITION_STATUS = 0x40000bd8                    # The acquisition status
    FLOAT_EXPOSURE_DELAY = 0x2000765c                       # The exposure delay

    # ----------------DigitalIO Section-----------------------------------
    ENUM_USER_OUTPUT_SELECTOR = 0x30000fa0                  # selects user settable output signal, Reference GxUserOutputSelectorEntry
    BOOL_USER_OUTPUT_VALUE = 0x40000fa1                     # The state of the output signal
    ENUM_USER_OUTPUT_MODE = 0x30000fa2                      # UserIO output mode, Reference GxUserOutputModeEntry
    ENUM_STROBE_SWITCH = 0x30000fa3                         # Strobe switch
    ENUM_LINE_SELECTOR = 0x30000fa4                         # Line selector, Reference GxLineSelectorEntry
    ENUM_LINE_MODE = 0x30000fa5                             # Line mode, Reference GxLineModeEntry
    BOOL_LINE_INVERTER = 0x40000fa6                         # Pin level reversal
    ENUM_LINE_SOURCE = 0x30000fa7                           # line source, Reference GxLineSourceEntry
    BOOL_LINE_STATUS = 0x40000fa8                           # line status
    INT_LINE_STATUS_ALL = 0x10000fa9                        # all line status
    FLOAT_PULSE_WIDTH = 0x20000faa                          #

    # ----------------AnalogControls Section------------------------------
    ENUM_GAIN_AUTO = 0x30001388                             # gain auto, Reference GxGainAutoEntry
    ENUM_GAIN_SELECTOR = 0x30001389                         # selects gain channel, Reference GxGainSelectorEntry
    ENUM_BLACK_LEVEL_AUTO = 0x3000138b                      # Black level auto, Reference GxBlackLevelAutoEntry
    ENUM_BLACK_LEVEL_SELECTOR = 0x3000138c                  # Black level channel, Reference GxBlackLevelSelectEntry
    ENUM_BALANCE_WHITE_AUTO = 0x3000138e                    # Balance white auto, Reference GxBalanceWhiteAutoEntry
    ENUM_BALANCE_RATIO_SELECTOR = 0x3000138f                # selects Balance white channel, Reference GxBalanceRatioSelectorEntry
    FLOAT_BALANCE_RATIO = 0x20001390                        # Balance white channel ratio
    ENUM_COLOR_CORRECT = 0x30001391                         # Color correct, Reference GxColorCorrectEntry
    ENUM_DEAD_PIXEL_CORRECT = 0x30001392                    # Pixel correct, Reference GxDeadPixelCorrectEntry
    FLOAT_GAIN = 0x20001393                                 # gain
    FLOAT_BLACK_LEVEL = 0x20001394                          # Black level
    BOOL_GAMMA_ENABLE = 0x40001395                          # Gamma enable bit
    ENUM_GAMMA_MODE = 0x30001396                            # Gamma mode
    FLOAT_GAMMA = 0x20001397                                # The value of Gamma
    INT_DIGITAL_SHIFT = 0x10001398                          #

    # ---------------CustomFeature Section--------------------------------
    INT_ADC_LEVEL = 0x10001770                              # AD conversion level
    INT_H_BLANKING = 0x10001771                             # Horizontal blanking
    INT_V_BLANKING = 0x10001772                             # Vertical blanking
    STRING_USER_PASSWORD = 0x50001773                       # User encrypted zone cipher
    STRING_VERIFY_PASSWORD = 0x50001774                     # User encrypted zone check cipher
    BUFFER_USER_DATA = 0x60001775                           # User encrypted area content
    INT_GRAY_VALUE = 0x10001776                             # Expected gray value
    ENUM_AA_LIGHT_ENVIRONMENT = 0x30001777                  # Gain auto, Exposure auto, Light environment type,
                                                            # Reference GxAALightEnvironmentEntry
    INT_AAROI_OFFSETX = 0x10001778                          # The X offset for the rect of interest in pixels for 2A
    INT_AAROI_OFFSETY = 0x10001779                          # The Y offset for the rect of interest in pixels for 2A
    INT_AAROI_WIDTH = 0x1000177a                            # The width offset for the rect of interest in pixels for 2A
    INT_AAROI_HEIGHT = 0x1000177b                           # The height offset for the rect of interest in pixels for 2A
    FLOAT_AUTO_GAIN_MIN = 0x2000177c                        # Automatic gain minimum
    FLOAT_AUTO_GAIN_MAX = 0x2000177d                        # Automatic gain maximum
    FLOAT_AUTO_EXPOSURE_TIME_MIN = 0x2000177e               # Automatic exposure minimum
    FLOAT_AUTO_EXPOSURE_TIME_MAX = 0x2000177f               # Automatic exposure maximum
    BUFFER_FRAME_INFORMATION = 0x60001780                   # Image frame information
    INT_CONTRAST_PARAM = 0x10001781                         # Contrast parameter
    FLOAT_GAMMA_PARAM = 0x20001782                          # Gamma parameter
    INT_COLOR_CORRECTION_PARAM = 0x10001783                 # Color correction param
    ENUM_IMAGE_GRAY_RAISE_SWITCH = 0x30001784               # Image gray raise, Reference GxImageGrayRaiseSwitchEntry
    ENUM_AWB_LAMP_HOUSE = 0x30001785                        # Automatic white balance light source
                                                            # Reference GxAWBLampHouseEntry
    INT_AWBROI_OFFSETX = 0x10001786                         # Offset_X of automatic white balance region
    INT_AWBROI_OFFSETY = 0x10001787                         # Offset_Y of automatic white balance region
    INT_AWBROI_WIDTH = 0x10001788                           # Width of automatic white balance region
    INT_AWBROI_HEIGHT = 0x10001789                          # Height of automatic white balance region
    ENUM_SHARPNESS_MODE = 0x3000178a                        # Sharpness mode, Reference GxSharpnessModeEntry
    FLOAT_SHARPNESS = 0x2000178b                            # Sharpness

    # ---------------UserSetControl Section-------------------------------
    ENUM_USER_SET_SELECTOR = 0x30001b58                     # Parameter group selection, Reference GxUserSetSelectorEntry
    COMMAND_USER_SET_LOAD = 0x70001b59                      # Load parameter group
    COMMAND_USER_SET_SAVE = 0x70001b5a                      # Save parameter group
    ENUM_USER_SET_DEFAULT = 0x30001b5b                      # Startup parameter group, Reference GxUserSetDefaultEntry

    # ---------------Event Section----------------------------------------
    ENUM_EVENT_SELECTOR = 0x30001f40                        # Event source select, Reference GxEventSelectorEntry
    ENUM_EVENT_NOTIFICATION = 0x30001f41                    # Event enabled, Reference GxEventNotificationEntry
    INT_EVENT_EXPOSURE_END = 0x10001f42                     # Exposure end event
    INT_EVENT_EXPOSURE_END_TIMESTAMP = 0x10001f43           # The timestamp of Exposure end event
    INT_EVENT_EXPOSURE_END_FRAME_ID = 0x10001f44            # The frame id of Exposure end event
    INT_EVENT_BLOCK_DISCARD = 0x10001f45                    # Block discard event
    INT_EVENT_BLOCK_DISCARD_TIMESTAMP = 0x10001f46          # The timestamp of Block discard event
    INT_EVENT_OVERRUN = 0x10001f47                          # Event queue overflow event
    INT_EVENT_OVERRUN_TIMESTAMP = 0x10001f48                # The timestamp of event queue overflow event
    INT_EVENT_FRAME_START_OVER_TRIGGER = 0x10001f49         # Trigger signal shield event
    INT_EVENT_FRAME_START_OVER_TRIGGER_TIMESTAMP = 0x10001f4a   # The timestamp of trigger signal shield event
    INT_EVENT_BLOCK_NOT_EMPTY = 0x10001f4b                  # Frame memory not empty event
    INT_EVENT_BLOCK_NOT_EMPTY_TIMESTAMP = 0x10001f4c        # The timestamp of frame memory not empty event
    INT_EVENT_INTERNAL_ERROR = 0x10001f4d                   # Internal erroneous event
    INT_EVENT_INTERNAL_ERROR_TIMESTAMP = 0x10001f4e         # The timestamp of internal erroneous event

    # ---------------LUT Section------------------------------------------
    ENUM_LUT_SELECTOR = 0x30002328                          # Select lut, Reference GxLutSelectorEntry
    BUFFER_LUT_VALUE_ALL = 0x60002329                       # Lut data
    BOOL_LUT_ENABLE = 0x4000232a                            # Lut enable bit
    INT_LUT_INDEX = 0x1000232b                              # Lut index
    INT_LUT_VALUE = 0x1000232c                              # Lut value

    # ---------------Color Transformation Control-------------------------
    ENUM_COLOR_TRANSFORMATION_MODE = 0x30002af8             # Color transformation mode
    BOOL_COLOR_TRANSFORMATION_ENABLE = 0x40002af9           # Color transformation enable bit
    ENUM_COLOR_TRANSFORMATION_VALUE_SELECTOR = 0x30002afa   # The selector of color transformation value
    FLOAT_COLOR_TRANSFORMATION_VALUE = 0x20002afb           # The value of color transformation

    # ---------------ChunkData Section------------------------------------
    BOOL_CHUNK_MODE_ACTIVE = 0x40002711                     # Enable frame information
    ENUM_CHUNK_SELECTOR = 0x30002712                        # Select frame information channel, Reference GxChunkSelectorEntry
    BOOL_CHUNK_ENABLE = 0x40002713                          # Enable single frame information channel

    # ---------------Device Feature---------------------------------------
    INT_COMMAND_TIMEOUT = 0x13000000                        # The time of command timeout
    INT_COMMAND_RETRY_COUNT = 0x13000001                    # Command retry times

    # ---------------DataStream Feature-----------------------------------
    INT_ANNOUNCED_BUFFER_COUNT = 0x14000000                 # The number of Buffer declarations
    INT_DELIVERED_FRAME_COUNT = 0x14000001                  # Number of received frames (including remnant frames)
    INT_LOST_FRAME_COUNT = 0x14000002                       # Number of lost frames caused by buffer deficiency
    INT_INCOMPLETE_FRAME_COUNT = 0x14000003                 # Number of residual frames received
    INT_DELIVERED_PACKET_COUNT = 0x14000004                 # The number of packets received
    INT_RESEND_PACKET_COUNT = 0x14000005                    # Number of retransmission packages
    INT_RESCUED_PACKED_COUNT = 0x14000006                   # Retransmission success package number
    INT_RESEND_COMMAND_COUNT = 0x14000007                   # Retransmission command times
    INT_UNEXPECTED_PACKED_COUNT = 0x14000008                # Exception packet number
    INT_MAX_PACKET_COUNT_IN_ONE_BLOCK = 0x14000009          # Data block maximum retransmission number
    INT_MAX_PACKET_COUNT_IN_ONE_COMMAND = 0x1400000a        # The maximum number of packets contained in one command
    INT_RESEND_TIMEOUT = 0x1400000b                         # Retransmission timeout time
    INT_MAX_WAIT_PACKET_COUNT = 0x1400000c                  # Maximum waiting packet number
    ENUM_RESEND_MODE = 0x3400000d                           # Retransmission mode, Reference GxDSResendModeEntry
    INT_MISSING_BLOCK_ID_COUNT = 0x1400000e                 # BlockID lost number
    INT_BLOCK_TIMEOUT = 0x1400000f                          # Data block timeout time
    INT_STREAM_TRANSFER_SIZE = 0x14000010                   # Data block size
    INT_STREAM_TRANSFER_NUMBER_URB = 0x14000011             # Number of data blocks
    INT_MAX_NUM_QUEUE_BUFFER = 0x14000012                   # The maximum Buffer number of the collection queue
    INT_PACKET_TIMEOUT = 0x14000013                         # Packet timeout time

    def __init__(self):
        pass


class GxDeviceIPInfo(Structure):
    _fields_ = [
        ('device_id', c_char * 68),         # The unique identifier of the device.
        ('mac', c_char * 32),               # MAC address
        ('ip', c_char * 32),                # IP address
        ('subnet_mask', c_char * 32),       # Subnet mask
        ('gateway', c_char * 32),           # Gateway
        ('nic_mac', c_char * 32),           # The MAC address of the corresponding NIC(Network Interface Card).
        ('nic_ip', c_char * 32),            # The IP of the corresponding NIC
        ('nic_subnet_mask', c_char * 32),   # The subnet mask of the corresponding NIC
        ('nic_gateWay', c_char * 32),       # The Gateway of the corresponding NIC
        ('nic_description', c_char * 132),  # The description of the corresponding NIC
        ('reserved', c_char * 512),         # Reserved 512 bytes
    ]

    def __str__(self):
        return "GxDeviceIPInfo\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxDeviceBaseInfo(Structure):
    _fields_ = [
        ('vendor_name', c_char*32),         # Vendor name
        ('model_name', c_char*32),          # TModel name
        ('serial_number', c_char*32),       # Serial number
        ('display_name', c_char*132),       # Display name
        ('device_id', c_char*68),           # The unique identifier of the device.
        ('user_id', c_char*68),             # User's custom name
        ('access_status', c_int),           # Access status that is currently supported by the device
                                            # Refer to GxAccessStatus
        ('device_class', c_int),            # Device type. Such as USB2.0, GEV.
        ('reserved', c_char*300),           # Reserved 300 bytes
    ]

    def __str__(self):
        return "GxDeviceBaseInfo\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxOpenParam(Structure):
    _fields_ = [
        ('content',             c_char_p),
        ('open_mode',           c_uint),
        ('access_mode',         c_uint),
    ]

    def __str__(self):
        return "GxOpenParam\n%s" % "\n".join( "%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxFrameCallbackParam(Structure):
    _fields_ = [
        ('user_param_index',    c_void_p),      # User private data
        ('status',              c_int),         # The return state of the image
        ('image_buf',           c_void_p),      # Image buff address
        ('image_size',          c_int),         # Image data size, Including frame information
        ('width',               c_int),         # Image width
        ('height',              c_int),         # Image height
        ('pixel_format',        c_int),         # Image PixFormat
        ('frame_id',            c_ulonglong),   # The frame id of the image
        ('timestamp',           c_ulonglong),   # Time stamp of image
        ('reserved',            c_int),         # Reserved
    ]

    def __str__(self):
        return "GxFrameCallbackParam\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxFrameData(Structure):
    _fields_ = [
        ('status', c_int),                      # The return state of the image
        ('image_buf', c_void_p),                # Image buff address
        ('width', c_int),                       # Image width
        ('height', c_int),                      # Image height
        ('pixel_format', c_int),                # Image PixFormat
        ('image_size', c_int),                  # Image data size, Including frame information
        ('frame_id', c_ulonglong),              # The frame id of the image
        ('timestamp', c_ulonglong),             # Time stamp of image
        ('buf_id', c_ulonglong),                # Image buff ID
        ('reserved',  c_int),                   # Reserved
    ]

    def __str__(self):
        return "GxFrameData\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxIntRange(Structure):
    _fields_ = [
        ('min',                 c_ulonglong),
        ('max',                 c_ulonglong),
        ('inc',                 c_ulonglong),
        ('reserved',            c_int * 8),
    ]

    def __str__(self):
        return "GxIntRange\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxFloatRange(Structure):
    _fields_ = [
        ('min',                 c_double),
        ('max',                 c_double),
        ('inc',                 c_double),
        ('unit',                c_char * 8),
        ('inc_is_valid',        c_bool),
        ('reserved',            c_char * 31),
    ]

    def __str__(self):
        return "GxFloatRange\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


class GxEnumDescription(Structure):
    _fields_ = [
        ('value',               c_longlong),    # Enum value
        ('symbolic',            c_char * 64),   # Character description
        ('reserved',            c_int * 8),
    ]

    def __str__(self):
        return "GxEnumDescription\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


if hasattr(dll, 'GXInitLib'):
    def gx_init_lib():
        """
        :brief      Initialize the device library for some resource application operations
        :return:    None
        """
        return dll.GXInitLib()


if hasattr(dll, 'GXCloseLib'):
    def gx_close_lib():
        """
        :brief      Close the device library to release resources.
        :return:    None
        """
        return dll.GXCloseLib()


if hasattr(dll, 'GXGetLastError'):
    def gx_get_last_error(size=1024):
        """
        :brief      To get the latest error descriptions information of the program
        :param      size:           string buff length(size=1024)
                                    Type: Int, Minnum: 0
        :return:    status:         State return value, See detail in GxStatusList
                    err_code:       Return the last error code
                    err_content:    the latest error descriptions information of the program
        """
        err_code = c_int()
        err_content_buff = create_string_buffer(size)

        content_size = c_size_t()
        content_size.value = size

        status = dll.GXGetLastError(byref(err_code), byref(err_content_buff), byref(content_size))
        err_content = string_at(err_content_buff, content_size.value-1)

        return status, err_code.value, string_decoding(err_content)


if hasattr(dll, 'GXUpdateDeviceList'):
    def gx_update_device_list(time_out=200):
        """
        :brief      Enumerating currently all available devices in subnet and gets the number of devices.
        :param      time_out:           The timeout time of enumeration (unit: ms).
                                        Type: Int, Minimum:0
        :return:    status:             State return value, See detail in GxStatusList
                    device_num:         The number of devices
        """
        time_out_c = c_uint()
        time_out_c.value = time_out

        device_num = c_uint()
        status = dll.GXUpdateDeviceList(byref(device_num), time_out_c)
        return status, device_num.value


if hasattr(dll, 'GXUpdateAllDeviceList'):
    def gx_update_all_device_list(time_out=200):
        """
        :brief      Enumerating currently all available devices in entire network and gets the number of devices
        :param      time_out:           The timeout time of enumeration (unit: ms).
                                        Type: Int, Minimum: 0
        :return:    status:             State return value, See detail in GxStatusList
                    device_num:         The number of devices
        """
        time_out_c = c_uint()
        time_out_c.value = time_out

        device_num = c_uint()
        status = dll.GXUpdateAllDeviceList(byref(device_num), time_out_c)
        return status, device_num.value


if hasattr(dll, 'GXGetAllDeviceBaseInfo'):
    def gx_get_all_device_base_info(devices_num):
        """
        :brief      To get the basic information of all the devices
        :param      devices_num:        The number of devices
                                        Type: Int, Minimum: 0
        :return:    status:             State return value, See detail in GxStatusList
                    device_ip_info:     The structure pointer of the device information(GxDeviceIPInfo)
        """
        devices_info = (GxDeviceBaseInfo * devices_num)()

        buf_size_c = c_size_t()
        buf_size_c.value = sizeof(GxDeviceBaseInfo) * devices_num

        status = dll.GXGetAllDeviceBaseInfo(byref(devices_info), byref(buf_size_c))
        return status, devices_info
        

if hasattr(dll, 'GXGetDeviceIPInfo'):
    def gx_get_device_ip_info(index):
        """
        :brief      To get the network information of the device.
        :param      index:              Device index
                                        Type: Int, Minimum: 1
        :return:    status:             State return value, See detail in GxStatusList
                    device_ip_info:     The structure pointer of the device information(GxDeviceIPInfo)
        """
        index_c = c_uint()
        index_c.value = index

        device_ip_info = GxDeviceIPInfo()
        status = dll.GXGetDeviceIPInfo(index_c, byref(device_ip_info))

        return status, device_ip_info


if hasattr(dll, 'GXOpenDeviceByIndex'):
    def gx_open_device_by_index(index):
        """
        :brief      Open the device by a specific Index(1, 2, 3, ...)
        :param      index:          Device index
                                    Type: Int, Minimum: 1
        :return:    status:         State return value, See detail in GxStatusList
                    handle:         The device handle returned by the interface
        """
        index_c = c_uint()
        index_c.value = index

        handle_c = c_void_p()
        status = dll.GXOpenDeviceByIndex(index_c, byref(handle_c))
        return status, handle_c.value


if hasattr(dll, 'GXOpenDevice'):
    def gx_open_device(open_param):
        """
        :brief      Open the device by a specific unique identification, such as: SN, IP, MAC, Index etc.
        :param      open_param:     The open device parameter which is configurated by the user.
                                    Type: GxOpenParam
        :return:    status:         State return value, See detail in GxStatusList
                    handle:         The device handle returned by the interface
        """
        handle = c_void_p()
        status = dll.GXOpenDevice(byref(open_param), byref(handle))
        return status, handle.value


if hasattr(dll, 'GXCloseDevice'):
    def gx_close_device(handle):
        """
        :brief      Specify the device handle to close the device
        :param      handle:     The device handle that the user specified to close.
                                Type: Long, Greater than 0
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXCloseDevice(handle_c)
        return status

'''
if hasattr(dll, 'GXGetDevicePersistentIpAddress'):
    def gx_get_device_persistent_ip_address(handle, ip_length=16, subnet_mask_length=16, default_gateway_length=16):
        """
        :brief      Get the persistent IP information of the device
        :param      handle:                 The handle of the device
        :param      ip_length:              The character string length of the device persistent IP address.
        :param      subnet_mask_length:     The character string length of the device persistent subnet mask.
        :param      default_gateway_length: The character string length of the device persistent gateway
        :return:    status:                 State return value, See detail in GxStatusList
                    ip:                     The device persistent IP address(str)
                    subnet_mask:            The device persistent subnet mask(str)
                    default_gateway:        The device persistent gateway
        """
        handle_c = c_void_p()
        handle_c.value = handle

        ip_length_c = c_uint()
        ip_length_c.value = ip_length
        ip_c = create_string_buffer(ip_length)

        subnet_mask_length_c = c_uint()
        subnet_mask_length_c.value = subnet_mask_length
        subnet_mask_c = create_string_buffer(subnet_mask_length)

        default_gateway_length_c = c_uint()
        default_gateway_length_c.value = default_gateway_length
        default_gateway_c = create_string_buffer(default_gateway_length)

        status = dll.GXGetDevicePersistentIpAddress(handle_c, byref(ip_c), byref(ip_length_c),
                                                    byref(subnet_mask_c), byref(subnet_mask_length_c),
                                                    byref(default_gateway_c), byref(default_gateway_length_c))

        ip = string_at(ip_c, ip_length_c.value-1)
        subnet_mask = string_at(subnet_mask_c, subnet_mask_length_c.value-1)
        default_gateway = string_at(default_gateway_c, default_gateway_length_c.value-1)

        return status, string_decoding(ip), string_decoding(subnet_mask), string_decoding(default_gateway)

if hasattr(dll, 'GXSetDevicePersistentIpAddress'):
    def gx_set_device_persistent_ip_address(handle, ip, subnet_mask, default_gate_way):
        """
        :brief      Set the persistent IP information of the device
        :param      handle:             The handle of the device
        :param      ip:                 The persistent IP character string of the device(str)
        :param      subnet_mask:        The persistent subnet mask character string of the device(str)
        :param      default_gate_way:   The persistent gateway character string of the device(str)
        :return:    status:             State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        ip_c = create_string_buffer(string_encoding(ip))
        subnet_mask_c = create_string_buffer(string_encoding(subnet_mask))
        default_gate_way_c = create_string_buffer(string_encoding(default_gate_way))

        status = dll.GXSetDevicePersistentIpAddress(handle_c, byref(ip_c), byref(subnet_mask_c),
                                                    byref(default_gate_way_c))
        return status
'''

if hasattr(dll, 'GXGetFeatureName'):
    def gx_get_feature_name(handle, feature_id):
        """
        :brief      Get the string description for the feature code
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: Int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    name:           The string description for the feature code
        """
        handle_c = c_void_p()
        handle_c.value = handle
        feature_id_c = c_int()
        feature_id_c.value = feature_id

        size_c = c_size_t()
        status = dll.GXGetFeatureName(handle_c, feature_id_c, None, byref(size_c))

        name_buff = create_string_buffer(size_c.value)
        status = dll.GXGetFeatureName(handle_c, feature_id_c, byref(name_buff), byref(size_c))

        name = string_at(name_buff, size_c.value-1)
        return status, string_decoding(name)


if hasattr(dll, 'GXIsImplemented'):
    def gx_is_implemented(handle, feature_id):
        """
        :brief      Inquire the current camera whether support a special feature.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    is_implemented: To return the result whether is support this feature
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        is_implemented = c_bool()
        status = dll.GXIsImplemented(handle_c, feature_id_c, byref(is_implemented))
        return status, is_implemented.value


if hasattr(dll, 'GXIsReadable'):
    def gx_is_readable(handle, feature_id):
        """
        :brief      Inquire if a feature code is currently readable
        :param      handle:             The handle of the device
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    is_readable:        To return the result whether the feature code ID is readable
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        is_readable = c_bool()
        status = dll.GXIsReadable(handle_c, feature_id_c, byref(is_readable))
        return status, is_readable.value


if hasattr(dll, 'GXIsWritable'):
    def gx_is_writable(handle, feature_id):
        """
        :brief      Inquire if a feature code is currently writable
        :param      handle:             The handle of the device.
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    is_writeable:       To return the result whether the feature code ID is writable(Bool)
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        is_writeable = c_bool()
        status = dll.GXIsWritable(handle_c, feature_id_c, byref(is_writeable))
        return status, is_writeable.value


if hasattr(dll, 'GXGetIntRange'):
    def gx_get_int_range(handle, feature_id):
        """
        :brief      To get the minimum value, maximum value and steps of the int type
        :param      handle:         The handle of the device.
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    int_range:      The structure of range description(GxIntRange)
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        int_range = GxIntRange()
        status = dll.GXGetIntRange(handle_c, feature_id_c, byref(int_range))
        return status, int_range


if hasattr(dll, 'GXGetInt'):
    def gx_get_int(handle, feature_id):
        """
        :brief      Get the current value of the int type.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    int_value:      Get the current value of the int type
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        int_value = c_int64()
        status = dll.GXGetInt(handle_c, feature_id_c, byref(int_value))
        return status, int_value.value


if hasattr(dll, 'GXSetInt'):
    def gx_set_int(handle, feature_id, int_value):
        """
        :brief      Set the value of int type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID.
                                    Type: int, Greater than 0
        :param      int_value:      The value that the user will set
                                    Type: long, minnum:0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        value_c = c_int64()
        value_c.value = int_value

        status = dll.GXSetInt(handle_c, feature_id_c, value_c)
        return status


if hasattr(dll, 'GXGetFloatRange'):
    def gx_get_float_range(handle, feature_id):
        """
        :brief      To get the minimum value, maximum value, stepsand unit of the float type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    float_range:    The description structure(GxFloatRange)
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        float_range = GxFloatRange()
        status = dll.GXGetFloatRange(handle_c, feature_id_c, byref(float_range))
        return status, float_range


if hasattr(dll, 'GXSetFloat'):
    def gx_set_float(handle, feature_id, float_value):
        """
        :brief      Set the value of float type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :param      float_value:    The float value that the user will set
                                    Type: double
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        value_c = c_double()
        value_c.value = float_value

        status = dll.GXSetFloat(handle_c, feature_id_c, value_c)
        return status


if hasattr(dll, 'GXGetFloat'):
    def gx_get_float(handle, feature_id):
        """
        :brief      Get the value of float type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        float_value = c_double()
        status = dll.GXGetFloat(handle_c, feature_id_c, byref(float_value))

        return status, float_value.value


if hasattr(dll, 'GXGetEnumEntryNums'):
    def gx_get_enum_entry_nums(handle, feature_id):
        """
        :brief      Get the number of the options for the enumeration item
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    enum_num:       The number of the options for the enumeration item
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        enum_nums = c_uint()
        status = dll.GXGetEnumEntryNums(handle_c, feature_id_c, byref(enum_nums))
        return status, enum_nums.value


if hasattr(dll, 'GXGetEnumDescription'):
    def gx_get_enum_description(handle, feature_id, enum_num):
        """
        :brief      To get the description information of the enumerated type values
                    the number of enumerated items and the value and descriptions of each item
                    please reference GxEnumDescription.
        :param      handle:             The handle of the device
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :param      enum_num:           The number of enumerated information
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    enum_description:   Enumerated information array(GxEnumDescription)
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        buf_size_c = c_size_t()
        buf_size_c.value = sizeof(GxEnumDescription) * enum_num

        enum_description = (GxEnumDescription * enum_num)()
        status = dll.GXGetEnumDescription(handle_c, feature_id_c, byref(enum_description), byref(buf_size_c))
        return status, enum_description


if hasattr(dll, 'GXGetEnum'):
    def gx_get_enum(handle, feature_id):
        """
        :brief      To get the current enumeration value
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    enum_value:     Get the current enumeration value
        """
        handle_c = c_void_p()
        handle_c.value = handle
        feature_id_c = c_int()
        feature_id_c.value = feature_id

        enum_value = c_int64()
        status = dll.GXGetEnum(handle_c, feature_id_c, byref(enum_value))

        return status, enum_value.value


if hasattr(dll, 'GXSetEnum'):
    def gx_set_enum(handle, feature_id, enum_value):
        """
        :brief      Set the enumeration value
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :param      enum_value:     Set the enumeration value
                                    Type: int
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        value_c = c_int64()
        value_c.value = enum_value

        status = dll.GXSetEnum(handle_c, feature_id_c, value_c)
        return status


if hasattr(dll, 'GXGetBool'):
    def gx_get_bool(handle, feature_id):
        """
        :brief      Get the value of bool type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    boot_value:     the value of bool type
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        boot_value = c_bool()
        status = dll.GXGetBool(handle_c, feature_id_c, byref(boot_value))
        return status, boot_value.value


if hasattr(dll, 'GXSetBool'):
    def gx_set_bool(handle, feature_id, bool_value):
        """
        :brief      Set the value of bool type
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :param      bool_value:     The bool value that the user will set
                                    Type: Bool
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        value_c = c_bool()
        value_c.value = bool_value

        status = dll.GXSetBool(handle_c, feature_id_c, value_c)
        return status


if hasattr(dll, 'GXGetStringLength'):
    def gx_get_string_length(handle, feature_id):
        """
        :brief      Get the current value length of the character string type. Unit: byte
        :param      handle:             The handle of the device
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    string_length:      the current value length of the character string type
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        string_length = c_size_t()
        status = dll.GXGetStringLength(handle_c, feature_id_c, byref(string_length))

        return status, string_length.value - 1


if hasattr(dll, 'GXGetStringMaxLength'):
    def gx_get_string_max_length(handle, feature_id):
        """
        :brief      Get the maximum length of the string type value,  Unit: byte
        :param      handle:             The handle of the device
                                        Type: Long, Greater than 0
        :param      feature_id:         The feature code ID
                                        Type: int, Greater than 0
        :return:    status:             State return value, See detail in GxStatusList
                    string_max_length:  the maximum length of the string type value
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        string_max_length = c_size_t()
        status = dll.GXGetStringMaxLength(handle_c, feature_id, byref(string_max_length))

        return status, string_max_length.value - 1


if hasattr(dll, 'GXGetString'):
    def gx_get_string(handle, feature_id):
        """
        :brief      Get the content of the string type value
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        size_c = c_size_t()
        status = dll.GXGetString(handle_c, feature_id_c, None, byref(size_c))

        content_c = create_string_buffer(size_c.value)
        status = dll.GXGetString(handle_c, feature_id_c, byref(content_c), byref(size_c))

        content = string_at(content_c, size_c.value-1)
        return status, string_decoding(content)


if hasattr(dll, 'GXSetString'):
    def gx_set_string(handle, feature_id, content):
        """
        :brief      Set the content of the string value
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :param      content:        The string will be setting(str)
                                    Type: str
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        content_c = create_string_buffer(string_encoding(content))

        status = dll.GXSetString(handle_c, feature_id_c, byref(content_c))
        return status


if hasattr(dll, 'GXGetBufferLength'):
    def gx_get_buffer_length(handle, feature_id):
        """
        :brief      Get the length of the chunk data and the unit is byte,
                    the user can apply the buffer based on the length obtained,
                    and then call the gx_get_buffer to get the chunk data.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    buff_length:    Buff length, Unit: byte
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        buff_length = c_size_t()
        status = dll.GXGetBufferLength(handle_c, feature_id_c, byref(buff_length))
        return status, buff_length.value


if hasattr(dll, 'GXGetBuffer'):
    def gx_get_buffer(handle, feature_id):
        """
        :brief      Get the chunk data
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      feature_id:     The feature code ID
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
                    buff:           chunk data
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        buff_length_c = c_size_t()
        status = dll.GXGetBuffer(handle_c, feature_id_c, None, byref(buff_length_c))

        buff_c = (c_ubyte * buff_length_c.value)()
        status = dll.GXGetBuffer(handle_c, feature_id_c, byref(buff_c), byref(buff_length_c))
        return status, buff_c


if hasattr(dll, 'GXSetBuffer'):
    def gx_set_buffer(handle, feature_id, buff, buff_size):
        """
        :brief      Set the chunk data
        :param      handle:         The handle of the device
        :param      feature_id:     The feature code ID
                                    Type: long, Greater than 0
        :param      buff:           chunk data buff
                                    Type: Ctype array
        :param      buff_size:      chunk data buff size
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """

        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        buff_size_c = c_size_t()
        buff_size_c.value = buff_size

        status = dll.GXSetBuffer(handle_c, feature_id_c, buff, buff_size_c)
        return status


if hasattr(dll, 'GXSendCommand'):
    def gx_send_command(handle, feature_id):
        """
        :brief      Send the command
        :param      handle:         The handle of the device
                                    Type: long, Greater than 0
        :param      feature_id:     The feature code ID.
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        status = dll.GXSendCommand(handle_c, feature_id_c)
        return status


CAP_CALL = CFUNCTYPE(None, POINTER(GxFrameCallbackParam))
if hasattr(dll, 'GXRegisterCaptureCallback'):
    def gx_register_capture_callback(handle, cap_call):
        """
        :brief      Register the capture callback function
        :param      handle:         The handle of the device
        :param      cap_call:       The callback function that the user will register(@ CAP_CALL)
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXRegisterCaptureCallback(handle_c, None, cap_call)
        return status


if hasattr(dll, 'GXUnregisterCaptureCallback'):
    def gx_unregister_capture_callback(handle):
        """
        :brief      Unregister the capture callback function
        :param      handle:         The handle of the device
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXUnregisterCaptureCallback(handle_c)
        return status


if hasattr(dll, 'GXGetImage'):
    def gx_get_image(handle, frame_data, time_out=200):
        """
        :brief      After starting acquisition, you can call this function to get images directly.
                    Noting that the interface can not be mixed with the callback capture mode.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      frame_data:     [out]User introduced to receive the image data
                                    Type: GxFrameData
        :param      time_out:       The timeout time of capture image.(unit: ms)
                                    Type: int, minnum: 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        time_out_c = c_uint()
        time_out_c.value = time_out

        status = dll.GXGetImage(handle_c, byref(frame_data), time_out_c)
        return status


if hasattr(dll, 'GXFlushQueue'):
    def gx_flush_queue(handle):
        """
        :brief      Empty the cache image in the image output queue.
        :param      handle:     The handle of the device
                                Type: Long, Greater than 0
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXFlushQueue(handle_c)
        return status



OFF_LINE_CALL = CFUNCTYPE(None, c_void_p)
if hasattr(dll, 'GXRegisterDeviceOfflineCallback'):
    def gx_register_device_offline_callback(handle, call_back):
        """
        :brief      At present, the mercury GIGE camera provides the device offline notification event mechanism,
                    the user can call this interface to register the event handle callback function
        :param      handle:             The handle of the device
        :param      call_back:          The user event handle callback function(@ OFF_LINE_CALL)
        :return:    status:             State return value, See detail in GxStatusList
                    call_back_handle:   The handle of offline callback function
                                        the handle is used for unregistering the callback function
        """
        handle_c = c_void_p()
        handle_c.value = handle

        call_back_handle = c_void_p()
        status = dll.GXRegisterDeviceOfflineCallback(handle_c, None, call_back, byref(call_back_handle))
        return status, call_back_handle.value


if hasattr(dll, 'GXUnregisterDeviceOfflineCallback'):
    def gx_unregister_device_offline_callback(handle, call_back_handle):
        """
        :brief      Unregister event handle callback function
        :param      handle:             The handle of the device
        :param      call_back_handle:   The handle of device offline callback function
        :return:    status:             State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        call_back_handle_c = c_void_p()
        call_back_handle_c.value = call_back_handle

        status = dll.GXUnregisterDeviceOfflineCallback(handle_c, call_back_handle_c)
        return status

'''
if hasattr(dll, 'GXFlushEvent'):
    def gx_flush_event(handle):
        """
        :brief      Empty the device event, such as the frame exposure to end the event data queue
        :param      handle:    The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXFlushEvent(handle_c)
        return status


if hasattr(dll, 'GXGetEventNumInQueue'):
    def gx_get_event_num_in_queue(handle):
        """
        :brief      Get the number of the events in the current remote device event queue cache.
        :param      handle:     The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
                    event_num:  event number.
        """
        handle_c = c_void_p()
        handle_c.value = handle

        event_num = c_uint()

        status = dll.GXGetEventNumInQueue(handle_c, byref(event_num))
        return status, event_num.value


FEATURE_CALL = CFUNCTYPE(None, c_uint, c_void_p)
if hasattr(dll, 'GXRegisterFeatureCallback'):
    def gx_register_feature_callback(handle, call_back, feature_id):
        """
        :brief      Register device attribute update callback function.
                    When the current value of the device property has updated, or the accessible property is changed,
                    call this callback function.
        :param      handle:             The handle of the device
        :param      call_back:          The user event handle callback function(@ FEATURE_CALL)
        :param      feature_id:         The feature code ID
        :return:    status:             State return value, See detail in GxStatusList
                    call_back_handle:   The handle of property update callback function,
                                        to unregister the callback function.
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        call_back_handle = c_void_p()
        status = dll.GXRegisterFeatureCallback(handle_c, None, call_back, feature_id_c, byref(call_back_handle))

        return status, call_back_handle.value


if hasattr(dll, 'GXUnregisterFeatureCallback'):
    """
    """
    def gx_unregister_feature_cEallback(handle, feature_id, call_back_handle):
        """
        :brief      Unregister device attribute update callback function
        :param      handle:             The handle of the device
        :param      feature_id:         The feature code ID
        :param      call_back_handle:   Handle of property update callback function
        :return:    status:             State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        feature_id_c = c_int()
        feature_id_c.value = feature_id

        call_back_handle_c = c_void_p()
        call_back_handle_c.value = call_back_handle

        status = dll.GXUnregisterFeatureCallback(handle_c, feature_id_c, call_back_handle_c)
        return status
'''

if hasattr(dll, 'GXExportConfigFile'):
    def gx_export_config_file(handle, file_path):
        """
        :brief      Export the current parameter of the camera to the configuration file.
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      file_path:      The path of the configuration file that to be generated
                                    Type: str
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        file_path_c = create_string_buffer(string_encoding(file_path))
        status = dll.GXExportConfigFile(handle_c, byref(file_path_c))

        return status


if hasattr(dll, 'GXImportConfigFile'):
    def gx_import_config_file(handle, file_path, verify):
        """
        :brief      Import the configuration file for the camera
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      file_path:      The path of the configuration file(str)
                                    Type: str
        :param      verify:         If this value is true, all imported values will be read out
                                    to check whether they are consistent.
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        verify_c = c_bool()
        verify_c.value = verify

        file_path_c = create_string_buffer(string_encoding(file_path))
        status = dll.GXImportConfigFile(handle_c, byref(file_path_c), verify_c)
        return status

'''
if hasattr(dll, 'GXReadRemoteDevicePort'):
    def gx_read_remote_device_port(handle, address, buff, size):
        """
        :brief      Read data for user specified register.
        :param      handle:     The handle of the device
        :param      address:    Register address
        :param      buff:       Output data buff
        :param      size:       Buff size
        :return:    status:     State return value, See detail in GxStatusList
                    size:       Returns the length of the actual read register
        """
        handle_c = c_void_p()
        handle_c.value = handle

        address_c = c_ulonglong()
        address_c.value = address

        size_c = c_uint()
        size_c.value = size

        status = dll.GXReadRemoteDevicePort(handle_c, address_c, byref(buff), byref(size_c))
        return status, size_c.value


if hasattr(dll, 'GXWriteRemoteDevicePort'):
    def gx_write_remote_device_port(handle, address, buff, size):
        """
        :brief      Writes user specified data to a user specified register.
        :param      handle:     The handle of the device
        :param      address:    Register address
        :param      buff:       User data
        :param      size:       User data size
        :return:    status:     State return value, See detail in GxStatusList
                    size:       Returns the length of the actual write register
        """
        handle_c = c_void_p()
        handle_c.value = handle

        address_c = c_ulonglong()
        address_c.value = address

        size_c = c_uint()
        size_c.value = size

        status = dll.GXWriteRemoteDevicePort(handle_c, address_c, byref(buff), byref(size_c))
        return status, size_c.value


if hasattr(dll, 'GXGigEIpConfiguration'):
    def gx_gige_ip_configuration(mac_address, ipconfig_flag, ip_address, subnet_mask, default_gateway, user_id):
        """
        "brief      Configure the static IP address of the camera
        :param      mac_address:        The MAC address of the device(str)
        :param      ipconfig_flag:      IP Configuration mode(GxIPConfigureModeList)
        :param      ip_address:         The IP address to be set(str)
        :param      subnet_mask:        The subnet mask to be set(str)
        :param      default_gateway:    The default gateway to be set(str)
        :param      user_id:            The user-defined name to be set(str)
        :return:    status:             State return value, See detail in GxStatusList
        """
        mac_address_c = create_string_buffer(string_encoding(mac_address))
        ip_address_c = create_string_buffer(string_encoding(ip_address))
        subnet_mask_c = create_string_buffer(string_encoding(subnet_mask))
        default_gateway_c = create_string_buffer(string_encoding(default_gateway))
        user_id_c = create_string_buffer(string_encoding(user_id))

        status = dll.GXGigEIpConfiguration(mac_address_c, ipconfig_flag,
                                           ip_address_c, subnet_mask_c,
                                           default_gateway_c, user_id_c)
        return status


if hasattr(dll, 'GXGigEForceIp'):
    def gx_gige_force_ip(mac_address, ip_address, subnet_mask, default_gate_way):
        """
        :brief      Execute the Force IP
        :param      mac_address:        The MAC address of the device(str)
        :param      ip_address:         The IP address to be set(str)
        :param      subnet_mask:        The subnet mask to be set(str)
        :param      default_gate_way:   The default gateway to be set(str)
        :return:    status:             State return value, See detail in GxStatusList
        """
        mac_address_c = create_string_buffer(string_encoding(mac_address))
        ip_address_c = create_string_buffer(string_encoding(ip_address))
        subnet_mask_c = create_string_buffer(string_encoding(subnet_mask))
        default_gate_way_c = create_string_buffer(string_encoding(default_gate_way))

        status = dll.GXGigEForceIp(mac_address_c, ip_address_c, subnet_mask_c, default_gate_way_c)
        return status
'''

if hasattr(dll, 'GXSetAcqusitionBufferNumber'):
    def gx_set_acquisition_buffer_number(handle, buffer_num):
        """
        :brief      Users Set Acquisition buffer Number
        :param      handle:         The handle of the device
                                    Type: Long, Greater than 0
        :param      buffer_num:     Acquisition buffer Number
                                    Type: int, Greater than 0
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        buffer_num_c = c_uint64()
        buffer_num_c.value = buffer_num

        status = dll.GXSetAcqusitionBufferNumber(handle_c, buffer_num_c)
        return status

'''
if hasattr(dll, 'GXStreamOn'):
    def gx_stream_on(handle):
        """
        :brief      Start acquisition
        :param      handle:     The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXStreamOn(handle_c)
        return status


if hasattr(dll, 'GXDQBuf'):
    def gx_dequeue_buf(handle, time_out):
        """
        :brief      Get a image
                    After the image processing is completed, the gx_queue_buf interface needs to be called
                    otherwise the collection will not be able to continue.
        :param      handle:             The handle of the device
        :param      time_out:           The timeout time of capture image.(unit: ms)
        :return:    status:             State return value, See detail in GxStatusList
                    frame_data:         Image data
                    frame_data_p:       Image buff address
        """
        handle_c = c_void_p()
        handle_c.value = handle

        time_out_c = c_uint()
        time_out_c.value = time_out

        frame_data_p = c_void_p()
        status = dll.GXDQBuf(handle_c, byref(frame_data_p), time_out_c)

        frame_data = GxFrameData()
        memmove(addressof(frame_data), frame_data_p.value, sizeof(frame_data))
        return status, frame_data, frame_data_p.value


if hasattr(dll, 'GXQBuf'):
    def gx_queue_buf(handle, frame_data_p):
        """
        :brief      Put an image Buff back to the GxIAPI library and continue to be used for collection.
        :param      handle:         The handle of the device
        :param      frame_data_p:   Image buff address
        :return:    status:         State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        frame_data_p_p = c_void_p()
        frame_data_p_p.value = frame_data_p

        status = dll.GXQBuf(handle_c, frame_data_p_p)
        return status
        

if hasattr(dll, 'GXDQAllBufs'):
    def gx_dequeue_all_bufs(handle, buff_num, time_out):
        """
        :brief      Get images
                    After the image processing is completed, the gx_queue_all_bufs interface needs to be called
                    otherwise the collection will not be able to continue.
        :param      handle:         The handle of the device
        :param      buff_num:       The number of images expected to be obtained
        :param      time_out:       The timeout time of capture image.(unit: ms)
        :return:    status:         State return value, See detail in GxStatusList
                    frame_data:     Image data arrays
                    frame_count:    The number of images that are actually returned
        """
        handle_c = c_void_p()
        handle_c.value = handle

        time_out_c = c_uint()
        time_out_c.value = time_out

        frame_data_p = (c_void_p * buff_num)()
        frame_count_c = c_uint()

        status = dll.GXDQAllBufs(handle_c, frame_data_p, buff_num, byref(frame_count_c), time_out_c)
        frame_data = (GxFrameData * buff_num)()

        for i in range(buff_num):
            memmove(addressof(frame_data[i]), frame_data_p[i], sizeof(GxFrameData))

        return status, frame_data, frame_count_c.value


if hasattr(dll, 'GXQAllBufs'):
    def gx_queue_all_bufs(handle):
        """
        :brief      The image data Buf is returned to the GxIAPI library and used for collection.
        :param      handle:     The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXQAllBufs(handle_c)
        return status


if hasattr(dll, 'GXStreamOff'):
    def gx_stream_off(handle):
        """
        :brief      Stop acquisition
        :param      handle:     The handle of the device
        :return:    status:     State return value, See detail in GxStatusList
        """
        handle_c = c_void_p()
        handle_c.value = handle

        status = dll.GXStreamOff(handle_c)
        return status
'''


def string_encoding(string):
    """
    :breif      Python3.X: String encoded as bytes
    :param      string
    :return:
    """
    if sys.version_info.major == 3:
        string = string.encode()
    return string


def string_decoding(string):
    """
    :brief      Python3.X: bytes decoded as string
    :param      string
    :return:
    """
    if sys.version_info.major == 3:
        string = string.decode()
    return string


def range_check(value, min_value, max_value, inc_value=0):
    """
    :brief      Determine if the input parameter is within range
    :param      value:       input value
    :param      min_value:   max value
    :param      max_value:   min value
    :param      inc_value:   step size, default=0
    :return:    True/False
    """
    if value < min_value:
        return False
    elif value > max_value:
        return False
    elif (inc_value != 0) and (value != int(value / inc_value) * inc_value):
        return False
    return True

#!/usr/bin/python
# -*- coding:utf-8 -*-
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-

from control.gxipy.gxiapi import *
from control.gxipy.gxidef import *
from control.gxipy.gxwrapper import *

__all__ = ["gxwrapper", "dxwrapper", "gxiapi", "gxidef"]

__version__ = '1.0.1809.9281'

class shortcut:
    """ Decorator for shortcuts. """

    def __init__(self, key, name):
        self.key = key
        self.name = name

    def __call__(self, func):
        func._Shortcut = True
        func._Key = self.key
        func._Name = self.name
        return func


def generateShortcuts(objs):
    """ Generates a dict from shortcut-decorated methods in the objects in the
    passed array objs. """

    exportedFuncs = {}
    for obj in objs:
        for subObjName in dir(obj):
            subObj = getattr(obj, subObjName)

            if not callable(getattr(obj, subObjName)):
                continue

            if not hasattr(subObj, '_Shortcut') or not subObj._Shortcut:
                continue

            if subObjName in exportedFuncs:
                raise NameError(f'Shortcut for method name "{subObjName}" is already in use')

            exportedFuncs[subObjName] = {'callback': subObj,
                                         'key': subObj._Key,
                                         'name': subObj._Name}

    return exportedFuncs


# Copyright (C) 2020-2021 ImSwitch developers
# This file is part of ImSwitch.
#
# ImSwitch is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# ImSwitch is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

import numpy as np


def bestLevels(arr):
    # Best cmin, cmax algorithm taken from ImageJ routine:
    # http://cmci.embl.de/documents/120206pyip_cooking/
    # python_imagej_cookbook#automatic_brightnesscontrast_button
    pixelCount = arr.size
    limit = pixelCount / 10
    threshold = pixelCount / 5000
    hist, bin_edges = np.histogram(arr, 256)
    i = 0
    found = False
    count = 0
    while True:
        i += 1
        count = hist[i]
        if count > limit:
            count = 0
        found = count > threshold
        if found or i >= 255:
            break
    hmin = i

    i = 256
    while True:
        i -= 1
        count = hist[i]
        if count > limit:
            count = 0
        found = count > threshold
        if found or i < 1:
            break
    hmax = i

    return bin_edges[hmin], bin_edges[hmax]


def minmaxLevels(arr):
    minlevel = 0
    maxlevel = arr.max() + 2

    return minlevel, maxlevel


# Copyright (C) 2017 Federico Barabas
# This file is part of Tormenta.
#
# Tormenta is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Tormenta is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera_TIS as camera
import control.core as core
import control.microcontroller as microcontroller

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		self.camera = camera.Camera(sn='39810456',width=3072,height=2048,framerate=60,color=True)
		self.microcontroller = microcontroller.Microcontroller_Simulation()
		
		self.configurationManager = core.ConfigurationManager()
		self.streamHandler = core.StreamHandler()
		self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
		self.imageSaver = core.ImageSaver()
		self.imageDisplay = core.ImageDisplay()

		# open the camera
		# camera start streaming
		self.camera.open()
		self.camera.set_software_triggered_acquisition()
		self.camera.set_callback(self.streamHandler.on_new_frame)
		self.camera.enable_callback()

		# load widgets
		self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,self.liveController)
		self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager)
		self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)

		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget,0,0)
		layout.addWidget(self.liveControlWidget,1,0)
		layout.addWidget(self.recordingControlWidget,4,0)
		
		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# load window
		self.imageDisplayWindow = core.ImageDisplayWindow()
		self.imageDisplayWindow.show()

		# make connections
		self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
		self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
		self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
		self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
		self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
		self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
		self.liveControlWidget.update_camera_settings()
		
	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.liveController.stop_live()
		self.camera.close()
		self.imageSaver.close()
		self.imageDisplay.close()
		self.imageDisplayWindow.close()

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.widgets_tracking as widgets_tracking
import control.camera_TIS as camera
import control.core as core
import control.core_tracking as core_tracking
import control.microcontroller as microcontroller

SIMULATION = True

class OctopiGUI(QMainWindow):

	# variables
	fps_software_trigger = 100

	def __init__(self, *args, **kwargs):
		super().__init__(*args, **kwargs)

		# load objects
		if SIMULATION is True:
			self.camera = camera.Camera_Simulation()
			self.microcontroller = microcontroller.Microcontroller_Simulation()
		else:
			self.camera = camera.Camera(sn=17910085)
			self.microcontroller = microcontroller.Microcontroller()
		
		self.streamHandler = core.StreamHandler()
		self.liveController = core.LiveController(self.camera,self.microcontroller)
		self.navigationController = core.NavigationController(self.microcontroller)
		#self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
		#self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController)
		self.trackingController = core_tracking.TrackingController(self.microcontroller,self.navigationController)
		self.imageSaver = core.ImageSaver()
		self.imageDisplay = core.ImageDisplay()

		'''
		# thread
		self.thread_multiPoint = QThread()
		self.thread_multiPoint.start()
		self.multipointController.moveToThread(self.thread_multiPoint)
		'''

		# open the camera
		# camera start streaming
		self.camera.open()
		self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
		self.camera.set_callback(self.streamHandler.on_new_frame)
		self.camera.enable_callback()

		# load widgets
		self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,self.liveController)
		self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController)
		self.navigationWidget = widgets.NavigationWidget(self.navigationController)
		#self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
		self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)
		self.trackingControlWidget = widgets_tracking.TrackingControllerWidget(self.streamHandler,self.trackingController)
		#self.multiPointWidget = widgets.MultiPointWidget(self.multipointController)

		self.recordTabWidget = QTabWidget()
		self.recordTabWidget.addTab(self.recordingControlWidget, "Simple Recording")
		self.recordTabWidget.addTab(self.trackingControlWidget, "Tracking")
		#self.recordTabWidget.addTab(self.multiPointWidget, "Multipoint Acquisition")

		# layout widgets
		layout = QGridLayout() #layout = QStackedLayout()
		layout.addWidget(self.cameraSettingWidget,0,0)
		layout.addWidget(self.liveControlWidget,1,0)
		layout.addWidget(self.navigationWidget,2,0)
		#layout.addWidget(self.autofocusWidget,3,0)
		layout.addWidget(self.recordTabWidget,4,0)
		
		# transfer the layout to the central widget
		self.centralWidget = QWidget()
		self.centralWidget.setLayout(layout)
		self.setCentralWidget(self.centralWidget)

		# load window
		self.imageDisplayWindow = core.ImageDisplayWindow('Main Display')
		self.imageDisplayWindow.show()

		self.imageDisplayWindow_ThresholdedImage = core.ImageDisplayWindow('Thresholded Image')
		# self.imageDisplayWindow_ThresholdedImage.show()

		# make connections
		self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
		self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
		# self.streamHandler.image_to_display.connect(self.imageDisplay.emit_directly) # test emitting image to display without queueing and threading
		self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
		self.streamHandler.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
		self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
		self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
		self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
		self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)
		#self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
		#self.multipointController.image_to_display.connect(self.imageDisplayWindow.display_image)

		self.camera.start_streaming()

	def closeEvent(self, event):
		event.accept()
		# self.softwareTriggerGenerator.stop() @@@ => 
		self.liveController.stop_live()
		self.camera.close()
		self.imageSaver.close()
		self.imageDisplay.close()
		self.imageDisplayWindow.close()
		self.imageDisplayWindow_ThresholdedImage.close()

from lxml import etree as ET
top = ET.Element('modes')

def generate_default_configuration(filename):

    mode_1 = ET.SubElement(top,'mode')
    mode_1.set('ID','1')
    mode_1.set('Name','BF LED matrix full')
    mode_1.set('ExposureTime','12')
    mode_1.set('AnalogGain','0')
    mode_1.set('IlluminationSource','0')
    mode_1.set('IlluminationIntensity','5')
    mode_1.set('CameraSN','')
    mode_1.set('ZOffset','0.0')
    mode_1.set('PixelFormat','default')
    mode_1.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_1.set('EmissionFilterPosition','1')

    mode_4 = ET.SubElement(top,'mode')
    mode_4.set('ID','4')
    mode_4.set('Name','DF LED matrix')
    mode_4.set('ExposureTime','22')
    mode_4.set('AnalogGain','0')
    mode_4.set('IlluminationSource','3')
    mode_4.set('IlluminationIntensity','5')
    mode_4.set('CameraSN','')
    mode_4.set('ZOffset','0.0')
    mode_4.set('PixelFormat','default')
    mode_4.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_4.set('EmissionFilterPosition','1')

    mode_5 = ET.SubElement(top,'mode')
    mode_5.set('ID','5')
    mode_5.set('Name','Fluorescence 405 nm Ex')
    mode_5.set('ExposureTime','100')
    mode_5.set('AnalogGain','10')
    mode_5.set('IlluminationSource','11')
    mode_5.set('IlluminationIntensity','100')
    mode_5.set('CameraSN','')
    mode_5.set('ZOffset','0.0')
    mode_5.set('PixelFormat','default')
    mode_5.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_5.set('EmissionFilterPosition','1')

    mode_6 = ET.SubElement(top,'mode')
    mode_6.set('ID','6')
    mode_6.set('Name','Fluorescence 488 nm Ex')
    mode_6.set('ExposureTime','100')
    mode_6.set('AnalogGain','10')
    mode_6.set('IlluminationSource','12')
    mode_6.set('IlluminationIntensity','100')
    mode_6.set('CameraSN','')
    mode_6.set('ZOffset','0.0')
    mode_6.set('PixelFormat','default')
    mode_6.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_6.set('EmissionFilterPosition','1')

    mode_7 = ET.SubElement(top,'mode')
    mode_7.set('ID','7')
    mode_7.set('Name','Fluorescence 638 nm Ex')
    mode_7.set('ExposureTime','100')
    mode_7.set('AnalogGain','10')
    mode_7.set('IlluminationSource','13')
    mode_7.set('IlluminationIntensity','100')
    mode_7.set('CameraSN','')
    mode_7.set('ZOffset','0.0')
    mode_7.set('PixelFormat','default')
    mode_7.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_7.set('EmissionFilterPosition','1')

    mode_8 = ET.SubElement(top,'mode')
    mode_8.set('ID','8')
    mode_8.set('Name','Fluorescence 561 nm Ex')
    mode_8.set('ExposureTime','100')
    mode_8.set('AnalogGain','10')
    mode_8.set('IlluminationSource','14')
    mode_8.set('IlluminationIntensity','100')
    mode_8.set('CameraSN','')
    mode_8.set('ZOffset','0.0')
    mode_8.set('PixelFormat','default')
    mode_8.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_8.set('EmissionFilterPosition','1')

    mode_12 = ET.SubElement(top,'mode')
    mode_12.set('ID','12')
    mode_12.set('Name','Fluorescence 730 nm Ex')
    mode_12.set('ExposureTime','50')
    mode_12.set('AnalogGain','10')
    mode_12.set('IlluminationSource','15')
    mode_12.set('IlluminationIntensity','100')
    mode_12.set('CameraSN','')
    mode_12.set('ZOffset','0.0')
    mode_12.set('PixelFormat','default')
    mode_12.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_12.set('EmissionFilterPosition','1')

    mode_9 = ET.SubElement(top,'mode')
    mode_9.set('ID','9')
    mode_9.set('Name','BF LED matrix low NA')
    mode_9.set('ExposureTime','20')
    mode_9.set('AnalogGain','0')
    mode_9.set('IlluminationSource','4')
    mode_9.set('IlluminationIntensity','20')
    mode_9.set('CameraSN','')
    mode_9.set('ZOffset','0.0')
    mode_9.set('PixelFormat','default')
    mode_9.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_9.set('EmissionFilterPosition','1')

    # mode_10 = ET.SubElement(top,'mode')
    # mode_10.set('ID','10')
    # mode_10.set('Name','BF LED matrix left dot')
    # mode_10.set('ExposureTime','20')
    # mode_10.set('AnalogGain','0')
    # mode_10.set('IlluminationSource','5')
    # mode_10.set('IlluminationIntensity','20')
    # mode_10.set('CameraSN','') 
    # mode_10.set('ZOffset','0.0')
    # mode_10.set('PixelFormat','default')
    # mode_10.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')

    # mode_11 = ET.SubElement(top,'mode')
    # mode_11.set('ID','11')
    # mode_11.set('Name','BF LED matrix right dot')
    # mode_11.set('ExposureTime','20')
    # mode_11.set('AnalogGain','0')
    # mode_11.set('IlluminationSource','6')
    # mode_11.set('IlluminationIntensity','20')
    # mode_11.set('CameraSN','')
    # mode_11.set('ZOffset','0.0')
    # mode_11.set('PixelFormat','default')
    # mode_11.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')

    mode_2 = ET.SubElement(top,'mode')
    mode_2.set('ID','2')
    mode_2.set('Name','BF LED matrix left half')
    mode_2.set('ExposureTime','16')
    mode_2.set('AnalogGain','0')
    mode_2.set('IlluminationSource','1')
    mode_2.set('IlluminationIntensity','5')
    mode_2.set('CameraSN','')
    mode_2.set('ZOffset','0.0')
    mode_2.set('PixelFormat','default')
    mode_2.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_2.set('EmissionFilterPosition','1')

    mode_3 = ET.SubElement(top,'mode')
    mode_3.set('ID','3')
    mode_3.set('Name','BF LED matrix right half')
    mode_3.set('ExposureTime','16')
    mode_3.set('AnalogGain','0')
    mode_3.set('IlluminationSource','2')
    mode_3.set('IlluminationIntensity','5')
    mode_3.set('CameraSN','')
    mode_3.set('ZOffset','0.0')
    mode_3.set('PixelFormat','default')
    mode_3.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_3.set('EmissionFilterPosition','1')

    mode_12 = ET.SubElement(top,'mode')
    mode_12.set('ID','12')
    mode_12.set('Name','BF LED matrix top half')
    mode_12.set('ExposureTime','20')
    mode_12.set('AnalogGain','0')
    mode_12.set('IlluminationSource','7')
    mode_12.set('IlluminationIntensity','20')
    mode_12.set('CameraSN','')
    mode_12.set('ZOffset','0.0')
    mode_12.set('PixelFormat','default')
    mode_12.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_12.set('EmissionFilterPosition','1')

    mode_13 = ET.SubElement(top,'mode')
    mode_13.set('ID','13')
    mode_13.set('Name','BF LED matrix bottom half')
    mode_13.set('ExposureTime','20')
    mode_13.set('AnalogGain','0')
    mode_13.set('IlluminationSource','8')
    mode_13.set('IlluminationIntensity','20')
    mode_13.set('CameraSN','')
    mode_13.set('ZOffset','0.0')
    mode_13.set('PixelFormat','default')
    mode_13.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_13.set('EmissionFilterPosition','1')

    mode_14 = ET.SubElement(top,'mode')
    mode_14.set('ID','1')
    mode_14.set('Name','BF LED matrix full_R')
    mode_14.set('ExposureTime','12')
    mode_14.set('AnalogGain','0')
    mode_14.set('IlluminationSource','0')
    mode_14.set('IlluminationIntensity','5')
    mode_14.set('CameraSN','')
    mode_14.set('ZOffset','0.0')
    mode_14.set('PixelFormat','default')
    mode_14.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_14.set('EmissionFilterPosition','1')

    mode_15 = ET.SubElement(top,'mode')
    mode_15.set('ID','1')
    mode_15.set('Name','BF LED matrix full_G')
    mode_15.set('ExposureTime','12')
    mode_15.set('AnalogGain','0')
    mode_15.set('IlluminationSource','0')
    mode_15.set('IlluminationIntensity','5')
    mode_15.set('CameraSN','')
    mode_15.set('ZOffset','0.0')
    mode_15.set('PixelFormat','default')
    mode_15.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_15.set('EmissionFilterPosition','1')

    mode_16 = ET.SubElement(top,'mode')
    mode_16.set('ID','1')
    mode_16.set('Name','BF LED matrix full_B')
    mode_16.set('ExposureTime','12')
    mode_16.set('AnalogGain','0')
    mode_16.set('IlluminationSource','0')
    mode_16.set('IlluminationIntensity','5')
    mode_16.set('CameraSN','')
    mode_16.set('ZOffset','0.0')
    mode_16.set('PixelFormat','default')
    mode_16.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_16.set('EmissionFilterPosition','1')

    mode_21 = ET.SubElement(top,'mode')
    mode_21.set('ID','21')
    mode_21.set('Name','BF LED matrix full_RGB')
    mode_21.set('ExposureTime','12')
    mode_21.set('AnalogGain','0')
    mode_21.set('IlluminationSource','0')
    mode_21.set('IlluminationIntensity','5')
    mode_21.set('CameraSN','')
    mode_21.set('ZOffset','0.0')
    mode_21.set('PixelFormat','default')
    mode_21.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_21.set('EmissionFilterPosition','1')

    mode_20 = ET.SubElement(top,'mode')
    mode_20.set('ID','20')
    mode_20.set('Name','USB Spectrometer')
    mode_20.set('ExposureTime','20')
    mode_20.set('AnalogGain','0')
    mode_20.set('IlluminationSource','6')
    mode_20.set('IlluminationIntensity','0')
    mode_20.set('CameraSN','')
    mode_20.set('ZOffset','0.0')
    mode_20.set('PixelFormat','default')
    mode_20.set('_PixelFormat_options','[default,MONO8,MONO12,MONO14,MONO16,BAYER_RG8,BAYER_RG12]')
    mode_20.set('EmissionFilterPosition','1')

    tree = ET.ElementTree(top)
    tree.write(filename,encoding="utf-8", xml_declaration=True, pretty_print=True)

import numpy as np
from qtpy import QtWidgets

from control.ImSwitch import shortcut
from control.ImSwitch import naparitools


class ImageWidget(QtWidgets.QWidget):
    """ Widget containing viewbox that displays the new detector frames. """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        naparitools.addNapariGrayclipColormap()
        self.napariViewer = naparitools.EmbeddedNapari()
        # self.updateLevelsWidget = naparitools.NapariUpdateLevelsWidget.addToViewer(
        #     self.napariViewer
        # )
        # self.NapariResetViewWidget = naparitools.NapariResetViewWidget.addToViewer(self.napariViewer, 'right')
        # self.NapariShiftWidget = naparitools.NapariShiftWidget.addToViewer(self.napariViewer)
        self.imgLayers = {}

        self.viewCtrlLayout = QtWidgets.QVBoxLayout()
        self.viewCtrlLayout.addWidget(self.napariViewer.get_widget())
        self.setLayout(self.viewCtrlLayout)

        self.grid = naparitools.VispyGridVisual(color='yellow')
        self.grid.hide()
        self.addItem(self.grid)

        self.crosshair = naparitools.VispyCrosshairVisual(color='yellow')
        self.crosshair.hide()
        self.addItem(self.crosshair)

    def setLiveViewLayers(self, names):
        for name, img in self.imgLayers.items():
            if name not in names:
                self.napariViewer.layers.remove(img, force=True)

        def addImage(name, colormap=None):
            self.imgLayers[name] = self.napariViewer.add_image(
                np.zeros((1, 1)), rgb=False, name=f'Live: {name}', blending='additive',
                colormap=colormap, protected=True
            )

        for name in names:
            if name not in self.napariViewer.layers:
                try:
                    addImage(name, name.lower())
                except KeyError:
                    addImage(name, 'grayclip')

    def addStaticLayer(self, name, im):
        self.napariViewer.add_image(im, rgb=False, name=name, blending='additive')

    def getCurrentImageName(self):
        return self.napariViewer.active_layer.name

    def getImage(self, name):
        return self.imgLayers[name].data

    def setImage(self, name, im, scale = None):
        self.imgLayers[name].data = im
        if scale is not None:
            self.imgLayers[name].scale = tuple(scale)

    def clearImage(self, name):
        self.setImage(name, np.zeros((1, 1)))

    def getImageDisplayLevels(self, name):
        return self.imgLayers[name].contrast_limits

    def setImageDisplayLevels(self, name, minimum, maximum):
        self.imgLayers[name].contrast_limits = (minimum, maximum)

    def getCenterViewbox(self):
        """ Returns the center point of the viewbox, as an (x, y) tuple. """
        return (
            self.napariViewer.window.qt_viewer.camera.center[2],
            self.napariViewer.window.qt_viewer.camera.center[1]
        )

    def updateGrid(self, imShape):
        self.grid.update(imShape)

    def setGridVisible(self, visible):
        self.grid.setVisible(visible)

    def setCrosshairVisible(self, visible):
        self.crosshair.setVisible(visible)

    def resetView(self):
        self.napariViewer.reset_view()

    def addItem(self, item):
        item.attach(self.napariViewer,
                    canvas=self.napariViewer.window.qt_viewer.canvas,
                    view=self.napariViewer.window.qt_viewer.view,
                    parent=self.napariViewer.window.qt_viewer.view.scene,
                    order=1e6 + 8000)

    def removeItem(self, item):
        item.detach()

    '''
    @shortcut('Ctrl+U', "Update levels")
    def updateLevelsButton(self):
        self.updateLevelsWidget.updateLevelsButton.click()
    '''


# Copyright (C) 2020-2021 ImSwitch developers
# This file is part of ImSwitch.
#
# ImSwitch is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# ImSwitch is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *

# app specific libraries
import control.widgets as widgets
import control.camera as camera
import control.core as core
import control.microcontroller as microcontroller
from control._def import *

import pyqtgraph.dockarea as dock
SINGLE_WINDOW = True # set to False if use separate windows for display and control

class OctopiGUI(QMainWindow):

    # variables
    fps_software_trigger = 100

    def __init__(self, is_simulation = False, *args, **kwargs):
        super().__init__(*args, **kwargs)

        # load window
        if ENABLE_TRACKING:
            self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True,autoLevels=AUTOLEVEL_DEFAULT_SETTING)
            self.imageDisplayWindow.show_ROI_selector()
        else:
            self.imageDisplayWindow = core.ImageDisplayWindow(draw_crosshairs=True,autoLevels=AUTOLEVEL_DEFAULT_SETTING)
        self.imageArrayDisplayWindow = core.ImageArrayDisplayWindow() 
        # self.imageDisplayWindow.show()
        # self.imageArrayDisplayWindow.show()

        # image display windows
        self.imageDisplayTabs = QTabWidget()
        self.imageDisplayTabs.addTab(self.imageDisplayWindow.widget, "Live View")
        self.imageDisplayTabs.addTab(self.imageArrayDisplayWindow.widget, "Multichannel Acquisition")

        # load objects
        if is_simulation:
            self.camera = camera.Camera_Simulation(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
            self.microcontroller = microcontroller.Microcontroller_Simulation()
        else:
            try:
                self.camera = camera.Camera(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
                self.camera.open()
            except:
                self.camera = camera.Camera_Simulation(rotate_image_angle=ROTATE_IMAGE_ANGLE,flip_image=FLIP_IMAGE)
                self.camera.open()
                print('! camera not detected, using simulated camera !')
            try:
                self.microcontroller = microcontroller.Microcontroller(version=CONTROLLER_VERSION)
            except:
                print('! Microcontroller not detected, using simulated microcontroller !')
                self.microcontroller = microcontroller.Microcontroller_Simulation()

        # reset the MCU
        self.microcontroller.reset()

        # configure the actuators
        self.microcontroller.configure_actuators()

        self.objectiveStore = core.ObjectiveStore()
        self.configurationManager = core.ConfigurationManager('./channel_configurations.xml')
        self.streamHandler = core.StreamHandler(display_resolution_scaling=DEFAULT_DISPLAY_CROP/100)
        self.liveController = core.LiveController(self.camera,self.microcontroller,self.configurationManager)
        self.navigationController = core.NavigationController(self.microcontroller)
        self.autofocusController = core.AutoFocusController(self.camera,self.navigationController,self.liveController)
        self.multipointController = core.MultiPointController(self.camera,self.navigationController,self.liveController,self.autofocusController,self.configurationManager)
        if ENABLE_TRACKING:
            self.trackingController = core.TrackingController(self.camera,self.microcontroller,self.navigationController,self.configurationManager,self.liveController,self.autofocusController,self.imageDisplayWindow)
        self.imageSaver = core.ImageSaver(image_format=Acquisition.IMAGE_FORMAT)
        self.imageDisplay = core.ImageDisplay()

        # set up the camera		
        # self.camera.set_reverse_x(CAMERA_REVERSE_X) # these are not implemented for the cameras in use
        # self.camera.set_reverse_y(CAMERA_REVERSE_Y) # these are not implemented for the cameras in use
        self.camera.set_software_triggered_acquisition() #self.camera.set_continuous_acquisition()
        self.camera.set_callback(self.streamHandler.on_new_frame)
        self.camera.enable_callback()
        if ENABLE_STROBE_OUTPUT:
            self.camera.set_line3_to_exposure_active()

        # load widgets:
        self.objectivesWidget=widgets.ObjectivesWidget(self.objectiveStore)

        self.cameraSettingWidget = widgets.CameraSettingsWidget(self.camera,include_gain_exposure_time=False)
        self.liveControlWidget = widgets.LiveControlWidget(self.streamHandler,self.liveController,self.configurationManager,show_trigger_options=True,show_display_options=True,show_autolevel=SHOW_AUTOLEVEL_BTN,autolevel=AUTOLEVEL_DEFAULT_SETTING)
        self.navigationWidget = widgets.NavigationWidget(self.navigationController)
        self.dacControlWidget = widgets.DACControWidget(self.microcontroller)
        self.autofocusWidget = widgets.AutoFocusWidget(self.autofocusController)
        self.recordingControlWidget = widgets.RecordingWidget(self.streamHandler,self.imageSaver)
        if ENABLE_TRACKING:
            self.trackingControlWidget = widgets.TrackingControllerWidget(self.trackingController,self.configurationManager,show_configurations=TRACKING_SHOW_MICROSCOPE_CONFIGURATIONS)
        self.multiPointWidget = widgets.MultiPointWidget(self.multipointController,self.configurationManager)

        self.recordTabWidget = QTabWidget()
        if ENABLE_TRACKING:
            self.recordTabWidget.addTab(self.trackingControlWidget, "Tracking")
        self.recordTabWidget.addTab(self.recordingControlWidget, "Simple Recording")
        self.recordTabWidget.addTab(self.multiPointWidget, "Multipoint Acquisition")

        # layout widgets
        layout = QVBoxLayout() 
        layout.addWidget(self.cameraSettingWidget)
        #self.objectivesWidget.setFixedHeight(100)
        layout.addWidget(self.liveControlWidget)
        layout.addWidget(self.navigationWidget)
        if SHOW_DAC_CONTROL:
            layout.addWidget(self.dacControlWidget)
        layout.addWidget(self.autofocusWidget)
        layout.addWidget(self.recordTabWidget)
        layout.addWidget(self.objectivesWidget)
        layout.addStretch()

        # transfer the layout to the central widget
        self.centralWidget = QWidget()
        self.centralWidget.setLayout(layout)
        # self.centralWidget.setFixedSize(self.centralWidget.minimumSize())
        # self.centralWidget.setFixedWidth(self.centralWidget.minimumWidth())
        # self.centralWidget.setMaximumWidth(self.centralWidget.minimumWidth())
        self.centralWidget.setFixedWidth(self.centralWidget.minimumSizeHint().width())

        if SINGLE_WINDOW:
            dock_display = dock.Dock('Image Display', autoOrientation = False)
            dock_display.showTitleBar()
            dock_display.addWidget(self.imageDisplayTabs)
            dock_display.setStretch(x=100,y=None)
            dock_controlPanel = dock.Dock('Controls', autoOrientation = False)
            # dock_controlPanel.showTitleBar()
            dock_controlPanel.addWidget(self.centralWidget)
            dock_controlPanel.setStretch(x=1,y=None)
            dock_controlPanel.setFixedWidth(dock_controlPanel.minimumSizeHint().width())
            main_dockArea = dock.DockArea()
            main_dockArea.addDock(dock_display)
            main_dockArea.addDock(dock_controlPanel,'right')
            self.setCentralWidget(main_dockArea)
            desktopWidget = QDesktopWidget()
            height_min = 0.9*desktopWidget.height()
            width_min = 0.96*desktopWidget.width()
            self.setMinimumSize(int(width_min),int(height_min))
        else:
            self.setCentralWidget(self.centralWidget)
            self.tabbedImageDisplayWindow = QMainWindow()
            self.tabbedImageDisplayWindow.setCentralWidget(self.imageDisplayTabs)
            self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() | Qt.CustomizeWindowHint)
            self.tabbedImageDisplayWindow.setWindowFlags(self.windowFlags() & ~Qt.WindowCloseButtonHint)
            desktopWidget = QDesktopWidget()
            width = 0.96*desktopWidget.height()
            height = width
            self.tabbedImageDisplayWindow.setFixedSize(width,height)
            self.tabbedImageDisplayWindow.show()

        # make connections
        self.streamHandler.signal_new_frame_received.connect(self.liveController.on_new_frame)
        self.streamHandler.image_to_display.connect(self.imageDisplay.enqueue)
        self.streamHandler.packet_image_to_write.connect(self.imageSaver.enqueue)
        # self.streamHandler.packet_image_for_tracking.connect(self.trackingController.on_new_frame)
        self.imageDisplay.image_to_display.connect(self.imageDisplayWindow.display_image) # may connect streamHandler directly to imageDisplayWindow
        self.navigationController.xPos.connect(self.navigationWidget.label_Xpos.setNum)
        self.navigationController.yPos.connect(self.navigationWidget.label_Ypos.setNum)
        self.navigationController.zPos.connect(self.navigationWidget.label_Zpos.setNum)
        if ENABLE_TRACKING:
            self.navigationController.signal_joystick_button_pressed.connect(self.trackingControlWidget.slot_joystick_button_pressed)
        else:
            self.navigationController.signal_joystick_button_pressed.connect(self.autofocusController.autofocus)
        self.autofocusController.image_to_display.connect(self.imageDisplayWindow.display_image)
        self.multipointController.image_to_display.connect(self.imageDisplayWindow.display_image)
        self.multipointController.signal_current_configuration.connect(self.liveControlWidget.set_microscope_mode)
        self.multipointController.image_to_display_multi.connect(self.imageArrayDisplayWindow.display_image)
        self.liveControlWidget.signal_newExposureTime.connect(self.cameraSettingWidget.set_exposure_time)
        self.liveControlWidget.signal_newAnalogGain.connect(self.cameraSettingWidget.set_analog_gain)
        self.liveControlWidget.update_camera_settings()
        self.liveControlWidget.signal_autoLevelSetting.connect(self.imageDisplayWindow.set_autolevel)

    def closeEvent(self, event):
        event.accept()
        # self.softwareTriggerGenerator.stop() @@@ => 
        self.navigationController.home()
        self.liveController.stop_live()
        self.camera.close()
        self.imageSaver.close()
        self.imageDisplay.close()
        if not SINGLE_WINDOW:
            self.imageDisplayWindow.close()
            self.imageArrayDisplayWindow.close()
            self.tabbedImageDisplayWindow.close()
        self.microcontroller.close()

import threading
import queue
import numpy as np
import pandas as pd
import control.utils as utils

def default_image_preprocessor(image, callable_list):
    """
    :param image: ndarray representing an image
    :param callable_list: List of dictionaries in the form {'func': callable,
    'args': list of positional args, 'kwargs': dict of keyword args}. The function
    should take an image ndarray as its first positional argument,
    and the image should
    not be included in the collection of args/kwargs
    :return: Image with the elements of callable_list applied in sequence
    """
    output_image = np.copy(image)
    for c in callable_list:
        output_image = c['func'](output_image, *c['args'],**c['kwargs'])
    return output_image

class ProcessingHandler():
    """
    :brief: Handler class for parallelizing FOV processing. GENERAL NOTE:
        REMEMBER TO PASS COPIES OF IMAGES WHEN QUEUEING THEM FOR PROCESSING
    """
    def __init__(self):
        self.processing_queue = queue.Queue() # elements in this queue are
                                              # dicts in the form
                                              # {'function': callable, 'args':list
                                              # of positional arguments to pass,
                                              # 'kwargs': dict of kwargs to pass}
                                              # a dict in the form {'function':'end'}
                                              # will cause processing to terminate
                                              # the function called should return
                                              # a dict in the same form it received,
                                              # in appropriate form to pass to the
                                              # upload queue

        self.upload_queue = queue.Queue()     # elements in this queue are
                                              # dicts in the form
                                              # {'function': callable, 'args':list
                                              # of positional arguments to pass,
                                              # 'kwargs': dict of kwargs to pass}
                                              # a dict in the form {'function':'end'}
                                              # will cause the uploading to terminate
        self.processing_thread = None
        self.uploading_thread = None

    def processing_queue_handler(self, queue_timeout=None):
        while True:
            processing_task = None
            try:
                processing_task = self.processing_queue.get(timeout=queue_timeout)
            except queue.Empty:
                break
            if processing_task['function'] == 'end':
                self.processing_queue.task_done()
                break
            else:
                upload_task = processing_task['function'](
                                                *processing_task['args'],
                                                **processing_task['kwargs'])
                self.upload_queue.put(upload_task)
                self.processing_queue.task_done()

    def upload_queue_handler(self, queue_timeout=None):
        while True:
            upload_task = None
            try:
                upload_task = self.upload_queue.get(timeout=queue_timeout)
            except queue.Empty:
                break
            if upload_task['function'] == 'end':
                self.upload_queue.task_done()
                break
            else:
                upload_task['function'](*upload_task['args'],**upload_task['kwargs'])
                self.upload_queue.task_done()

    def start_processing(self, queue_timeout=None):
        self.processing_thread =\
        threading.Thread(target=self.processing_queue_handler, args=[queue_timeout])
        self.processing_thread.start()
    def start_uploading(self,queue_timeout=None):
        self.uploading_thread =\
        threading.Thread(target=self.upload_queue_handler,args=[queue_timeout])
        self.uploading_thread.start()
    def end_uploading(self, *args, **kwargs):
        return {'function':'end'}
    def end_processing(self):
        self.processing_queue.put({'function':self.end_uploading,'args':[],
                                   'kwargs':{}})
        self.processing_queue.put({'function':'end'})


# set QT_API environment variable
import os 
os.environ["QT_API"] = "pyqt5"
import qtpy

# qt libraries
from qtpy.QtCore import *
from qtpy.QtWidgets import *
from qtpy.QtGui import *
import pyqtgraph as pg
from datetime import datetime
from control._def import *

class SpectrometerControlWidget(QFrame):

    signal_newExposureTime = Signal(float)
    signal_newAnalogGain = Signal(float)

    def __init__(self, spectrometer, streamHandler, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.spectrometer = spectrometer
        self.streamHandler = streamHandler
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        self.btn_live = QPushButton("Live")
        self.btn_live.setCheckable(True)
        self.btn_live.setChecked(False)
        self.btn_live.setDefault(False)

        # line 3: exposure time and analog gain associated with the current mode
        self.entry_exposureTime = QDoubleSpinBox()
        self.entry_exposureTime.setMinimum(0.001) 
        self.entry_exposureTime.setMaximum(5000) 
        self.entry_exposureTime.setSingleStep(1)
        self.entry_exposureTime.setValue(50)
        self.entry_exposureTime.setKeyboardTracking(False)
        self.spectrometer.set_integration_time_ms(50)

        # connections
        self.btn_live.clicked.connect(self.toggle_live)
        self.entry_exposureTime.valueChanged.connect(self.spectrometer.set_integration_time_ms)

        # layout
        grid_line2 = QHBoxLayout()
        grid_line2.addWidget(QLabel('USB spectrometer'))
        grid_line2.addWidget(QLabel('Integration Time (ms)'))
        grid_line2.addWidget(self.entry_exposureTime)
        grid_line2.addWidget(self.btn_live)

        self.grid = QVBoxLayout()
        self.grid.addLayout(grid_line2)
        # self.grid.addStretch()
        self.setLayout(self.grid)

    def toggle_live(self,pressed):
        if pressed:
            self.spectrometer.start_streaming()
        else:
            self.spectrometer.pause_streaming()

class RecordingWidget(QFrame):
    def __init__(self, streamHandler, imageSaver, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.imageSaver = imageSaver # for saving path control
        self.streamHandler = streamHandler
        self.base_path_is_set = False
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        self.btn_setSavingDir = QPushButton('Browse')
        self.btn_setSavingDir.setDefault(False)
        self.btn_setSavingDir.setIcon(QIcon('icon/folder.png'))
        
        self.lineEdit_savingDir = QLineEdit()
        self.lineEdit_savingDir.setReadOnly(True)
        self.lineEdit_savingDir.setText('Choose a base saving directory')

        self.lineEdit_experimentID = QLineEdit()

        self.entry_saveFPS = QDoubleSpinBox()
        self.entry_saveFPS.setMinimum(0.02) 
        self.entry_saveFPS.setMaximum(1000) 
        self.entry_saveFPS.setSingleStep(1)
        self.entry_saveFPS.setValue(1)
        self.streamHandler.set_save_fps(1)

        self.entry_timeLimit = QSpinBox()
        self.entry_timeLimit.setMinimum(-1) 
        self.entry_timeLimit.setMaximum(60*60*24*30) 
        self.entry_timeLimit.setSingleStep(1)
        self.entry_timeLimit.setValue(-1)

        self.btn_record = QPushButton("Record")
        self.btn_record.setCheckable(True)
        self.btn_record.setChecked(False)
        self.btn_record.setDefault(False)

        grid_line1 = QGridLayout()
        grid_line1.addWidget(QLabel('Saving Path'))
        grid_line1.addWidget(self.lineEdit_savingDir, 0,1)
        grid_line1.addWidget(self.btn_setSavingDir, 0,2)

        grid_line2 = QGridLayout()
        grid_line2.addWidget(QLabel('Experiment ID'), 0,0)
        grid_line2.addWidget(self.lineEdit_experimentID,0,1)

        grid_line3 = QGridLayout()
        grid_line3.addWidget(QLabel('Saving FPS'), 0,0)
        grid_line3.addWidget(self.entry_saveFPS, 0,1)
        grid_line3.addWidget(QLabel('Time Limit (s)'), 0,2)
        grid_line3.addWidget(self.entry_timeLimit, 0,3)
        grid_line3.addWidget(self.btn_record, 0,4)

        self.grid = QGridLayout()
        self.grid.addLayout(grid_line1,0,0)
        self.grid.addLayout(grid_line2,1,0)
        self.grid.addLayout(grid_line3,2,0)
        self.grid.setRowStretch(self.grid.rowCount(), 1)
        self.setLayout(self.grid)

        # add and display a timer - to be implemented
        # self.timer = QTimer()

        # connections
        self.btn_setSavingDir.clicked.connect(self.set_saving_dir)
        self.btn_record.clicked.connect(self.toggle_recording)
        self.entry_saveFPS.valueChanged.connect(self.streamHandler.set_save_fps)
        self.entry_timeLimit.valueChanged.connect(self.imageSaver.set_recording_time_limit)
        self.imageSaver.stop_recording.connect(self.stop_recording)

    def set_saving_dir(self):
        dialog = QFileDialog()
        save_dir_base = dialog.getExistingDirectory(None, "Select Folder")
        self.imageSaver.set_base_path(save_dir_base)
        self.lineEdit_savingDir.setText(save_dir_base)
        self.base_path_is_set = True

    def toggle_recording(self,pressed):
        if self.base_path_is_set == False:
            self.btn_record.setChecked(False)
            msg = QMessageBox()
            msg.setText("Please choose base saving directory first")
            msg.exec_()
            return
        if pressed:
            self.lineEdit_experimentID.setEnabled(False)
            self.btn_setSavingDir.setEnabled(False)
            self.imageSaver.start_new_experiment(self.lineEdit_experimentID.text())
            self.streamHandler.start_recording()
        else:
            self.streamHandler.stop_recording()
            self.lineEdit_experimentID.setEnabled(True)
            self.btn_setSavingDir.setEnabled(True)

    # stop_recording can be called by imageSaver
    def stop_recording(self):
        self.lineEdit_experimentID.setEnabled(True)
        self.btn_record.setChecked(False)
        self.streamHandler.stop_recording()
        self.btn_setSavingDir.setEnabled(True)


class SpectrumDisplay(QFrame):

    def __init__(self, N=1000, main=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.N = N
        self.add_components()
        self.setFrameStyle(QFrame.Panel | QFrame.Raised)

    def add_components(self):
        self.plotWidget = PlotWidget('', add_legend=True)

        layout = QGridLayout() #layout = QStackedLayout()
        layout.addWidget(self.plotWidget,0,0)
        self.setLayout(layout)

    def plot(self,data):
        self.plotWidget.plot(data[0,:],data[1,:],clear=True)


class PlotWidget(pg.GraphicsLayoutWidget):
    
    def __init__(self,title='',parent=None,add_legend=False):
        super().__init__(parent)
        self.plotWidget = self.addPlot(title=title)
        if add_legend:
            self.plotWidget.addLegend()
    
    def plot(self,x,y,clear=False):
        self.plotWidget.plot(x,y,clear=clear)

import ctypes
from ctypes import c_int, c_char_p, create_string_buffer
from pycparser import c_parser, c_ast, parse_file
import re
import sys

C_TO_CTYPES = {
    'void': None,
    'int': ctypes.c_int,
    'char': ctypes.c_char,
    'char*': ctypes.c_char_p,
    'bool': ctypes.c_bool,
    'double': ctypes.c_double,
    # Add more mappings as needed
}

def extract_macros_from_header(file_path):
    macros = {}
    with open(file_path, 'r') as file:
        for line in file:
            # Ignore lines containing keywords like "_declspec"
            if "_declspec" in line or "_BUILD_DLL_" in line:
                continue
            match = re.match(r'#define\s+(\w+)\s+(\d+)', line)
            if match:
                name, value = match.groups()
                macros[name] = int(value)
    return macros


def extract_functions_from_header(file_path):
    functions = []
    with open(file_path, 'r') as file:
        content = file.read()
        # Match function prototypes
        matches = re.findall(r'\b(\w[\w\s\*]+)\s+(\w+)\s*\(([^)]*)\)\s*;', content)
        for ret_type, func_name, params in matches:
            param_list = []
            if params.strip():  # Check if there are parameters
                for param in params.split(','):
                    param = param.strip()
                    param_type = ' '.join(param.split()[:-1])
                    param_list.append(C_TO_CTYPES.get(param_type.strip(), ctypes.c_void_p))
            functions.append({
                'name': func_name,
                # 'return_type': C_TO_CTYPES.get(ret_type.strip(), ctypes.c_void_p),
                'return_type': c_int,
                'arg_types': param_list
            })
    return functions


class RCM_API:
    def __init__(self):

        # Load the header
        macros = extract_macros_from_header('.\\RCM_API.h')
        functions = extract_functions_from_header('.\\RCM_API.h')

        # Load the DLL
        self.rcm_api = ctypes.CDLL('.\\RCM_API.dll')
        
        # Set constants from macros
        for name, value in macros.items():
            setattr(self, name, int(value))
            # print(name + ' ' + str(value))
        self.ERR_OK = -1

        # Dynamically define functions from the header file
        for func in functions:
            # print(func)
            func_name = func['name']
            ret_type = func['return_type']
            arg_types = func['arg_types']
            function = getattr(self.rcm_api, func_name)
            function.restype = ret_type
            function.argtypes = arg_types
            setattr(self, func_name, function)

    def get_string_parameter(self, param: int):
        buffer = create_string_buffer(100)
        result = self.getStringParameter(param, buffer)
        if result == self.ERR_OK:
            return buffer.value.decode()
        else:
            return None

    def set_integer_parameter(self, param: int, value: int):
        return self.setIntegerParameter(param, value)

    def set_float_parameter(self, param: int, value: float):
        return self.setFloatParameter(param, value)

    def initialize_device(self, simulated: bool):
        return self.initializeDevice(simulated)

    def get_device_type(self):
        return self.getDeviceType()

    def start_acquisition(self):
        return self.startAcquisition()

    def set_bypass(self, mode: int):
        return self.setBypass(mode)

    def start_continuous_acquisition(self):
        return self.startContinuousAcquisition()

    def stop_continuous_acquisition(self):
        return self.stopContinuousAcquisition()

    def get_full_error(self):
        err_code = c_int()
        buffer = create_string_buffer(100)
        result = self.getFullError(ctypes.byref(err_code), buffer)
        if result == self.ERR_OK:
            return err_code.value, buffer.value.decode()
        else:
            return None
# -*- coding: utf-8 -*-
"""
Created on Mon May  7 19:44:40 2018

@author: Francois and Deepak
"""

import numpy as np
import cv2
from scipy.ndimage.filters import laplace
from numpy import std, square, mean

#color is a vector HSV whose size is 3


def default_lower_HSV(color):
    c=[0,100,100]
    c[0]=np.max([color[0]-10,0])
    c[1]=np.max([color[1]-40,0])
    c[2]=np.max([color[2]-40,0])
    return np.array(c,dtype="uint8")

def default_upper_HSV(color):
    c=[0,255,255]
    c[0]=np.min([color[0]+10,178])
    c[1]=np.min([color[1]+40,255])
    c[2]=np.min([color[2]+40,255])
    return np.array(c,dtype="uint8")

def threshold_image(image_BGR,LOWER,UPPER):
    image_HSV = cv2.cvtColor(image_BGR,cv2.COLOR_BGR2HSV)
    imgMask = 255*np.array(cv2.inRange(image_HSV, LOWER, UPPER), dtype='uint8')  #The tracked object will be in white
    imgMask = cv2.erode(imgMask, None, iterations=2) # Do a series of erosions and dilations on the thresholded image to reduce smaller blobs
    imgMask = cv2.dilate(imgMask, None, iterations=2)
    
    return imgMask

def threshold_image_gray(image_gray, LOWER, UPPER):
    imgMask = np.array((image_gray >= LOWER) & (image_gray <= UPPER), dtype='uint8')
    
    # imgMask = cv2.inRange(cv2.UMat(image_gray), LOWER, UPPER)  #The tracked object will be in white
    imgMask = cv2.erode(imgMask, None, iterations=2) # Do a series of erosions and dilations on the thresholded image to reduce smaller blobs
    imgMask = cv2.dilate(imgMask, None, iterations=2)
    
    return imgMask

def bgr2gray(image_BGR):
    return cv2.cvtColor(image_BGR,cv2.COLOR_BGR2GRAY)

def crop(image,center,imSize): #center is the vector [x,y]
    imH,imW,*rest=image.shape  #image.shape:[nb of row -->height,nb of column --> Width]
    xmin = max(10,center[0] - int(imSize))
    xmax = min(imW-10,center[0] + int(imSize))
    ymin = max(10,center[1] - int(imSize))
    ymax = min(imH-10,center[1] + int(imSize))
    return np.array([[xmin,ymin],[xmax,ymax]]),np.array(image[ymin:ymax,xmin:xmax])


def crop_image(image,crop_width,crop_height):
    image_height = image.shape[0]
    image_width = image.shape[1]
    roi_left = int(max(image_width/2 - crop_width/2,0))
    roi_right = int(min(image_width/2 + crop_width/2,image_width))
    roi_top = int(max(image_height/2 - crop_height/2,0))
    roi_bottom = int(min(image_height/2 + crop_height/2,image_height))
    image_cropped = image[roi_top:roi_bottom,roi_left:roi_right]
    image_cropped_height = image_cropped.shape[0]
    image_cropped_width = image_cropped.shape[1]
    return image_cropped, image_cropped_width, image_cropped_height


def get_bbox(cnt):
    return cv2.boundingRect(cnt)


def find_centroid_enhanced(image,last_centroid):
    #find contour takes image with 8 bit int and only one channel
    #find contour looks for white object on a black back ground
    # This looks for all contours in the thresholded image and then finds the centroid that maximizes a tracking metric
    # Tracking metric : current centroid area/(1 + dist_to_prev_centroid**2)
    contours = cv2.findContours(image, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)[-2]
    centroid=False
    isCentroidFound=False
    if len(contours)>0:
        all_centroid=[]
        dist=[]
        for cnt in contours:
            M = cv2.moments(cnt)
            if M['m00']!=0:
                cx = int(M['m10']/M['m00'])
                cy = int(M['m01']/M['m00'])
                centroid=np.array([cx,cy])
                isCentroidFound=True
                all_centroid.append(centroid)
                dist.append([cv2.contourArea(cnt)/(1+(centroid-last_centroid)**2)])

    if isCentroidFound:
        ind=dist.index(max(dist))
        centroid=all_centroid[ind]

    return isCentroidFound,centroid

def find_centroid_enhanced_Rect(image,last_centroid):
    #find contour takes image with 8 bit int and only one channel
    #find contour looks for white object on a black back ground
    # This looks for all contours in the thresholded image and then finds the centroid that maximizes a tracking metric
    # Tracking metric : current centroid area/(1 + dist_to_prev_centroid**2)
    contours = cv2.findContours(image, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)[-2]
    centroid=False
    isCentroidFound=False
    rect = False
    if len(contours)>0:
        all_centroid=[]
        dist=[]
        for cnt in contours:
            M = cv2.moments(cnt)
            if M['m00']!=0:
                cx = int(M['m10']/M['m00'])
                cy = int(M['m01']/M['m00'])
                centroid=np.array([cx,cy])
                isCentroidFound=True
                all_centroid.append(centroid)
                dist.append([cv2.contourArea(cnt)/(1+(centroid-last_centroid)**2)])

    if isCentroidFound:
        ind=dist.index(max(dist))
        centroid=all_centroid[ind]
        cnt = contours[ind]
        xmin,ymin,width,height = cv2.boundingRect(cnt)
        xmin = max(0,xmin)
        ymin = max(0,ymin)
        width = min(width, imW - int(cx))
        height = min(height, imH - int(cy))
        rect = (xmin, ymin, width, height)


    return isCentroidFound,centroid, rect

def find_centroid_basic(image):
    #find contour takes image with 8 bit int and only one channel
    #find contour looks for white object on a black back ground
    # This finds the centroid with the maximum area in the current frame
    contours = cv2.findContours(image, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)[-2]
    centroid=False
    isCentroidFound=False
    if len(contours)>0:
        cnt = max(contours, key=cv2.contourArea)
        M = cv2.moments(cnt)
        if M['m00']!=0:
            cx = int(M['m10']/M['m00'])
            cy = int(M['m01']/M['m00'])
            centroid=np.array([cx,cy])
            isCentroidFound=True
    return isCentroidFound,centroid

def find_centroid_basic_Rect(image):
    #find contour takes image with 8 bit int and only one channel
    #find contour looks for white object on a black back ground
    # This finds the centroid with the maximum area in the current frame and alsio the bounding rectangle. - DK 2018_12_12
    imH,imW = image.shape
    contours = cv2.findContours(image, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)[-2]
    centroid=False
    isCentroidFound=False
    bbox = None
    rect = False
    if len(contours)>0:
        # Find contour with max area
        cnt = max(contours, key=cv2.contourArea)
        M = cv2.moments(cnt)

        if M['m00']!=0:
            # Centroid coordinates
            cx = int(M['m10']/M['m00'])
            cy = int(M['m01']/M['m00'])
            centroid=np.array([cx,cy])
            isCentroidFound=True

             # Find the bounding rectangle
            xmin,ymin,width,height = cv2.boundingRect(cnt)
            xmin = max(0,xmin)
            ymin = max(0,ymin)
            width = min(width, imW - xmin)
            height = min(height, imH - ymin)
            
            bbox = (xmin, ymin, width, height)

    return isCentroidFound,centroid, bbox

def scale_square_bbox(bbox, scale_factor, square = True):

    xmin, ymin, width, height = bbox

    if(square==True):
        min_dim = min(width, height)
        width, height = min_dim, min_dim

    new_width, new_height = int(scale_factor*width), int(scale_factor*height)

    new_xmin = xmin - (new_width - width)/2
    new_ymin = ymin - (new_height - height)/2

    new_bbox = (new_xmin, new_ymin, new_width, new_height)
    return new_bbox

def get_image_center_width(image):
    ImShape=image.shape
    ImH,ImW=ImShape[0],ImShape[1]
    return np.array([ImW*0.5,ImH*0.5]), ImW

def get_image_height_width(image):
    ImShape=image.shape
    ImH,ImW=ImShape[0],ImShape[1]
    return ImH, ImW

def get_image_top_center_width(image):
    ImShape=image.shape
    ImH,ImWs=ImShape[0],ImShape[1]
    return np.array([ImW*0.5,0.25*ImH]),ImW


def YTracking_Objective_Function(image, color):
    #variance method
    if(image.size != 0):
        if(color):
            image = bgr2gray(image)
        mean,std=cv2.meanStdDev(image)
        return std[0][0]**2
    else:
        return 0

def calculate_focus_measure(image):
    if len(image.shape) == 3:
        image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY) # optional
    lap = cv2.Laplacian(image,cv2.CV_16S)
    focus_measure = mean(square(lap))
    return focus_measure

#test part
if __name__ == "__main__":
    # Load an color image in grayscale
    rouge=np.array([[[255,0,0]]],dtype="uint8")
    vert=np.array([[[0,255,0]]],dtype="uint8")
    bleu=np.array([[[0,0,255]]],dtype="uint8")

    rouge_HSV=cv2.cvtColor(rouge,cv2.COLOR_RGB2HSV)[0][0]
    vert_HSV=cv2.cvtColor(vert,cv2.COLOR_RGB2HSV)[0][0]
    bleu_HSV=cv2.cvtColor(bleu,cv2.COLOR_RGB2HSV)[0][0]
    
    img = cv2.imread('C:/Users/Francois/Documents/11-Stage_3A/6-Code_Python/ConsoleWheel/test/rouge.jpg')
    print(img)
    img2=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)
    
    couleur = bleu_HSV
    LOWER = default_lower_HSV(couleur)
    UPPER = default_upper_HSV(couleur)
    
    img3=threshold_image(img2,LOWER,UPPER)
    cv2.imshow('image',img3)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

#for more than one tracked object
'''
def find_centroid_many(image,contour_area_min,contour_area_max):
    contours = cv2.findContours(image, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)[-2]
    count=0
    last_centroids=[]
    for j in range(len(contours)):
        cnt = contours[j]
        if cv2.contourArea(contours[j])>contour_area_min and cv2.contourArea(contours[j])<contour_area_max :
            M = cv2.moments(cnt)
            cx = int(M['m10']/M['m00'])
            cy = int(M['m01']/M['m00'])
            last_centroids.append([cx,cy])
            count+=1
    return last_centroids,count
'''


import control.utils_.image_processing as image_processing
import numpy as np
from os.path import realpath, dirname, join

try:
	import torch
	from control.DaSiamRPN.code.net import SiamRPNvot
	print(1)
	from control.DaSiamRPN.code import vot
	print(2) 
	from control.DaSiamRPN.code.utils import get_axis_aligned_bbox, cxy_wh_2_rect
	print(3)
	from control.DaSiamRPN.code.run_SiamRPN import SiamRPN_init, SiamRPN_track
	print(4)
except Exception as e:
	print(e)
	# print('Warning: DaSiamRPN is not available!')
from control._def import Tracking
import cv2

class Tracker_Image(object):
	'''
	SLOTS: update_tracker_type, Connected to: Tracking Widget
	'''

	def __init__(self):
		# Define list of trackers being used(maybe do this as a definition?)
		# OpenCV tracking suite
		# self.OPENCV_OBJECT_TRACKERS = {}
		self.OPENCV_OBJECT_TRACKERS = {
			"csrt": cv2.legacy.TrackerCSRT_create,
			"kcf": cv2.legacy.TrackerKCF_create,
			"mil": cv2.legacy.TrackerMIL_create,
			}
		try:
			self.OPENCV_OBJECT_TRACKERS = {
			"csrt": cv2.legacy.TrackerCSRT_create,
			"kcf": cv2.legacy.TrackerKCF_create,
			"boosting": cv2.legacy.TrackerBoosting_create,
			"mil": cv2.legacy.TrackerMIL_create,
			"tld": cv2.legacy.TrackerTLD_create,
			"medianflow": cv2.legacy.TrackerMedianFlow_create,
			"mosse": cv2.legacy.TrackerMOSSE_create
			}
		except:
			print('Warning: OpenCV-Contrib trackers unavailable!')
		
		# Neural Net based trackers
		self.NEURALNETTRACKERS = {"daSiamRPN":[]}
		try:
			# load net
			self.net = SiamRPNvot()
			self.net.load_state_dict(torch.load(join(realpath(dirname(__file__)),'DaSiamRPN','code','SiamRPNOTB.model')))
			self.net.eval().cuda()
			print('Finished loading net ...')
		except Exception as e:
			print(e)
			print('No neural net model found ...')
			print('reverting to default OpenCV tracker')

		# Image Tracker type
		self.tracker_type = Tracking.DEFAULT_TRACKER
		# Init method for tracker
		self.init_method = Tracking.DEFAULT_INIT_METHOD
		# Create the tracker
		self.create_tracker()

		# Centroid of object from the image
		self.centroid_image = None # (2,1)
		self.bbox = None
		self.rect_pts = None
		self.roi_bbox = None
		self.origin = np.array([0,0])

		self.isCentroidFound = False
		self.trackerActive = False
		self.searchArea = None
		self.is_color = None
		
	def track(self, image, thresh_image, is_first_frame = False):

		# case 1: initialize the tracker
		if(is_first_frame == True or self.trackerActive == False):
			# tracker initialization - using ROI
			if(self.init_method=="roi"):
				self.bbox = tuple(self.roi_bbox)
				self.centroid_image = self.centroid_from_bbox(self.bbox)
				self.isCentroidFound = True
			# tracker initialization - using thresholded image
			else:
				self.isCentroidFound, self.centroid_image, self.bbox = image_processing.find_centroid_basic_Rect(thresh_image)
				self.bbox = image_processing.scale_square_bbox(self.bbox, Tracking.BBOX_SCALE_FACTOR, square = True)
			# initialize the tracker
			if(self.bbox is not None):
				print('Starting tracker with initial bbox: {}'.format(self.bbox))
				self._initialize_tracker(image, self.centroid_image, self.bbox)
				self.trackerActive = True
				self.rect_pts = self.rectpts_from_bbox(self.bbox)
		
		# case 2: continue tracking an object using tracking
		else:
			# Find centroid using the tracking.
			objectFound, self.bbox = self._update_tracker(image, thresh_image) # (x,y,w,h)
			if(objectFound):
				self.isCentroidFound = True
				self.centroid_image = self.centroid_from_bbox(self.bbox) + self.origin
				self.bbox = np.array(self.bbox)
				self.bbox[0], self.bbox[1] = self.bbox[0] + self.origin[0], self.bbox[1] + self.origin[1]
				self.rect_pts = self.rectpts_from_bbox(self.bbox)
			else:
				print('No object found ...')
				self.isCentroidFound = False
				self.trackerActive = False
		return self.isCentroidFound, self.centroid_image, self.rect_pts

	def reset(self):
		print('Reset image tracker state')
		self.is_first_frame = True
		self.trackerActive = False
		self.isCentroidFound = False

	def create_tracker(self):
		if(self.tracker_type in self.OPENCV_OBJECT_TRACKERS.keys()):
			self.tracker = self.OPENCV_OBJECT_TRACKERS[self.tracker_type]()
		elif(self.tracker_type in self.NEURALNETTRACKERS.keys()):
			print('Using {} tracker'.format(self.tracker_type))
			pass

	def _initialize_tracker(self, image, centroid, bbox):
		bbox = tuple(int(x) for x in bbox)
		# check if the image is color or not
		if(len(image.shape)<3):
			self.is_color = False		
		# Initialize the OpenCV based tracker
		if(self.tracker_type in self.OPENCV_OBJECT_TRACKERS.keys()):
			print('Initializing openCV tracker')
			print(self.tracker_type)
			print(bbox)
			if(self.is_color == False):
				image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
			self.create_tracker() # for a new track, just calling self.tracker.init(image,bbox) is not sufficient, this line needs to be called
			self.tracker.init(image, bbox)
		# Initialize Neural Net based Tracker
		elif(self.tracker_type in self.NEURALNETTRACKERS.keys()):
			# Initialize the tracker with this centroid position
			print('Initializing with daSiamRPN tracker')
			target_pos, target_sz = np.array([centroid[0], centroid[1]]), np.array([bbox[2], bbox[3]])
			if(self.is_color==False):
				image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
			self.state = SiamRPN_init(image, target_pos, target_sz, self.net)
			print('daSiamRPN tracker initialized')
		else:
			pass

	def _update_tracker(self, image, thresh_image):
		# Input: image or thresh_image
		# Output: new_bbox based on tracking
		new_bbox = None
		# tracking w/ openCV tracker
		if(self.tracker_type in self.OPENCV_OBJECT_TRACKERS.keys()):
			self.origin = np.array([0,0])
			# (x,y,w,h)\
			if(self.is_color==False):
				image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
			ok, new_bbox = self.tracker.update(image)
			return ok, new_bbox
		# tracking w/ the neural network-based tracker
		elif(self.tracker_type in self.NEURALNETTRACKERS.keys()):
			self.origin = np.array([0,0])
			if(self.is_color==False):
				image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
			self.state = SiamRPN_track(self.state, image)
			ok = True
			if(ok):
				# (x,y,w,h)
				new_bbox = cxy_wh_2_rect(self.state['target_pos'], self.state['target_sz'])
				new_bbox = [int(l) for l in new_bbox]
				# print('Updated daSiamRPN tracker')
			return ok, new_bbox
		# tracking w/ nearest neighbhour using the thresholded image 
		else:
			# If no tracker is specified, use basic thresholding and
			# nearest neighbhour tracking. i.e Look for objects in a search region 
			# near the last detected centroid

			# Get the latest thresholded image from the queue
			# thresh_image = 
			pts, thresh_image_cropped = image_processing.crop(thresh_image, self.centroid_image, self.searchArea)
			self.origin = pts[0]
			isCentroidFound, centroid, new_bbox = image_processing.find_centroid_basic_Rect(thresh_image_cropped)
			return isCentroidFound, new_bbox
		# @@@ Can add additional methods here for future tracker implementations

	# Signal from Tracking Widget connects to this Function
	def update_tracker_type(self, tracker_type):
		self.tracker_type = tracker_type
		print('set tracker set to {}'.format(self.tracker_type))
		# self.create_tracker()

	def update_init_method(self, method):
		self.init_method = method
		print("Tracking init method set to : {}".format(self.init_method))

	def centroid_from_bbox(self, bbox):
		# Coordinates of the object centroid are taken as the center of the bounding box
		assert(len(bbox) == 4)
		cx = int(bbox[0] + bbox[2]/2)
		cy = int(bbox[1] + bbox[3]/2)
		centroid = np.array([cx, cy])
		return centroid

	def rectpts_from_bbox(self, bbox):
		if(self.bbox is not None):
			pts = np.array([[bbox[0], bbox[1]],[bbox[0] + bbox[2], bbox[1] + bbox[3]]], dtype = 'int')
		else:
			pts = None
		return pts

	def update_searchArea(self, value):
		self.searchArea = value

	def set_roi_bbox(self, bbox):
		# Updates roi bbox from ImageDisplayWindow
		self.roi_bbox = bbox
		print('Rec bbox from ImageDisplay: {}'.format(self.roi_bbox))

"""Version: 54.23714.20231029
We use ctypes to call into the toupcam.dll/libtoupcam.so/libtoupcam.dylib API,
the python class Toupcam is a thin wrapper class to the native api of toupcam.dll/libtoupcam.so/libtoupcam.dylib.
So the manual en.html(English) and hans.html(Simplified Chinese) are also applicable for programming with toupcam.py.
See them in the 'doc' directory:
   (1) en.html, English
   (2) hans.html, Simplified Chinese
"""
import sys, ctypes, os.path

TOUPCAM_MAX = 128

TOUPCAM_FLAG_CMOS                = 0x00000001          # cmos sensor
TOUPCAM_FLAG_CCD_PROGRESSIVE     = 0x00000002          # progressive ccd sensor
TOUPCAM_FLAG_CCD_INTERLACED      = 0x00000004          # interlaced ccd sensor
TOUPCAM_FLAG_ROI_HARDWARE        = 0x00000008          # support hardware ROI
TOUPCAM_FLAG_MONO                = 0x00000010          # monochromatic
TOUPCAM_FLAG_BINSKIP_SUPPORTED   = 0x00000020          # support bin/skip mode
TOUPCAM_FLAG_USB30               = 0x00000040          # usb3.0
TOUPCAM_FLAG_TEC                 = 0x00000080          # Thermoelectric Cooler
TOUPCAM_FLAG_USB30_OVER_USB20    = 0x00000100          # usb3.0 camera connected to usb2.0 port
TOUPCAM_FLAG_ST4                 = 0x00000200          # ST4
TOUPCAM_FLAG_GETTEMPERATURE      = 0x00000400          # support to get the temperature of the sensor
TOUPCAM_FLAG_HIGH_FULLWELL       = 0x00000800          # high fullwell capacity
TOUPCAM_FLAG_RAW10               = 0x00001000          # pixel format, RAW 10bits
TOUPCAM_FLAG_RAW12               = 0x00002000          # pixel format, RAW 12bits
TOUPCAM_FLAG_RAW14               = 0x00004000          # pixel format, RAW 14bits
TOUPCAM_FLAG_RAW16               = 0x00008000          # pixel format, RAW 16bits
TOUPCAM_FLAG_FAN                 = 0x00010000          # cooling fan
TOUPCAM_FLAG_TEC_ONOFF           = 0x00020000          # Thermoelectric Cooler can be turn on or off, support to set the target temperature of TEC
TOUPCAM_FLAG_ISP                 = 0x00040000          # ISP (Image Signal Processing) chip
TOUPCAM_FLAG_TRIGGER_SOFTWARE    = 0x00080000          # support software trigger
TOUPCAM_FLAG_TRIGGER_EXTERNAL    = 0x00100000          # support external trigger
TOUPCAM_FLAG_TRIGGER_SINGLE      = 0x00200000          # only support trigger single: one trigger, one image
TOUPCAM_FLAG_BLACKLEVEL          = 0x00400000          # support set and get the black level
TOUPCAM_FLAG_AUTO_FOCUS          = 0x00800000          # support auto focus
TOUPCAM_FLAG_BUFFER              = 0x01000000          # frame buffer
TOUPCAM_FLAG_DDR                 = 0x02000000          # use very large capacity DDR (Double Data Rate SDRAM) for frame buffer. The capacity is not less than one full frame
TOUPCAM_FLAG_CG                  = 0x04000000          # support Conversion Gain mode: HCG, LCG
TOUPCAM_FLAG_YUV411              = 0x08000000          # pixel format, yuv411
TOUPCAM_FLAG_VUYY                = 0x10000000          # pixel format, yuv422, VUYY
TOUPCAM_FLAG_YUV444              = 0x20000000          # pixel format, yuv444
TOUPCAM_FLAG_RGB888              = 0x40000000          # pixel format, RGB888
TOUPCAM_FLAG_RAW8                = 0x80000000          # pixel format, RAW 8 bits
TOUPCAM_FLAG_GMCY8               = 0x0000000100000000  # pixel format, GMCY, 8 bits
TOUPCAM_FLAG_GMCY12              = 0x0000000200000000  # pixel format, GMCY, 12 bits
TOUPCAM_FLAG_UYVY                = 0x0000000400000000  # pixel format, yuv422, UYVY
TOUPCAM_FLAG_CGHDR               = 0x0000000800000000  # Conversion Gain: HCG, LCG, HDR
TOUPCAM_FLAG_GLOBALSHUTTER       = 0x0000001000000000  # global shutter
TOUPCAM_FLAG_FOCUSMOTOR          = 0x0000002000000000  # support focus motor
TOUPCAM_FLAG_PRECISE_FRAMERATE   = 0x0000004000000000  # support precise framerate & bandwidth, see TOUPCAM_OPTION_PRECISE_FRAMERATE & TOUPCAM_OPTION_BANDWIDTH
TOUPCAM_FLAG_HEAT                = 0x0000008000000000  # support heat to prevent fogging up
TOUPCAM_FLAG_LOW_NOISE           = 0x0000010000000000  # support low noise mode (Higher signal noise ratio, lower frame rate)
TOUPCAM_FLAG_LEVELRANGE_HARDWARE = 0x0000020000000000  # hardware level range, put(get)_LevelRangeV2
TOUPCAM_FLAG_EVENT_HARDWARE      = 0x0000040000000000  # hardware event, such as exposure start & stop
TOUPCAM_FLAG_LIGHTSOURCE         = 0x0000080000000000  # embedded light source
TOUPCAM_FLAG_FILTERWHEEL         = 0x0000100000000000  # astro filter wheel
TOUPCAM_FLAG_GIGE                = 0x0000200000000000  # 1 Gigabit GigE
TOUPCAM_FLAG_10GIGE              = 0x0000400000000000  # 10 Gigabit GigE
TOUPCAM_FLAG_5GIGE               = 0x0000800000000000  # 5 Gigabit GigE
TOUPCAM_FLAG_25GIGE              = 0x0001000000000000  # 2.5 Gigabit GigE
TOUPCAM_FLAG_AUTOFOCUSER         = 0x0002000000000000  # astro auto focuser
TOUPCAM_FLAG_LIGHT_SOURCE        = 0x0004000000000000  # stand alone light source
TOUPCAM_FLAG_CAMERALINK          = 0x0008000000000000  # camera link
TOUPCAM_FLAG_CXP                 = 0x0010000000000000  # CXP: CoaXPress
TOUPCAM_FLAG_RAW12PACK           = 0x0020000000000000  # pixel format, RAW 12bits packed

TOUPCAM_EVENT_EXPOSURE           = 0x0001          # exposure time or gain changed
TOUPCAM_EVENT_TEMPTINT           = 0x0002          # white balance changed, Temp/Tint mode
TOUPCAM_EVENT_CHROME             = 0x0003          # reversed, do not use it
TOUPCAM_EVENT_IMAGE              = 0x0004          # live image arrived, use PullImageXXXX to get this image
TOUPCAM_EVENT_STILLIMAGE         = 0x0005          # snap (still) frame arrived, use PullStillImageXXXX to get this frame
TOUPCAM_EVENT_WBGAIN             = 0x0006          # white balance changed, RGB Gain mode
TOUPCAM_EVENT_TRIGGERFAIL        = 0x0007          # trigger failed
TOUPCAM_EVENT_BLACK              = 0x0008          # black balance changed
TOUPCAM_EVENT_FFC                = 0x0009          # flat field correction status changed
TOUPCAM_EVENT_DFC                = 0x000a          # dark field correction status changed
TOUPCAM_EVENT_ROI                = 0x000b          # roi changed
TOUPCAM_EVENT_LEVELRANGE         = 0x000c          # level range changed
TOUPCAM_EVENT_AUTOEXPO_CONV      = 0x000d          # auto exposure convergence
TOUPCAM_EVENT_AUTOEXPO_CONVFAIL  = 0x000e          # auto exposure once mode convergence failed
TOUPCAM_EVENT_ERROR              = 0x0080          # generic error
TOUPCAM_EVENT_DISCONNECTED       = 0x0081          # camera disconnected
TOUPCAM_EVENT_NOFRAMETIMEOUT     = 0x0082          # no frame timeout error
TOUPCAM_EVENT_AFFEEDBACK         = 0x0083          # auto focus information feedback
TOUPCAM_EVENT_FOCUSPOS           = 0x0084          # focus positon
TOUPCAM_EVENT_NOPACKETTIMEOUT    = 0x0085          # no packet timeout
TOUPCAM_EVENT_EXPO_START         = 0x4000          # hardware event: exposure start
TOUPCAM_EVENT_EXPO_STOP          = 0x4001          # hardware event: exposure stop
TOUPCAM_EVENT_TRIGGER_ALLOW      = 0x4002          # hardware event: next trigger allow
TOUPCAM_EVENT_HEARTBEAT          = 0x4003          # hardware event: heartbeat, can be used to monitor whether the camera is alive
TOUPCAM_EVENT_TRIGGER_IN         = 0x4004          # hardware event: trigger in
TOUPCAM_EVENT_FACTORY            = 0x8001          # restore factory settings

TOUPCAM_OPTION_NOFRAME_TIMEOUT        = 0x01       # no frame timeout: 0 => disable, positive value (>= NOFRAME_TIMEOUT_MIN) => timeout milliseconds. default: disable
TOUPCAM_OPTION_THREAD_PRIORITY        = 0x02       # set the priority of the internal thread which grab data from the usb device.
                                                   #   Win: iValue: 0 => THREAD_PRIORITY_NORMAL; 1 => THREAD_PRIORITY_ABOVE_NORMAL; 2 => THREAD_PRIORITY_HIGHEST; 3 => THREAD_PRIORITY_TIME_CRITICAL; default: 1; see: https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-setthreadpriority
                                                   #   Linux & macOS: The high 16 bits for the scheduling policy, and the low 16 bits for the priority; see: https://linux.die.net/man/3/pthread_setschedparam
                                                   #
TOUPCAM_OPTION_RAW                    = 0x04       # raw data mode, read the sensor "raw" data. This can be set only while camea is NOT running. 0 = rgb, 1 = raw, default value: 0
TOUPCAM_OPTION_HISTOGRAM              = 0x05       # 0 = only one, 1 = continue mode
TOUPCAM_OPTION_BITDEPTH               = 0x06       # 0 = 8 bits mode, 1 = 16 bits mode
TOUPCAM_OPTION_FAN                    = 0x07       # 0 = turn off the cooling fan, [1, max] = fan speed
TOUPCAM_OPTION_TEC                    = 0x08       # 0 = turn off the thermoelectric cooler, 1 = turn on the thermoelectric cooler
TOUPCAM_OPTION_LINEAR                 = 0x09       # 0 = turn off the builtin linear tone mapping, 1 = turn on the builtin linear tone mapping, default value: 1
TOUPCAM_OPTION_CURVE                  = 0x0a       # 0 = turn off the builtin curve tone mapping, 1 = turn on the builtin polynomial curve tone mapping, 2 = logarithmic curve tone mapping, default value: 2
TOUPCAM_OPTION_TRIGGER                = 0x0b       # 0 = video mode, 1 = software or simulated trigger mode, 2 = external trigger mode, 3 = external + software trigger, default value = 0
TOUPCAM_OPTION_RGB                    = 0x0c       # 0 => RGB24; 1 => enable RGB48 format when bitdepth > 8; 2 => RGB32; 3 => 8 Bits Grey (only for mono camera); 4 => 16 Bits Grey (only for mono camera when bitdepth > 8); 5 => 64(RGB64)
TOUPCAM_OPTION_COLORMATIX             = 0x0d       # enable or disable the builtin color matrix, default value: 1
TOUPCAM_OPTION_WBGAIN                 = 0x0e       # enable or disable the builtin white balance gain, default value: 1
TOUPCAM_OPTION_TECTARGET              = 0x0f       # get or set the target temperature of the thermoelectric cooler, in 0.1 degree Celsius. For example, 125 means 12.5 degree Celsius, -35 means -3.5 degree Celsius
TOUPCAM_OPTION_AUTOEXP_POLICY         = 0x10       # auto exposure policy:
                                                   #      0: Exposure Only
                                                   #      1: Exposure Preferred
                                                   #      2: Gain Only
                                                   #      3: Gain Preferred
                                                   #      default value: 1
                                                   #
TOUPCAM_OPTION_FRAMERATE              = 0x11       # limit the frame rate, range=[0, 63], the default value 0 means no limit
TOUPCAM_OPTION_DEMOSAIC               = 0x12       # demosaic method for both video and still image: BILINEAR = 0, VNG(Variable Number of Gradients) = 1, PPG(Patterned Pixel Grouping) = 2, AHD(Adaptive Homogeneity Directed) = 3, EA(Edge Aware) = 4, see https://en.wikipedia.org/wiki/Demosaicing, default value: 0
TOUPCAM_OPTION_DEMOSAIC_VIDEO         = 0x13       # demosaic method for video
TOUPCAM_OPTION_DEMOSAIC_STILL         = 0x14       # demosaic method for still image
TOUPCAM_OPTION_BLACKLEVEL             = 0x15       # black level
TOUPCAM_OPTION_MULTITHREAD            = 0x16       # multithread image processing
TOUPCAM_OPTION_BINNING                = 0x17       # binning
                                                   #     0x01: (no binning)
                                                   #     n: (saturating add, n*n), 0x02(2*2), 0x03(3*3), 0x04(4*4), 0x05(5*5), 0x06(6*6), 0x07(7*7), 0x08(8*8). The Bitdepth of the data remains unchanged.
                                                   #     0x40 | n: (unsaturated add, n*n, works only in RAW mode), 0x42(2*2), 0x43(3*3), 0x44(4*4), 0x45(5*5), 0x46(6*6), 0x47(7*7), 0x48(8*8). The Bitdepth of the data is increased. For example, the original data with bitdepth of 12 will increase the bitdepth by 2 bits and become 14 after 2*2 binning.
                                                   #     0x80 | n: (average, n*n), 0x82(2*2), 0x83(3*3), 0x84(4*4), 0x85(5*5), 0x86(6*6), 0x87(7*7), 0x88(8*8). The Bitdepth of the data remains unchanged.
                                                   # The final image size is rounded down to an even number, such as 640/3 to get 212
                                                   #
TOUPCAM_OPTION_ROTATE                 = 0x18       # rotate clockwise: 0, 90, 180, 270
TOUPCAM_OPTION_CG                     = 0x19       # Conversion Gain mode: 0 = LCG, 1 = HCG, 2 = HDR
TOUPCAM_OPTION_PIXEL_FORMAT           = 0x1a       # pixel format
TOUPCAM_OPTION_FFC                    = 0x1b       # flat field correction
                                                   #      set:
                                                   #          0: disable
                                                   #          1: enable
                                                   #          -1: reset
                                                   #          (0xff000000 | n): set the average number to n, [1~255]
                                                   #      get:
                                                   #          (val & 0xff): 0 => disable, 1 => enable, 2 => inited
                                                   #          ((val & 0xff00) >> 8): sequence
                                                   #          ((val & 0xff0000) >> 16): average number
                                                   #
TOUPCAM_OPTION_DDR_DEPTH              = 0x1c       # the number of the frames that DDR can cache
                                                   #     1: DDR cache only one frame
                                                   #     0: Auto:
                                                   #         => one for video mode when auto exposure is enabled
                                                   #         => full capacity for others
                                                   #     1: DDR can cache frames to full capacity
                                                   #
TOUPCAM_OPTION_DFC                    = 0x1d       # dark field correction
                                                   #     set:
                                                   #         0: disable
                                                   #         1: enable
                                                   #         -1: reset
                                                   #         (0xff000000 | n): set the average number to n, [1~255]
                                                   #     get:
                                                   #         (val & 0xff): 0 => disable, 1 => enable, 2 => inited
                                                   #         ((val & 0xff00) >> 8): sequence
                                                   #         ((val & 0xff0000) >> 16): average number
                                                   #
TOUPCAM_OPTION_SHARPENING             = 0x1e       # Sharpening: (threshold << 24) | (radius << 16) | strength)
                                                   #     strength: [0, 500], default: 0 (disable)
                                                   #     radius: [1, 10]
                                                   #     threshold: [0, 255]
                                                   #
TOUPCAM_OPTION_FACTORY                = 0x1f       # restore the factory settings
TOUPCAM_OPTION_TEC_VOLTAGE            = 0x20       # get the current TEC voltage in 0.1V, 59 mean 5.9V; readonly
TOUPCAM_OPTION_TEC_VOLTAGE_MAX        = 0x21       # TEC maximum voltage in 0.1V
TOUPCAM_OPTION_DEVICE_RESET           = 0x22       # reset usb device, simulate a replug
TOUPCAM_OPTION_UPSIDE_DOWN            = 0x23       # upsize down:
                                                   #     1: yes
                                                   #     0: no
                                                   #     default: 1 (win), 0 (linux/macos)
                                                   #
TOUPCAM_OPTION_FOCUSPOS               = 0x24       # focus positon
TOUPCAM_OPTION_AFMODE                 = 0x25       # auto focus mode (0:manul focus; 1:auto focus; 2:once focus; 3:conjugate calibration)
TOUPCAM_OPTION_AFZONE                 = 0x26       # auto focus zone
TOUPCAM_OPTION_AFFEEDBACK             = 0x27       # auto focus information feedback; 0:unknown; 1:focused; 2:focusing; 3:defocus; 4:up; 5:down
TOUPCAM_OPTION_TESTPATTERN            = 0x28       # test pattern:
                                                   #     0: off
                                                   #     3: monochrome diagonal stripes
                                                   #     5: monochrome vertical stripes
                                                   #     7: monochrome horizontal stripes
                                                   #     9: chromatic diagonal stripes
                                                   #
TOUPCAM_OPTION_AUTOEXP_THRESHOLD      = 0x29       # threshold of auto exposure, default value: 5, range = [2, 15]
TOUPCAM_OPTION_BYTEORDER              = 0x2a       # Byte order, BGR or RGB: 0 => RGB, 1 => BGR, default value: 1(Win), 0(macOS, Linux, Android)
TOUPCAM_OPTION_NOPACKET_TIMEOUT       = 0x2b       # no packet timeout: 0 => disable, positive value (>= NOPACKET_TIMEOUT_MIN) => timeout milliseconds. default: disable
TOUPCAM_OPTION_MAX_PRECISE_FRAMERATE  = 0x2c       # get the precise frame rate maximum value in 0.1 fps, such as 115 means 11.5 fps. E_NOTIMPL means not supported
TOUPCAM_OPTION_PRECISE_FRAMERATE      = 0x2d       # precise frame rate current value in 0.1 fps, range:[1~maximum]
TOUPCAM_OPTION_BANDWIDTH              = 0x2e       # bandwidth, [1-100]%
TOUPCAM_OPTION_RELOAD                 = 0x2f       # reload the last frame in trigger mode
TOUPCAM_OPTION_CALLBACK_THREAD        = 0x30       # dedicated thread for callback
TOUPCAM_OPTION_FRONTEND_DEQUE_LENGTH  = 0x31       # frontend (raw) frame buffer deque length, range: [2, 1024], default: 4
                                                   # All the memory will be pre-allocated when the camera starts, so, please attention to memory usage
                                                   #
TOUPCAM_OPTION_FRAME_DEQUE_LENGTH     = 0x31       # alias of TOUPCAM_OPTION_FRONTEND_DEQUE_LENGTH
TOUPCAM_OPTION_MIN_PRECISE_FRAMERATE  = 0x32       # get the precise frame rate minimum value in 0.1 fps, such as 15 means 1.5 fps
TOUPCAM_OPTION_SEQUENCER_ONOFF        = 0x33       # sequencer trigger: on/off
TOUPCAM_OPTION_SEQUENCER_NUMBER       = 0x34       # sequencer trigger: number, range = [1, 255]
TOUPCAM_OPTION_SEQUENCER_EXPOTIME     = 0x01000000 # sequencer trigger: exposure time, iOption = TOUPCAM_OPTION_SEQUENCER_EXPOTIME | index, iValue = exposure time
                                                   #   For example, to set the exposure time of the third group to 50ms, call:
                                                   #     Toupcam_put_Option(TOUPCAM_OPTION_SEQUENCER_EXPOTIME | 3, 50000)
                                                   #
TOUPCAM_OPTION_SEQUENCER_EXPOGAIN     = 0x02000000 # sequencer trigger: exposure gain, iOption = TOUPCAM_OPTION_SEQUENCER_EXPOGAIN | index, iValue = gain
TOUPCAM_OPTION_DENOISE                = 0x35       # denoise, strength range: [0, 100], 0 means disable
TOUPCAM_OPTION_HEAT_MAX               = 0x36       # get maximum level: heat to prevent fogging up
TOUPCAM_OPTION_HEAT                   = 0x37       # heat to prevent fogging up
TOUPCAM_OPTION_LOW_NOISE              = 0x38       # low noise mode (Higher signal noise ratio, lower frame rate): 1 => enable
TOUPCAM_OPTION_POWER                  = 0x39       # get power consumption, unit: milliwatt
TOUPCAM_OPTION_GLOBAL_RESET_MODE      = 0x3a       # global reset mode
TOUPCAM_OPTION_OPEN_ERRORCODE         = 0x3b       # get the open camera error code
TOUPCAM_OPTION_FLUSH                  = 0x3d       # 1 = hard flush, discard frames cached by camera DDR (if any)
                                                   # 2 = soft flush, discard frames cached by toupcam.dll (if any)
                                                   # 3 = both flush
                                                   # Toupcam_Flush means 'both flush'
                                                   # return the number of soft flushed frames if successful, HRESULT if failed
                                                   #
TOUPCAM_OPTION_NUMBER_DROP_FRAME      = 0x3e       # get the number of frames that have been grabbed from the USB but dropped by the software
TOUPCAM_OPTION_DUMP_CFG               = 0x3f       # 0 = when camera is stopped, do not dump configuration automatically
                                                   # 1 = when camera is stopped, dump configuration automatically
                                                   # -1 = explicitly dump configuration once
                                                   # default: 1
                                                   #
TOUPCAM_OPTION_DEFECT_PIXEL           = 0x40       # Defect Pixel Correction: 0 => disable, 1 => enable; default: 1
TOUPCAM_OPTION_BACKEND_DEQUE_LENGTH   = 0x41       # backend (pipelined) frame buffer deque length (Only available in pull mode), range: [2, 1024], default: 3
                                                   # All the memory will be pre-allocated when the camera starts, so, please attention to memory usage
                                                   #
TOUPCAM_OPTION_LIGHTSOURCE_MAX        = 0x42       # get the light source range, [0 ~ max]
TOUPCAM_OPTION_LIGHTSOURCE            = 0x43       # light source
TOUPCAM_OPTION_HEARTBEAT              = 0x44       # Heartbeat interval in millisecond, range = [TOUPCAM_HEARTBEAT_MIN, TOUPCAM_HEARTBEAT_MAX], 0 = disable, default: disable
TOUPCAM_OPTION_FRONTEND_DEQUE_CURRENT = 0x45       # get the current number in frontend deque
TOUPCAM_OPTION_BACKEND_DEQUE_CURRENT  = 0x46       # get the current number in backend deque
TOUPCAM_OPTION_EVENT_HARDWARE         = 0x04000000 # enable or disable hardware event: 0 => disable, 1 => enable; default: disable
                                                   #     (1) iOption = TOUPCAM_OPTION_EVENT_HARDWARE, master switch for notification of all hardware events
                                                   #     (2) iOption = TOUPCAM_OPTION_EVENT_HARDWARE | (event type), a specific type of sub-switch
                                                   # Only if both the master switch and the sub-switch of a particular type remain on are actually enabled for that type of event notification.
                                                   #
TOUPCAM_OPTION_PACKET_NUMBER          = 0x47       # get the received packet number
TOUPCAM_OPTION_FILTERWHEEL_SLOT       = 0x48       # filter wheel slot number
TOUPCAM_OPTION_FILTERWHEEL_POSITION   = 0x49       # filter wheel position:
                                                   #     set:
                                                   #         -1: calibrate
                                                   #         val & 0xff: position between 0 and N-1, where N is the number of filter slots
                                                   #         (val >> 8) & 0x1: direction, 0 => clockwise spinning, 1 => auto direction spinning
                                                   #     get:
                                                   #         -1: in motion
                                                   #         val: position arrived
                                                   #
TOUPCAM_OPTION_AUTOEXPOSURE_PERCENT   = 0x4a       # auto exposure percent to average:
                                                   #     1~99: peak percent average
                                                   #     0 or 100: full roi average, means "disabled"
                                                   #
TOUPCAM_OPTION_ANTI_SHUTTER_EFFECT    = 0x4b       # anti shutter effect: 1 => disable, 0 => disable; default: 1
TOUPCAM_OPTION_CHAMBER_HT             = 0x4c       # get chamber humidity & temperature:
                                                   #     high 16 bits: humidity, in 0.1%, such as: 325 means humidity is 32.5%
                                                   #     low 16 bits: temperature, in 0.1 degrees Celsius, such as: 32 means 3.2 degrees Celsius
                                                   #
TOUPCAM_OPTION_ENV_HT                 = 0x4d       # get environment humidity & temperature
TOUPCAM_OPTION_EXPOSURE_PRE_DELAY     = 0x4e       # exposure signal pre-delay, microsecond
TOUPCAM_OPTION_EXPOSURE_POST_DELAY    = 0x4f       # exposure signal post-delay, microsecond
TOUPCAM_OPTION_AUTOEXPO_CONV          = 0x50       # get auto exposure convergence status: 1(YES) or 0(NO), -1(NA)
TOUPCAM_OPTION_AUTOEXPO_TRIGGER       = 0x51       # auto exposure on trigger mode: 0 => disable, 1 => enable; default: 0
TOUPCAM_OPTION_LINE_PRE_DELAY         = 0x52       # specified line signal pre-delay, microsecond
TOUPCAM_OPTION_LINE_POST_DELAY        = 0x53       # specified line signal post-delay, microsecond
TOUPCAM_OPTION_TEC_VOLTAGE_MAX_RANGE  = 0x54       # get the tec maximum voltage range:
                                                   #      high 16 bits: max
                                                   #      low 16 bits: min
TOUPCAM_OPTION_HIGH_FULLWELL          = 0x55       # high fullwell capacity: 0 => disable, 1 => enable
TOUPCAM_OPTION_DYNAMIC_DEFECT         = 0x56       # dynamic defect pixel correction:
                                                   #      threshold, t1: high 16 bits: [10, 100], means: [1.0, 10.0]
                                                   #      value, t2: low 16 bits: [0, 100], means: [0.00, 1.00]
TOUPCAM_OPTION_HDR_KB                 = 0x57       # HDR synthesize
                                                   #      K (high 16 bits): [1, 25500]
                                                   #      B (low 16 bits): [0, 65535]
                                                   #      0xffffffff => set to default
TOUPCAM_OPTION_HDR_THRESHOLD          = 0x58       # HDR synthesize
                                                   #      threshold: [1, 4094]
                                                   #      0xffffffff => set to default
TOUPCAM_OPTION_GIGETIMEOUT            = 0x5a       # For GigE cameras, the application periodically sends heartbeat signals to the camera to keep the connection to the camera alive.
                                                   # If the camera doesn't receive heartbeat signals within the time period specified by the heartbeat timeout counter, the camera resets the connection.
                                                   # When the application is stopped by the debugger, the application cannot create the heartbeat signals
                                                   #     0 => auto: when the camera is opened, disable if debugger is present or enable if no debugger is present
                                                   #     1 => enable
                                                   #     2 => disable
                                                   #     default: auto
TOUPCAM_OPTION_EEPROM_SIZE            = 0x5b       # get EEPROM size
TOUPCAM_OPTION_OVERCLOCK_MAX          = 0x5c       # get overclock range: [0, max]
TOUPCAM_OPTION_OVERCLOCK              = 0x5d       # overclock, default: 0
TOUPCAM_OPTION_RESET_SENSOR           = 0x5e       # reset sensor

TOUPCAM_OPTION_ADC                    = 0x08000000 # Analog-Digital Conversion:
                                                   #    get:
                                                   #        (option | 'C'): get the current value
                                                   #        (option | 'N'): get the supported ADC number
                                                   #        (option | n): get the nth supported ADC value, such as 11bits, 12bits, etc; the first value is the default
                                                   #    set: val = ADC value, such as 11bits, 12bits, etc                                                     
TOUPCAM_OPTION_ISP                    = 0x5f       # Enable hardware ISP: 0 => auto (disable in RAW mode, otherwise enable), 1 => enable, -1 => disable; default: 0
TOUPCAM_OPTION_AUTOEXP_EXPOTIME_STEP  = 0x60       # Auto exposure: time step (thousandths)
TOUPCAM_OPTION_AUTOEXP_GAIN_STEP      = 0x61       # Auto exposure: gain step (thousandths)
TOUPCAM_OPTION_MOTOR_NUMBER           = 0x62       # range: [1, 20]
TOUPCAM_OPTION_MOTOR_POS              = 0x10000000 # range: [1, 702]
TOUPCAM_OPTION_PSEUDO_COLOR_START     = 0x63       # Pseudo: start color, BGR format
TOUPCAM_OPTION_PSEUDO_COLOR_END       = 0x64       # Pseudo: end color, BGR format
TOUPCAM_OPTION_PSEUDO_COLOR_ENABLE    = 0x65       # Pseudo: 1 => enable, 0 => disable

TOUPCAM_PIXELFORMAT_RAW8              = 0x00
TOUPCAM_PIXELFORMAT_RAW10             = 0x01
TOUPCAM_PIXELFORMAT_RAW12             = 0x02
TOUPCAM_PIXELFORMAT_RAW14             = 0x03
TOUPCAM_PIXELFORMAT_RAW16             = 0x04
TOUPCAM_PIXELFORMAT_YUV411            = 0x05
TOUPCAM_PIXELFORMAT_VUYY              = 0x06
TOUPCAM_PIXELFORMAT_YUV444            = 0x07
TOUPCAM_PIXELFORMAT_RGB888            = 0x08
TOUPCAM_PIXELFORMAT_GMCY8             = 0x09   # map to RGGB 8 bits
TOUPCAM_PIXELFORMAT_GMCY12            = 0x0a   # map to RGGB 12 bits
TOUPCAM_PIXELFORMAT_UYVY              = 0x0b
TOUPCAM_PIXELFORMAT_RAW12PACK         = 0x0c

TOUPCAM_FRAMEINFO_FLAG_SEQ            = 0x00000001   # frame sequence number
TOUPCAM_FRAMEINFO_FLAG_TIMESTAMP      = 0x00000002   # timestamp
TOUPCAM_FRAMEINFO_FLAG_EXPOTIME       = 0x00000004   # exposure time
TOUPCAM_FRAMEINFO_FLAG_EXPOGAIN       = 0x00000008   # exposure gain
TOUPCAM_FRAMEINFO_FLAG_BLACKLEVEL     = 0x00000010   # black level
TOUPCAM_FRAMEINFO_FLAG_SHUTTERSEQ     = 0x00000020   # sequence shutter counter
TOUPCAM_FRAMEINFO_FLAG_STILL          = 0x00008000   # still image

TOUPCAM_IOCONTROLTYPE_GET_SUPPORTEDMODE         = 0x01  # 0x01 => Input, 0x02 => Output, (0x01 | 0x02) => support both Input and Output
TOUPCAM_IOCONTROLTYPE_GET_GPIODIR               = 0x03  # 0x01 => Input, 0x02 => Output
TOUPCAM_IOCONTROLTYPE_SET_GPIODIR               = 0x04
TOUPCAM_IOCONTROLTYPE_GET_FORMAT                = 0x05  # 0x00 => not connected
                                                        # 0x01 => Tri-state: Tri-state mode (Not driven)
                                                        # 0x02 => TTL: TTL level signals
                                                        # 0x03 => LVDS: LVDS level signals
                                                        # 0x04 => RS422: RS422 level signals
                                                        # 0x05 => Opto-coupled
TOUPCAM_IOCONTROLTYPE_SET_FORMAT                = 0x06
TOUPCAM_IOCONTROLTYPE_GET_OUTPUTINVERTER        = 0x07  # boolean, only support output signal
TOUPCAM_IOCONTROLTYPE_SET_OUTPUTINVERTER        = 0x08
TOUPCAM_IOCONTROLTYPE_GET_INPUTACTIVATION       = 0x09  # 0x00 => Rising edge, 0x01 => Falling edge, 0x02 => Level high, 0x03 => Level low
TOUPCAM_IOCONTROLTYPE_SET_INPUTACTIVATION       = 0x0a
TOUPCAM_IOCONTROLTYPE_GET_DEBOUNCERTIME         = 0x0b  # debouncer time in microseconds, range: [0, 20000]
TOUPCAM_IOCONTROLTYPE_SET_DEBOUNCERTIME         = 0x0c
TOUPCAM_IOCONTROLTYPE_GET_TRIGGERSOURCE         = 0x0d  # 0x00 => Opto-isolated input
                                                        # 0x01 => GPIO0
                                                        # 0x02 => GPIO1
                                                        # 0x03 => Counter
                                                        # 0x04 => PWM
                                                        # 0x05 => Software
TOUPCAM_IOCONTROLTYPE_SET_TRIGGERSOURCE         = 0x0e
TOUPCAM_IOCONTROLTYPE_GET_TRIGGERDELAY          = 0x0f  # Trigger delay time in microseconds, range: [0, 5000000]
TOUPCAM_IOCONTROLTYPE_SET_TRIGGERDELAY          = 0x10
TOUPCAM_IOCONTROLTYPE_GET_BURSTCOUNTER          = 0x11  # Burst Counter, range: [1 ~ 65535]
TOUPCAM_IOCONTROLTYPE_SET_BURSTCOUNTER          = 0x12
TOUPCAM_IOCONTROLTYPE_GET_COUNTERSOURCE         = 0x13  # 0x00 => Opto-isolated input, 0x01 => GPIO0, 0x02 => GPIO1
TOUPCAM_IOCONTROLTYPE_SET_COUNTERSOURCE         = 0x14
TOUPCAM_IOCONTROLTYPE_GET_COUNTERVALUE          = 0x15  # Counter Value, range: [1 ~ 65535]
TOUPCAM_IOCONTROLTYPE_SET_COUNTERVALUE          = 0x16
TOUPCAM_IOCONTROLTYPE_SET_RESETCOUNTER          = 0x18
TOUPCAM_IOCONTROLTYPE_GET_PWM_FREQ              = 0x19
TOUPCAM_IOCONTROLTYPE_SET_PWM_FREQ              = 0x1a
TOUPCAM_IOCONTROLTYPE_GET_PWM_DUTYRATIO         = 0x1b
TOUPCAM_IOCONTROLTYPE_SET_PWM_DUTYRATIO         = 0x1c
TOUPCAM_IOCONTROLTYPE_GET_PWMSOURCE             = 0x1d  # 0x00 => Opto-isolated input, 0x01 => GPIO0, 0x02 => GPIO1
TOUPCAM_IOCONTROLTYPE_SET_PWMSOURCE             = 0x1e
TOUPCAM_IOCONTROLTYPE_GET_OUTPUTMODE            = 0x1f  # 0x00 => Frame Trigger Wait
                                                        # 0x01 => Exposure Active
                                                        # 0x02 => Strobe
                                                        # 0x03 => User output                                                        
                                                        # 0x04 => Counter Output
                                                        # 0x05 => Timer Output
TOUPCAM_IOCONTROLTYPE_SET_OUTPUTMODE            = 0x20
TOUPCAM_IOCONTROLTYPE_GET_STROBEDELAYMODE       = 0x21  # boolean, 1 => delay, 0 => pre-delay; compared to exposure active signal
TOUPCAM_IOCONTROLTYPE_SET_STROBEDELAYMODE       = 0x22
TOUPCAM_IOCONTROLTYPE_GET_STROBEDELAYTIME       = 0x23  # Strobe delay or pre-delay time in microseconds, range: [0, 5000000]
TOUPCAM_IOCONTROLTYPE_SET_STROBEDELAYTIME       = 0x24
TOUPCAM_IOCONTROLTYPE_GET_STROBEDURATION        = 0x25  # Strobe duration time in microseconds, range: [0, 5000000]
TOUPCAM_IOCONTROLTYPE_SET_STROBEDURATION        = 0x26
TOUPCAM_IOCONTROLTYPE_GET_USERVALUE             = 0x27  # bit0 => Opto-isolated output
                                                        # bit1 => GPIO0 output
                                                        # bit2 => GPIO1 output
TOUPCAM_IOCONTROLTYPE_SET_USERVALUE             = 0x28
TOUPCAM_IOCONTROLTYPE_GET_UART_ENABLE           = 0x29  # enable: 1 => on; 0 => off
TOUPCAM_IOCONTROLTYPE_SET_UART_ENABLE           = 0x2a
TOUPCAM_IOCONTROLTYPE_GET_UART_BAUDRATE         = 0x2b  # baud rate: 0 => 9600; 1 => 19200; 2 => 38400; 3 => 57600; 4 => 115200
TOUPCAM_IOCONTROLTYPE_SET_UART_BAUDRATE         = 0x2c
TOUPCAM_IOCONTROLTYPE_GET_UART_LINEMODE         = 0x2d  # line mode: 0 => TX(GPIO_0)/RX(GPIO_1); 1 => TX(GPIO_1)/RX(GPIO_0)
TOUPCAM_IOCONTROLTYPE_SET_UART_LINEMODE         = 0x2e
TOUPCAM_IOCONTROLTYPE_GET_EXPO_ACTIVE_MODE      = 0x2f  # exposure time signal: 0 => specified line, 1 => common exposure time
TOUPCAM_IOCONTROLTYPE_SET_EXPO_ACTIVE_MODE      = 0x30
TOUPCAM_IOCONTROLTYPE_GET_EXPO_START_LINE       = 0x31  # exposure start line, default: 0
TOUPCAM_IOCONTROLTYPE_SET_EXPO_START_LINE       = 0x32
TOUPCAM_IOCONTROLTYPE_GET_EXPO_END_LINE         = 0x33  # exposure end line, default: 0
                                                        # end line must be no less than start line
TOUPCAM_IOCONTROLTYPE_SET_EXPO_END_LINE         = 0x34
TOUPCAM_IOCONTROLTYPE_GET_EXEVT_ACTIVE_MODE     = 0x35  # exposure event: 0 => specified line, 1 => common exposure time
TOUPCAM_IOCONTROLTYPE_SET_EXEVT_ACTIVE_MODE     = 0x36
TOUPCAM_IOCONTROLTYPE_GET_OUTPUTCOUNTERVALUE    = 0x37  # Output Counter Value, range: [0 ~ 65535]
TOUPCAM_IOCONTROLTYPE_SET_OUTPUTCOUNTERVALUE    = 0x38
TOUPCAM_IOCONTROLTYPE_SET_OUTPUT_PAUSE          = 0x3a  # Output pause: 1 => puase, 0 => unpause

# AAF: Astro Auto Focuser
TOUPCAM_AAF_SETPOSITION     = 0x01
TOUPCAM_AAF_GETPOSITION     = 0x02
TOUPCAM_AAF_SETZERO         = 0x03
TOUPCAM_AAF_GETZERO         = 0x04
TOUPCAM_AAF_SETDIRECTION    = 0x05
TOUPCAM_AAF_SETMAXINCREMENT = 0x07
TOUPCAM_AAF_GETMAXINCREMENT = 0x08
TOUPCAM_AAF_SETFINE         = 0x09
TOUPCAM_AAF_GETFINE         = 0x0a
TOUPCAM_AAF_SETCOARSE       = 0x0b
TOUPCAM_AAF_GETCOARSE       = 0x0c
TOUPCAM_AAF_SETBUZZER       = 0x0d
TOUPCAM_AAF_GETBUZZER       = 0x0e
TOUPCAM_AAF_SETBACKLASH     = 0x0f
TOUPCAM_AAF_GETBACKLASH     = 0x10
TOUPCAM_AAF_GETAMBIENTTEMP  = 0x12
TOUPCAM_AAF_GETTEMP         = 0x14
TOUPCAM_AAF_ISMOVING        = 0x16
TOUPCAM_AAF_HALT            = 0x17
TOUPCAM_AAF_SETMAXSTEP      = 0x1b
TOUPCAM_AAF_GETMAXSTEP      = 0x1c
TOUPCAM_AAF_RANGEMIN        = 0xfd  # Range: min value
TOUPCAM_AAF_RANGEMAX        = 0xfe  # Range: max value
TOUPCAM_AAF_RANGEDEF        = 0xff  # Range: default value

# hardware level range mode
TOUPCAM_LEVELRANGE_MANUAL   = 0x0000 # manual
TOUPCAM_LEVELRANGE_ONCE     = 0x0001 # once
TOUPCAM_LEVELRANGE_CONTINUE = 0x0002 # continue
TOUPCAM_LEVELRANGE_ROI      = 0xffff # update roi rect only

# see rwc_Flash
TOUPCAM_FLASH_SIZE      = 0x00    # query total size
TOUPCAM_FLASH_EBLOCK    = 0x01    # query erase block size
TOUPCAM_FLASH_RWBLOCK   = 0x02    # query read/write block size
TOUPCAM_FLASH_STATUS    = 0x03    # query status
TOUPCAM_FLASH_READ      = 0x04    # read
TOUPCAM_FLASH_WRITE     = 0x05    # write
TOUPCAM_FLASH_ERASE     = 0x06    # erase

# HRESULT: error code
S_OK            = 0x00000000 # Success
S_FALSE         = 0x00000001 # Yet another success
E_UNEXPECTED    = 0x8000ffff # Catastrophic failure
E_NOTIMPL       = 0x80004001 # Not supported or not implemented
E_ACCESSDENIED  = 0x80070005 # Permission denied
E_OUTOFMEMORY   = 0x8007000e # Out of memory
E_INVALIDARG    = 0x80070057 # One or more arguments are not valid
E_POINTER       = 0x80004003 # Pointer that is not valid
E_FAIL          = 0x80004005 # Generic failure
E_WRONG_THREAD  = 0x8001010e # Call function in the wrong thread
E_GEN_FAILURE   = 0x8007001f # Device not functioning
E_BUSY          = 0x800700aa # The requested resource is in use
E_PENDING       = 0x8000000a # The data necessary to complete this operation is not yet available
E_TIMEOUT       = 0x8001011f # This operation returned because the timeout period expired

TOUPCAM_EXPOGAIN_DEF             = 100      # exposure gain, default value
TOUPCAM_EXPOGAIN_MIN             = 100      # exposure gain, minimum value
TOUPCAM_TEMP_DEF                 = 6503     # color temperature, default value
TOUPCAM_TEMP_MIN                 = 2000     # color temperature, minimum value
TOUPCAM_TEMP_MAX                 = 15000    # color temperature, maximum value
TOUPCAM_TINT_DEF                 = 1000     # tint
TOUPCAM_TINT_MIN                 = 200      # tint
TOUPCAM_TINT_MAX                 = 2500     # tint
TOUPCAM_HUE_DEF                  = 0        # hue
TOUPCAM_HUE_MIN                  = -180     # hue
TOUPCAM_HUE_MAX                  = 180      # hue
TOUPCAM_SATURATION_DEF           = 128      # saturation
TOUPCAM_SATURATION_MIN           = 0        # saturation
TOUPCAM_SATURATION_MAX           = 255      # saturation
TOUPCAM_BRIGHTNESS_DEF           = 0        # brightness
TOUPCAM_BRIGHTNESS_MIN           = -64      # brightness
TOUPCAM_BRIGHTNESS_MAX           = 64       # brightness
TOUPCAM_CONTRAST_DEF             = 0        # contrast
TOUPCAM_CONTRAST_MIN             = -100     # contrast
TOUPCAM_CONTRAST_MAX             = 100      # contrast
TOUPCAM_GAMMA_DEF                = 100      # gamma
TOUPCAM_GAMMA_MIN                = 20       # gamma
TOUPCAM_GAMMA_MAX                = 180      # gamma
TOUPCAM_AETARGET_DEF             = 120      # target of auto exposure
TOUPCAM_AETARGET_MIN             = 16       # target of auto exposure
TOUPCAM_AETARGET_MAX             = 220      # target of auto exposure
TOUPCAM_WBGAIN_DEF               = 0        # white balance gain
TOUPCAM_WBGAIN_MIN               = -127     # white balance gain
TOUPCAM_WBGAIN_MAX               = 127      # white balance gain
TOUPCAM_BLACKLEVEL_MIN           = 0        # minimum black level
TOUPCAM_BLACKLEVEL8_MAX          = 31       # maximum black level for bitdepth = 8
TOUPCAM_BLACKLEVEL10_MAX         = 31 * 4   # maximum black level for bitdepth = 10
TOUPCAM_BLACKLEVEL12_MAX         = 31 * 16  # maximum black level for bitdepth = 12
TOUPCAM_BLACKLEVEL14_MAX         = 31 * 64  # maximum black level for bitdepth = 14
TOUPCAM_BLACKLEVEL16_MAX         = 31 * 256 # maximum black level for bitdepth = 16
TOUPCAM_SHARPENING_STRENGTH_DEF  = 0        # sharpening strength
TOUPCAM_SHARPENING_STRENGTH_MIN  = 0        # sharpening strength
TOUPCAM_SHARPENING_STRENGTH_MAX  = 500      # sharpening strength
TOUPCAM_SHARPENING_RADIUS_DEF    = 2        # sharpening radius
TOUPCAM_SHARPENING_RADIUS_MIN    = 1        # sharpening radius
TOUPCAM_SHARPENING_RADIUS_MAX    = 10       # sharpening radius
TOUPCAM_SHARPENING_THRESHOLD_DEF = 0        # sharpening threshold
TOUPCAM_SHARPENING_THRESHOLD_MIN = 0        # sharpening threshold
TOUPCAM_SHARPENING_THRESHOLD_MAX = 255      # sharpening threshold
TOUPCAM_AUTOEXPO_THRESHOLD_DEF   = 5        # auto exposure threshold
TOUPCAM_AUTOEXPO_THRESHOLD_MIN   = 2        # auto exposure threshold
TOUPCAM_AUTOEXPO_THRESHOLD_MAX   = 15       # auto exposure threshold
TOUPCAM_AUTOEXPO_STEP_DEF        = 1000     # auto exposure step: thousandths
TOUPCAM_AUTOEXPO_STEP_MIN        = 1        # auto exposure step: thousandths
TOUPCAM_AUTOEXPO_STEP_MAX        = 1000     # auto exposure step: thousandths
TOUPCAM_BANDWIDTH_DEF            = 100      # bandwidth
TOUPCAM_BANDWIDTH_MIN            = 1        # bandwidth
TOUPCAM_BANDWIDTH_MAX            = 100      # bandwidth
TOUPCAM_DENOISE_DEF              = 0        # denoise
TOUPCAM_DENOISE_MIN              = 0        # denoise
TOUPCAM_DENOISE_MAX              = 100      # denoise
TOUPCAM_TEC_TARGET_MIN           = -500     # TEC target: -50.0 degrees Celsius
TOUPCAM_TEC_TARGET_DEF           = 100      # TEC target: 0.0 degrees Celsius
TOUPCAM_TEC_TARGET_MAX           = 400      # TEC target: 40.0 degrees Celsius
TOUPCAM_HEARTBEAT_MIN            = 100      # millisecond
TOUPCAM_HEARTBEAT_MAX            = 10000    # millisecond
TOUPCAM_AE_PERCENT_MIN           = 0        # auto exposure percent; 0 or 100 => full roi average, means "disabled"
TOUPCAM_AE_PERCENT_MAX           = 100
TOUPCAM_AE_PERCENT_DEF           = 10       # auto exposure percent: enabled, percentage = 10%
TOUPCAM_NOPACKET_TIMEOUT_MIN     = 500      # no packet timeout minimum: 500ms
TOUPCAM_NOFRAME_TIMEOUT_MIN      = 500      # no frame timeout minimum: 500ms
TOUPCAM_DYNAMIC_DEFECT_T1_MIN    = 10       # dynamic defect pixel correction, threshold, means: 1.0
TOUPCAM_DYNAMIC_DEFECT_T1_MAX    = 100      # means: 10.0
TOUPCAM_DYNAMIC_DEFECT_T1_DEF    = 13       # means: 1.3
TOUPCAM_DYNAMIC_DEFECT_T2_MIN    = 0        # dynamic defect pixel correction, value, means: 0.00
TOUPCAM_DYNAMIC_DEFECT_T2_MAX    = 100      # means: 1.00
TOUPCAM_DYNAMIC_DEFECT_T2_DEF    = 100
TOUPCAM_HDR_K_MIN                = 1        # HDR synthesize
TOUPCAM_HDR_K_MAX                = 25500
TOUPCAM_HDR_B_MIN                = 0
TOUPCAM_HDR_B_MAX                = 65535
TOUPCAM_HDR_THRESHOLD_MIN        = 0
TOUPCAM_HDR_THRESHOLD_MAX        = 4094

def TDIBWIDTHBYTES(bits):
    return ((bits + 31) // 32 * 4)

"""
------------------------------------------------------------------|
| Parameter               |   Range       |   Default             |
|-----------------------------------------------------------------|
| Auto Exposure Target    |   16~235      |   120                 |
| Exposure Gain           |   100~        |   100                 |
| Temp                    |   2000~15000  |   6503                |
| Tint                    |   200~2500    |   1000                |
| LevelRange              |   0~255       |   Low = 0, High = 255 |
| Contrast                |   -100~100    |   0                   |
| Hue                     |   -180~180    |   0                   |
| Saturation              |   0~255       |   128                 |
| Brightness              |   -64~64      |   0                   |
| Gamma                   |   20~180      |   100                 |
| WBGain                  |   -127~127    |   0                   |
------------------------------------------------------------------|
"""

class ToupcamResolution:
    def __init__(self, w, h):
        self.width = w
        self.height = h

class ToupcamAfParam:
    def __init__(self, imax, imin, idef, imaxabs, iminabs, zoneh, zonev):
        self.imax = imax                 # maximum auto focus sensor board positon
        self.imin = imin                 # minimum auto focus sensor board positon
        self.idef = idef                 # conjugate calibration positon
        self.imaxabs = imaxabs           # maximum absolute auto focus sensor board positon, micrometer
        self.iminabs = iminabs           # maximum absolute auto focus sensor board positon, micrometer
        self.zoneh = zoneh               # zone horizontal
        self.zonev = zonev               # zone vertical

class ToupcamFrameInfoV3:
    def __init__(self):
        self.width = 0
        self.height = 0
        self.flag = 0                    # TOUPCAM_FRAMEINFO_FLAG_xxxx
        self.seq = 0                     # frame sequence number
        self.timestamp = 0               # microsecond
        self.shutterseq = 0              # sequence shutter counter
        self.expotime = 0                # expotime
        self.expogain = 0                # expogain
        self.blacklevel = 0              # black level

class ToupcamFrameInfoV2:
    def __init__(self):
        self.width = 0
        self.height = 0
        self.flag = 0                    # TOUPCAM_FRAMEINFO_FLAG_xxxx
        self.seq = 0                     # frame sequence number
        self.timestamp = 0               # microsecond

class ToupcamModelV2:                    # camera model v2
    def __init__(self, name, flag, maxspeed, preview, still, maxfanspeed, ioctrol, xpixsz, ypixsz, res):
        self.name = name                 # model name, in Windows, we use unicode
        self.flag = flag                 # TOUPCAM_FLAG_xxx, 64 bits
        self.maxspeed = maxspeed         # number of speed level, same as Toupcam_get_MaxSpeed(), the speed range = [0, maxspeed], closed interval
        self.preview = preview           # number of preview resolution, same as Toupcam_get_ResolutionNumber()
        self.still = still               # number of still resolution, same as Toupcam_get_StillResolutionNumber()
        self.maxfanspeed = maxfanspeed   # maximum fan speed, fan speed range = [0, max], closed interval
        self.ioctrol = ioctrol           # number of input/output control
        self.xpixsz = xpixsz             # physical pixel size in micrometer
        self.ypixsz = ypixsz             # physical pixel size in micrometer
        self.res = res                   # ToupcamResolution

class ToupcamDeviceV2:
    def __init__(self, displayname, id, model):
        self.displayname = displayname   # display name
        self.id = id                     # unique and opaque id of a connected camera, for Toupcam_Open
        self.model = model               # ToupcamModelV2

if sys.platform == 'win32':
    class HRESULTException(OSError):
        def __init__(self, hr):
            OSError.__init__(self, None, ctypes.FormatError(hr).strip(), None)
            self.hr = hr
else:
    class HRESULTException(Exception):
        def __init__(self, hr):
            self.hr = hr

class _Resolution(ctypes.Structure):
    _fields_ = [('width', ctypes.c_uint),
                ('height', ctypes.c_uint)]

if sys.platform == 'win32':
    class _ModelV2(ctypes.Structure):                      # camera model v2 win32
        _fields_ = [('name', ctypes.c_wchar_p),            # model name, in Windows, we use unicode
                    ('flag', ctypes.c_ulonglong),          # TOUPCAM_FLAG_xxx, 64 bits
                    ('maxspeed', ctypes.c_uint),           # number of speed level, same as Toupcam_get_MaxSpeed(), the speed range = [0, maxspeed], closed interval
                    ('preview', ctypes.c_uint),            # number of preview resolution, same as Toupcam_get_ResolutionNumber()
                    ('still', ctypes.c_uint),              # number of still resolution, same as Toupcam_get_StillResolutionNumber()
                    ('maxfanspeed', ctypes.c_uint),        # maximum fan speed, fan speed range = [0, max], closed interval
                    ('ioctrol', ctypes.c_uint),            # number of input/output control
                    ('xpixsz', ctypes.c_float),            # physical pixel size in micrometer
                    ('ypixsz', ctypes.c_float),            # physical pixel size in micrometer
                    ('res', _Resolution * 16)]
    class _DeviceV2(ctypes.Structure):                     # win32
        _fields_ = [('displayname', ctypes.c_wchar * 64),  # display name
                    ('id', ctypes.c_wchar * 64),           # unique and opaque id of a connected camera, for Toupcam_Open
                    ('model', ctypes.POINTER(_ModelV2))]
else:
    class _ModelV2(ctypes.Structure):                      # camera model v2 linux/mac
        _fields_ = [('name', ctypes.c_char_p),             # model name
                    ('flag', ctypes.c_ulonglong),          # TOUPCAM_FLAG_xxx, 64 bits
                    ('maxspeed', ctypes.c_uint),           # number of speed level, same as Toupcam_get_MaxSpeed(), the speed range = [0, maxspeed], closed interval
                    ('preview', ctypes.c_uint),            # number of preview resolution, same as Toupcam_get_ResolutionNumber()
                    ('still', ctypes.c_uint),              # number of still resolution, same as Toupcam_get_StillResolutionNumber()
                    ('maxfanspeed', ctypes.c_uint),        # maximum fan speed
                    ('ioctrol', ctypes.c_uint),            # number of input/output control
                    ('xpixsz', ctypes.c_float),            # physical pixel size in micrometer
                    ('ypixsz', ctypes.c_float),            # physical pixel size in micrometer
                    ('res', _Resolution * 16)]
    class _DeviceV2(ctypes.Structure):                     # linux/mac
        _fields_ = [('displayname', ctypes.c_char * 64),   # display name
                    ('id', ctypes.c_char * 64),            # unique and opaque id of a connected camera, for Toupcam_Open
                    ('model', ctypes.POINTER(_ModelV2))]

class Toupcam:
    class __RECT(ctypes.Structure):
        _fields_ = [('left', ctypes.c_int),
                    ('top', ctypes.c_int),
                    ('right', ctypes.c_int),
                    ('bottom', ctypes.c_int)]

    class __AfParam(ctypes.Structure):
        _fields_ = [('imax', ctypes.c_int),                # maximum auto focus sensor board positon
                    ('imin', ctypes.c_int),                # minimum auto focus sensor board positon
                    ('idef', ctypes.c_int),                # conjugate calibration positon
                    ('imaxabs', ctypes.c_int),             # maximum absolute auto focus sensor board positon, micrometer
                    ('iminabs', ctypes.c_int),             # maximum absolute auto focus sensor board positon, micrometer
                    ('zoneh', ctypes.c_int),               # zone horizontal
                    ('zonev', ctypes.c_int)]               # zone vertical

    class __FrameInfoV3(ctypes.Structure):
        _fields_ = [('width', ctypes.c_uint),
                    ('height', ctypes.c_uint),
                    ('flag', ctypes.c_uint),               # TOUPCAM_FRAMEINFO_FLAG_xxxx
                    ('seq', ctypes.c_uint),                # frame sequence number
                    ('timestamp', ctypes.c_longlong),      # microsecond
                    ('shutterseq', ctypes.c_uint),         # sequence shutter counter
                    ('expotime', ctypes.c_uint),           # expotime
                    ('expogain', ctypes.c_ushort),         # expogain
                    ('blacklevel', ctypes.c_ushort)]       # black level

    class __FrameInfoV2(ctypes.Structure):
        _fields_ = [('width', ctypes.c_uint),
                    ('height', ctypes.c_uint),
                    ('flag', ctypes.c_uint),               # TOUPCAM_FRAMEINFO_FLAG_xxxx
                    ('seq', ctypes.c_uint),                # frame sequence number
                    ('timestamp', ctypes.c_longlong)]      # microsecond

    if sys.platform == 'win32':
        __EVENT_CALLBACK = ctypes.WINFUNCTYPE(None, ctypes.c_uint, ctypes.py_object)
        __PROGRESS_CALLBACK = ctypes.WINFUNCTYPE(None, ctypes.c_int, ctypes.py_object)
        __HOTPLUG_CALLBACK = ctypes.WINFUNCTYPE(None, ctypes.c_void_p)
        __HISTOGRAM_CALLBACK = ctypes.WINFUNCTYPE(None, ctypes.c_void_p, ctypes.c_uint, ctypes.py_object)
    else:
        __EVENT_CALLBACK = ctypes.CFUNCTYPE(None, ctypes.c_uint, ctypes.py_object)
        __PROGRESS_CALLBACK = ctypes.CFUNCTYPE(None, ctypes.c_int, ctypes.py_object)
        __HOTPLUG_CALLBACK = ctypes.CFUNCTYPE(None, ctypes.c_void_p)
        __HISTOGRAM_CALLBACK = ctypes.CFUNCTYPE(None, ctypes.c_void_p, ctypes.c_uint, ctypes.py_object)

    __lib = None
    __progress_fun = None
    __progress_ctx = None
    __progress_cb = None
    __hotplug_fun = None
    __hotplug_ctx = None
    __hotplug_cb = None
    __gigeenable_fun = None
    __gigeenable_ctx = None
    __gigeenable_cb = None

    @staticmethod
    def __errcheck(result, fun, args):
        if result < 0:
            raise HRESULTException(result)
        return args

    @staticmethod
    def __convertStr(x):
        if isinstance(x, str):
            return x
        else:
            return x.decode('ascii')

    @classmethod
    def Version(cls):
        """get the version of this dll, which is: 54.23714.20231029"""
        cls.__initlib()
        return cls.__lib.Toupcam_Version()

    @staticmethod
    def __convertResolution(a):
        t = []
        for i in range(0, a.preview):
            t.append(ToupcamResolution(a.res[i].width, a.res[i].height))
        return t

    @staticmethod
    def __convertModel(a):
        t = ToupcamModelV2(__class__.__convertStr(a.name), a.flag, a.maxspeed, a.preview, a.still, a.maxfanspeed, a.ioctrol, a.xpixsz, a.ypixsz, __class__.__convertResolution(a))
        return t

    @staticmethod
    def __convertDevice(a):
        return ToupcamDeviceV2(__class__.__convertStr(a.displayname), __class__.__convertStr(a.id), __class__.__convertModel(a.model.contents))

    @staticmethod
    def __gigeEnableCallbackFun(ctx):
        if __class__.__gigeenable_fun:
            __class__.__gigeenable_fun(__class__.__gigeenable_ctx)

    @classmethod
    def GigeEnable(cls, fun, ctx):
        """Initialize support for GigE cameras. If online/offline notifications are not required, the callback function can be set to None"""
        cls.__initlib()
        cls.__gigeenable_fun = fun
        cls.__gigeenable_ctx = ctx
        if cls.__gigeenable_fun is None:
            cls.__lib.Toupcam_GigeEnable(cls.__HOTPLUG_CALLBACK(0), None)
        else:
            cls.__gigeenable_cb = cls.__HOTPLUG_CALLBACK(cls.__gigeEnableCallbackFun)
            cls.__lib.Toupcam_GigeEnable(cls.__gigeenable_cb, None)

    @staticmethod
    def __hotplugCallbackFun(ctx):
        if __class__.__hotplug_fun:
            __class__.__hotplug_fun(__class__.__hotplug_ctx)

    @classmethod
    def HotPlug(cls, fun, ctx):
        """
        USB hotplug is only available on macOS and Linux, it's unnecessary on Windows & Android. To process the device plug in / pull out:
            (1) On Windows, please refer to the MSDN
                (a) Device Management, https://docs.microsoft.com/en-us/windows/win32/devio/device-management
                (b) Detecting Media Insertion or Removal, https://docs.microsoft.com/en-us/windows/win32/devio/detecting-media-insertion-or-removal
            (2) On Android, please refer to https://developer.android.com/guide/topics/connectivity/usb/host
            (3) On Linux / macOS, please call this function to register the callback function.
                When the device is inserted or pulled out, you will be notified by the callback funcion, and then call Toupcam_EnumV2(...) again to enum the cameras.
            (4) On macOS, IONotificationPortCreate series APIs can also be used as an alternative.
        """
        if sys.platform == 'win32' or sys.platform == 'android':
            raise HRESULTException(0x80004001)
        else:
            cls.__initlib()
            cls.__hotplug_fun = fun
            cls.__hotplug_ctx = ctx
            if cls.__hotplug_fun is None:
                cls.__lib.Toupcam_HotPlug(cls.__HOTPLUG_CALLBACK(0), None)
            else:
                cls.__hotplug_cb = cls.__HOTPLUG_CALLBACK(cls.__hotplugCallbackFun)
                cls.__lib.Toupcam_HotPlug(__hotplug_cb, None)

    @classmethod
    def EnumV2(cls):
        cls.__initlib()
        a = (_DeviceV2 * TOUPCAM_MAX)()
        n = cls.__lib.Toupcam_EnumV2(a)
        arr = []
        for i in range(0, n):
            arr.append(cls.__convertDevice(a[i]))
        return arr

    @classmethod
    def EnumWithName(cls):
        cls.__initlib()
        a = (_DeviceV2 * TOUPCAM_MAX)()
        n = cls.__lib.Toupcam_EnumWithName(a)
        arr = []
        for i in range(0, n):
            arr.append(cls.__convertDevice(a[i]))
        return arr

    def __init__(self, h):
        """the object of Toupcam must be obtained by classmethod Open or OpenByIndex, it cannot be obtained by obj = toupcam.Toupcam()"""
        self.__h = h
        self.__fun = None
        self.__ctx = None
        self.__cb = None
        self.__ctxhistogram = None
        self.__cbhistogram = None

    def __del__(self):
        self.Close()

    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.Close()

    def __nonzero__(self):
        return self.__h is not None

    def __bool__(self):
        return self.__h is not None

    @classmethod
    def Open(cls, camId):
        """
        the object of Toupcam must be obtained by classmethod Open or OpenByIndex, it cannot be obtained by obj = toupcam.Toupcam()
        Open(None) means try to Open the first enumerated camera
        """
        cls.__initlib()
        if camId is None:
            h = cls.__lib.Toupcam_Open(None)
        elif sys.platform == 'win32':
            h = cls.__lib.Toupcam_Open(camId)
        else:
            h = cls.__lib.Toupcam_Open(camId.encode('ascii'))
        if h is None:
            return None
        return __class__(h)

    @classmethod
    def OpenByIndex(cls, index):
        """
        the object of Toupcam must be obtained by classmethod Open or OpenByIndex, it cannot be obtained by obj = toupcam.Toupcam()

        the same with Toupcam_Open, but use the index as the parameter. such as:
        index == 0, open the first camera,
        index == 1, open the second camera,
        etc
        """
        cls.__initlib()
        h = cls.__lib.Toupcam_OpenByIndex(index)
        if h is None:
            return None
        return __class__(h)

    def Close(self):
        if self.__h:
            self.__lib.Toupcam_Close(self.__h)
            self.__h = None

    @staticmethod
    def __eventCallbackFun(nEvent, ctx):
        if ctx:
            ctx.__callbackFun(nEvent)

    def __callbackFun(self, nEvent):
        if self.__fun:
            self.__fun(nEvent, self.__ctx)

    def StartPullModeWithCallback(self, fun, ctx):
        self.__fun = fun
        self.__ctx = ctx
        self.__cb = __class__.__EVENT_CALLBACK(__class__.__eventCallbackFun)
        self.__lib.Toupcam_StartPullModeWithCallback(self.__h, self.__cb, ctypes.py_object(self))

    @staticmethod
    def __convertFrameInfoV3(pInfo, x):
        pInfo.width = x.width
        pInfo.height = x.height
        pInfo.flag = x.flag
        pInfo.seq = x.seq
        pInfo.shutterseq = x.shutterseq
        pInfo.timestamp = x.timestamp
        pInfo.expotime = x.expotime
        pInfo.expogain = x.expogain
        pInfo.blacklevel = x.blacklevel

    @staticmethod
    def __convertFrameInfoV2(pInfo, x):
        pInfo.width = x.width
        pInfo.height = x.height
        pInfo.flag = x.flag
        pInfo.seq = x.seq
        pInfo.timestamp = x.timestamp

    """
        nWaitMS: The timeout interval, in milliseconds. If a non-zero value is specified, the function either successfully fetches the image or waits for a timeout.
                 If nWaitMS is zero, the function does not wait when there are no images to fetch; It always returns immediately; this is equal to PullImageV3.
        bStill: to pull still image, set to 1, otherwise 0
        bits: 24 (RGB24), 32 (RGB32), 48 (RGB48), 8 (Grey), 16 (Grey), 64 (RGB64).
              In RAW mode, this parameter is ignored.
              bits = 0 means using default bits (see TOUPCAM_OPTION_RGB).
              When bits and TOUPCAM_OPTION_RGB are inconsistent, format conversion will have to be performed, resulting in loss of efficiency.
              See the following bits and TOUPCAM_OPTION_RGB correspondence table:
                ----------------------------------------------------------------------------------------------------------------------
                | TOUPCAM_OPTION_RGB |   0 (RGB24)   |   1 (RGB48)   |   2 (RGB32)   |   3 (Grey8)   |  4 (Grey16)   |   5 (RGB64)   |
                |--------------------|---------------|---------------|---------------|---------------|---------------|---------------|
                | bits = 0           |      24       |       48      |      32       |       8       |       16      |       64      |
                |--------------------|---------------|---------------|---------------|---------------|---------------|---------------|
                | bits = 24          |      24       |       NA      | Convert to 24 | Convert to 24 |       NA      |       NA      |
                |--------------------|---------------|---------------|---------------|---------------|---------------|---------------|
                | bits = 32          | Convert to 32 |       NA      |       32      | Convert to 32 |       NA      |       NA      |
                |--------------------|---------------|---------------|---------------|---------------|---------------|---------------|
                | bits = 48          |      NA       |       48      |       NA      |       NA      | Convert to 48 | Convert to 48 |
                |--------------------|---------------|---------------|---------------|---------------|---------------|---------------|
                | bits = 8           | Convert to 8  |       NA      | Convert to 8  |       8       |       NA      |       NA      |
                |--------------------|---------------|---------------|---------------|---------------|---------------|---------------|
                | bits = 16          |      NA       | Convert to 16 |       NA      |       NA      |       16      | Convert to 16 |
                |--------------------|---------------|-----------|-------------------|---------------|---------------|---------------|
                | bits = 64          |      NA       | Convert to 64 |       NA      |       NA      | Convert to 64 |       64      |
                |--------------------|---------------|---------------|---------------|---------------|---------------|---------------|
        
        rowPitch: The distance from one row to the next row. rowPitch = 0 means using the default row pitch. rowPitch = -1 means zero padding, see below:
                ----------------------------------------------------------------------------------------------
                | format                             | 0 means default row pitch     | -1 means zero padding |
                |------------------------------------|-------------------------------|-----------------------|
                | RGB       | RGB24                  | TDIBWIDTHBYTES(24 * Width)    | Width * 3             |
                |           | RGB32                  | Width * 4                     | Width * 4             |
                |           | RGB48                  | TDIBWIDTHBYTES(48 * Width)    | Width * 6             |
                |           | GREY8                  | TDIBWIDTHBYTES(8 * Width)     | Width                 |
                |           | GREY16                 | TDIBWIDTHBYTES(16 * Width)    | Width * 2             |
                |           | RGB64                  | Width * 8                     | Width * 8             |
                |-----------|------------------------|-------------------------------|-----------------------|
                | RAW       | 8bits Mode             | Width                         | Width                 |
                |           | 10/12/14/16bits Mode   | Width * 2                     | Width * 2             |
                |-----------|------------------------|-------------------------------|-----------------------|
    """
    def PullImageV3(self, pImageData, bStill, bits, rowPitch, pInfo):
        if pInfo is None:
            self.__lib.Toupcam_PullImageV3(self.__h, pImageData, bStill, bits, rowPitch, None)
        else:
            x = self.__FrameInfoV3()
            self.__lib.Toupcam_PullImageV3(self.__h, pImageData, bStill, bits, rowPitch, ctypes.byref(x))
            self.__convertFrameInfoV3(pInfo, x)

    def WaitImageV3(self, nWaitMS, pImageData, bStill, bits, rowPitch, pInfo):
        if pInfo is None:
            self.__lib.Toupcam_WaitImageV3(self.__h, nWaitMS, pImageData, bStill, bits, rowPitch, None)
        else:
            x = self.__FrameInfoV3()
            self.__lib.Toupcam_WaitImageV3(self.__h, nWaitMS, pImageData, bStill, bits, rowPitch, ctypes.byref(x))
            self.__convertFrameInfoV3(pInfo, x)

    def PullImageV2(self, pImageData, bits, pInfo):
        if pInfo is None:
            self.__lib.Toupcam_PullImageV2(self.__h, pImageData, bits, None)
        else:
            x = self.__FrameInfoV2()
            self.__lib.Toupcam_PullImageV2(self.__h, pImageData, bits, ctypes.byref(x))
            self.__convertFrameInfoV2(pInfo, x)

    def PullStillImageV2(self, pImageData, bits, pInfo):
        if pInfo is None:
            self.__lib.Toupcam_PullStillImageV2(self.__h, pImageData, bits, None)
        else:
            x = self.__FrameInfoV2()
            self.__lib.Toupcam_PullStillImageV2(self.__h, pImageData, bits, ctypes.byref(x))
            self.__convertFrameInfoV2(pInfo, x)

    def PullImageWithRowPitchV2(self, pImageData, bits, rowPitch, pInfo):
        if pInfo is None:
            self.__lib.Toupcam_PullImageWithRowPitchV2(self.__h, pImageData, bits, rowPitch, None)
        else:
            x = self.__FrameInfoV2()
            self.__lib.Toupcam_PullImageWithRowPitchV2(self.__h, pImageData, bits, rowPitch, ctypes.byref(x))
            self.__convertFrameInfoV2(pInfo, x)

    def PullStillImageWithRowPitchV2(self, pImageData, bits, rowPitch, pInfo):
        if pInfo is None:
            self.__lib.Toupcam_PullStillImageWithRowPitchV2(self.__h, pImageData, bits, rowPitch, None)
        else:
            x = self.__FrameInfoV2()
            self.__lib.Toupcam_PullStillImageWithRowPitchV2(self.__h, pImageData, bits, rowPitch, ctypes.byref(x))
            self.__convertFrameInfoV2(pInfo, x)

    def ResolutionNumber(self):
        return self.__lib.Toupcam_get_ResolutionNumber(self.__h)

    def StillResolutionNumber(self):
        """return (width, height)"""
        return self.__lib.Toupcam_get_StillResolutionNumber(self.__h)

    def MonoMode(self):
        return (self.__lib.Toupcam_get_MonoMode(self.__h) == 0)

    def MaxSpeed(self):
        """get the maximum speed, 'Frame Speed Level'"""
        return self.__lib.Toupcam_get_MaxSpeed(self.__h)

    def MaxBitDepth(self):
        """get the max bitdepth of this camera, such as 8, 10, 12, 14, 16"""
        return self.__lib.Toupcam_get_MaxBitDepth(self.__h)

    def FanMaxSpeed(self):
        """get the maximum fan speed, the fan speed range = [0, max], closed interval"""
        return self.__lib.Toupcam_get_FanMaxSpeed(self.__h)

    def Revision(self):
        """get the revision"""
        x = ctypes.c_ushort(0)
        self.__lib.Toupcam_get_Revision(self.__h, ctypes.byref(x))
        return x.value

    def SerialNumber(self):
        """get the serial number which is always 32 chars which is zero-terminated such as: TP110826145730ABCD1234FEDC56787"""
        str = (ctypes.c_char * 32)()
        self.__lib.Toupcam_get_SerialNumber(self.__h, str)
        return str.value.decode('ascii')

    def FwVersion(self):
        """get the camera firmware version, such as: 3.2.1.20140922"""
        str = (ctypes.c_char * 16)()
        self.__lib.Toupcam_get_FwVersion(self.__h, str)
        return str.value.decode('ascii')

    def HwVersion(self):
        """get the camera hardware version, such as: 3.2.1.20140922"""
        str = (ctypes.c_char * 16)()
        self.__lib.Toupcam_get_HwVersion(self.__h, str)
        return str.value.decode('ascii')

    def ProductionDate(self):
        """such as: 20150327"""
        str = (ctypes.c_char * 16)()
        self.__lib.Toupcam_get_ProductionDate(self.__h, str)
        return str.value.decode('ascii')

    def FpgaVersion(self):
        str = (ctypes.c_char * 16)()
        self.__lib.Toupcam_get_FpgaVersion(self.__h, str)
        return str.value.decode('ascii')

    def Field(self):
        return self.__lib.Toupcam_get_Field(self.__h)

    def Stop(self):
        self.__lib.Toupcam_Stop(self.__h)

    def Pause(self, bPause):
        '''1 => pause, 0 => continue'''
        self.__lib.Toupcam_Pause(self.__h, ctypes.c_int(1 if bPause else 0))

    def Snap(self, nResolutionIndex):
        """still image snap, nResolutionIndex = 0xffffffff means use the cureent preview resolution"""
        self.__lib.Toupcam_Snap(self.__h, ctypes.c_uint(nResolutionIndex))

    def SnapN(self, nResolutionIndex, nNumber):
        """multiple still image snap, nResolutionIndex = 0xffffffff means use the cureent preview resolution"""
        self.__lib.Toupcam_SnapN(self.__h, ctypes.c_uint(nResolutionIndex), ctypes.c_uint(nNumber))

    def SnapR(self, nResolutionIndex, nNumber):
        """multiple RAW still image snap, nResolutionIndex = 0xffffffff means use the cureent preview resolution"""
        self.__lib.Toupcam_SnapR(self.__h, ctypes.c_uint(nResolutionIndex), ctypes.c_uint(nNumber))

    def Trigger(self, nNumber):
        """
        soft trigger:
        nNumber:    0xffff:     trigger continuously
                    0:          cancel trigger
                    others:     number of images to be triggered
        """
        self.__lib.Toupcam_Trigger(self.__h, ctypes.c_ushort(nNumber))

    def TriggerSync(self, nTimeout, pImageData, bits, rowPitch, pInfo):
        """
        trigger synchronously
        nTimeout:   0:              by default, exposure * 102% + 4000 milliseconds
                    0xffffffff:     wait infinite
                    other:          milliseconds to wait        
        """
        if pInfo is None:
            self.__lib.TriggerSync(self.__h, nTimeout, pImageData, bits, rowPitch, None)
        else:
            x = self.__FrameInfoV3()
            self.__lib.TriggerSync(self.__h, nTimeout, pImageData, bits, rowPitch, ctypes.byref(x))
            self.__convertFrameInfoV3(pInfo, x)

    def put_Size(self, nWidth, nHeight):
        self.__lib.Toupcam_put_Size(self.__h, ctypes.c_int(nWidth), ctypes.c_int(nHeight))

    def get_Size(self):
        """return (width, height)"""
        x = ctypes.c_int(0)
        y = ctypes.c_int(0)
        self.__lib.Toupcam_get_Size(self.__h, ctypes.byref(x), ctypes.byref(y))
        return (x.value, y.value)

    def put_eSize(self, nResolutionIndex):
        """
        put_Size, put_eSize, can be used to set the video output resolution BEFORE Start.
        put_Size use width and height parameters, put_eSize use the index parameter.
        for example, UCMOS03100KPA support the following resolutions:
            index 0:    2048,   1536
            index 1:    1024,   768
            index 2:    680,    510
        so, we can use put_Size(h, 1024, 768) or put_eSize(h, 1). Both have the same effect.
        """
        self.__lib.Toupcam_put_eSize(self.__h, ctypes.c_uint(nResolutionIndex))

    def get_eSize(self):
        x = ctypes.c_uint(0)
        self.__lib.Toupcam_get_eSize(self.__h, ctypes.byref(x))
        return x.value

    def get_FinalSize(self):
        """final size after ROI, rotate, binning"""
        x = ctypes.c_int(0)
        y = ctypes.c_int(0)
        self.__lib.Toupcam_get_FinalSize(self.__h, ctypes.byref(x), ctypes.byref(y))
        return (x.value, y.value)

    def get_Resolution(self, nResolutionIndex):
        """return (width, height)"""
        x = ctypes.c_int(0)
        y = ctypes.c_int(0)
        self.__lib.Toupcam_get_Resolution(self.__h, ctypes.c_uint(nResolutionIndex), ctypes.byref(x), ctypes.byref(y))
        return (x.value, y.value)

    def get_PixelSize(self, nResolutionIndex):
        """get the sensor pixel size, such as: 2.4um x 2.4um"""
        x = ctypes.c_float(0)
        y = ctypes.c_float(0)
        self.__lib.Toupcam_get_PixelSize(self.__h, ctypes.c_uint(nResolutionIndex), ctypes.byref(x), ctypes.byref(y))
        return (x.value, y.value)

    def get_ResolutionRatio(self, nResolutionIndex):
        """numerator/denominator, such as: 1/1, 1/2, 1/3"""
        x = ctypes.c_int(0)
        y = ctypes.c_int(0)
        self.__lib.Toupcam_get_ResolutionRatio(self.__h, ctypes.c_uint(nResolutionIndex), ctypes.byref(x), ctypes.byref(y))
        return (x.value, y.value)

    def get_RawFormat(self):
        """
        see: http://www.fourcc.org
        FourCC:
            MAKEFOURCC('G', 'B', 'R', 'G'), see http://www.siliconimaging.com/RGB%20Bayer.htm
            MAKEFOURCC('R', 'G', 'G', 'B')
            MAKEFOURCC('B', 'G', 'G', 'R')
            MAKEFOURCC('G', 'R', 'B', 'G')
            MAKEFOURCC('Y', 'Y', 'Y', 'Y'), monochromatic sensor
            MAKEFOURCC('Y', '4', '1', '1'), yuv411
            MAKEFOURCC('V', 'U', 'Y', 'Y'), yuv422
            MAKEFOURCC('U', 'Y', 'V', 'Y'), yuv422
            MAKEFOURCC('Y', '4', '4', '4'), yuv444
            MAKEFOURCC('R', 'G', 'B', '8'), RGB888
        """
        x = ctypes.c_uint(0)
        y = ctypes.c_uint(0)
        self.__lib.Toupcam_get_RawFormat(self.__h, ctypes.byref(x), ctypes.byref(y))
        return (x.value, y.value)

    def put_RealTime(self, val):
        """
        0: stop grab frame when frame buffer deque is full, until the frames in the queue are pulled away and the queue is not full
        1: realtime
            use minimum frame buffer. When new frame arrive, drop all the pending frame regardless of whether the frame buffer is full.
            If DDR present, also limit the DDR frame buffer to only one frame.
        2: soft realtime
            Drop the oldest frame when the queue is full and then enqueue the new frame
        default: 0
        """
        self.__lib.Toupcam_put_RealTime(self.__h, val)

    def get_RealTime(self):
        b = ctypes.c_int(0)
        self.__lib.Toupcam_get_RealTime(self.__h, b)
        return b.value

    def Flush(self):
        """Flush is obsolete, recommend using put_Option(h, TOUPCAM_OPTION_FLUSH, 3)"""
        self.__lib.Toupcam_Flush(self.__h)

    def get_AutoExpoEnable(self):
        """
        bAutoExposure:
           0: disable auto exposure
           1: auto exposure continue mode
           2: auto exposure once mode
        """
        b = ctypes.c_int(0)
        self.__lib.Toupcam_get_AutoExpoEnable(self.__h, b)
        return b.value

    def put_AutoExpoEnable(self, bAutoExposure):
        """
        bAutoExposure:
           0: disable auto exposure
           1: auto exposure continue mode
           2: auto exposure once mode
        """
        self.__lib.Toupcam_put_AutoExpoEnable(self.__h, ctypes.c_int(bAutoExposure))

    def get_AutoExpoTarget(self):
        x = ctypes.c_ushort(TOUPCAM_AETARGET_DEF)
        self.__lib.Toupcam_get_AutoExpoTarget(self.__h, ctypes.byref(x))
        return x.value

    def put_AutoExpoTarget(self, Target):
        self.__lib.Toupcam_put_AutoExpoTarget(self.__h, ctypes.c_int(Target))

    def put_AutoExpoRange(self, maxTime, minTime, maxGain, minGain):
        return self.__lib.Toupcam_put_AutoExpoRange(self.__h, ctypes.c_uint(maxTime), ctypes.c_uint(minTime), ctypes.c_ushort(maxGain), ctypes.c_ushort(minGain))

    def get_AutoExpoRange(self):
        maxTime = ctypes.c_uint(0)
        minTime = ctypes.c_uint(0)
        maxGain = ctypes.c_ushort(0)
        minGain = ctypes.c_ushort(0)
        self.__lib.Toupcam_get_AutoExpoRange(self.__h, ctypes.byref(maxTime), ctypes.byref(minTime), ctypes.byref(maxGain), ctypes.byref(minGain))
        return (maxTime.value, minTime.value, maxGain.value, minGain.value)

    def put_MaxAutoExpoTimeAGain(self, maxTime, maxGain):
        return self.__lib.Toupcam_put_MaxAutoExpoTimeAGain(self.__h, ctypes.c_uint(maxTime), ctypes.c_ushort(maxGain))

    def get_MaxAutoExpoTimeAGain(self):
        x = ctypes.c_uint(0)
        y = ctypes.c_ushort(0)
        self.__lib.Toupcam_get_MaxAutoExpoTimeAGain(self.__h, ctypes.byref(x), ctypes.byref(y))
        return (x.value, y.value)

    def put_MinAutoExpoTimeAGain(self, minTime, minGain):
        self.__lib.Toupcam_put_MinAutoExpoTimeAGain(self.__h, ctypes.c_uint(minTime), ctypes.c_ushort(minGain))

    def get_MinAutoExpoTimeAGain(self):
        x = ctypes.c_uint(0)
        y = ctypes.c_ushort(0)
        self.__lib.Toupcam_get_MinAutoExpoTimeAGain(self.__h, ctypes.byref(x), ctypes.byref(y))
        return (x.value, y.value)

    def get_ExpoTime(self):
        """in microseconds"""
        x = ctypes.c_uint(0)
        self.__lib.Toupcam_get_ExpoTime(self.__h, ctypes.byref(x))
        return x.value

    def put_ExpoTime(self, Time):
        self.__lib.Toupcam_put_ExpoTime(self.__h, ctypes.c_uint(Time))

    def get_ExpTimeRange(self):
        x = ctypes.c_uint(0)
        y = ctypes.c_uint(0)
        z = ctypes.c_uint(0)
        self.__lib.Toupcam_get_ExpTimeRange(self.__h, ctypes.byref(x), ctypes.byref(y), ctypes.byref(z))
        return (x.value, y.value, z.value)

    def get_ExpoAGain(self):
        """percent, such as 300"""
        x = ctypes.c_ushort(0)
        self.__lib.Toupcam_get_ExpoAGain(self.__h, ctypes.byref(x))
        return x.value

    def put_ExpoAGain(self, Gain):
        self.__lib.Toupcam_put_ExpoAGain(self.__h, ctypes.c_ushort(Gain))

    def get_ExpoAGainRange(self):
        """ return (min, max, default)"""
        x = ctypes.c_ushort(0)
        y = ctypes.c_ushort(0)
        z = ctypes.c_ushort(0)
        self.__lib.Toupcam_get_ExpoAGainRange(self.__h, ctypes.byref(x), ctypes.byref(y), ctypes.byref(z))
        return (x.value, y.value, z.value)

    def put_LevelRange(self, aLow, aHigh):
        if len(aLow) == 4 and len(aHigh) == 4:
            x = (ctypes.c_ushort * 4)(aLow[0], aLow[1], aLow[2], aLow[3])
            y = (ctypes.c_ushort * 4)(aHigh[0], aHigh[1], aHigh[2], aHigh[3])
            self.__lib.Toupcam_put_LevelRange(self.__h, x, y)
        else:
            raise HRESULTException(0x80070057)

    def get_LevelRange(self):
        x = (ctypes.c_ushort * 4)()
        y = (ctypes.c_ushort * 4)()
        self.__lib.Toupcam_get_LevelRange(self.__h, x, y)
        aLow = (x[0], x[1], x[2], x[3])
        aHigh = (y[0], y[1], y[2], y[3])
        return (aLow, aHigh)

    def put_LevelRangeV2(self, mode, roiX, roiY, roiWidth, roiHeight, aLow, aHigh):
        if len(aLow) == 4 and len(aHigh) == 4:
            x = (ctypes.c_ushort * 4)(aLow[0], aLow[1], aLow[2], aLow[3])
            y = (ctypes.c_ushort * 4)(aHigh[0], aHigh[1], aHigh[2], aHigh[3])
            rc = self.__RECT()
            rc.left = roiX
            rc.right = roiX + roiWidth
            rc.top = roiY
            rc.bottom = roiY + roiHeight
            self.__lib.Toupcam_put_LevelRangeV2(self.__h, mode, ctypes.byref(rc), x, y)
        else:
            raise HRESULTException(0x80070057)

    def get_LevelRangeV2(self):
        mode = ctypes.c_ushort(0)
        x = (ctypes.c_ushort * 4)()
        y = (ctypes.c_ushort * 4)()
        rc = self.__RECT()
        self.__lib.Toupcam_get_LevelRange(self.__h, mode, ctypes.byref(rc), x, y)
        aLow = (x[0], x[1], x[2], x[3])
        aHigh = (y[0], y[1], y[2], y[3])
        return (mode, (rc.left, rc.top, rc.right - rc.left, rc.bottom - rc.top), aLow, aHigh)

    def put_Hue(self, Hue):
        self.__lib.Toupcam_put_Hue(self.__h, ctypes.c_int(Hue))

    def get_Hue(self):
        x = ctypes.c_int(TOUPCAM_HUE_DEF)
        self.__lib.Toupcam_get_Hue(self.__h, ctypes.byref(x))
        return x.value

    def put_Saturation(self, Saturation):
        self.__lib.Toupcam_put_Saturation(self.__h, ctypes.c_int(Saturation))

    def get_Saturation(self):
        x = ctypes.c_int(TOUPCAM_SATURATION_DEF)
        self.__lib.Toupcam_get_Saturation(self.__h, ctypes.byref(x))
        return x.value

    def put_Brightness(self, Brightness):
        self.__lib.Toupcam_put_Brightness(self.__h, ctypes.c_int(Brightness))

    def get_Brightness(self):
        x = ctypes.c_int(TOUPCAM_BRIGHTNESS_DEF)
        self.__lib.Toupcam_get_Brightness(self.__h, ctypes.byref(x))
        return x.value

    def get_Contrast(self):
        x = ctypes.c_int(TOUPCAM_CONTRAST_DEF)
        self.__lib.Toupcam_get_Contrast(self.__h, ctypes.byref(x))
        return x.value

    def put_Contrast(self, Contrast):
        self.__lib.Toupcam_put_Contrast(self.__h, ctypes.c_int(Contrast))

    def get_Gamma(self):
        x = ctypes.c_int(TOUPCAM_GAMMA_DEF)
        self.__lib.Toupcam_get_Gamma(self.__h, ctypes.byref(x))
        return x.value

    def put_Gamma(self, Gamma):
        self.__lib.Toupcam_put_Gamma(self.__h, ctypes.c_int(Gamma))

    def get_Chrome(self):
        """monochromatic mode"""
        b = ctypes.c_int(0)
        self.__lib.Toupcam_get_Chrome(self.__h, ctypes.byref(b)) < 0
        return (b.value != 0)

    def put_Chrome(self, bChrome):
        self.__lib.Toupcam_put_Chrome(self.__h, ctypes.c_int(1 if bChrome else 0))

    def get_VFlip(self):
        """vertical flip"""
        b = ctypes.c_int(0)
        self.__lib.Toupcam_get_VFlip(self.__h, ctypes.byref(b))
        return (b.value != 0)

    def put_VFlip(self, bVFlip):
        """vertical flip"""
        self.__lib.Toupcam_put_VFlip(self.__h, ctypes.c_int(1 if bVFlip else 0))

    def get_HFlip(self):
        """horizontal flip"""
        b = ctypes.c_int(0)
        self.__lib.Toupcam_get_HFlip(self.__h, ctypes.byref(b))
        return (b.value != 0)

    def put_HFlip(self, bHFlip):
        """horizontal flip"""
        self.__lib.Toupcam_put_HFlip(self.__h, ctypes.c_int(1 if bHFlip else 0))

    def get_Negative(self):
        """negative film"""
        b = ctypes.c_int(0)
        self.__lib.Toupcam_get_Negative(self.__h, ctypes.byref(b))
        return (b.value != 0)

    def put_Negative(self, bNegative):
        """negative film"""
        self.__lib.Toupcam_put_Negative(self.__h, ctypes.c_int(1 if bNegative else 0))

    def put_Speed(self, nSpeed):
        self.__lib.Toupcam_put_Speed(self.__h, ctypes.c_ushort(nSpeed))

    def get_Speed(self):
        x = ctypes.c_ushort(0)
        self.__lib.Toupcam_get_Speed(self.__h, ctypes.byref(x))
        return x.value

    def put_HZ(self, nHZ):
        """
        power supply:
            0 => 60HZ AC
            1 => 50Hz AC
            2 => DC
        """
        self.__lib.Toupcam_put_HZ(self.__h, ctypes.c_int(nHZ))

    def get_HZ(self):
        x = ctypes.c_int(0)
        self.__lib.Toupcam_get_HZ(self.__h, ctypes.byref(x))
        return x.value

    def put_Mode(self, bSkip):
        """skip or bin"""
        self.__lib.Toupcam_put_Mode(self.__h, ctypes.c_int(1 if bSkip else 0))

    def get_Mode(self):
        b = ctypes.c_int(0)
        self.__lib.Toupcam_get_Mode(self.__h, ctypes.byref(b))
        return (b.value != 0)

    def put_TempTint(self, nTemp, nTint):
        """White Balance, Temp/Tint mode"""
        self.__lib.Toupcam_put_TempTint(self.__h, ctypes.c_int(nTemp), ctypes.c_int(nTint))

    def get_TempTint(self):
        """White Balance, Temp/Tint mode"""
        x = ctypes.c_int(TOUPCAM_TEMP_DEF)
        y = ctypes.c_int(TOUPCAM_TINT_DEF)
        self.__lib.Toupcam_get_TempTint(self.__h, ctypes.byref(x), ctypes.byref(y))
        return (x.value, y.value)

    def put_WhiteBalanceGain(self, aGain):
        """White Balance, RGB Gain Mode"""
        if len(aGain) == 3:
            x = (ctypes.c_int * 3)(aGain[0], aGain[1], aGain[2])
            self.__lib.Toupcam_put_WhiteBalanceGain(self.__h, x)
        else:
            raise HRESULTException(0x80070057)

    def get_WhiteBalanceGain(self):
        """White Balance, RGB Gain Mode"""
        x = (ctypes.c_int * 3)()
        self.__lib.Toupcam_get_WhiteBalanceGain(self.__h, x)
        return (x[0], x[1], x[2])

    def put_AWBAuxRect(self, X, Y, Width, Height):
        rc = self.__RECT()
        rc.left = X
        rc.right = X + Width
        rc.top = Y
        rc.bottom = Y + Height
        self.__lib.Toupcam_put_AWBAuxRect(self.__h, ctypes.byref(rc))

    def get_AWBAuxRect(self):
        """return (left, top, width, height)"""
        rc = self.__RECT()
        self.__lib.Toupcam_get_AWBAuxRect(self.__h, ctypes.byref(rc))
        return (rc.left, rc.top, rc.right - rc.left, rc.bottom - rc.top)

    def put_AEAuxRect(self, X, Y, Width, Height):
        rc = self.__RECT()
        rc.left = X
        rc.right = X + Width
        rc.top = Y
        rc.bottom = Y + Height
        self.__lib.Toupcam_put_AEAuxRect(self.__h, ctypes.byref(rc))

    def get_AEAuxRect(self):
        """return (left, top, width, height)"""
        rc = self.__RECT()
        self.__lib.Toupcam_get_AEAuxRect(self.__h, ctypes.byref(rc))
        return (rc.left, rc.top, rc.right - rc.left, rc.bottom - rc.top)

    def put_BlackBalance(self, aSub):
        if len(aSub) == 3:
            x = (ctypes.c_ushort * 3)(aSub[0], aSub[1], aSub[2])
            self.__lib.Toupcam_put_BlackBalance(self.__h, x)
        else:
            raise HRESULTException(0x80070057)

    def get_BlackBalance(self):
        x = (ctypes.c_ushort * 3)()
        self.__lib.Toupcam_get_BlackBalance(self.__h, x)
        return (x[0], x[1], x[2])

    def put_ABBAuxRect(self, X, Y, Width, Height):
        rc = self.__RECT()
        rc.left = X
        rc.right = X + Width
        rc.top = Y
        rc.bottom = Y + Height
        self.__lib.Toupcam_put_ABBAuxRect(self.__h, ctypes.byref(rc))

    def get_ABBAuxRect(self):
        """return (left, top, width, height)"""
        rc = self.__RECT()
        self.__lib.Toupcam_get_ABBAuxRect(self.__h, ctypes.byref(rc))
        return (rc.left, rc.top, rc.right - rc.left, rc.bottom - rc.top)

    def get_StillResolution(self, nResolutionIndex):
        x = ctypes.c_int(0)
        y = ctypes.c_int(0)
        self.__lib.Toupcam_get_StillResolution(self.__h, ctypes.c_uint(nResolutionIndex), ctypes.byref(x), ctypes.byref(y))
        return (x.value, y.value)

    def put_LEDState(self, iLed, iState, iPeriod):
        """
        led state:
            iLed: Led index, (0, 1, 2, ...)
            iState: 1 => Ever bright; 2 => Flashing; other => Off
            iPeriod: Flashing Period (>= 500ms)
        """
        self.__lib.Toupcam_put_LEDState(self.__h, ctypes.c_ushort(iLed), ctypes.c_ushort(iState), ctypes.c_ushort(iPeriod))

    def write_EEPROM(self, addr, pBuffer):
        self.__lib.Toupcam_write_EEPROM(self.__h, addr, pBuffer, ctypes.c_uint(len(pBuffer)))

    def read_EEPROM(self, addr, pBuffer):
        self.__lib.Toupcam_read_EEPROM(self.__h, addr, pBuffer, ctypes.c_uint(len(pBuffer)))

    def rwc_Flash(self, action, addr, pData):
        """
        Flash:
        action = TOUPCAM_FLASH_XXXX: read, write, erase, query total size, query read/write block size, query erase block size
        addr = address
        see democpp
        """
        self.__lib.Toupcam_rwc_Flash(self.__h, action, addr, ctypes.c_uint(len(pData)), pData)

    def write_Pipe(self, pipeId, pBuffer):
        self.__lib.Toupcam_write_Pipe(self.__h, pipeId, pBuffer, ctypes.c_uint(len(pBuffer)))

    def read_Pipe(self, pipeId, pBuffer):
        self.__lib.Toupcam_read_Pipe(self.__h, pipeId, pBuffer, ctypes.c_uint(len(pBuffer)))

    def feed_Pipe(self, pipeId):
        self.__lib.Toupcam_feed_Pipe(self.__h, ctypes.c_uint(pipeId))

    def write_UART(self, pBuffer):
        self.__lib.Toupcam_write_UART(self.__h, pBuffer, ctypes.c_uint(len(pBuffer)))

    def read_UART(self, pBuffer):
        self.__lib.Toupcam_read_UART(self.__h, pBuffer, ctypes.c_uint(len(pBuffer)))

    def put_Option(self, iOption, iValue):
        self.__lib.Toupcam_put_Option(self.__h, ctypes.c_uint(iOption), ctypes.c_int(iValue))

    def get_Option(self, iOption):
        x = ctypes.c_int(0)
        self.__lib.Toupcam_get_Option(self.__h, ctypes.c_uint(iOption), ctypes.byref(x))
        return x.value

    def put_Linear(self, v8, v16):
        self.__lib.Toupcam_put_Linear(self.__h, v8, v16)

    def put_Curve(self, v8, v16):
        self.__lib.Toupcam_put_Curve(self.__h, v8, v16)

    def put_ColorMatrix(self, v):
        if len(v) == 9:
            a = (ctypes.c_double * 9)(v[0], v[1], v[2], v[3], v[4], v[5], v[6], v[7], v[8])
            return self.__lib.Toupcam_put_ColorMatrix(self.__h, v)
        else:
            raise HRESULTException(0x80070057)

    def put_InitWBGain(self, v):
        if len(v) == 3:
            a = (ctypes.c_short * 3)(v[0], v[1], v[2])
            self.__lib.Toupcam_put_InitWBGain(self.__h, a)
        else:
            raise HRESULTException(0x80070057)

    def get_Temperature(self):
        """get the temperature of the sensor, in 0.1 degrees Celsius (32 means 3.2 degrees Celsius, -35 means -3.5 degree Celsius)"""
        x = ctypes.c_short(0)
        self.__lib.Toupcam_get_Temperature(self.__h, ctypes.byref(x))
        return x.value

    def put_Temperature(self, nTemperature):
        """set the target temperature of the sensor or TEC, in 0.1 degrees Celsius (32 means 3.2 degrees Celsius, -35 means -3.5 degree Celsius)"""
        self.__lib.Toupcam_put_Temperature(self.__h, ctypes.c_short(nTemperature))

    def put_Roi(self, xOffset, yOffset, xWidth, yHeight):
        """xOffset, yOffset, xWidth, yHeight: must be even numbers"""
        self.__lib.Toupcam_put_Roi(self.__h, ctypes.c_uint(xOffset), ctypes.c_uint(yOffset), ctypes.c_uint(xWidth), ctypes.c_uint(yHeight))

    def get_Roi(self):
        """return (xOffset, yOffset, xWidth, yHeight)"""
        x = ctypes.c_uint(0)
        y = ctypes.c_uint(0)
        w = ctypes.c_uint(0)
        h = ctypes.c_uint(0)
        self.__lib.Toupcam_get_Roi(self.__h, ctypes.byref(x), ctypes.byref(y), ctypes.byref(w), ctypes.byref(h))
        return (x.value, y.value, w.value, h.value)

    def get_FrameRate(self):
        """
        get the frame rate: framerate (fps) = Frame * 1000.0 / nTime
        return (Frame, Time, TotalFrame)
        """
        x = ctypes.c_uint(0)
        y = ctypes.c_uint(0)
        z = ctypes.c_uint(0)
        self.__lib.Toupcam_get_FrameRate(self.__h, ctypes.byref(x), ctypes.byref(y), ctypes.byref(z))
        return (x.value, y.value, z.value)

    def LevelRangeAuto(self):
        self.__lib.Toupcam_LevelRangeAuto(self.__h)

    def AwbOnce(self):
        """Auto White Balance "Once", Temp/Tint Mode"""
        self.__lib.Toupcam_AwbOnce(self.__h, None, None)

    def AwbOnePush(self):
        AwbOnce(self)

    def AwbInit(self):
        """Auto White Balance "Once", Temp/Tint Mode"""
        self.__lib.Toupcam_AwbInit(self.__h, None, None)

    def AbbOnce(self):
        self.__lib.Toupcam_AbbOnce(self.__h, None, None)

    def AbbOnePush(self):
        AbbOnce(self)

    def FfcOnce(self):
        self.__lib.Toupcam_FfcOnce(self.__h)

    def FfcOnePush(self):
        FfcOnce(self)

    def DfcOnce(self):
        self.__lib.Toupcam_DfcOnce(self.__h)

    def DfcOnePush(self):
        DfcOnce(self)

    def DfcExport(self, filepath):
        if sys.platform == 'win32':
            self.__lib.Toupcam_DfcExport(self.__h, filepath)
        else:
            self.__lib.Toupcam_DfcExport(self.__h, filepath.encode())

    def FfcExport(self, filepath):
        if sys.platform == 'win32':
            self.__lib.Toupcam_FfcExport(self.__h, filepath)
        else:
            self.__lib.Toupcam_FfcExport(self.__h, filepath.encode())

    def DfcImport(self, filepath):
        if sys.platform == 'win32':
            self.__lib.Toupcam_DfcImport(self.__h, filepath)
        else:
            self.__lib.Toupcam_DfcImport(self.__h, filepath.encode())

    def FfcImport(self, filepath):
        if sys.platform == 'win32':
            self.__lib.Toupcam_FfcImport(self.__h, filepath)
        else:
            self.__lib.Toupcam_FfcImport(self.__h, filepath.encode())

    def IoControl(self, ioLineNumber, eType, outVal):
        x = ctypes.c_int(0)
        self.__lib.Toupcam_IoControl(self.__h, ctypes.c_uint(ioLineNumber), ctypes.c_uint(eType), ctypes.c_int(outVal), ctypes.byref(x))
        return x.value

    def AAF(self, action, outVal):
        x = ctypes.c_int(0)
        self.__lib.Toupcam_AAF(self.__h, ctypes.c_int(action), ctypes.c_int(outVal), ctypes.byref(x))
        return x.value

    def get_AfParam(self):
        x = self.__AfParam()
        self.__lib.Toupcam_get_AfParam(self.__h, ctypes.byref(x))
        return ToupcamAfParam(x.imax.value, x.imin.value, x.idef.value, x.imaxabs.value, x.iminabs.value, x.zoneh.value, x.zonev.value)

    @staticmethod
    def __histogramCallbackFun(aHist, nFlag, ctx):
        if ctx:
            ctx.__histogramFun(aHist, nFlag)

    def __histogramFun(self, aHist, nFlag):
        if self.__funhistogram:
            arraySize = 1 << (nFlag & 0x0f)
            if nFlag & 0x8000 == 0:
                arraySize *= 3
            self.__funhistogram(aHist, self.__ctxhistogram)

    def GetHistogram(self, fun, ctx):
        self.__funhistogram = fun
        self.__ctxhistogram = ctx
        self.__cbhistogram = __class__.__HISTOGRAM_CALLBACK(__class__.__histogramCallbackFun)
        self.__lib.Toupcam_GetHistogramV2(self.__h, self.__cbhistogram, ctypes.py_object(self))

    @classmethod
    def Replug(cls, camId):
        """
        simulate replug:
        return > 0, the number of device has been replug
        return = 0, no device found
        return E_ACCESSDENIED if without UAC Administrator privileges
        for each device found, it will take about 3 seconds
        """
        cls.__initlib()
        if sys.platform == 'win32':
            return cls.__lib.Toupcam_Replug(camId)
        else:
            return cls.__lib.Toupcam_Replug(camId.encode('ascii'))

    @staticmethod
    def __progressCallbackFun(percent, ctx):
        if __class__.__progress_fun:
            __class__.__progress_fun(percent, __progress_ctx)

    @classmethod
    def Update(cls, camId, filePath, pFun, pCtx):
        """
        firmware update:
           camId: camera ID
           filePath: ufw file full path
           pFun: progress percent callback
        Please do not unplug the camera or lost power during the upgrade process, this is very very important.
        Once an unplugging or power outage occurs during the upgrade process, the camera will no longer be available and can only be returned to the factory for repair.
        """
        cls.__initlib()
        cls.__progress_fun = pFun
        cls.__progress_ctx = pCtx
        cls.__progress_cb = cls.__PROGRESS_CALLBACK(cls.__progressCallbackFun)
        if sys.platform == 'win32':
            return cls.__lib.Toupcam_Update(camId, filePath, __progress_cb, None)
        else:
            return cls.__lib.Toupcam_Update(camId.encode('ascii'), filePath.encode('ascii'), __progress_cb, None)

    @classmethod
    def Gain2TempTint(cls, gain):
        cls.__initlib()
        if len(gain) == 3:
            x = (ctypes.c_int * 3)(gain[0], gain[1], gain[2])
            temp = ctypes.c_int(TOUPCAM_TINT_DEF)
            tint = ctypes.c_int(TOUPCAM_TINT_DEF)
            cls.__lib.Toupcam_Gain2TempTint(x, ctypes.byref(temp), ctypes.byref(tint))
            return (temp.value, tint.value)
        else:
            raise HRESULTException(0x80070057)

    @classmethod
    def TempTint2Gain(cls, temp, tint):
        cls.__initlib()
        x = (ctypes.c_int * 3)()
        cls.__lib.Toupcam_TempTint2Gain(ctypes.c_int(temp), ctypes.c_int(tint), x)
        return (x[0], x[1], x[2])

    @classmethod
    def __initlib(cls):
        if cls.__lib is None:
            try: # Firstly try to load the library in the directory where this file is located
                #dir = os.path.dirname(os.path.realpath(__file__))
                dir_ = os.path.abspath(os.path.join(os.path.dirname(__file__),'..','drivers and libraries','toupcam'))
                # to do: auto detect platform and architecture
                if sys.platform == 'win32':
                    cls.__lib = ctypes.windll.LoadLibrary(os.path.join(dir_,  'win',
                        'x64','toupcam.dll'))
                elif sys.platform.startswith('linux'):
                    cls.__lib = ctypes.cdll.LoadLibrary(os.path.join(dir_,'linux','x64','libtoupcam.so'))
                else:
                    print("----------" + os.path.join(dir_,'mac','libtoupcam.dylib') + "----------")
                    cls.__lib = ctypes.cdll.LoadLibrary(os.path.join(dir_,'mac','libtoupcam.dylib'))
            except OSError:
                pass

            if cls.__lib is None:
                if sys.platform == 'win32':
                    cls.__lib = ctypes.windll.LoadLibrary("drivers and libraries/toupcam/windows/toupcam.dll")
                elif sys.platform.startswith('linux'):
                    cls.__lib = ctypes.cdll.LoadLibrary('libtoupcam.so')
                else:
                    cls.__lib = ctypes.cdll.LoadLibrary('libtoupcam.dylib')

            cls.__lib.Toupcam_Version.argtypes = None
            cls.__lib.Toupcam_EnumV2.restype = ctypes.c_uint
            cls.__lib.Toupcam_EnumV2.argtypes = [_DeviceV2 * TOUPCAM_MAX]
            cls.__lib.Toupcam_EnumWithName.restype = ctypes.c_uint
            cls.__lib.Toupcam_EnumWithName.argtypes = [_DeviceV2 * TOUPCAM_MAX]
            cls.__lib.Toupcam_Open.restype = ctypes.c_void_p
            cls.__lib.Toupcam_Replug.restype = ctypes.c_int
            cls.__lib.Toupcam_Update.restype = ctypes.c_int
            if sys.platform == 'win32':
                cls.__lib.Toupcam_Version.restype = ctypes.c_wchar_p
                cls.__lib.Toupcam_Open.argtypes = [ctypes.c_wchar_p]
                cls.__lib.Toupcam_Replug.argtypes = [ctypes.c_wchar_p]
                cls.__lib.Toupcam_Update.argtypes = [ctypes.c_wchar_p, ctypes.c_wchar_p, cls.__PROGRESS_CALLBACK, ctypes.py_object]
            else:
                cls.__lib.Toupcam_Version.restype = ctypes.c_char_p
                cls.__lib.Toupcam_Open.argtypes = [ctypes.c_char_p]
                cls.__lib.Toupcam_Replug.argtypes = [ctypes.c_char_p]
                cls.__lib.Toupcam_Update.argtypes = [ctypes.c_char_p, ctypes.c_char_p, cls.__PROGRESS_CALLBACK, ctypes.py_object]
            cls.__lib.Toupcam_Replug.errcheck = cls.__errcheck
            cls.__lib.Toupcam_Update.errcheck = cls.__errcheck
            cls.__lib.Toupcam_OpenByIndex.restype = ctypes.c_void_p
            cls.__lib.Toupcam_OpenByIndex.argtypes = [ctypes.c_uint]
            cls.__lib.Toupcam_Close.restype = None
            cls.__lib.Toupcam_Close.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_StartPullModeWithCallback.restype = ctypes.c_int
            cls.__lib.Toupcam_StartPullModeWithCallback.errcheck = cls.__errcheck
            cls.__lib.Toupcam_StartPullModeWithCallback.argtypes = [ctypes.c_void_p, cls.__EVENT_CALLBACK, ctypes.py_object]
            cls.__lib.Toupcam_PullImageV3.restype = ctypes.c_int
            cls.__lib.Toupcam_PullImageV3.errcheck = cls.__errcheck
            cls.__lib.Toupcam_PullImageV3.argtypes = [ctypes.c_void_p, ctypes.c_char_p, ctypes.c_int, ctypes.c_int, ctypes.c_int, ctypes.POINTER(cls.__FrameInfoV3)]
            cls.__lib.Toupcam_WaitImageV3.restype = ctypes.c_int
            cls.__lib.Toupcam_WaitImageV3.errcheck = cls.__errcheck
            cls.__lib.Toupcam_WaitImageV3.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_char_p, ctypes.c_int, ctypes.c_int, ctypes.c_int, ctypes.POINTER(cls.__FrameInfoV3)]       
            cls.__lib.Toupcam_PullImageV2.restype = ctypes.c_int
            cls.__lib.Toupcam_PullImageV2.errcheck = cls.__errcheck
            cls.__lib.Toupcam_PullImageV2.argtypes = [ctypes.c_void_p, ctypes.c_char_p, ctypes.c_int, ctypes.POINTER(cls.__FrameInfoV2)]
            cls.__lib.Toupcam_PullStillImageV2.restype = ctypes.c_int
            cls.__lib.Toupcam_PullStillImageV2.errcheck = cls.__errcheck
            cls.__lib.Toupcam_PullStillImageV2.argtypes = [ctypes.c_void_p, ctypes.c_char_p, ctypes.c_int, ctypes.POINTER(cls.__FrameInfoV2)]
            cls.__lib.Toupcam_PullImageWithRowPitchV2.restype = ctypes.c_int
            cls.__lib.Toupcam_PullImageWithRowPitchV2.errcheck = cls.__errcheck
            cls.__lib.Toupcam_PullImageWithRowPitchV2.argtypes = [ctypes.c_void_p, ctypes.c_char_p, ctypes.c_int, ctypes.c_int, ctypes.POINTER(cls.__FrameInfoV2)]
            cls.__lib.Toupcam_PullStillImageWithRowPitchV2.restype = ctypes.c_int
            cls.__lib.Toupcam_PullStillImageWithRowPitchV2.errcheck = cls.__errcheck
            cls.__lib.Toupcam_PullStillImageWithRowPitchV2.argtypes = [ctypes.c_void_p, ctypes.c_char_p, ctypes.c_int, ctypes.c_int, ctypes.POINTER(cls.__FrameInfoV2)]
            cls.__lib.Toupcam_Stop.restype = ctypes.c_int
            cls.__lib.Toupcam_Stop.errcheck = cls.__errcheck
            cls.__lib.Toupcam_Stop.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_Pause.restype = ctypes.c_int
            cls.__lib.Toupcam_Pause.errcheck = cls.__errcheck
            cls.__lib.Toupcam_Pause.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_Snap.restype = ctypes.c_int
            cls.__lib.Toupcam_Snap.errcheck = cls.__errcheck
            cls.__lib.Toupcam_Snap.argtypes = [ctypes.c_void_p, ctypes.c_uint]
            cls.__lib.Toupcam_SnapN.restype = ctypes.c_int
            cls.__lib.Toupcam_SnapN.errcheck = cls.__errcheck
            cls.__lib.Toupcam_SnapN.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_uint]
            cls.__lib.Toupcam_SnapR.restype = ctypes.c_int
            cls.__lib.Toupcam_SnapR.errcheck = cls.__errcheck
            cls.__lib.Toupcam_SnapR.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_uint]
            cls.__lib.Toupcam_Trigger.restype = ctypes.c_int
            cls.__lib.Toupcam_Trigger.errcheck = cls.__errcheck
            cls.__lib.Toupcam_Trigger.argtypes = [ctypes.c_void_p, ctypes.c_ushort]
            cls.__lib.Toupcam_TriggerSync.restype = ctypes.c_int
            cls.__lib.Toupcam_TriggerSync.errcheck = cls.__errcheck
            cls.__lib.Toupcam_TriggerSync.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_char_p, ctypes.c_int, ctypes.c_int, ctypes.POINTER(cls.__FrameInfoV3)]            
            cls.__lib.Toupcam_put_Size.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Size.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Size.argtypes = [ctypes.c_void_p, ctypes.c_int, ctypes.c_int]
            cls.__lib.Toupcam_get_Size.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Size.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Size.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int), ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_eSize.restype = ctypes.c_int
            cls.__lib.Toupcam_put_eSize.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_eSize.argtypes = [ctypes.c_void_p, ctypes.c_uint]
            cls.__lib.Toupcam_get_eSize.restype = ctypes.c_int
            cls.__lib.Toupcam_get_eSize.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_eSize.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_uint)]
            cls.__lib.Toupcam_get_FinalSize.restype = ctypes.c_int
            cls.__lib.Toupcam_get_FinalSize.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_FinalSize.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int), ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_get_ResolutionNumber.restype = ctypes.c_int
            cls.__lib.Toupcam_get_ResolutionNumber.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_ResolutionNumber.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_get_Resolution.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Resolution.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Resolution.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.POINTER(ctypes.c_int), ctypes.POINTER(ctypes.c_int)];
            cls.__lib.Toupcam_get_ResolutionRatio.restype = ctypes.c_int
            cls.__lib.Toupcam_get_ResolutionRatio.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_ResolutionRatio.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.POINTER(ctypes.c_int), ctypes.POINTER(ctypes.c_int)];
            cls.__lib.Toupcam_get_Field.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Field.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Field.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_get_RawFormat.restype = ctypes.c_int
            cls.__lib.Toupcam_get_RawFormat.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_RawFormat.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint)]
            cls.__lib.Toupcam_get_AutoExpoEnable.restype = ctypes.c_int
            cls.__lib.Toupcam_get_AutoExpoEnable.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_AutoExpoEnable.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_AutoExpoEnable.restype = ctypes.c_int
            cls.__lib.Toupcam_put_AutoExpoEnable.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_AutoExpoEnable.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_AutoExpoTarget.restype = ctypes.c_int
            cls.__lib.Toupcam_get_AutoExpoTarget.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_AutoExpoTarget.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_ushort)]
            cls.__lib.Toupcam_put_AutoExpoTarget.restype = ctypes.c_int
            cls.__lib.Toupcam_put_AutoExpoTarget.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_AutoExpoTarget.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_put_AutoExpoRange.restype = ctypes.c_int
            cls.__lib.Toupcam_put_AutoExpoRange.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_AutoExpoRange.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_uint, ctypes.c_ushort, ctypes.c_ushort]
            cls.__lib.Toupcam_get_AutoExpoRange.restype = ctypes.c_int
            cls.__lib.Toupcam_get_AutoExpoRange.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_AutoExpoRange.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_ushort), ctypes.POINTER(ctypes.c_ushort)]
            cls.__lib.Toupcam_put_MaxAutoExpoTimeAGain.restype = ctypes.c_int
            cls.__lib.Toupcam_put_MaxAutoExpoTimeAGain.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_MaxAutoExpoTimeAGain.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_ushort]
            cls.__lib.Toupcam_get_MaxAutoExpoTimeAGain.restype = ctypes.c_int
            cls.__lib.Toupcam_get_MaxAutoExpoTimeAGain.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_MaxAutoExpoTimeAGain.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_ushort)]
            cls.__lib.Toupcam_put_MinAutoExpoTimeAGain.restype = ctypes.c_int
            cls.__lib.Toupcam_put_MinAutoExpoTimeAGain.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_MinAutoExpoTimeAGain.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_ushort]
            cls.__lib.Toupcam_get_MinAutoExpoTimeAGain.restype = ctypes.c_int
            cls.__lib.Toupcam_get_MinAutoExpoTimeAGain.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_MinAutoExpoTimeAGain.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_ushort)]
            cls.__lib.Toupcam_put_ExpoTime.restype = ctypes.c_int
            cls.__lib.Toupcam_put_ExpoTime.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_ExpoTime.argtypes = [ctypes.c_void_p, ctypes.c_uint]
            cls.__lib.Toupcam_get_ExpoTime.restype = ctypes.c_int
            cls.__lib.Toupcam_get_ExpoTime.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_ExpoTime.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_uint)]
            cls.__lib.Toupcam_get_RealExpoTime.restype = ctypes.c_int
            cls.__lib.Toupcam_get_RealExpoTime.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_RealExpoTime.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_uint)]
            cls.__lib.Toupcam_get_ExpTimeRange.restype = ctypes.c_int
            cls.__lib.Toupcam_get_ExpTimeRange.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_ExpTimeRange.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint)]
            cls.__lib.Toupcam_put_ExpoAGain.restype = ctypes.c_int
            cls.__lib.Toupcam_put_ExpoAGain.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_ExpoAGain.argtypes = [ctypes.c_void_p, ctypes.c_ushort]
            cls.__lib.Toupcam_get_ExpoAGain.restype = ctypes.c_int
            cls.__lib.Toupcam_get_ExpoAGain.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_ExpoAGain.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_ushort)]
            cls.__lib.Toupcam_get_ExpoAGainRange.restype = ctypes.c_int
            cls.__lib.Toupcam_get_ExpoAGainRange.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_ExpoAGainRange.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_ushort), ctypes.POINTER(ctypes.c_ushort), ctypes.POINTER(ctypes.c_ushort)]
            cls.__lib.Toupcam_AwbOnce.restype = ctypes.c_int
            cls.__lib.Toupcam_AwbOnce.errcheck = cls.__errcheck
            cls.__lib.Toupcam_AwbOnce.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p]
            cls.__lib.Toupcam_AwbInit.restype = ctypes.c_int
            cls.__lib.Toupcam_AwbInit.errcheck = cls.__errcheck
            cls.__lib.Toupcam_AwbInit.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p]
            cls.__lib.Toupcam_put_TempTint.restype = ctypes.c_int
            cls.__lib.Toupcam_put_TempTint.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_TempTint.argtypes = [ctypes.c_void_p, ctypes.c_int, ctypes.c_int]
            cls.__lib.Toupcam_get_TempTint.restype = ctypes.c_int
            cls.__lib.Toupcam_get_TempTint.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_TempTint.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int), ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_WhiteBalanceGain.restype = ctypes.c_int
            cls.__lib.Toupcam_put_WhiteBalanceGain.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_WhiteBalanceGain.argtypes = [ctypes.c_void_p, (ctypes.c_int * 3)]
            cls.__lib.Toupcam_get_WhiteBalanceGain.restype = ctypes.c_int
            cls.__lib.Toupcam_get_WhiteBalanceGain.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_WhiteBalanceGain.argtypes = [ctypes.c_void_p, (ctypes.c_int * 3)]
            cls.__lib.Toupcam_put_BlackBalance.restype = ctypes.c_int
            cls.__lib.Toupcam_put_BlackBalance.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_BlackBalance.argtypes = [ctypes.c_void_p, (ctypes.c_ushort * 3)]
            cls.__lib.Toupcam_get_BlackBalance.restype = ctypes.c_int
            cls.__lib.Toupcam_get_BlackBalance.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_BlackBalance.argtypes = [ctypes.c_void_p, (ctypes.c_ushort * 3)]
            cls.__lib.Toupcam_AbbOnce.restype = ctypes.c_int
            cls.__lib.Toupcam_AbbOnce.errcheck = cls.__errcheck
            cls.__lib.Toupcam_AbbOnce.argtypes = [ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p]
            cls.__lib.Toupcam_FfcOnce.restype = ctypes.c_int
            cls.__lib.Toupcam_FfcOnce.errcheck = cls.__errcheck
            cls.__lib.Toupcam_FfcOnce.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_DfcOnce.restype = ctypes.c_int
            cls.__lib.Toupcam_DfcOnce.errcheck = cls.__errcheck
            cls.__lib.Toupcam_DfcOnce.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_FfcExport.restype = ctypes.c_int
            cls.__lib.Toupcam_FfcExport.errcheck = cls.__errcheck
            cls.__lib.Toupcam_FfcImport.restype = ctypes.c_int
            cls.__lib.Toupcam_FfcImport.errcheck = cls.__errcheck
            cls.__lib.Toupcam_DfcExport.restype = ctypes.c_int
            cls.__lib.Toupcam_DfcExport.errcheck = cls.__errcheck
            cls.__lib.Toupcam_DfcImport.restype = ctypes.c_int
            cls.__lib.Toupcam_DfcImport.errcheck = cls.__errcheck
            if sys.platform == 'win32':
                cls.__lib.Toupcam_FfcExport.argtypes = [ctypes.c_void_p, ctypes.c_wchar_p]
                cls.__lib.Toupcam_FfcImport.argtypes = [ctypes.c_void_p, ctypes.c_wchar_p]
                cls.__lib.Toupcam_DfcExport.argtypes = [ctypes.c_void_p, ctypes.c_wchar_p]
                cls.__lib.Toupcam_DfcImport.argtypes = [ctypes.c_void_p, ctypes.c_wchar_p]
            else:
                cls.__lib.Toupcam_FfcExport.argtypes = [ctypes.c_void_p, ctypes.c_char_p]
                cls.__lib.Toupcam_FfcImport.argtypes = [ctypes.c_void_p, ctypes.c_char_p]
                cls.__lib.Toupcam_DfcExport.argtypes = [ctypes.c_void_p, ctypes.c_char_p]
                cls.__lib.Toupcam_DfcImport.argtypes = [ctypes.c_void_p, ctypes.c_char_p]
            cls.__lib.Toupcam_put_Hue.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Hue.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Hue.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_Hue.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Hue.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Hue.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_Saturation.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Saturation.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Saturation.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_Saturation.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Saturation.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Saturation.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_Brightness.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Brightness.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Brightness.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_Brightness.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Brightness.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Brightness.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_Contrast.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Contrast.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Contrast.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_Contrast.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Contrast.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Contrast.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_Gamma.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Gamma.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Gamma.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_Gamma.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Gamma.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Gamma.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_Chrome.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Chrome.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Chrome.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_Chrome.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Chrome.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Chrome.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_VFlip.restype = ctypes.c_int
            cls.__lib.Toupcam_put_VFlip.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_VFlip.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_VFlip.restype = ctypes.c_int
            cls.__lib.Toupcam_get_VFlip.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_VFlip.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_HFlip.restype = ctypes.c_int
            cls.__lib.Toupcam_put_HFlip.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_HFlip.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_HFlip.restype = ctypes.c_int
            cls.__lib.Toupcam_get_HFlip.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_HFlip.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_Negative.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Negative.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Negative.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_Negative.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Negative.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Negative.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_Speed.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Speed.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Speed.argtypes = [ctypes.c_void_p, ctypes.c_ushort]
            cls.__lib.Toupcam_get_Speed.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Speed.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Speed.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_ushort)]
            cls.__lib.Toupcam_get_MaxSpeed.restype = ctypes.c_int
            cls.__lib.Toupcam_get_MaxSpeed.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_MaxSpeed.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_get_FanMaxSpeed.restype = ctypes.c_int
            cls.__lib.Toupcam_get_FanMaxSpeed.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_FanMaxSpeed.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_get_MaxBitDepth.restype = ctypes.c_int
            cls.__lib.Toupcam_get_MaxBitDepth.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_MaxBitDepth.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_put_HZ.restype = ctypes.c_int
            cls.__lib.Toupcam_put_HZ.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_HZ.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_HZ.restype = ctypes.c_int
            cls.__lib.Toupcam_get_HZ.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_HZ.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_Mode.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Mode.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Mode.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_Mode.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Mode.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Mode.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_AWBAuxRect.restype = ctypes.c_int
            cls.__lib.Toupcam_put_AWBAuxRect.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_AWBAuxRect.argtypes = [ctypes.c_void_p, ctypes.POINTER(cls.__RECT)]
            cls.__lib.Toupcam_get_AWBAuxRect.restype = ctypes.c_int
            cls.__lib.Toupcam_get_AWBAuxRect.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_AWBAuxRect.argtypes = [ctypes.c_void_p, ctypes.POINTER(cls.__RECT)]
            cls.__lib.Toupcam_put_AEAuxRect.restype = ctypes.c_int
            cls.__lib.Toupcam_put_AEAuxRect.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_AEAuxRect.argtypes = [ctypes.c_void_p, ctypes.POINTER(cls.__RECT)]
            cls.__lib.Toupcam_get_AEAuxRect.restype = ctypes.c_int
            cls.__lib.Toupcam_get_AEAuxRect.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_AEAuxRect.argtypes = [ctypes.c_void_p, ctypes.POINTER(cls.__RECT)]
            cls.__lib.Toupcam_put_ABBAuxRect.restype = ctypes.c_int
            cls.__lib.Toupcam_put_ABBAuxRect.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_ABBAuxRect.argtypes = [ctypes.c_void_p, ctypes.POINTER(cls.__RECT)]
            cls.__lib.Toupcam_get_ABBAuxRect.restype = ctypes.c_int
            cls.__lib.Toupcam_get_ABBAuxRect.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_ABBAuxRect.argtypes = [ctypes.c_void_p, ctypes.POINTER(cls.__RECT)]
            cls.__lib.Toupcam_get_MonoMode.restype = ctypes.c_int
            cls.__lib.Toupcam_get_MonoMode.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_MonoMode.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_get_StillResolutionNumber.restype = ctypes.c_int
            cls.__lib.Toupcam_get_StillResolutionNumber.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_StillResolutionNumber.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_get_StillResolution.restype = ctypes.c_int
            cls.__lib.Toupcam_get_StillResolution.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_StillResolution.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.POINTER(ctypes.c_int), ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_RealTime.restype = ctypes.c_int
            cls.__lib.Toupcam_put_RealTime.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_RealTime.argtypes = [ctypes.c_void_p, ctypes.c_int]
            cls.__lib.Toupcam_get_RealTime.restype = ctypes.c_int
            cls.__lib.Toupcam_get_RealTime.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_RealTime.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_Flush.restype = ctypes.c_int
            cls.__lib.Toupcam_Flush.errcheck = cls.__errcheck
            cls.__lib.Toupcam_Flush.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_put_Temperature.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Temperature.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Temperature.argtypes = [ctypes.c_void_p, ctypes.c_short]
            cls.__lib.Toupcam_get_Temperature.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Temperature.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Temperature.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_short)]
            cls.__lib.Toupcam_get_Revision.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Revision.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Revision.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_ushort)]
            cls.__lib.Toupcam_get_SerialNumber.restype = ctypes.c_int
            cls.__lib.Toupcam_get_SerialNumber.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_SerialNumber.argtypes = [ctypes.c_void_p, ctypes.c_char * 32]
            cls.__lib.Toupcam_get_FwVersion.restype = ctypes.c_int
            cls.__lib.Toupcam_get_FwVersion.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_FwVersion.argtypes = [ctypes.c_void_p, ctypes.c_char * 16]
            cls.__lib.Toupcam_get_HwVersion.restype = ctypes.c_int
            cls.__lib.Toupcam_get_HwVersion.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_HwVersion.argtypes = [ctypes.c_void_p, ctypes.c_char * 16]
            cls.__lib.Toupcam_get_ProductionDate.restype = ctypes.c_int
            cls.__lib.Toupcam_get_ProductionDate.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_ProductionDate.argtypes = [ctypes.c_void_p, ctypes.c_char * 16]
            cls.__lib.Toupcam_get_FpgaVersion.restype = ctypes.c_int
            cls.__lib.Toupcam_get_FpgaVersion.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_FpgaVersion.argtypes = [ctypes.c_void_p, ctypes.c_char * 16]
            cls.__lib.Toupcam_get_PixelSize.restype = ctypes.c_int
            cls.__lib.Toupcam_get_PixelSize.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_PixelSize.argtypes = [ctypes.c_void_p, ctypes.c_int, ctypes.POINTER(ctypes.c_float), ctypes.POINTER(ctypes.c_float)]
            cls.__lib.Toupcam_put_LevelRange.restype = ctypes.c_int
            cls.__lib.Toupcam_put_LevelRange.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_LevelRange.argtypes = [ctypes.c_void_p, (ctypes.c_ushort * 4), (ctypes.c_ushort * 4)]
            cls.__lib.Toupcam_get_LevelRange.restype = ctypes.c_int
            cls.__lib.Toupcam_get_LevelRange.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_LevelRange.argtypes = [ctypes.c_void_p, (ctypes.c_ushort * 4), (ctypes.c_ushort * 4)]
            cls.__lib.Toupcam_put_LevelRangeV2.restype = ctypes.c_int
            cls.__lib.Toupcam_put_LevelRangeV2.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_LevelRangeV2.argtypes = [ctypes.c_void_p, ctypes.c_ushort, ctypes.POINTER(cls.__RECT), (ctypes.c_ushort * 4), (ctypes.c_ushort * 4)]
            cls.__lib.Toupcam_get_LevelRangeV2.restype = ctypes.c_int
            cls.__lib.Toupcam_get_LevelRangeV2.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_LevelRangeV2.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_ushort), ctypes.POINTER(cls.__RECT), (ctypes.c_ushort * 4), (ctypes.c_ushort * 4)]
            cls.__lib.Toupcam_LevelRangeAuto.restype = ctypes.c_int
            cls.__lib.Toupcam_LevelRangeAuto.errcheck = cls.__errcheck
            cls.__lib.Toupcam_LevelRangeAuto.argtypes = [ctypes.c_void_p]
            cls.__lib.Toupcam_put_LEDState.restype = ctypes.c_int
            cls.__lib.Toupcam_put_LEDState.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_LEDState.argtypes = [ctypes.c_void_p, ctypes.c_ushort, ctypes.c_ushort, ctypes.c_ushort, ctypes.c_ushort]
            cls.__lib.Toupcam_write_EEPROM.restype = ctypes.c_int
            cls.__lib.Toupcam_write_EEPROM.errcheck = cls.__errcheck
            cls.__lib.Toupcam_write_EEPROM.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_char_p, ctypes.c_uint]
            cls.__lib.Toupcam_read_EEPROM.restype = ctypes.c_int
            cls.__lib.Toupcam_read_EEPROM.errcheck = cls.__errcheck
            cls.__lib.Toupcam_read_EEPROM.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_char_p, ctypes.c_uint]
            cls.__lib.Toupcam_rwc_Flash.restype = ctypes.c_int
            cls.__lib.Toupcam_rwc_Flash.errcheck = cls.__errcheck
            cls.__lib.Toupcam_rwc_Flash.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_uint, ctypes.c_uint, ctypes.c_char_p]
            cls.__lib.Toupcam_read_Pipe.restype = ctypes.c_int
            cls.__lib.Toupcam_read_Pipe.errcheck = cls.__errcheck
            cls.__lib.Toupcam_read_Pipe.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_char_p, ctypes.c_uint]
            cls.__lib.Toupcam_write_Pipe.restype = ctypes.c_int
            cls.__lib.Toupcam_write_Pipe.errcheck = cls.__errcheck
            cls.__lib.Toupcam_write_Pipe.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_char_p, ctypes.c_uint]
            cls.__lib.Toupcam_feed_Pipe.restype = ctypes.c_int
            cls.__lib.Toupcam_feed_Pipe.errcheck = cls.__errcheck
            cls.__lib.Toupcam_feed_Pipe.argtypes = [ctypes.c_void_p, ctypes.c_uint]
            cls.__lib.Toupcam_put_Option.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Option.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Option.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_int]
            cls.__lib.Toupcam_get_Option.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Option.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Option.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_put_Roi.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Roi.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Roi.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_uint, ctypes.c_uint, ctypes.c_uint]
            cls.__lib.Toupcam_get_Roi.restype = ctypes.c_int
            cls.__lib.Toupcam_get_Roi.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_Roi.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint)]
            cls.__lib.Toupcam_get_AfParam.restype = ctypes.c_int
            cls.__lib.Toupcam_get_AfParam.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_AfParam.argtypes = [ctypes.c_void_p, ctypes.POINTER(cls.__AfParam)]
            cls.__lib.Toupcam_IoControl.restype = ctypes.c_int
            cls.__lib.Toupcam_IoControl.errcheck = cls.__errcheck
            cls.__lib.Toupcam_IoControl.argtypes = [ctypes.c_void_p, ctypes.c_uint, ctypes.c_uint, ctypes.c_int, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_AAF.restype = ctypes.c_int
            cls.__lib.Toupcam_AAF.errcheck = cls.__errcheck
            cls.__lib.Toupcam_AAF.argtypes = [ctypes.c_void_p, ctypes.c_int, ctypes.c_int, ctypes.POINTER(ctypes.c_int)]
            cls.__lib.Toupcam_read_UART.restype = ctypes.c_int
            cls.__lib.Toupcam_read_UART.errcheck = cls.__errcheck
            cls.__lib.Toupcam_read_UART.argtypes = [ctypes.c_void_p, ctypes.c_char_p, ctypes.c_uint]
            cls.__lib.Toupcam_write_UART.restype = ctypes.c_int
            cls.__lib.Toupcam_write_UART.errcheck = cls.__errcheck
            cls.__lib.Toupcam_write_UART.argtypes = [ctypes.c_void_p, ctypes.c_char_p, ctypes.c_uint]
            cls.__lib.Toupcam_put_Linear.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Linear.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Linear.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_ubyte), ctypes.POINTER(ctypes.c_ushort)]
            cls.__lib.Toupcam_put_Curve.restype = ctypes.c_int
            cls.__lib.Toupcam_put_Curve.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_Curve.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_ubyte), ctypes.POINTER(ctypes.c_ushort)]
            cls.__lib.Toupcam_put_ColorMatrix.restype = ctypes.c_int
            cls.__lib.Toupcam_put_ColorMatrix.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_ColorMatrix.argtypes = [ctypes.c_void_p, ctypes.c_double * 9]
            cls.__lib.Toupcam_put_InitWBGain.restype = ctypes.c_int
            cls.__lib.Toupcam_put_InitWBGain.errcheck = cls.__errcheck
            cls.__lib.Toupcam_put_InitWBGain.argtypes = [ctypes.c_void_p, ctypes.c_ushort * 3]
            cls.__lib.Toupcam_get_FrameRate.restype = ctypes.c_int
            cls.__lib.Toupcam_get_FrameRate.errcheck = cls.__errcheck
            cls.__lib.Toupcam_get_FrameRate.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint)]
            cls.__lib.Toupcam_GetHistogramV2.restype = ctypes.c_int
            cls.__lib.Toupcam_GetHistogramV2.errcheck = cls.__errcheck
            cls.__lib.Toupcam_GetHistogramV2.argtypes = [ctypes.c_void_p, cls.__HISTOGRAM_CALLBACK, ctypes.py_object]
            cls.__lib.Toupcam_GigeEnable.restype = ctypes.c_int
            cls.__lib.Toupcam_GigeEnable.argtypes = [cls.__HOTPLUG_CALLBACK, ctypes.c_void_p]
            cls.__lib.Toupcam_Gain2TempTint.restype = ctypes.c_int
            cls.__lib.Toupcam_Gain2TempTint.errcheck = cls.__errcheck
            cls.__lib.Toupcam_Gain2TempTint.argtypes = [ctypes.c_int * 3, ctypes.POINTER(ctypes.c_int), ctypes.POINTER(ctypes.c_int)];
            cls.__lib.Toupcam_TempTint2Gain.restype = None
            cls.__lib.Toupcam_TempTint2Gain.argtypes = [ctypes.c_int, ctypes.c_int, ctypes.c_int * 3];
            if sys.platform != 'win32' and sys.platform != 'android':
                cls.__lib.Toupcam_HotPlug.restype = None
                cls.__lib.Toupcam_HotPlug.argtypes = [cls.__HOTPLUG_CALLBACK, ctypes.c_void_p]

#!/usr/bin/python
# -*- coding:utf-8 -*-
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-
#

from ctypes import *
import sys

if sys.platform == 'linux2' or sys.platform == 'linux':
    try:
        dll = CDLL('/usr/lib/libgxiapi.so')
    except OSError:
        print('Cannot find libgxiapi.so.')
else:
    try:
        if (sys.version_info.major == 3 and sys.version_info.minor >= 8) or (sys.version_info.major > 3):
            dll = WinDLL('DxImageProc.dll', winmode=0)
        else:
            dll = WinDLL('DxImageProc.dll')
    except OSError:
        print('Cannot find DxImageProc.dll.')


# status  definition
class DxStatus:
    OK = 0                               # Operation is successful
    PARAMETER_INVALID = -101             # Invalid input parameter
    PARAMETER_OUT_OF_BOUND = -102        # The input parameter is out of bounds
    NOT_ENOUGH_SYSTEM_MEMORY = -103      # System out of memory
    NOT_FIND_DEVICE = -104               # not find device
    STATUS_NOT_SUPPORTED = -105          # operation is not supported
    CPU_NOT_SUPPORT_ACCELERATE = -106    # CPU does not support acceleration
  
    def __init__(self):
        pass


if sys.platform == 'linux2' or sys.platform == 'linux':
    # Bayer layout
    class DxPixelColorFilter:
        NONE = 0                                # Isn't bayer format
        RG = 1                                  # The first row starts with RG
        GB = 2                                  # The first line starts with GB
        GR = 3                                  # The first line starts with GR
        BG = 4                                  # The first line starts with BG

        def __init__(self):
            pass
else:
    # Bayer layout
    class DxPixelColorFilter:
        NONE = 0                                # Isn't bayer format
        BG = 1                                  # The first row starts with BG
        GR = 2                                  # The first line starts with GR
        GB = 3                                  # The first line starts with GB
        RG = 4                                  # The first line starts with RG

        def __init__(self):
            pass


# image actual bits
class DxActualBits:
    BITS_10 = 10             # 10bit
    BITS_12 = 12             # 12bit
    BITS_14 = 14             # 14bit
    BITS_16 = 16             # 16bit

    def __init__(self):
        pass


'''
# mono8 image process structure
class MonoImgProcess(Structure):
    _fields_ = [
        ('defective_pixel_correct',     c_bool),        # Pixel correct switch
        ('sharpness',                   c_bool),        # Sharpness switch　
        ('accelerate',                  c_bool),        # Accelerate switch
        ('sharp_factor',                c_float),       # Sharpen the intensity factor
        ('pro_lut',                     c_char_p),      # Lookup table
        ('lut_length',                  c_ushort),      # Lut Buffer length
        ('array_reserved',              c_ubyte * 32),  # Reserved
    ]

    def __str__(self):
        return "MonoImgProcess\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


# Raw8 Image process structure
class ColorImgProcess(Structure):
    _fields_ = [
        ('defective_pixel_correct',     c_bool),        # Pixel correct switch
        ('denoise',                     c_bool),        # Noise reduction switch
        ('sharpness',                   c_bool),        # Sharpness switch
        ('accelerate',                  c_bool),        # Accelerate switch
        ('arr_cc',                      c_void_p),      # Color processing parameters
        ('cc_buf_length',               c_ubyte),       # Color processing parameters length（sizeof(VxInt16)*9）
        ('sharp_factor',                c_float),       # Sharpen the intensity factor
        ('pro_lut',                     c_char_p),      # Lookup table
        ('lut_length',                  c_ushort),      # The length of the lookup table
        ('cv_type',                     c_uint),        # Interpolation algorithm
        ('layout',                      c_uint),        # Bayer format
        ('flip',                        c_bool),        # Image flip flag
        ('array_reserved',              c_ubyte*32),    # Reserved
    ]

    def __str__(self):
        return "ColorImgProcess\n%s" % "\n".join("%s:\t%s" % (n, getattr(self, n[0])) for n in self._fields_)


if hasattr(dll, 'DxGetLut'):
    def gx_get_lut(contrast_param, gamma, lightness):
        """
        :brief calculating lookup table of 8bit image
        :param contrast_param:  contrast param,range(-50~100)
        :param gamma:           gamma param,range(0.1~10)
        :param lightness:       lightness param,range(-150~150)
        :return: status         State return value, See detail in DxStatus
                 lut            lookup table
                 lut_length     lookup table length(unit:byte)
        """
        contrast_param_c = c_int()
        contrast_param_c.value = contrast_param

        gamma_c = c_double()
        gamma_c.value = gamma

        lightness_c = c_int()
        lightness_c.value = lightness

        lut_length_c = c_int()
        lut_length_c.value = 0

        # Get length of the lookup table
        dll.DxGetLut(contrast_param_c, gamma_c, lightness_c, None, byref(lut_length_c))

        # Create buff to get LUT data
        lut_c = (c_ubyte * lut_length_c.value)()
        status = dll.DxGetLut(contrast_param_c, gamma_c, lightness_c,  byref(lut_c), byref(lut_length_c))

        return status, lut_c, lut_length_c.value
'''

if hasattr(dll, "DxGetGammatLut"):
    def dx_get_gamma_lut(gamma_param):
        """
        :brief  calculating gamma lookup table (RGB24)
        :param  gamma_param:    gamma param,range(0.1 ~ 10)
        :return: status:        State return value, See detail in DxStatus
                gamma_lut:      gamma lookup table
                lut_length:     gamma lookup table length(unit:byte)
        """
        gamma_param_c = c_double()
        gamma_param_c.value = gamma_param

        lut_length_c = c_int()
        status = dll.DxGetGammatLut(gamma_param_c, None, byref(lut_length_c))

        gamma_lut = (c_ubyte * lut_length_c.value)()
        status = dll.DxGetGammatLut(gamma_param_c, byref(gamma_lut), byref(lut_length_c))

        return status, gamma_lut, lut_length_c.value


if hasattr(dll, "DxGetContrastLut"):
    def dx_get_contrast_lut(contrast_param):
        """
        :brief  ccalculating contrast lookup table (RGB24)
        :param  contrast_param: contrast param,range(-50 ~ 100)
        :return: status：       State return value, See detail in DxStatus
                 contrast_lut： contrast lookup table
                 lut_length：   contrast lookup table length(unit:byte)
        """
        contrast_param_c = c_int()
        contrast_param_c.value = contrast_param

        lut_length_c = c_int()
        status = dll.DxGetContrastLut(contrast_param_c, None, byref(lut_length_c))

        contrast_lut = (c_ubyte * lut_length_c.value)()
        status = dll.DxGetContrastLut(contrast_param_c, byref(contrast_lut), byref(lut_length_c))

        return status, contrast_lut, lut_length_c.value


if hasattr(dll, 'DxRaw8toRGB24'):
    def dx_raw8_to_rgb24(input_address, output_address, width, height, convert_type, bayer_type, flip):
        """
        :brief  Convert Raw8 to Rgb24
        :param input_address:      The input raw image buff address, buff size = width * height
        :param output_address:     The output rgb image buff address, buff size = width * height * 3
        :param width:           Image width
        :param height:          Image height
        :param convert_type:    Bayer convert type, See detail in DxBayerConvertType
        :param bayer_type:      pixel color filter, See detail in DxPixelColorFilter
        :param flip:            Output image flip flag
                                True: turn the image upside down
                                False: do not flip
        :return: status         State return value, See detail in DxStatus
                 data_array     Array of output images, buff size = width * height * 3
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        convert_type_c = c_uint()
        convert_type_c.value = convert_type

        bayer_type_c = c_uint()
        bayer_type_c.value = bayer_type

        flip_c = c_bool()
        flip_c.value = flip

        input_address_p = c_void_p()
        input_address_p.value = input_address

        output_address_p = c_void_p()
        output_address_p.value = output_address

        status = dll.DxRaw8toRGB24(input_address_p, output_address_p,
                                   width_c, height_c, convert_type_c, bayer_type_c, flip_c)
        return status


if hasattr(dll, 'DxRaw16toRaw8'):
    def dx_raw16_to_raw8(input_address, out_address, width, height, valid_bits):
        """
        :biref  Raw16 converted to Raw8
        :param  input_address:     The input image buff address, buff size = width * height * 2
        :param  out_address:       The output image buff address, buff size = width * height
        :param  width:          Image width
        :param  height:         Image height
        :param  valid_bits:     Data valid digit, See detail in DxValidBit
        :return: status         State return value, See detail in DxStatus
                 data_array     Array of output images, buff size = width * height
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        valid_bits_c = c_uint()
        valid_bits_c.value = valid_bits

        input_address_p = c_void_p()
        input_address_p.value = input_address

        out_address_p = c_void_p()
        out_address_p.value = out_address

        status = dll.DxRaw16toRaw8(input_address_p, out_address_p,
                                   width_c, height_c, valid_bits_c)
        return status


if hasattr(dll, "DxImageImprovment"):
    def dx_image_improvement(input_address, output_address, width, height,
                             color_correction_param, contrast_lut, gamma_lut):
        """
        :brief      image quality improvement
        :param      input_address:              input buffer address, buff size = width * height *3
        :param      output_address:             input buffer address, buff size = width * height *3
        :param      width:                      image width
        :param      height:                     image height
        :param      color_correction_param:     color correction param(get from camera)
        :param      contrast_lut:               contrast lookup table
        :param      gamma_lut:                  gamma lookup table
        :return:    status                      State return value, See detail in DxStatus
                    data_array                  Array of output images, buff size = width * height * 3
        """
        width_c = c_uint()
        width_c.value = width

        height_c = c_uint()
        height_c.value = height

        input_address_p = c_void_p()
        input_address_p.value = input_address

        output_address_p = c_void_p()
        output_address_p.value = output_address

        color_correction_param_p = c_int64()
        color_correction_param_p.value = color_correction_param

        status = dll.DxImageImprovment(input_address_p, output_address_p, width_c, height_c,
                                       color_correction_param_p, contrast_lut, gamma_lut)
        return status


import numpy
from collections import namedtuple
from time import sleep
import sys
import time #@@@
import numpy as np
from scipy import misc
import cv2

try:
    import gi
    gi.require_version("Gst", "1.0")
    gi.require_version("Tcam", "0.1")
    from gi.repository import Tcam, Gst, GLib, GObject
except ImportError:
    print('gi import error')

DeviceInfo = namedtuple("DeviceInfo", "status name identifier connection_type")
CameraProperty = namedtuple("CameraProperty", "status value min max default step type flags category group")

class Camera(object):

    def __init__(self,sn=None,width=1920,height=1080,framerate=30,color=False):
        Gst.init(sys.argv)
        self.height = height
        self.width = width
        self.sample = None
        self.samplelocked = False
        self.newsample = False
        self.gotimage = False
        self.img_mat = None
        self.new_image_callback_external = None
        self.image_locked = False
        self.is_streaming = False
        self.is_color = color

        self.GAIN_MAX = 480
        self.GAIN_MIN = 0
        self.GAIN_STEP = 10
        self.EXPOSURE_TIME_MS_MIN = 0.02
        self.EXPOSURE_TIME_MS_MAX = 4000

        self.callback_is_enabled = False
        self.callback_was_enabled_before_autofocus = False
        self.callback_was_enabled_before_multipoint = False

        format = "BGRx"
        if(color == False):
            format="GRAY8"

        if(framerate == 2500000):    
            p = 'tcambin serial="%s" name=source ! video/x-raw,format=%s,width=%d,height=%d,framerate=%d/10593' % (sn,format,width,height,framerate,)
        else:
            p = 'tcambin serial="%s" name=source ! video/x-raw,format=%s,width=%d,height=%d,framerate=%d/1' % (sn,format,width,height,framerate,)

        p += ' ! videoconvert ! appsink name=sink'

        print(p)
        try:
            self.pipeline = Gst.parse_launch(p)
        except GLib.Error as error:
            print("Error creating pipeline: {0}".format(err))
            raise

        self.pipeline.set_state(Gst.State.READY)
        self.pipeline.get_state(Gst.CLOCK_TIME_NONE)
        # Query a pointer to our source, so we can set properties.
        self.source = self.pipeline.get_by_name("source")

        # Query a pointer to the appsink, so we can assign the callback function.
        self.appsink = self.pipeline.get_by_name("sink")
        self.appsink.set_property("max-buffers",5)
        self.appsink.set_property("drop", True)
        self.appsink.set_property("emit-signals", True)

    def open(self,index=0):
        pass

    def set_callback(self,function):
        self.new_image_callback_external = function

    def enable_callback(self):
        self.appsink.connect('new-sample', self._on_new_buffer)

    def disable_callback(self):
        pass

    def open_by_sn(self,sn):
        pass

    def close(self):
        self.stop_streaming()

    def set_exposure_time(self,exposure_time):
        self._set_property('Exposure Auto',False)
        self._set_property('Exposure Time (us)',int(exposure_time*1000))

    def set_analog_gain(self,analog_gain):
        self._set_property('Gain Auto',False)
        self._set_property('Gain',int(analog_gain))

    def get_awb_ratios(self):
        pass

    def set_wb_ratios(self, wb_r=None, wb_g=None, wb_b=None):
        pass

    def start_streaming(self):
        try:
            self.pipeline.set_state(Gst.State.PLAYING)
            self.pipeline.get_state(Gst.CLOCK_TIME_NONE)
            self.is_streaming = True
        except GLib.Error as error:
            print("Error starting pipeline: {0}".format(err))#error?
            raise
        self.frame_ID = 0

    def stop_streaming(self):
        self.pipeline.set_state(Gst.State.NULL)
        print("pipeline stopped")
        self.pipeline.set_state(Gst.State.READY)
        self.is_streaming = False

    def set_continuous_acquisition(self):
        self._set_property('Trigger Mode', False)

    def set_software_triggered_acquisition(self):
        pass

    def set_hardware_triggered_acquisition(self):
        self._set_property('Trigger Mode', True)
        self._set_property('Trigger Polarity', 'RisingEdge')
        self._set_property('Trigger Delay (us)', 0)

    def send_trigger(self):
        pass

    def read_frame(self):
        return self.current_frame

    def _on_new_buffer(self, appsink):
        # Function that is called when a new sample from camera is available
        self.newsample = True
        # print('new buffer received: ' + str(time.time())) #@@@
        if self.image_locked:
            print('last image is still being processed, a frame is dropped')
            return
        if self.samplelocked is False:
            self.samplelocked = True
            try:
                self.sample = self.appsink.get_property('last-sample')
                self._gstbuffer_to_opencv()
                # print('new buffer read into RAM: ' + str(time.time())) #@@@
                self.samplelocked = False
                self.newsample = False
                # gotimage reflects if a new image was triggered
                self.gotimage = True
                self.frame_ID = self.frame_ID + 1 # @@@ read frame ID from the camera
                self.timestamp = time.time()
                if self.new_image_callback_external is not None:
                    self.new_image_callback_external(self)
            except GLib.Error as error:
                print("Error on_new_buffer pipeline: {0}".format(err)) #error
                self.img_mat = None
        return Gst.FlowReturn.OK

    def _get_property(self, PropertyName):
        try:
            return CameraProperty(*self.source.get_tcam_property(PropertyName))
        except GLib.Error as error:
            print("Error get Property {0}: {1}",PropertyName, format(err))
            raise

    def _set_property(self, PropertyName, value):
        try:
            print('setting ' + PropertyName + 'to ' + str(value))
            self.source.set_tcam_property(PropertyName,GObject.Value(type(value),value))
        except GLib.Error as error:
            print("Error set Property {0}: {1}",PropertyName, format(err))
            raise

    def _gstbuffer_to_opencv(self):
        # Sample code from https://gist.github.com/cbenhagen/76b24573fa63e7492fb6#file-gst-appsink-opencv-py-L34
        buf = self.sample.get_buffer()
        caps = self.sample.get_caps()
        bpp = 4;
        if caps.get_structure(0).get_value('format') == "BGRx":
            bpp = 4;

        if caps.get_structure(0).get_value('format') == "GRAY8":
            bpp = 1;

        self.current_frame = numpy.ndarray(
            (caps.get_structure(0).get_value('height'),
             caps.get_structure(0).get_value('width'),
             bpp),
            buffer=buf.extract_dup(0, buf.get_size()),
            dtype=numpy.uint8)
    def set_pixel_format(self,format):
        pass
class Camera_Simulation(object):

    def __init__(self,sn=None,width=640,height=480,framerate=30,color=False):
        self.height = height
        self.width = width
        self.sample = None
        self.samplelocked = False
        self.newsample = False
        self.gotimage = False
        self.img_mat = None
        self.new_image_callback_external = None
        self.image_locked = False
        self.is_streaming = False
        self.is_color = color

        self.GAIN_MAX = 480
        self.GAIN_MIN = 0
        self.GAIN_STEP = 10
        self.EXPOSURE_TIME_MS_MIN = 0.02
        self.EXPOSURE_TIME_MS_MAX = 4000

        self.callback_is_enabled = False
        self.callback_was_enabled_before_autofocus = False
        self.callback_was_enabled_before_multipoint = False

    def open(self,index=0):
        pass

    def set_callback(self,function):
        self.new_image_callback_external = function

    def enable_callback(self):
        pass

    def disable_callback(self):
        pass

    def open_by_sn(self,sn):
        pass

    def close(self):
        pass

    def set_exposure_time(self,exposure_time):
        pass

    def set_analog_gain(self,analog_gain):
        pass

    def get_awb_ratios(self):
        pass

    def set_wb_ratios(self, wb_r=None, wb_g=None, wb_b=None):
        pass

    def start_streaming(self):
        self.frame_ID = 0

    def stop_streaming(self):
        pass

    def set_continuous_acquisition(self):
        pass

    def set_software_triggered_acquisition(self):
        pass

    def set_hardware_triggered_acquisition(self):
        pass

    def send_trigger(self):
        self.frame_ID = self.frame_ID + 1
        self.timestamp = time.time()
        if self.frame_ID == 1:
            self.current_frame = np.random.randint(255,size=(2000,2000),dtype=np.uint8)
            self.current_frame[901:1100,901:1100] = 200
        else:
            self.current_frame = np.roll(self.current_frame,10,axis=0)
            pass 
            # self.current_frame = np.random.randint(255,size=(768,1024),dtype=np.uint8)
        if self.new_image_callback_external is not None:
            self.new_image_callback_external(self)

    def read_frame(self):
        return self.current_frame

    def _on_new_buffer(self, appsink):
        pass

    def _get_property(self, PropertyName):
        pass

    def _set_property(self, PropertyName, value):
        pass

    def _gstbuffer_to_opencv(self):
        pass

    def set_pixel_format(self,format):
        pass

from abc import abstractmethod

import napari
import numpy as np
from napari.utils.translations import trans
from qtpy import QtCore, QtGui, QtWidgets
from vispy.color import Color
from vispy.scene.visuals import Compound, Line, Markers
from vispy.visuals.transforms import STTransform

from .imagetools import minmaxLevels


def addNapariGrayclipColormap():
    if hasattr(napari.utils.colormaps.AVAILABLE_COLORMAPS, 'grayclip'):
        return

    grayclip = []
    for i in range(255):
        grayclip.append([i / 255, i / 255, i / 255])
    grayclip.append([1, 0, 0])
    napari.utils.colormaps.AVAILABLE_COLORMAPS['grayclip'] = napari.utils.Colormap(
        name='grayclip', colors=grayclip
    )


class EmbeddedNapari(napari.Viewer):
    """ Napari viewer to be embedded in non-napari windows. Also includes a
    feature to protect certain layers from being removed when added using
    the add_image method. """

    def __init__(self, *args, show=False, **kwargs):
        super().__init__(*args, show=show, **kwargs)

        # Monkeypatch layer removal methods
        oldDelitemIndices = self.layers._delitem_indices

        def newDelitemIndices(key):
            indices = oldDelitemIndices(key)
            for index in indices[:]:
                layer = index[0][index[1]]
                if hasattr(layer, 'protected') and layer.protected:
                    indices.remove(index)
            return indices

        self.layers._delitem_indices = newDelitemIndices

        # Make menu bar not native
        self.window._qt_window.menuBar().setNativeMenuBar(False)

        # Remove unwanted menu bar items
        menuChildren = self.window._qt_window.findChildren(QtWidgets.QAction)
        for menuChild in menuChildren:
            try:
                if menuChild.text() in [trans._('Close Window'), trans._('Exit')]:
                    self.window.file_menu.removeAction(menuChild)
            except Exception:
                pass
        
        self.scale_bar.visible = True

    def add_image(self, *args, protected=False, **kwargs):
        result = super().add_image(*args, **kwargs)

        if isinstance(result, list):
            for layer in result:
                layer.protected = protected
        else:
            result.protected = protected

        return result

    def get_widget(self):
        return self.window._qt_window


class NapariBaseWidget(QtWidgets.QWidget):
    """ Base class for Napari widgets. """

    @property
    @abstractmethod
    def name(self):
        pass

    def __init__(self, napariViewer):
        super().__init__()
        self.viewer = napariViewer

    @classmethod
    def addToViewer(cls, napariViewer, position='left'):
        """ Adds this widget to the specified Napari viewer. """

        # Add dock for this widget
        widget = cls(napariViewer)
        napariViewer.window.add_dock_widget(widget, name=widget.name, area=position)

        # Move layer list to bottom
        napariViewer.window._qt_window.removeDockWidget(
            napariViewer.window.qt_viewer.dockLayerList
        )
        napariViewer.window._qt_window.addDockWidget(
            napariViewer.window.qt_viewer.dockLayerList.qt_area,
            napariViewer.window.qt_viewer.dockLayerList
        )
        napariViewer.window.qt_viewer.dockLayerList.show()
        return widget

    def addItemToViewer(self, item):
        item.attach(self.viewer,
                    canvas=self.viewer.window.qt_viewer.canvas,
                    view=self.viewer.window.qt_viewer.view,
                    parent=self.viewer.window.qt_viewer.view.scene,
                    order=1e6 + 8000)


class NapariUpdateLevelsWidget(NapariBaseWidget):
    """ Napari widget for auto-levelling the currently selected layer with a
    single click. """

    @property
    def name(self):
        return 'update levels widget'

    def __init__(self, napariViewer):
        super().__init__(napariViewer)

        # Update levels button
        self.updateLevelsButton = QtWidgets.QPushButton('Update levels')
        self.updateLevelsButton.clicked.connect(self._on_update_levels)

        # Layout
        self.setLayout(QtWidgets.QVBoxLayout())
        self.layout().addWidget(self.updateLevelsButton)

        # Make sure widget isn't too big
        self.setSizePolicy(QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Expanding,
                                                 QtWidgets.QSizePolicy.Maximum))

    def _on_update_levels(self):
        for layer in self.viewer.layers.selected:
            layer.contrast_limits = minmaxLevels(layer.data)


class NapariResetViewWidget(NapariBaseWidget):
    """ Napari widget for resetting the dimensional view of the currently
    selected layer with a single click. """

    @property
    def name(self):
        return 'reset view widget'

    def __init__(self, napariViewer):
        super().__init__(napariViewer)

        # Reset buttons and line edit
        self.resetViewButton = QtWidgets.QPushButton('Reset view')
        self.resetViewButton.clicked.connect(self._on_reset_view)
        self.resetOrderButton = QtWidgets.QPushButton('Reset axis order')
        self.resetOrderButton.clicked.connect(self._on_reset_axis_order)
        self.setOrderButton = QtWidgets.QPushButton('Set axis order')
        self.setOrderButton.clicked.connect(self._on_set_axis_order)
        self.setOrderLineEdit = QtWidgets.QLineEdit('0,1')

        # Layout
        self.setLayout(QtWidgets.QVBoxLayout())
        self.layout().addWidget(self.resetViewButton)
        self.layout().addWidget(self.resetOrderButton)
        self.layout().addWidget(self.setOrderLineEdit)
        self.layout().addWidget(self.setOrderButton)

        # Make sure widget isn't too big
        self.setSizePolicy(QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Expanding,
                                                 QtWidgets.QSizePolicy.Maximum))

    def _on_reset_view(self):
        self.viewer.reset_view()

    def _on_reset_axis_order(self):
        order_curr = self.viewer.dims.order
        self.viewer.dims.order = tuple(sorted(order_curr))
        step_curr = self.viewer.dims.current_step
        step_curr = [0 for _ in step_curr]
        self.viewer.dims.current_step = tuple(step_curr)

    def _on_set_axis_order(self):
        order_new = [int(c) for c in self.setOrderLineEdit.text().split(',')]
        self.viewer.dims.order = tuple(order_new)


class NapariShiftWidget(NapariBaseWidget):
    """ Napari widget for shifting the currently selected layer by a
    user-defined number of pixels. """

    @property
    def name(self):
        return 'image shift controls'

    def __init__(self, napariViewer):
        super().__init__(napariViewer)

        # Title label
        self.titleLabel = QtWidgets.QLabel('<h3>Image shift controls</h3>')

        # Shift up button
        self.upButton = QtWidgets.QPushButton()
        self.upButton.setToolTip('Shift selected layer up')
        self.upButton.setIcon(QtGui.QIcon(f':/themes/{self.viewer.theme}/up_arrow.svg'))
        self.upButton.clicked.connect(self._on_up)

        # Shift right button
        self.rightButton = QtWidgets.QPushButton()
        self.rightButton.setToolTip('Shift selected layer right')
        self.rightButton.setIcon(QtGui.QIcon(f':/themes/{self.viewer.theme}/right_arrow.svg'))
        self.rightButton.clicked.connect(self._on_right)

        # Shift down button
        self.downButton = QtWidgets.QPushButton()
        self.downButton.setToolTip('Shift selected layer down')
        self.downButton.setIcon(QtGui.QIcon(f':/themes/{self.viewer.theme}/down_arrow.svg'))
        self.downButton.clicked.connect(self._on_down)

        # Shift left button
        self.leftButton = QtWidgets.QPushButton()
        self.leftButton.setToolTip('Shift selected layer left')
        self.leftButton.setIcon(QtGui.QIcon(f':/themes/{self.viewer.theme}/left_arrow.svg'))
        self.leftButton.clicked.connect(self._on_left)

        # Reset button
        self.resetButton = QtWidgets.QPushButton('Reset')
        self.resetButton.clicked.connect(self._on_reset)

        # Shift distance field
        self.shiftDistanceLabel = QtWidgets.QLabel('Shift distance:')
        self.shiftDistanceInput = QtWidgets.QSpinBox()
        self.shiftDistanceInput.setMinimum(1)
        self.shiftDistanceInput.setMaximum(9999)
        self.shiftDistanceInput.setValue(1)
        self.shiftDistanceInput.setSuffix(' px')

        # Layout
        self.buttonGrid = QtWidgets.QGridLayout()
        self.buttonGrid.setSpacing(6)
        self.buttonGrid.addWidget(self.upButton, 0, 1)
        self.buttonGrid.addWidget(self.rightButton, 1, 2)
        self.buttonGrid.addWidget(self.downButton, 2, 1)
        self.buttonGrid.addWidget(self.leftButton, 1, 0)
        self.buttonGrid.addWidget(self.resetButton, 1, 1)

        self.shiftDistanceLayout = QtWidgets.QHBoxLayout()
        self.shiftDistanceLayout.setSpacing(12)
        self.shiftDistanceLayout.addWidget(self.shiftDistanceLabel)
        self.shiftDistanceLayout.addWidget(self.shiftDistanceInput, 1)

        self.setLayout(QtWidgets.QVBoxLayout())
        self.layout().setSpacing(24)
        self.layout().addWidget(self.titleLabel)
        self.layout().addLayout(self.buttonGrid)
        self.layout().addLayout(self.shiftDistanceLayout)

        # Make sure widget isn't too big
        self.setSizePolicy(QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Expanding,
                                                 QtWidgets.QSizePolicy.Maximum))

    def _on_up(self):
        self._do_shift(0, -self._get_shift_distance())

    def _on_right(self):
        self._do_shift(self._get_shift_distance(), 0)

    def _on_down(self):
        self._do_shift(0, self._get_shift_distance())

    def _on_left(self):
        self._do_shift(-self._get_shift_distance(), 0)

    def _on_reset(self):
        for layer in self.viewer.layers.selected:
            layer.translate = [0, 0]

    def _do_shift(self, xDist, yDist):
        for layer in self.viewer.layers.selected:
            y, x = layer.translate
            layer.translate = [y + yDist, x + xDist]

    def _get_shift_distance(self):
        return self.shiftDistanceInput.value()


class VispyBaseVisual(QtCore.QObject):
    def __init__(self):
        super().__init__()
        self._viewer = None
        self._view = None
        self._canvas = None
        self._nodes = []
        self._visible = True
        self._attached = False

    def attach(self, viewer, view, canvas, parent=None, order=0):
        self._viewer = viewer
        self._view = view
        self._canvas = canvas
        self._attached = True

    def detach(self):
        for node in self._nodes:
            node.parent = None

        self._viewer = None
        self._view = None
        self._canvas = None
        self._attached = False

    def setVisible(self, value):
        for node in self._nodes:
            node.visible = value

        self._visible = value

    def show(self):
        self.setVisible(True)

    def hide(self):
        self.setVisible(False)

    def _get_center_line_p1(self, pos, line_length, vertical):
        if vertical:
            return [pos[0], pos[1] - line_length / 2, 0]
        else:
            return [pos[0] - line_length / 2, pos[1], 0]

    def _get_center_line_p2(self, pos, line_length, vertical):
        if vertical:
            return [pos[0], pos[1] + line_length / 2, 0]
        else:
            return [pos[0] + line_length / 2, pos[1], 0]


class VispyROIVisual(VispyBaseVisual):
    sigROIChanged = QtCore.Signal(object, object)

    @property
    def position(self):
        return self._position

    @position.setter
    def position(self, value):
        self._position = np.array(value, dtype=int)
        self._update_position()
        self.sigROIChanged.emit(self.position, self.size)

    @property
    def size(self):
        return self._size

    @size.setter
    def size(self, value):
        self._size = np.array(value, dtype=int)
        self._update_size()
        self.sigROIChanged.emit(self.position, self.size)

    @property
    def bounds(self):
        pos = self.position
        size = self.size
        x0 = int(pos[0])
        y0 = int(pos[1])
        x1 = int(x0 + size[0])
        y1 = int(y0 + size[1])
        return x0, y0, x1, y1

    def __init__(self, rect_color='yellow', handle_color='orange'):
        super().__init__()
        self._drag_mode = None
        self._world_scale = 1

        self._position = [0, 0]
        self._size = [64, 64]

        self._rect_color = Color(rect_color)
        self._handle_color = Color(handle_color)

        # note order is x, y, z for VisPy
        self._rect_line_data2D = np.array(
            [[0, 0, 0], [1, 0, 0], [1, 0, 0], [1, 1, 0],
             [1, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 0]]
        )
        self._handle_line_data2D = np.array(
            [[0, 0, 0], [1, 0, 0], [1, 0, 0], [1, 1, 0],
             [1, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 0]]
        )
        self._handle_side_length = 16

    def attach(self, viewer, view, canvas, parent=None, order=0):
        super().attach(viewer, view, canvas, parent, order)

        self.rect_node = Compound(
            [Line(connect='segments', method='gl', width=4)],
            parent=parent,
        )
        self.rect_node.transform = STTransform()
        self.rect_node.order = order

        self.handle_node = Compound(
            [Line(connect='segments', method='gl', width=2)],
            parent=parent,
        )
        self.handle_node.transform = STTransform()
        self.handle_node.order = order

        self._nodes = [self.rect_node, self.handle_node]

        canvas.connect(self.on_mouse_press)
        canvas.connect(self.on_mouse_move)
        canvas.connect(self.on_mouse_release)
        self._viewer.camera.events.zoom.connect(self._on_zoom_change)
        self._viewer.dims.events.ndisplay.connect(self._on_data_change)

        self._on_zoom_change(None)
        self._on_data_change(None)
        self._update_position()
        self._update_size()

    def setVisible(self, value):
        super().setVisible(value)
        self._on_data_change(None)

    def _update_position(self):
        if not self._attached:
            return

        self.rect_node.transform.translate = [self._position[0] - 0.5,
                                              self._position[1] - 0.5,
                                              0, 0]
        self._update_handle()

    def _update_size(self):
        if not self._attached:
            return

        self.rect_node.transform.scale = [self._size[0], self._size[1], 1, 1]
        self._update_handle()

    def _update_handle(self):
        if not self._attached:
            return

        self.handle_node.transform.translate = [self._position[0] - 0.5 + self._size[0],
                                                self._position[1] - 0.5 + self._size[1],
                                                0, 0]

    def _on_data_change(self, event):
        if not self._attached or not self._visible:
            return

        # Actual number of displayed dims
        ndisplay = len(self._viewer.dims.displayed)
        if ndisplay != 2:
            raise ValueError('ndisplay not supported')

        self.rect_node._subvisuals[0].set_data(self._rect_line_data2D, self._rect_color)
        self.handle_node._subvisuals[0].set_data(self._handle_line_data2D, self._handle_color)

    def _on_zoom_change(self, event):
        if not self._attached:
            return

        self._world_scale = 1 / self._viewer.camera.zoom
        self.handle_node.transform.scale = [self._handle_side_length * self._world_scale,
                                            self._handle_side_length * self._world_scale,
                                            1, 1]

    def on_mouse_press(self, event):
        if not self._visible or event.button != 1:
            return

        # Determine whether the line was clicked
        mouse_pos = self._view.scene.node_transform(self._view).imap(event.pos)[0:2]

        pos_start = self.position
        pos_end = self.position + self._size

        if (pos_end[0] <= mouse_pos[0] <
                pos_end[0] + self._world_scale * self._handle_side_length and
            pos_end[1] <= mouse_pos[1] <
                pos_end[1] + self._world_scale * self._handle_side_length):
            self._drag_mode = 'scale'
        elif (pos_start[0] <= mouse_pos[0] < pos_end[0] and
              pos_start[1] <= mouse_pos[1] < pos_end[1]):
            self._drag_mode = 'move'
        else:
            return

        # Prepare for dragging
        self._view.interactive = False
        self._start_move_visual_pos = self.position
        self._start_move_visual_size = self.size
        self._start_move_mouse_pos = mouse_pos

    def on_mouse_move(self, event):
        if not self._visible or self._drag_mode is None:
            return

        mouse_pos = self._view.scene.node_transform(self._view).imap(event.pos)[0:2]
        if self._drag_mode == 'move':
            self.position = np.rint(
                self._start_move_visual_pos + mouse_pos - self._start_move_mouse_pos
            )
        elif self._drag_mode == 'scale':
            self.size = np.rint(
                np.clip(self._start_move_visual_size + mouse_pos - self._start_move_mouse_pos,
                        1, None)
            )

    def on_mouse_release(self, event):
        if not self._visible or event.button != 1:
            return

        self._view.interactive = True
        self._drag_mode = None


class VispyLineVisual(VispyBaseVisual):
    sigPositionChanged = QtCore.Signal(np.ndarray, int)

    @property
    def position(self):
        return self._position

    @position.setter
    def position(self, value):
        self._position = np.array(value, dtype=int)
        self._update_position()

    @property
    def angle(self):
        return self._angle

    @angle.setter
    def angle(self, value):
        self._angle = value
        self._update_angle()

    def __init__(self, color='yellow', movable=False):
        super().__init__()
        self._drag_mode = None
        self._world_scale = 1

        self._position = [0, 0]
        self._angle = 0.0

        self._color = Color(color)
        self._movable = movable
        self._click_sensitivity = 16

        # note order is x, y, z for VisPy
        self._line_data2D = np.array(
            [[0, 0, 0], [1, 0, 0]]
        )
        self._line_length = 4096

    def attach(self, viewer, view, canvas, parent=None, order=0):
        super().attach(viewer, view, canvas, parent, order)

        self.node = Compound(
            [Line(connect='segments', method='gl', width=4)],
            parent=parent,
        )
        self.node.transform = STTransform()
        self.node.order = order

        self._nodes = [self.node]

        canvas.connect(self.on_mouse_press)
        canvas.connect(self.on_mouse_move)
        canvas.connect(self.on_mouse_release)
        self._viewer.camera.events.zoom.connect(self._on_zoom_change)
        self._viewer.dims.events.ndisplay.connect(self._on_data_change)

        self._on_zoom_change(None)
        self._on_data_change(None)
        self._update_position()

    def setVisible(self, value):
        super().setVisible(value)
        self._on_data_change(None)

    def _update_position(self):
        if not self._attached:
            return

        angleRad = np.deg2rad(self._angle)
        self.node.transform.translate = [
            self._position[0] - self._line_length / 2 * self._world_scale * (np.cos(angleRad)),
            self._position[1] - self._line_length / 2 * self._world_scale * (np.sin(angleRad)),
            0, 0
        ]

    def _update_angle(self):
        if not self._attached:
            return

        self._line_data2D = np.array(
            [
                [0, 0, 0],
                [self._world_scale * self._line_length * np.cos(np.deg2rad(self._angle)),
                 self._world_scale * self._line_length * np.sin(np.deg2rad(self._angle)),
                 0]
            ]
        )
        self._on_data_change(None)
        self._update_position()

    def _on_data_change(self, event):
        if not self._attached or not self._visible:
            return

        # Actual number of displayed dims
        ndisplay = len(self._viewer.dims.displayed)
        if ndisplay != 2:
            raise ValueError('ndisplay not supported')

        self.node._subvisuals[0].set_data(self._line_data2D, self._color)

    def _on_zoom_change(self, event):
        if not self._attached:
            return

        self._world_scale = 1 / self._viewer.camera.zoom
        self._update_angle()

    def on_mouse_press(self, event):
        if not self._visible or not self._movable or event.button != 1:
            return

        # Determine whether the line was clicked
        mouse_pos = np.array(self._view.scene.node_transform(self._view).imap(event.pos)[0:2])

        s = np.sin(np.deg2rad(-self.angle))
        c = np.cos(np.deg2rad(-self.angle))

        center = np.array(self.position)

        mouse_pos_rot = mouse_pos - center
        mouse_pos_rot = np.array([mouse_pos_rot[0] * c - mouse_pos_rot[1] * s,
                                  mouse_pos_rot[0] * s + mouse_pos_rot[1] * c])
        mouse_pos_rot = mouse_pos_rot + center

        x_start = self.position[0] - self._line_length / 2
        x_end = self.position[0] + self._line_length / 2
        y_start = self.position[1] - self._click_sensitivity * self._world_scale
        y_end = self.position[1] + self._click_sensitivity * self._world_scale

        if x_start <= mouse_pos_rot[0] <= x_end and y_start <= mouse_pos_rot[1] <= y_end:
            self._drag_mode = 'move'
        else:
            return

        # Prepare for dragging
        self._view.interactive = False
        self._start_move_visual_pos = self.position
        self._start_move_mouse_pos = mouse_pos

    def on_mouse_move(self, event):
        if not self._visible or not self._movable or self._drag_mode is None:
            return

        mouse_pos = self._view.scene.node_transform(self._view).imap(event.pos)[0:2]
        if self._drag_mode == 'move':
            self.position = np.rint(
                self._start_move_visual_pos + mouse_pos - self._start_move_mouse_pos
            )

    def on_mouse_release(self, event):
        if not self._visible or not self._movable or event.button != 1:
            return

        self._view.interactive = True
        self._drag_mode = None


class VispyGridVisual(VispyBaseVisual):
    def __init__(self, color='yellow'):
        super().__init__()
        self._color = Color(color).rgba
        self._shape = np.array([0, 0])
        self._line_data2D = None
        self._line_length = 4096

    def attach(self, viewer, view, canvas, parent=None, order=0):
        super().attach(viewer, view, canvas, parent, order)

        self._update_line_data()

        self.node = Compound(
            [Line(connect='segments', method='gl', width=4)],
            parent=parent,
        )
        self.node.transform = STTransform()
        self.node.order = order

        self._nodes = [self.node]

        self._viewer.camera.events.zoom.connect(self._on_zoom_change)
        self._viewer.dims.events.ndisplay.connect(self._on_data_change)

        self._on_data_change(None)

    def setVisible(self, value):
        super().setVisible(value)
        self._on_data_change(None)

    def update(self, shape):
        self._shape = np.array(shape)
        self._update_line_data()

    def _update_line_data(self):
        scaled_line_length = self._line_length / self._viewer.camera.zoom
        self._line_data2D = np.array(
            [
                self._get_center_line_p1(0.25 * self._shape, scaled_line_length, True),
                self._get_center_line_p2(0.25 * self._shape, scaled_line_length, True),
                self._get_center_line_p1(0.375 * self._shape, scaled_line_length, True),
                self._get_center_line_p2(0.375 * self._shape, scaled_line_length, True),
                self._get_center_line_p1(0.50 * self._shape, scaled_line_length, True),
                self._get_center_line_p2(0.50 * self._shape, scaled_line_length, True),
                self._get_center_line_p1(0.625 * self._shape, scaled_line_length, True),
                self._get_center_line_p2(0.625 * self._shape, scaled_line_length, True),
                self._get_center_line_p1(0.75 * self._shape, scaled_line_length, True),
                self._get_center_line_p2(0.75 * self._shape, scaled_line_length, True),

                self._get_center_line_p1(0.25 * self._shape, scaled_line_length, False),
                self._get_center_line_p2(0.25 * self._shape, scaled_line_length, False),
                self._get_center_line_p1(0.375 * self._shape, scaled_line_length, False),
                self._get_center_line_p2(0.375 * self._shape, scaled_line_length, False),
                self._get_center_line_p1(0.50 * self._shape, scaled_line_length, False),
                self._get_center_line_p2(0.50 * self._shape, scaled_line_length, False),
                self._get_center_line_p1(0.625 * self._shape, scaled_line_length, False),
                self._get_center_line_p2(0.625 * self._shape, scaled_line_length, False),
                self._get_center_line_p1(0.75 * self._shape, scaled_line_length, False),
                self._get_center_line_p2(0.75 * self._shape, scaled_line_length, False)
            ]
        )
        self._on_data_change(None)

    def _on_data_change(self, event):
        if not self._attached or not self._visible or self._line_data2D is None:
            return

        # Actual number of displayed dims
        ndisplay = len(self._viewer.dims.displayed)
        if ndisplay != 2:
            raise ValueError('ndisplay not supported')

        self.node._subvisuals[0].set_data(self._line_data2D, self._color)

    def _on_zoom_change(self, event):
        if not self._attached:
            return

        self._update_line_data()


class VispyCrosshairVisual(VispyBaseVisual):
    def __init__(self, color='yellow'):
        super().__init__()
        self._paused = False
        self._mouse_moved_since_press = False
        self._color = Color(color).rgba
        self._line_positions = [0, 0]
        self._line_data2D = None
        self._line_length = 4096

    def attach(self, viewer, view, canvas, parent=None, order=0):
        super().attach(viewer, view, canvas, parent, order)

        self._update_line_data()

        self.node = Compound(
            [Line(connect='segments', method='gl', width=4)],
            parent=parent,
        )
        self.node.transform = STTransform()
        self.node.order = order

        self._nodes = [self.node]

        canvas.connect(self.on_mouse_press)
        canvas.connect(self.on_mouse_move)
        canvas.connect(self.on_mouse_release)
        self._viewer.camera.events.zoom.connect(self._on_zoom_change)
        self._viewer.dims.events.ndisplay.connect(self._on_data_change)

        self._on_data_change(None)

    def setVisible(self, value):
        super().setVisible(value)
        self._on_data_change(None)

    def _update_line_data(self):
        scaled_line_length = self._line_length / self._viewer.camera.zoom
        self._line_data2D = np.array(
            [
                self._get_center_line_p1(self._line_positions, scaled_line_length, True),
                self._get_center_line_p2(self._line_positions, scaled_line_length, True),
                self._get_center_line_p1(self._line_positions, scaled_line_length, False),
                self._get_center_line_p2(self._line_positions, scaled_line_length, False)
            ]
        )
        self._on_data_change(None)

    def _on_data_change(self, event):
        if not self._attached or not self._visible or self._line_data2D is None:
            return

        # Actual number of displayed dims
        ndisplay = len(self._viewer.dims.displayed)
        if ndisplay != 2:
            raise ValueError('ndisplay not supported')

        self.node._subvisuals[0].set_data(self._line_data2D, self._color)

    def _on_zoom_change(self, event):
        if not self._attached:
            return

        self._update_line_data()

    def on_mouse_press(self, event):
        if event.button != 1 or not self._visible:
            return

        self._mouse_moved_since_press = False

    def on_mouse_move(self, event):
        self._mouse_moved_since_press = True

        if not self._visible or self._paused:
            return

        mouse_pos = self._view.scene.node_transform(self._view).imap(event.pos)[0:2]
        self._line_positions = [mouse_pos[0], mouse_pos[1]]
        self._update_line_data()

    def on_mouse_release(self, event):
        if event.button != 1 or not self._visible or self._mouse_moved_since_press:
            return

        self._paused = not self._paused
        if not self._paused:
            self.on_mouse_move(event)


class VispyScatterVisual(VispyBaseVisual):
    def __init__(self, color='red', symbol='x'):
        super().__init__()
        self._color = Color(color)
        self._symbol = symbol
        self._markers_data = -1e8 * np.ones((1, 2))

    def attach(self, viewer, view, canvas, parent=None, order=0):
        super().attach(viewer, view, canvas, parent, order)

        self.node = Markers(pos=self._markers_data, parent=parent)
        self.node.transform = STTransform()
        self.node.order = order

        self._nodes = [self.node]

        self._viewer.dims.events.ndisplay.connect(self._on_data_change)

        self._on_data_change(None)

    def setVisible(self, value):
        super().setVisible(value)
        self._on_data_change(None)

    def setData(self, x, y):
        self._markers_data = np.column_stack((x, y))
        self._on_data_change(None)

    def _on_data_change(self, event):
        if not self._attached or not self._visible:
            return

        # Actual number of displayed dims
        ndisplay = len(self._viewer.dims.displayed)
        if ndisplay != 2:
            raise ValueError('ndisplay not supported')

        self.node.set_data(self._markers_data, edge_color=self._color, face_color=self._color,
                           symbol=self._symbol)

#!/usr/bin/python
# -*- coding:utf-8 -*-
# -*-mode:python ; tab-width:4 -*- ex:set tabstop=4 shiftwidth=4 expandtab: -*-

import numpy
from control.gxipy.gxwrapper import *
from control.gxipy.dxwrapper import *
from control.gxipy.gxidef import *

ERROR_SIZE = 1024
PIXEL_BIT_MASK = 0x00ff0000

if sys.version_info.major > 2:
    INT_TYPE = int
else:
    INT_TYPE = (int, long)


class DeviceManager(object):
    __instance_num = 0

    def __new__(cls, *args, **kw):
        cls.__instance_num += 1
        status = gx_init_lib()
        StatusProcessor.process(status, 'DeviceManager', 'init_lib')
        return object.__new__(cls, *args)
    
    def __init__(self):
        self.__device_num = 0
        self.__device_info_list = []

        

    def __del__(self):
        self.__class__.__instance_num -= 1
        if self.__class__.__instance_num <= 0:
            status = gx_close_lib()
            StatusProcessor.process(status, 'DeviceManager', 'close_lib')

    def __get_device_info_list(self, base_info, ip_info, num):
        """
        :brief      Convert GxDeviceBaseInfo and GxDeviceIPInfo to device info list
        :param      base_info:  device base info list[GxDeviceBaseInfo]
        :param      ip_info:    device ip info list[GxDeviceIPInfo]
        :param      num:        device number
        :return:    device info list
        """
        device_info_list = []
        for i in range(num):
            device_info_list.append({
                'index': i+1,
                'vendor_name': string_decoding(base_info[i].vendor_name),
                'model_name': string_decoding(base_info[i].model_name),
                'sn': string_decoding(base_info[i].serial_number),
                'display_name': string_decoding(base_info[i].display_name),
                'device_id': string_decoding(base_info[i].device_id),
                'user_id': string_decoding(base_info[i].user_id),
                'access_status': base_info[i].access_status,
                'device_class': base_info[i].device_class,
                'mac': string_decoding(ip_info[i].mac),
                'ip': string_decoding(ip_info[i].ip),
                'subnet_mask': string_decoding(ip_info[i].subnet_mask),
                'gateway': string_decoding(ip_info[i].gateway),
                'nic_mac': string_decoding(ip_info[i].nic_mac),
                'nic_ip': string_decoding(ip_info[i].nic_ip),
                'nic_subnet_mask': string_decoding(ip_info[i].nic_subnet_mask),
                'nic_gateWay': string_decoding(ip_info[i].nic_gateWay),
                'nic_description': string_decoding(ip_info[i].nic_description)
            })

        return device_info_list

    def __get_ip_info(self, base_info_list, dev_mum):
        """
        :brief      Get the network information
        """

        ip_info_list = []
        for i in range(dev_mum):
            if base_info_list[i].device_class == GxDeviceClassList.GEV:
                status, ip_info = gx_get_device_ip_info(i+1)
                StatusProcessor.process(status, 'DeviceManager', '__get_ip_info')
                ip_info_list.append(ip_info)
            else:
                ip_info_list.append(GxDeviceIPInfo())

        return ip_info_list

    def update_device_list(self, timeout=200):
        """
        :brief      enumerate the same network segment devices
        :param      timeout:    Enumeration timeout, range:[0, 0xFFFFFFFF]
        :return:    dev_num:    device number
                    device_info_list: all device info list
        """
        if not isinstance(timeout, INT_TYPE):
            raise ParameterTypeError("DeviceManager.update_device_list: "
                                     "Expected timeout type is int, not %s" % type(timeout))

        if (timeout < 0) or (timeout > UNSIGNED_INT_MAX):
            print("DeviceManager.update_device_list: "
                  "timeout out of bounds, timeout: minimum=0, maximum=%s" % hex(UNSIGNED_INT_MAX).__str__())
            return 0, None

        status, dev_num = gx_update_device_list(timeout)
        StatusProcessor.process(status, 'DeviceManager', 'update_device_list')

        status, base_info_list = gx_get_all_device_base_info(dev_num)
        StatusProcessor.process(status, 'DeviceManager', 'update_device_list')

        ip_info_list = self.__get_ip_info(base_info_list, dev_num)
        self.__device_num = dev_num
        self.__device_info_list = self.__get_device_info_list(base_info_list, ip_info_list, dev_num)

        return self.__device_num, self.__device_info_list

    def update_all_device_list(self, timeout=200):
        """
        :brief      Enumerate devices on different network segments
        :param      timeout:    Enumeration timeout, range:[0, 0xFFFFFFFF]
        :return:    dev_num:    device number
                    device_info_list:   all device info list
        """
        if not isinstance(timeout, INT_TYPE):
            raise ParameterTypeError("DeviceManager.update_all_device_list: "
                                     "Expected timeout type is int, not %s" % type(timeout))

        if (timeout < 0) or (timeout > UNSIGNED_INT_MAX):
            print("DeviceManager.update_all_device_list: "
                  "timeout out of bounds, timeout: minimum=0, maximum=%s" % hex(UNSIGNED_INT_MAX).__str__())
            return 0, None

        status, dev_num = gx_update_all_device_list(timeout)
        StatusProcessor.process(status, 'DeviceManager', 'update_all_device_list')

        status, base_info_list = gx_get_all_device_base_info(dev_num)
        StatusProcessor.process(status, 'DeviceManager', 'update_all_device_list')

        ip_info_list = self.__get_ip_info(base_info_list, dev_num)
        self.__device_num = dev_num
        self.__device_info_list = self.__get_device_info_list(base_info_list, ip_info_list, dev_num)

        return self.__device_num, self.__device_info_list

    def get_device_number(self):
        """
        :brief      Get device number
        :return:    device number
        """
        return self.__device_num

    def get_device_info(self):
        """
        :brief      Get all device info
        :return:    info_dict:      device info list
        """
        return self.__device_info_list

    def open_device_by_index(self, index, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by index
                    USB3 device return U3VDevice object
                    USB2 device return U2Device object
                    GEV  device return GEVDevice object
        :param      index:          device index must start from 1
        :param      access_mode:    the access of open device
        :return:    Device object
        """
        if not isinstance(index, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_index: "
                                     "Expected index type is int, not %s" % type(index))

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_index: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        if index < 1:
            print("DeviceManager.open_device_by_index: index must start from 1")
            return None
        elif index > UNSIGNED_INT_MAX:
            print("DeviceManager.open_device_by_index: index maximum: %s" % hex(UNSIGNED_INT_MAX).__str__())
            return None

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_index: "
                  "access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        if self.__device_num < index:
            # Re-update the device
            self.update_all_device_list()
            if self.__device_num < index:
                raise NotFoundDevice("DeviceManager.open_device_by_index: invalid index")

        # open devices by index
        open_param = GxOpenParam()
        open_param.content = string_encoding(str(index))
        open_param.open_mode = GxOpenMode.INDEX
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_index')

        # get device class
        device_class = self.__device_info_list[index-1]["device_class"]

        if device_class == GxDeviceClassList.U3V:
            return U3VDevice(handle)
        elif device_class == GxDeviceClassList.USB2:
            return U2Device(handle)
        elif device_class == GxDeviceClassList.GEV:
            return GEVDevice(handle)
        else:
            raise NotFoundDevice("DeviceManager.open_device_by_index: Does not support this device type.")

    def __get_device_class_by_sn(self, sn):
        """
        :brief:     1.find device by sn in self.__device_info_list
                    2.return different objects according to device class
        :param      sn:      device serial number
        :return:    device class
        """
        for index in range(self.__device_num):
            if self.__device_info_list[index]["sn"] == sn:
                return self.__device_info_list[index]["device_class"]

        # don't find this id in device base info list
        return -1

    def open_device_by_sn(self, sn, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by serial number(SN)
                    USB3 device return U3VDevice object
                    USB2 device return U2Device object
                    GEV device return GEVDevice object
        :param      sn:             device serial number, type: str
        :param      access_mode:    the mode of open device[GxAccessMode]
        :return:    Device object
        """
        if not isinstance(sn, str):
            raise ParameterTypeError("DeviceManager.open_device_by_sn: "
                                     "Expected sn type is str, not %s" % type(sn))

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_sn: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_sn: "
                  "access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        # get device class from self.__device_info_list
        device_class = self.__get_device_class_by_sn(sn)
        if device_class == -1:
            # Re-update the device
            self.update_all_device_list()
            device_class = self.__get_device_class_by_sn(sn)
            if device_class == -1:
                # don't find this sn
                raise NotFoundDevice("DeviceManager.open_device_by_sn: Not found device")

        # open devices by sn
        open_param = GxOpenParam()
        open_param.content = string_encoding(sn)
        open_param.open_mode = GxOpenMode.SN
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_sn')

        if device_class == GxDeviceClassList.U3V:
            return U3VDevice(handle)
        elif device_class == GxDeviceClassList.USB2:
            return U2Device(handle)
        elif device_class == GxDeviceClassList.GEV:
            return GEVDevice(handle)
        else:
            raise NotFoundDevice("DeviceManager.open_device_by_sn: Does not support this device type.")

    def __get_device_class_by_user_id(self, user_id):
        """
        :brief:     1.find device according to sn in self.__device_info_list
                    2.return different objects according to device class
        :param      user_id:        user ID
        :return:    device class
        """
        for index in range(self.__device_num):
            if self.__device_info_list[index]["user_id"] == user_id:
                return self.__device_info_list[index]["device_class"]

        # don't find this id in device base info list
        return -1

    def open_device_by_user_id(self, user_id, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by user defined name
                    USB3 device return U3VDevice object
                    GEV  device return GEVDevice object
        :param      user_id:        user defined name, type:str
        :param      access_mode:    the mode of open device[GxAccessMode]
        :return:    Device object
        """
        if not isinstance(user_id, str):
            raise ParameterTypeError("DeviceManager.open_device_by_user_id: "
                                     "Expected user_id type is str, not %s" % type(user_id))
        elif user_id.__len__() == 0:
            raise InvalidParameter("DeviceManager.open_device_by_user_id: Don't support user_id's length is 0")

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_user_id: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_user_id: access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        # get device class from self.__device_info_list
        device_class = self.__get_device_class_by_user_id(user_id)
        if device_class == -1:
            # Re-update the device
            self.update_all_device_list()
            device_class = self.__get_device_class_by_user_id(user_id)
            if device_class == -1:
                # don't find this user_id
                raise NotFoundDevice("DeviceManager.open_device_by_user_id: Not found device")

        # open device by user_id
        open_param = GxOpenParam()
        open_param.content = string_encoding(user_id)
        open_param.open_mode = GxOpenMode.USER_ID
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_user_id')

        if device_class == GxDeviceClassList.U3V:
            return U3VDevice(handle)
        elif device_class == GxDeviceClassList.GEV:
            return GEVDevice(handle)
        else:
            raise NotFoundDevice("DeviceManager.open_device_by_user_id: Does not support this device type.")

    def open_device_by_ip(self, ip, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by device ip address
        :param      ip:             device ip address, type:str
        :param      access_mode:    the mode of open device[GxAccessMode]
        :return:    GEVDevice object
        """
        if not isinstance(ip, str):
            raise ParameterTypeError("DeviceManager.open_device_by_ip: "
                                     "Expected ip type is str, not %s" % type(ip))

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_ip: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_ip: access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        # open device by ip
        open_param = GxOpenParam()
        open_param.content = string_encoding(ip)
        open_param.open_mode = GxOpenMode.IP
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_ip')

        return GEVDevice(handle)

    def open_device_by_mac(self, mac, access_mode=GxAccessMode.CONTROL):
        """
        :brief      open device by device mac address
        :param      mac:            device mac address, type:str
        :param      access_mode:    the mode of open device[GxAccessMode]
        :return:    GEVDevice object
        """
        if not isinstance(mac, str):
            raise ParameterTypeError("DeviceManager.open_device_by_mac: "
                                     "Expected mac type is str, not %s" % type(mac))

        if not isinstance(access_mode, INT_TYPE):
            raise ParameterTypeError("DeviceManager.open_device_by_mac: "
                                     "Expected access_mode type is int, not %s" % type(access_mode))

        access_mode_dict = dict((name, getattr(GxAccessMode, name)) for name in dir(GxAccessMode) if not name.startswith('__'))
        if access_mode not in access_mode_dict.values():
            print("DeviceManager.open_device_by_mac: access_mode out of bounds, %s" % access_mode_dict.__str__())
            return None

        # open device by ip
        open_param = GxOpenParam()
        open_param.content = string_encoding(mac)
        open_param.open_mode = GxOpenMode.MAC
        open_param.access_mode = access_mode
        status, handle = gx_open_device(open_param)
        StatusProcessor.process(status, 'DeviceManager', 'open_device_by_mac')

        return GEVDevice(handle)


class Feature:
    def __init__(self, handle, feature):
        """
        :param  handle:      The handle of the device
        :param  feature:     The feature code ID
        """
        self.__handle = handle
        self.__feature = feature
        self.feature_name = self.__get_name()

    def __get_name(self):
        """
        brief:  Getting Feature Name
        return: Success:    feature name
                Failed:     convert feature ID to string
        """
        status, name = gx_get_feature_name(self.__handle, self.__feature)
        if status != GxStatusList.SUCCESS:
            name = (hex(self.__feature)).__str__()

        return name

    def is_implemented(self):
        """
        brief:  Determining whether the feature is implemented
        return: is_implemented
        """
        status, is_implemented = gx_is_implemented(self.__handle, self.__feature)
        if status == GxStatusList.SUCCESS:
            return is_implemented
        elif status == GxStatusList.INVALID_PARAMETER:
            return False
        else:
            StatusProcessor.process(status, 'Feature', 'is_implemented')

    def is_readable(self):
        """
        brief:  Determining whether the feature is readable
        return: is_readable
        """
        implemented = self.is_implemented()
        if not implemented:
            return False

        status, is_readable = gx_is_readable(self.__handle, self.__feature)
        StatusProcessor.process(status, 'Feature', 'is_readable')
        return is_readable

    def is_writable(self):
        """
        brief:  Determining whether the feature is writable
        return: is_writable
        """
        implemented = self.is_implemented()
        if not implemented:
            return False

        status, is_writable = gx_is_writable(self.__handle, self.__feature)
        StatusProcessor.process(status, 'Feature', 'is_writable')
        return is_writable


class IntFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param  handle:      The handle of the device
        :param  feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def __range_dict(self, int_range):
        """
        :brief      Convert GxIntRange to dictionary
        :param      int_range:  GxIntRange
        :return:    range_dicts
        """
        range_dicts = {
            "min": int_range.min,
            "max": int_range.max,
            "inc": int_range.inc
        }
        return range_dicts

    def get_range(self):
        """
        :brief      Getting integer range
        :return:    integer range dictionary
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_range is not support" % self.feature_name)
            return None

        status, int_range = gx_get_int_range(self.__handle, self.__feature)
        StatusProcessor.process(status, 'IntFeature', 'get_range')
        return self.__range_dict(int_range)

    def get(self):
        """
        :brief      Getting integer value
        :return:    integer value
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get is not readable" % self.feature_name)
            return None

        status, int_value = gx_get_int(self.__handle, self.__feature)
        StatusProcessor.process(status, 'IntFeature', 'get')
        return int_value

    def set(self, int_value):
        """
        :brief      Setting integer value
        :param      int_value
        :return:    None
        """
        if not isinstance(int_value, INT_TYPE):
            raise ParameterTypeError("IntFeature.set: "
                                     "Expected int_value type is int, not %s" % type(int_value))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        int_range = self.get_range()
        check_ret = range_check(int_value, int_range["min"], int_range["max"], int_range["inc"])
        if not check_ret:
            print("IntFeature.set: "
                  "int_value out of bounds, %s.range=[%d, %d, %d]" %
                  (self.feature_name, int_range["min"], int_range["max"], int_range["inc"]))
            return

        status = gx_set_int(self.__handle, self.__feature, int_value)
        StatusProcessor.process(status, 'IntFeature', 'set')


class FloatFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param      handle:      The handle of the device
        :param      feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def __range_dict(self, float_range):
        """
        :brief      Convert GxFloatRange to dictionary
        :param      float_range:  GxFloatRange
        :return:    range_dicts
        """
        range_dicts = {
            "min": float_range.min,
            "max": float_range.max,
            "inc": float_range.inc,
            "unit": string_decoding(float_range.unit),
            "inc_is_valid": float_range.inc_is_valid
        }
        return range_dicts

    def get_range(self):
        """
        :brief      Getting float range
        :return:    float range dictionary
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_range is not support" % self.feature_name)
            return None

        status, float_range = gx_get_float_range(self.__handle, self.__feature)
        StatusProcessor.process(status, 'FloatFeature', 'get_range')
        return self.__range_dict(float_range)

    def get(self):
        """
        :brief      Getting float value
        :return:    float value
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get: is not readable" % self.feature_name)
            return None

        status, float_value = gx_get_float(self.__handle, self.__feature)
        StatusProcessor.process(status, 'FloatFeature', 'get')
        return float_value

    def set(self, float_value):
        """
        :brief      Setting float value
        :param      float_value
        :return:    None
        """
        if not isinstance(float_value, (INT_TYPE, float)):
            raise ParameterTypeError("FloatFeature.set: "
                                     "Expected float_value type is float, not %s" % type(float_value))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        float_range = self.get_range()
        check_ret = range_check(float_value, float_range["min"], float_range["max"])
        if not check_ret:
            print("FloatFeature.set: float_value out of bounds, %s.range=[%f, %f]" %
                  (self.feature_name, float_range["min"], float_range["max"]))
            return

        status = gx_set_float(self.__handle, self.__feature, float_value)
        StatusProcessor.process(status, 'FloatFeature', 'set')


class EnumFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param handle:      The handle of the device
        :param feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def get_range(self):
        """
        :brief      Getting range of Enum feature
        :return:    enum_dict:    enum range dictionary
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_range: is not support" % self.feature_name)
            return None

        status, enum_num = gx_get_enum_entry_nums(self.__handle, self.__feature)
        StatusProcessor.process(status, 'EnumFeature', 'get_range')

        status, enum_list = gx_get_enum_description(self.__handle, self.__feature, enum_num)
        StatusProcessor.process(status, 'EnumFeature', 'get_range')

        enum_dict = {}
        for i in range(enum_num):
            enum_dict[string_decoding(enum_list[i].symbolic)] = enum_list[i].value

        return enum_dict

    def get(self):
        """
        :brief      Getting value of Enum feature
        :return:    enum_value:     enum value
                    enum_str:       string for enum description
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get: is not readable" % self.feature_name)
            return None, None

        status, enum_value = gx_get_enum(self.__handle, self.__feature)
        StatusProcessor.process(status, 'EnumFeature', 'get')

        range_dict = self.get_range()
        new_dicts = {v: k for k, v in range_dict.items()}
        return enum_value, new_dicts[enum_value]

    def set(self, enum_value):
        """
        :brief      Setting enum value
        :param      enum_value
        :return:    None
        """
        if not isinstance(enum_value, INT_TYPE):
            raise ParameterTypeError("EnumFeature.set: "
                                     "Expected enum_value type is int, not %s" % type(enum_value))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        range_dict = self.get_range()
        enum_value_list = range_dict.values()
        if enum_value not in enum_value_list:
            print("EnumFeature.set: enum_value out of bounds, %s.range:%s" %
                  (self.feature_name, range_dict.__str__()))
            return

        status = gx_set_enum(self.__handle, self.__feature, enum_value)
        StatusProcessor.process(status, 'EnumFeature', 'set')


class BoolFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param handle:      The handle of the device
        :param feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def get(self):
        """
        :brief      Getting bool value
        :return:    bool value[bool]
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get is not readable" % self.feature_name)
            return None

        status, bool_value = gx_get_bool(self.__handle, self.__feature)
        StatusProcessor.process(status, 'BoolFeature', 'get')
        return bool_value

    def set(self, bool_value):
        """
        :brief      Setting bool value
        :param      bool_value[bool]
        :return:    None
        """
        if not isinstance(bool_value, bool):
            raise ParameterTypeError("BoolFeature.set: "
                                     "Expected bool_value type is bool, not %s" % type(bool_value))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        status = gx_set_bool(self.__handle, self.__feature, bool_value)
        StatusProcessor.process(status, 'BoolFeature', 'set')


class StringFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param      handle:      The handle of the device
        :param      feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def get_string_max_length(self):
        """
        :brief      Getting the maximum length that string can set
        :return:    length:     the maximum length that string can set
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_string_max_length is not support" % self.feature_name)
            return None

        status, length = gx_get_string_max_length(self.__handle, self.__feature)
        StatusProcessor.process(status, 'StringFeature', 'get_string_max_length')
        return length

    def get(self):
        """
        :brief      Getting string value
        :return:    strings
        """
        readable = self.is_readable()
        if not readable:
            print("%s.get is not readable" % self.feature_name)
            return None

        status, strings = gx_get_string(self.__handle, self.__feature)
        StatusProcessor.process(status, 'StringFeature', 'get')
        return strings

    def set(self, input_string):
        """
        :brief      Setting string value
        :param      input_string[string]
        :return:    None
        """
        if not isinstance(input_string, str):
            raise ParameterTypeError("StringFeature.set: "
                                     "Expected input_string type is str, not %s" % type(input_string))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set: is not writeable" % self.feature_name)
            return

        max_length = self.get_string_max_length()
        if input_string.__len__() > max_length:
            print("StringFeature.set: "
                  "input_string length out of bounds, %s.length_max:%s"
                  % (self.feature_name, max_length))
            return

        status = gx_set_string(self.__handle, self.__feature, input_string)
        StatusProcessor.process(status, 'StringFeature', 'set')


class BufferFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param      handle:      The handle of the device
        :param      feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def get_buffer_length(self):
        """
        :brief      Getting buffer length
        :return:    length:     buffer length
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.get_buffer_length is not support" % self.feature_name)
            return None

        status, length = gx_get_buffer_length(self.__handle, self.__feature)
        StatusProcessor.process(status, 'BuffFeature', 'get_buffer_length')
        return length

    def get_buffer(self):
        """
        :brief      Getting buffer data
        :return:    Buffer object

        """
        readable = self.is_readable()
        if not readable:
            print("%s.get_buffer is not readable" % self.feature_name)
            return None

        status, buf = gx_get_buffer(self.__handle, self.__feature)
        StatusProcessor.process(status, 'BuffFeature', 'get_buffer')
        return Buffer(buf)

    def set_buffer(self, buf):
        """
        :brief      Setting buffer data
        :param      buf:    Buffer object
        :return:    None
        """
        if not isinstance(buf, Buffer):
            raise ParameterTypeError("BuffFeature.set_buffer: "
                                     "Expected buff type is Buffer, not %s" % type(buf))

        writeable = self.is_writable()
        if not writeable:
            print("%s.set_buffer is not writeable" % self.feature_name)
            return

        max_length = self.get_buffer_length()
        if buf.get_length() > max_length:
            print("BuffFeature.set_buffer: "
                  "buff length out of bounds, %s.length_max:%s" % (self.feature_name, max_length))
            return

        status = gx_set_buffer(self.__handle, self.__feature,
                               buf.get_ctype_array(), buf.get_length())
        StatusProcessor.process(status, 'BuffFeature', 'set_buffer')


class CommandFeature(Feature):
    def __init__(self, handle, feature):
        """
        :param      handle:      The handle of the device
        :param      feature:     The feature code ID
        """
        Feature.__init__(self, handle, feature)
        self.__handle = handle
        self.__feature = feature

    def send_command(self):
        """
        :brief      Sending command
        :return:    None
        """
        implemented = self.is_implemented()
        if not implemented:
            print("%s.send_command is not support" % self.feature_name)
            return

        status = gx_send_command(self.__handle, self.__feature)
        StatusProcessor.process(status, 'CommandFeature', 'send_command')


class Buffer:
    def __init__(self, data_array):
        try:
            addressof(data_array)
        except TypeError:
            error_msg = "Buffer.__init__: param is error type."
            raise ParameterTypeError(error_msg)

        self.data_array = data_array

    @staticmethod
    def from_file(file_name):
        file_object = open(file_name, "rb")
        file_string = file_object.read()
        data_array = create_string_buffer(file_string)
        file_object.close()
        return Buffer(data_array)

    @staticmethod
    def from_string(string_data):
        data_array = create_string_buffer(string_data)
        return Buffer(data_array)

    def get_data(self):
        buff_p = c_void_p()
        buff_p.value = addressof(self.data_array)
        print(buff_p.value)
        string_data = string_at(buff_p, len(self.data_array))
        return string_data

    def get_ctype_array(self):
        return self.data_array

    def get_numpy_array(self):
        numpy_array = numpy.array(self.data_array)
        return numpy_array

    def get_length(self):
        return len(self.data_array)


class Device:
    """
    The Camera class mainly encapsulates some common operations and function attributes,
    which are the operations and properties usually found in the camera.
    In addition, this class also encapsulates the common operations of  some functions in the C interface,
    such as SetInt, SetFloat, etc. Can not open to the user, so that when the subsequent addition of features,
    Python interface does not upgrade, or only the definition of the control code can support new features
    """
    def __init__(self, handle):
        self.__dev_handle = handle
        self.data_stream = []

        self.__OfflineCallBack = None
        self.__py_offline_callback = None
        self.__offline_callback_handle = None
        self.__py_capture_callback = None
        self.__CaptureCallBack = None
        self.__user_param = None

        # ---------------Device Information Section--------------------------
        self.DeviceVendorName = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_VENDOR_NAME)
        self.DeviceModelName = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_MODEL_NAME)
        self.DeviceFirmwareVersion = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_FIRMWARE_VERSION)
        self.DeviceVersion = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_VERSION)
        self.DeviceSerialNumber = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_SERIAL_NUMBER)
        self.FactorySettingVersion = StringFeature(self.__dev_handle, GxFeatureID.STRING_FACTORY_SETTING_VERSION)
        self.DeviceUserID = StringFeature(self.__dev_handle, GxFeatureID.STRING_DEVICE_USER_ID)
        self.DeviceLinkSelector = IntFeature(self.__dev_handle, GxFeatureID.INT_DEVICE_LINK_SELECTOR)
        self.DeviceLinkThroughputLimitMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_DEVICE_LINK_THROUGHPUT_LIMIT_MODE)
        self.DeviceLinkThroughputLimit = IntFeature(self.__dev_handle, GxFeatureID.INT_DEVICE_LINK_THROUGHPUT_LIMIT)
        self.DeviceLinkCurrentThroughput = IntFeature(self.__dev_handle, GxFeatureID.INT_DEVICE_LINK_CURRENT_THROUGHPUT)
        self.DeviceReset = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_DEVICE_RESET)
        self.TimestampTickFrequency = IntFeature(self.__dev_handle, GxFeatureID.INT_TIMESTAMP_TICK_FREQUENCY)
        self.TimestampLatch = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TIMESTAMP_LATCH)
        self.TimestampReset = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TIMESTAMP_RESET)
        self.TimestampLatchReset = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TIMESTAMP_LATCH_RESET)
        self.TimestampLatchValue = IntFeature(self.__dev_handle, GxFeatureID.INT_TIMESTAMP_LATCH_VALUE)

        # ---------------ImageFormat Section--------------------------------
        self.SensorWidth = IntFeature(self.__dev_handle, GxFeatureID.INT_SENSOR_WIDTH)
        self.SensorHeight = IntFeature(self.__dev_handle, GxFeatureID.INT_SENSOR_HEIGHT)
        self.WidthMax = IntFeature(self.__dev_handle, GxFeatureID.INT_WIDTH_MAX)
        self.HeightMax = IntFeature(self.__dev_handle, GxFeatureID.INT_HEIGHT_MAX)
        self.OffsetX = IntFeature(self.__dev_handle, GxFeatureID.INT_OFFSET_X)
        self.OffsetY = IntFeature(self.__dev_handle, GxFeatureID.INT_OFFSET_Y)
        self.Width = IntFeature(self.__dev_handle, GxFeatureID.INT_WIDTH)
        self.Height = IntFeature(self.__dev_handle, GxFeatureID.INT_HEIGHT)
        self.BinningHorizontal = IntFeature(self.__dev_handle, GxFeatureID.INT_BINNING_HORIZONTAL)
        self.BinningVertical = IntFeature(self.__dev_handle, GxFeatureID.INT_BINNING_VERTICAL)
        self.DecimationHorizontal = IntFeature(self.__dev_handle, GxFeatureID.INT_DECIMATION_HORIZONTAL)
        self.DecimationVertical = IntFeature(self.__dev_handle, GxFeatureID.INT_DECIMATION_VERTICAL)
        self.PixelSize = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_PIXEL_SIZE)
        self.PixelColorFilter = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_PIXEL_COLOR_FILTER)
        self.PixelFormat = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_PIXEL_FORMAT)
        self.ReverseX = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_REVERSE_X)
        self.ReverseY = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_REVERSE_Y)
        self.TestPattern = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TEST_PATTERN)
        self.TestPatternGeneratorSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TEST_PATTERN_GENERATOR_SELECTOR)
        self.RegionSendMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_REGION_SEND_MODE)
        self.RegionMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_REGION_MODE)
        self.RegionSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_REGION_SELECTOR)
        self.CenterWidth = IntFeature(self.__dev_handle, GxFeatureID.INT_CENTER_WIDTH)
        self.CenterHeight = IntFeature(self.__dev_handle, GxFeatureID.INT_CENTER_HEIGHT)
        self.BinningHorizontalMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BINNING_HORIZONTAL_MODE)
        self.BinningVerticalMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BINNING_VERTICAL_MODE)

        # ---------------TransportLayer Section-------------------------------
        self.PayloadSize = IntFeature(self.__dev_handle, GxFeatureID.INT_PAYLOAD_SIZE)

        # ---------------AcquisitionTrigger Section---------------------------
        self.AcquisitionMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_ACQUISITION_MODE)
        self.AcquisitionStart = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_ACQUISITION_START)
        self.AcquisitionStop = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_ACQUISITION_STOP)
        self.TriggerMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_MODE)
        self.TriggerSoftware = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TRIGGER_SOFTWARE)
        self.TriggerActivation = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_ACTIVATION)
        self.ExposureTime = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_EXPOSURE_TIME)
        self.ExposureAuto = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_EXPOSURE_AUTO)
        self.TriggerFilterRaisingEdge = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TRIGGER_FILTER_RAISING)
        self.TriggerFilterFallingEdge = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TRIGGER_FILTER_FALLING)
        self.TriggerSource = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_SOURCE)
        self.ExposureMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_EXPOSURE_MODE)
        self.TriggerSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_SELECTOR)
        self.TriggerDelay = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_TRIGGER_DELAY)
        self.TransferControlMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRANSFER_CONTROL_MODE)
        self.TransferOperationMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRANSFER_OPERATION_MODE)
        self.TransferStart = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_TRANSFER_START)
        self.TransferBlockCount = IntFeature(self.__dev_handle, GxFeatureID.INT_TRANSFER_BLOCK_COUNT)
        self.FrameBufferOverwriteActive = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_FRAME_STORE_COVER_ACTIVE)
        self.AcquisitionFrameRateMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_ACQUISITION_FRAME_RATE_MODE)
        self.AcquisitionFrameRate = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_ACQUISITION_FRAME_RATE)
        self.CurrentAcquisitionFrameRate = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_CURRENT_ACQUISITION_FRAME_RATE)
        self.FixedPatternNoiseCorrectMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_FIXED_PATTERN_NOISE_CORRECT_MODE)
        self.AcquisitionBurstFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_ACQUISITION_BURST_FRAME_COUNT)
        self.AcquisitionStatusSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_ACQUISITION_STATUS_SELECTOR)
        self.AcquisitionStatus = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_ACQUISITION_STATUS)
        self.ExposureDelay = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_EXPOSURE_DELAY)

        # ----------------DigitalIO Section----------------------------------
        self.UserOutputSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_USER_OUTPUT_SELECTOR)
        self.UserOutputValue = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_USER_OUTPUT_VALUE)
        self.LineSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_LINE_SELECTOR)
        self.LineMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_LINE_MODE)
        self.LineInverter = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_LINE_INVERTER)
        self.LineSource = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_LINE_SOURCE)
        self.LineStatus = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_LINE_STATUS)
        self.LineStatusAll = IntFeature(self.__dev_handle, GxFeatureID.INT_LINE_STATUS_ALL)

        # ----------------AnalogControls Section----------------------------
        self.GainAuto = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_GAIN_AUTO)
        self.GainSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_GAIN_SELECTOR)
        self.BlackLevelAuto = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BLACK_LEVEL_AUTO)
        self.BlackLevelSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BLACK_LEVEL_SELECTOR)
        self.BalanceWhiteAuto = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BALANCE_WHITE_AUTO)
        self.BalanceRatioSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_BALANCE_RATIO_SELECTOR)
        self.BalanceRatio = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_BALANCE_RATIO)
        self.DeadPixelCorrect = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_DEAD_PIXEL_CORRECT)
        self.Gain = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_GAIN)
        self.BlackLevel = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_BLACK_LEVEL)
        self.GammaEnable = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_GAMMA_ENABLE)
        self.GammaMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_GAMMA_MODE)
        self.Gamma = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_GAMMA)
        self.DigitalShift = IntFeature(self.__dev_handle, GxFeatureID.INT_DIGITAL_SHIFT)

        # ---------------CustomFeature Section------------------------------
        self.ExpectedGrayValue = IntFeature(self.__dev_handle, GxFeatureID.INT_GRAY_VALUE)
        self.AAROIOffsetX = IntFeature(self.__dev_handle, GxFeatureID.INT_AAROI_OFFSETX)
        self.AAROIOffsetY = IntFeature(self.__dev_handle, GxFeatureID.INT_AAROI_OFFSETY)
        self.AAROIWidth = IntFeature(self.__dev_handle, GxFeatureID.INT_AAROI_WIDTH)
        self.AAROIHeight = IntFeature(self.__dev_handle, GxFeatureID.INT_AAROI_HEIGHT)
        self.AutoGainMin = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_AUTO_GAIN_MIN)
        self.AutoGainMax = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_AUTO_GAIN_MAX)
        self.AutoExposureTimeMin = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_AUTO_EXPOSURE_TIME_MIN)
        self.AutoExposureTimeMax = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_AUTO_EXPOSURE_TIME_MAX)
        self.ContrastParam = IntFeature(self.__dev_handle, GxFeatureID.INT_CONTRAST_PARAM)
        self.GammaParam = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_GAMMA_PARAM)
        self.ColorCorrectionParam = IntFeature(self.__dev_handle, GxFeatureID.INT_COLOR_CORRECTION_PARAM)
        self.AWBLampHouse = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_AWB_LAMP_HOUSE)
        self.AWBROIOffsetX = IntFeature(self.__dev_handle, GxFeatureID.INT_AWBROI_OFFSETX)
        self.AWBROIOffsetY = IntFeature(self.__dev_handle, GxFeatureID.INT_AWBROI_OFFSETY)
        self.AWBROIWidth = IntFeature(self.__dev_handle, GxFeatureID.INT_AWBROI_WIDTH)
        self.AWBROIHeight = IntFeature(self.__dev_handle, GxFeatureID.INT_AWBROI_HEIGHT)
        self.SharpnessMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_SHARPNESS_MODE)
        self.Sharpness = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_SHARPNESS)

        # ---------------UserSetControl Section-------------------------
        self.UserSetSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_USER_SET_SELECTOR)
        self.UserSetLoad = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_USER_SET_LOAD)
        self.UserSetSave = CommandFeature(self.__dev_handle, GxFeatureID.COMMAND_USER_SET_SAVE)
        self.UserSetDefault = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_USER_SET_DEFAULT)

        # ---------------LUT Section-------------------------------
        self.LUTSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_LUT_SELECTOR)
        self.LUTValueAll = BufferFeature(self.__dev_handle, GxFeatureID.BUFFER_LUT_VALUE_ALL)
        self.LUTEnable = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_LUT_ENABLE)
        self.LUTIndex = IntFeature(self.__dev_handle, GxFeatureID.INT_LUT_INDEX)
        self.LUTValue = IntFeature(self.__dev_handle, GxFeatureID.INT_LUT_VALUE)

        # ---------------Color Transformation Control--------------
        self.ColorTransformationMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COLOR_TRANSFORMATION_MODE)
        self.ColorTransformationEnable = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_COLOR_TRANSFORMATION_ENABLE)
        self.ColorTransformationValueSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_COLOR_TRANSFORMATION_VALUE_SELECTOR)
        self.ColorTransformationValue = FloatFeature(self.__dev_handle, GxFeatureID.FLOAT_COLOR_TRANSFORMATION_VALUE)

        # ---------------ChunkData Section-------------------------
        self.ChunkModeActive = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_CHUNK_MODE_ACTIVE)
        self.ChunkSelector = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_CHUNK_SELECTOR)
        self.ChunkEnable = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_CHUNK_ENABLE)


    def stream_on(self):
        """
        :brief      send start command, camera start transmission image data
        :return:    none
        """
        status = gx_send_command(self.__dev_handle, GxFeatureID.COMMAND_ACQUISITION_START)
        StatusProcessor.process(status, 'Device', 'stream_on')

        payload_size = self.PayloadSize.get()
        self.data_stream[0].set_payload_size(payload_size)
        self.data_stream[0].acquisition_flag = True

    def stream_off(self):
        """
        :brief      send stop command, camera stop transmission image data
        :return:    none
        """
        self.data_stream[0].acquisition_flag = False
        status = gx_send_command(self.__dev_handle, GxFeatureID.COMMAND_ACQUISITION_STOP)
        StatusProcessor.process(status, 'Device', 'stream_off')

    def export_config_file(self, file_path):
        """
        :brief      Export the current configuration file
        :param      file_path:      file path(type: str)
        :return:    none
        """
        if not isinstance(file_path, str):
            raise ParameterTypeError("Device.export_config_file: "
                                     "Expected file_path type is str, not %s" % type(file_path))

        status = gx_export_config_file(self.__dev_handle, file_path)
        StatusProcessor.process(status, 'Device', 'export_config_file')

    def import_config_file(self, file_path, verify=False):
        """
        :brief      Imported configuration file
        :param      file_path:  file path(type: str)
        :param      verify:     If this value is true, all the imported values will be read out
                                and checked for consistency(type: bool)
        :return:    none
        """
        if not isinstance(file_path, str):
            raise ParameterTypeError("Device.import_config_file: "
                                     "Expected file_path type is str, not %s" % type(file_path))

        if not isinstance(verify, bool):
            raise ParameterTypeError("Device.import_config_file: "
                                     "Expected verify type is bool, not %s" % type(verify))

        status = gx_import_config_file(self.__dev_handle, file_path, verify)
        StatusProcessor.process(status, 'Device', 'import_config_file')

    def close_device(self):
        """
        :brief      close device, close device handle
        :return:    None
        """
        status = gx_close_device(self.__dev_handle)
        StatusProcessor.process(status, 'Device', 'close_device')
        self.__dev_handle = None

    def get_stream_channel_num(self):
        """
        :brief      Get the number of stream channels supported by the current device.
        :return:    the number of stream channels
        """
        return len(self.data_stream)


    def register_device_offline_callback(self, call_back):
        """
        :brief      Register the device offline event callback function.
        :param      call_back:  callback function
        :return:    none
        """
        self.__py_offline_callback = call_back
        self.__OfflineCallBack = OFF_LINE_CALL(self.__on_device_offline_call_back)
        status, self.__offline_callback_handle = gx_register_device_offline_callback\
            (self.__dev_handle, self.__OfflineCallBack)
        StatusProcessor.process(status, 'Device', 'register_device_offline_callback')

    def unregister_device_offline_callback(self):
        """
        :brief      Unregister the device offline event callback function.
        :return:    none
        """
        status = gx_unregister_device_offline_callback(self.__dev_handle, self.__offline_callback_handle)
        self.__py_offline_callback = None
        self.__offline_callback_handle = None
        StatusProcessor.process(status, 'Device', 'unregister_device_offline_callback')

    def __on_device_offline_call_back(self, c_user_param):
        """
        :brief      Device offline event callback function with an unused c_void_p.
        :return:    none
        """
        self.__py_offline_callback()


    def register_capture_callback(self, user_param, cap_call):
        """
        :brief      Register the capture event callback function.
        :param      cap_call:  callback function
        :return:    none
        """
        self.__user_param = user_param
        self.__py_capture_callback = cap_call
        self.__CaptureCallBack = CAP_CALL(self.__on_capture_call_back)
        status = gx_register_capture_callback(self.__dev_handle, self.__CaptureCallBack)
        StatusProcessor.process(status, 'Device', 'register_capture_callback')

    def unregister_capture_callback(self):
        """
        :brief      Unregister the capture event callback function.
        :return:    none
        """
        status = gx_unregister_capture_callback(self.__dev_handle)
        self.__py_capture_callback = None
        self.__user_param = None
        StatusProcessor.process(status, 'Device', 'unregister_capture_callback')

    def __on_capture_call_back(self, capture_data):
        """
        :brief      Capture event callback function with capture date.
        :return:    none
        """
        frame_data = GxFrameData()
        frame_data.image_buf = capture_data.contents.image_buf
        frame_data.width = capture_data.contents.width
        frame_data.height = capture_data.contents.height
        frame_data.pixel_format = capture_data.contents.pixel_format
        frame_data.image_size = capture_data.contents.image_size
        frame_data.frame_id = capture_data.contents.frame_id
        frame_data.timestamp = capture_data.contents.timestamp
        frame_data.buf_id = capture_data.contents.frame_id
        image = RawImage(frame_data)
        self.__py_capture_callback(self.__user_param, image)


class GEVDevice(Device):
    def __init__(self, handle):
        self.__dev_handle = handle
        Device.__init__(self, self.__dev_handle)
        self.GevCurrentIPConfigurationLLA = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_GEV_CURRENT_IP_CONFIGURATION_LLA)
        self.GevCurrentIPConfigurationDHCP = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_GEV_CURRENT_IP_CONFIGURATION_DHCP)
        self.GevCurrentIPConfigurationPersistentIP = BoolFeature(self.__dev_handle, GxFeatureID.BOOL_GEV_CURRENT_IP_CONFIGURATION_PERSISTENT_IP)
        self.EstimatedBandwidth = IntFeature(self.__dev_handle, GxFeatureID.INT_ESTIMATED_BANDWIDTH)
        self.GevHeartbeatTimeout = IntFeature(self.__dev_handle, GxFeatureID.INT_GEV_HEARTBEAT_TIMEOUT)
        self.GevSCPSPacketSize = IntFeature(self.__dev_handle, GxFeatureID.INT_GEV_PACKET_SIZE)
        self.GevSCPD = IntFeature(self.__dev_handle, GxFeatureID.INT_GEV_PACKET_DELAY)
        self.GevLinkSpeed = IntFeature(self.__dev_handle, GxFeatureID.INT_GEV_LINK_SPEED)
        self.DeviceCommandTimeout = IntFeature(self.__dev_handle, GxFeatureID.INT_COMMAND_TIMEOUT)
        self.DeviceCommandRetryCount = IntFeature(self.__dev_handle, GxFeatureID.INT_COMMAND_RETRY_COUNT)
        self.data_stream.append(GEVDataStream(self.__dev_handle))


class U3VDevice(Device):
    """
    The U3VDevice class inherits from the Device class. In addition to inheriting the properties of the Device,
    the U3V Device has special attributes such as bandwidth limitation, URBSetting, frame info, etc.
    """
    def __init__(self, handle):
        self.__dev_handle = handle
        Device.__init__(self, self.__dev_handle)
        self.data_stream.append(U3VDataStream(self.__dev_handle))


class U2Device(Device):
    """
    The U2Device class inherits from the Device class
    """
    def __init__(self, handle):
        self.__dev_handle = handle
        Device.__init__(self, self.__dev_handle)
        self.AcquisitionSpeedLevel = IntFeature(self.__dev_handle, GxFeatureID.INT_ACQUISITION_SPEED_LEVEL)
        self.AcquisitionFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_ACQUISITION_FRAME_COUNT)
        self.TriggerSwitch = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_TRIGGER_SWITCH)
        self.UserOutputMode = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_USER_OUTPUT_MODE)
        self.StrobeSwitch = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_STROBE_SWITCH)
        self.ADCLevel = IntFeature(self.__dev_handle, GxFeatureID.INT_ADC_LEVEL)
        self.Hblanking = IntFeature(self.__dev_handle, GxFeatureID.INT_H_BLANKING)
        self.Vblanking = IntFeature(self.__dev_handle, GxFeatureID.INT_V_BLANKING)
        self.UserPassword = StringFeature(self.__dev_handle, GxFeatureID.STRING_USER_PASSWORD)
        self.VerifyPassword = StringFeature(self.__dev_handle, GxFeatureID.STRING_VERIFY_PASSWORD)
        self.UserData = BufferFeature(self.__dev_handle, GxFeatureID.BUFFER_USER_DATA)
        self.AALightEnvironment = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_AA_LIGHT_ENVIRONMENT)
        self.FrameInformation = BufferFeature(self.__dev_handle, GxFeatureID.BUFFER_FRAME_INFORMATION)
        self.ImageGrayRaiseSwitch = EnumFeature(self.__dev_handle, GxFeatureID.ENUM_IMAGE_GRAY_RAISE_SWITCH)
        self.data_stream.append(DataStream(self.__dev_handle))


class DataStream:
    def __init__(self, handle):
        self.__dev_handle = handle
        self.StreamAnnouncedBufferCount = IntFeature(self.__dev_handle, GxFeatureID.INT_ANNOUNCED_BUFFER_COUNT)
        self.StreamDeliveredFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_DELIVERED_FRAME_COUNT)
        self.StreamLostFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_LOST_FRAME_COUNT)
        self.StreamIncompleteFrameCount = IntFeature(self.__dev_handle, GxFeatureID.INT_INCOMPLETE_FRAME_COUNT)
        self.StreamDeliveredPacketCount = IntFeature(self.__dev_handle, GxFeatureID.INT_DELIVERED_PACKET_COUNT)
        self.payload_size = 0
        self.acquisition_flag = False

    def set_payload_size(self, payload_size):
        self.payload_size = payload_size

    def set_acquisition_buffer_number(self, buf_num):
        """
        :brief      set the number of acquisition buffer
        :param      buf_num:   the number of acquisition buffer, range:[1, 0xFFFFFFFF]
        """
        if not isinstance(buf_num, INT_TYPE):
            raise ParameterTypeError("DataStream.set_acquisition_buffer_number: "
                                     "Expected buf_num type is int, not %s" % type(buf_num))

        if (buf_num < 1) or (buf_num > UNSIGNED_LONG_LONG_MAX):
            print("DataStream.set_acquisition_buffer_number:"
                  "buf_num out of bounds, minimum=1, maximum=%s"
                  % hex(UNSIGNED_LONG_LONG_MAX).__str__())
            return

        status = gx_set_acquisition_buffer_number(self.__dev_handle, buf_num)
        StatusProcessor.process(status, 'DataStream', 'set_acquisition_buffer_number')

    def get_image(self, timeout=1000):
        """
        :brief          Get an image, get successfully create image class object
        :param          timeout:    Acquisition timeout, range:[0, 0xFFFFFFFF]
        :return:        image object
        """
        if not isinstance(timeout, INT_TYPE):
            raise ParameterTypeError("DataStream.get_image: "
                                     "Expected timeout type is int, not %s" % type(timeout))

        if (timeout < 0) or (timeout > UNSIGNED_INT_MAX):
            print("DataStream.get_image: "
                  "timeout out of bounds, minimum=0, maximum=%s"
                  % hex(UNSIGNED_INT_MAX).__str__())
            return None

        if self.acquisition_flag is False:
            print("DataStream.get_image: Current data steam don't  start acquisition")
            return None

        frame_data = GxFrameData()
        frame_data.image_size = self.payload_size
        frame_data.image_buf = None
        image = RawImage(frame_data)

        status = gx_get_image(self.__dev_handle, image.frame_data, timeout)
        if status == GxStatusList.SUCCESS:
            return image
        elif status == GxStatusList.TIMEOUT:
            return None
        else:
            StatusProcessor.process(status, 'DataStream', 'get_image')
            return None

    def flush_queue(self):
        status = gx_flush_queue(self.__dev_handle)
        StatusProcessor.process(status, 'DataStream', 'flush_queue')


class U3VDataStream(DataStream):
    def __init__(self, handle):
        self.__handle = handle
        DataStream.__init__(self, self.__handle)
        self.StreamTransferSize = IntFeature(self.__handle, GxFeatureID.INT_STREAM_TRANSFER_SIZE)
        self.StreamTransferNumberUrb = IntFeature(self.__handle, GxFeatureID.INT_STREAM_TRANSFER_NUMBER_URB)


class GEVDataStream(DataStream):
    def __init__(self, handle):
        self.__handle = handle
        DataStream.__init__(self, self.__handle)
        self.StreamResendPacketCount = IntFeature(self.__handle, GxFeatureID.INT_RESEND_PACKET_COUNT)
        self.StreamRescuedPacketCount = IntFeature(self.__handle, GxFeatureID.INT_RESCUED_PACKED_COUNT)
        self.StreamResendCommandCount = IntFeature(self.__handle, GxFeatureID.INT_RESEND_COMMAND_COUNT)
        self.StreamUnexpectedPacketCount = IntFeature(self.__handle, GxFeatureID.INT_UNEXPECTED_PACKED_COUNT)
        self.MaxPacketCountInOneBlock = IntFeature(self.__handle, GxFeatureID.INT_MAX_PACKET_COUNT_IN_ONE_BLOCK)
        self.MaxPacketCountInOneCommand = IntFeature(self.__handle, GxFeatureID.INT_MAX_PACKET_COUNT_IN_ONE_COMMAND)
        self.ResendTimeout = IntFeature(self.__handle, GxFeatureID.INT_RESEND_TIMEOUT)
        self.MaxWaitPacketCount = IntFeature(self.__handle, GxFeatureID.INT_MAX_WAIT_PACKET_COUNT)
        self.ResendMode = EnumFeature(self.__handle, GxFeatureID.ENUM_RESEND_MODE)
        self.StreamMissingBlockIDCount = IntFeature(self.__handle, GxFeatureID.INT_MISSING_BLOCK_ID_COUNT)
        self.BlockTimeout = IntFeature(self.__handle, GxFeatureID.INT_BLOCK_TIMEOUT)
        self.MaxNumQueueBuffer = IntFeature(self.__handle, GxFeatureID.INT_MAX_NUM_QUEUE_BUFFER)
        self.PacketTimeout = IntFeature(self.__handle, GxFeatureID.INT_PACKET_TIMEOUT)


class UnexpectedError(Exception):
    """
    brief:  Unexpected error exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class NotFoundTL(Exception):
    """
    brief:  not found TL exception
    param:  args             exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class NotFoundDevice(Exception):
    """
    brief:  not found device exception
    param:  args              exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class OffLine(Exception):
    """
    brief:  device offline exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class InvalidParameter(Exception):
    """
    brief:  input invalid parameter exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class InvalidHandle(Exception):
    """
    brief:  invalid handle exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class InvalidCall(Exception):
    """
    brief:  invalid callback exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class InvalidAccess(Exception):
    """
    brief:  invalid access exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class NeedMoreBuffer(Exception):
    """
    brief:  need more buffer exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class FeatureTypeError(Exception):
    """
    brief:  feature id error exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class OutOfRange(Exception):
    """
    brief:  param out of range exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class NotInitApi(Exception):
    """
    brief:  not init api exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class Timeout(Exception):
    """
    brief:  timeout exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


class ParameterTypeError(Exception):
    """
    brief:  parameter type error exception
    param:  args            exception description
    return: none
    """
    def __init__(self, args):
        Exception.__init__(self, args)


def exception_deal(status, args):
    """
    brief:  deal with different exception
    param:  status         function return value
    param:  args            exception description
    return: none
    """
    if status == GxStatusList.ERROR:
        raise UnexpectedError(args)
    elif status == GxStatusList.NOT_FOUND_TL:
        raise NotFoundTL(args)
    elif status == GxStatusList.NOT_FOUND_DEVICE:
        raise NotFoundDevice(args)
    elif status == GxStatusList.OFFLINE:
        raise OffLine(args)
    elif status == GxStatusList.INVALID_PARAMETER:
        raise InvalidParameter(args)
    elif status == GxStatusList.INVALID_HANDLE:
        raise InvalidHandle(args)
    elif status == GxStatusList.INVALID_CALL:
        raise InvalidCall(args)
    elif status == GxStatusList.INVALID_ACCESS:
        raise InvalidAccess(args)
    elif status == GxStatusList.NEED_MORE_BUFFER:
        raise NeedMoreBuffer(args)
    elif status == GxStatusList.ERROR_TYPE:
        raise FeatureTypeError(args)
    elif status == GxStatusList.OUT_OF_RANGE:
        raise OutOfRange(args)
    elif status == GxStatusList.NOT_INIT_API:
        raise NotInitApi(args)
    elif status == GxStatusList.TIMEOUT:
        raise Timeout(args)
    elif status == GxStatusList.REPEAT_OPENED:
        raise InvalidAccess(args)
    else:
        raise Exception(args)


class StatusProcessor:
    def __init__(self):
        pass

    @staticmethod
    def process(status, class_name, function_name):
        """
        :brief      1.Error code processing
                    2.combine the class name and function name of the transmitted function into a string
                    3.Throw an exception
        :param      status:   function return value
        :param      class_name:  class name
        :param      function_name: function name
        :return:    none
        """
        if status != GxStatusList.SUCCESS:
            ret, err_code, string = gx_get_last_error(ERROR_SIZE)
            error_message = "%s.%s:%s" % (class_name, function_name, string)
            exception_deal(status, error_message)

    @staticmethod
    def printing(status, class_name, function_name):
        """
        :brief      1.Error code processing
                    2.combine the class name and function name of the transmitted function into a string and print it out
        :param      status:   function return value
        :param      class_name:  class name
        :param      function_name: function name
        :return:    none
        """
        if status != GxStatusList.SUCCESS:
            ret, err_code, string = gx_get_last_error(ERROR_SIZE)
            error_message = "%s.%s:%s" % (class_name, function_name, string)
            print(error_message)


class RGBImage:
    def __init__(self, frame_data):
        self.frame_data = frame_data

        if self.frame_data.image_buf is not None:
            self.__image_array = string_at(self.frame_data.image_buf, self.frame_data.image_size)
        else:
            self.__image_array = (c_ubyte * self.frame_data.image_size)()
            self.frame_data.image_buf = addressof(self.__image_array)

    def image_improvement(self, color_correction_param=0, contrast_lut=None, gamma_lut=None):
        """
        :brief:     Improve image quality of the object itself
        :param      color_correction_param:     color correction param address
                                                (get from Device.ColorCorrectionParam.get_int())
        :param      contrast_lut:               contrast lut
        :param      gamma_lut:                  gamma lut
        :return:    None
        """
        if (color_correction_param == 0) and (contrast_lut is None) and (gamma_lut is None):
            return

        if contrast_lut is None:
            contrast_parameter = None
        elif isinstance(contrast_lut, Buffer):
            contrast_parameter = contrast_lut.get_ctype_array()
        else:
            raise ParameterTypeError("RGBImage.image_improvement: "
                                     "Expected contrast_lut type is Buffer, not %s" % type(contrast_lut))

        if gamma_lut is None:
            gamma_parameter = None
        elif isinstance(gamma_lut, Buffer):
            gamma_parameter = gamma_lut.get_ctype_array()
        else:
            raise ParameterTypeError("RGBImage.image_improvement: "
                                     "Expected gamma_lut type is Buffer, not %s" % type(gamma_lut))

        if not isinstance(color_correction_param, INT_TYPE):
            raise ParameterTypeError("RGBImage.image_improvement: "
                                     "Expected color_correction_param type is int, not %s" % type(color_correction_param))

        status = dx_image_improvement(self.frame_data.image_buf, self.frame_data.image_buf,
                                      self.frame_data.width, self.frame_data.height,
                                      color_correction_param, contrast_parameter, gamma_parameter)

        if status != DxStatus.OK:
            raise UnexpectedError("RGBImage.image_improvement: failed, error code:%s" % hex(status).__str__())

    def get_numpy_array(self):
        """
        :brief:     Return data as a numpy.Array type with dimension Image.height * Image.width * 3
        :return:    numpy.Array objects
        """
        image_np = numpy.frombuffer(self.__image_array, dtype=numpy.ubyte).reshape(self.frame_data.height, self.frame_data.width, 3)
        return image_np

    def get_image_size(self):
        """
        :brief      Get RGB data size
        :return:    size
        """
        return self.frame_data.image_size


class RawImage:
    def __init__(self, frame_data):
        self.frame_data = frame_data

        if self.frame_data.image_buf is not None:
            self.__image_array = string_at(self.frame_data.image_buf, self.frame_data.image_size)
        else:
            self.__image_array = (c_ubyte * self.frame_data.image_size)()
            self.frame_data.image_buf = addressof(self.__image_array)

    def __get_bit_depth(self, pixel_format):
        """
        :brief      Calculate pixel depth based on pixel format
        :param      pixel_format
        :return:    pixel depth
        """
        bpp10_tup = (GxPixelFormatEntry.MONO10, GxPixelFormatEntry.BAYER_GR10, GxPixelFormatEntry.BAYER_RG10,
                     GxPixelFormatEntry.BAYER_GB10, GxPixelFormatEntry.BAYER_BG10)

        bpp12_tup = (GxPixelFormatEntry.MONO12, GxPixelFormatEntry.BAYER_GR12, GxPixelFormatEntry.BAYER_RG12,
                     GxPixelFormatEntry.BAYER_GB12, GxPixelFormatEntry.BAYER_BG12)

        bpp16_tup = (GxPixelFormatEntry.MONO16, GxPixelFormatEntry.BAYER_GR16, GxPixelFormatEntry.BAYER_RG16,
                     GxPixelFormatEntry.BAYER_GB16, GxPixelFormatEntry.BAYER_BG16)

        if (pixel_format & PIXEL_BIT_MASK) == GX_PIXEL_8BIT:
            return GxPixelSizeEntry.BPP8
        elif pixel_format in bpp10_tup:
            return GxPixelSizeEntry.BPP10
        elif pixel_format in bpp12_tup:
            return GxPixelSizeEntry.BPP12
        elif pixel_format == GxPixelFormatEntry.MONO14:
            return GxPixelSizeEntry.BPP14
        elif pixel_format in bpp16_tup:
            return GxPixelSizeEntry.BPP16
        elif (pixel_format & PIXEL_BIT_MASK) == GX_PIXEL_24BIT:
            return GxPixelSizeEntry.BPP24
        elif (pixel_format & PIXEL_BIT_MASK) == GX_PIXEL_48BIT:
            return GxPixelSizeEntry.BPP48
        else:
            return -1

    def __get_pixel_color_filter(self, pixel_format):
        """
        :brief      Calculate pixel color filter based on pixel format
        :param      pixel_format
        :return:    pixel color filter
        """
        gr_tup = (GxPixelFormatEntry.BAYER_GR8, GxPixelFormatEntry.BAYER_GR10,
                  GxPixelFormatEntry.BAYER_GR12, GxPixelFormatEntry.BAYER_GR16)
        rg_tup = (GxPixelFormatEntry.BAYER_RG8, GxPixelFormatEntry.BAYER_RG10,
                  GxPixelFormatEntry.BAYER_RG12, GxPixelFormatEntry.BAYER_RG16)
        gb_tup = (GxPixelFormatEntry.BAYER_GB8, GxPixelFormatEntry.BAYER_GB10,
                  GxPixelFormatEntry.BAYER_GB12, GxPixelFormatEntry.BAYER_GB16)
        bg_tup = (GxPixelFormatEntry.BAYER_BG8, GxPixelFormatEntry.BAYER_BG10,
                  GxPixelFormatEntry.BAYER_BG12, GxPixelFormatEntry.BAYER_BG16)
        mono_tup = (GxPixelFormatEntry.MONO8, GxPixelFormatEntry.MONO8_SIGNED,
                    GxPixelFormatEntry.MONO10, GxPixelFormatEntry.MONO12,
                    GxPixelFormatEntry.MONO14, GxPixelFormatEntry.MONO16)

        if pixel_format in gr_tup:
            return DxPixelColorFilter.GR
        elif pixel_format in rg_tup:
            return DxPixelColorFilter.RG
        elif pixel_format in gb_tup:
            return DxPixelColorFilter.GB
        elif pixel_format in bg_tup:
            return DxPixelColorFilter.BG
        elif pixel_format in mono_tup:
            return DxPixelColorFilter.NONE
        else:
            return -1

    def __pixel_format_raw16_to_raw8(self, pixel_format):
        """
        :brief      convert raw16 to raw8, the pixel format need convert to 8bit bayer format
        :param      pixel_format(10bit, 12bit, 16bit)
        :return:    pixel_format(8bit)
        """
        gr16_tup = (GxPixelFormatEntry.BAYER_GR10, GxPixelFormatEntry.BAYER_GR12, GxPixelFormatEntry.BAYER_GR16)
        rg16_tup = (GxPixelFormatEntry.BAYER_RG10, GxPixelFormatEntry.BAYER_RG12, GxPixelFormatEntry.BAYER_RG16)
        gb16_tup = (GxPixelFormatEntry.BAYER_GB10, GxPixelFormatEntry.BAYER_GB12, GxPixelFormatEntry.BAYER_GB16)
        bg16_tup = (GxPixelFormatEntry.BAYER_BG10, GxPixelFormatEntry.BAYER_BG12, GxPixelFormatEntry.BAYER_BG16)
        mono16_tup = (GxPixelFormatEntry.MONO10, GxPixelFormatEntry.MONO12,
                      GxPixelFormatEntry.MONO14, GxPixelFormatEntry.MONO16)

        if pixel_format in gr16_tup:
            return GxPixelFormatEntry.BAYER_GR8
        elif pixel_format in rg16_tup:
            return GxPixelFormatEntry.BAYER_RG8
        elif pixel_format in gb16_tup:
            return GxPixelFormatEntry.BAYER_GB8
        elif pixel_format in bg16_tup:
            return GxPixelFormatEntry.BAYER_BG8
        elif pixel_format in mono16_tup:
            return GxPixelFormatEntry.MONO8
        else:
            return -1

    def __raw16_to_raw8(self, pixel_bit_depth, valid_bits):
        """
        :brief      convert raw16 to raw8
        :param      pixel_bit_depth     pixel bit depth
        :param      valid_bits:         data valid digit[DxValidBit]
        :return:    RAWImage object
        """
        if pixel_bit_depth == GxPixelSizeEntry.BPP10:
            valid_bits = min(valid_bits, DxValidBit.BIT2_9)
        elif pixel_bit_depth == GxPixelSizeEntry.BPP12:
            valid_bits = min(valid_bits, DxValidBit.BIT4_11)
        else:
            print("RawImage.__dx_raw16_to_raw8: Only support 10bit and 12bit")
            return None

        frame_data = GxFrameData()
        frame_data.status = self.frame_data.status
        frame_data.width = self.frame_data.width
        frame_data.height = self.frame_data.height
        frame_data.pixel_format = self.__pixel_format_raw16_to_raw8(self.frame_data.pixel_format)
        frame_data.image_size = self.frame_data.width * self.frame_data.height
        frame_data.frame_id = self.frame_data.frame_id
        frame_data.timestamp = self.frame_data.timestamp
        # frame_data.buf_id = self.frame_data.buf_id
        frame_data.image_buf = None
        image_raw8 = RawImage(frame_data)

        status = dx_raw16_to_raw8(self.frame_data.image_buf, image_raw8.frame_data.image_buf,
                                  self.frame_data.width, self.frame_data.height, valid_bits)

        if status != DxStatus.OK:
            raise UnexpectedError("RawImage.convert: raw16 convert to raw8 failed, Error core: %s"
                                  % hex(status).__str__())
        else:
            return image_raw8

    def __raw8_to_rgb(self, raw8_image, convert_type, pixel_color_filter, flip):
        """
        :brief      convert raw8 to RGB
        :param      raw8_image          RAWImage object, bit depth is 8bit
        :param      convert_type:       Bayer convert type, See detail in DxBayerConvertType
        :param      pixel_color_filter: pixel color filter, See detail in DxPixelColorFilter
        :param      flip:               Output image flip flag
                                        True: turn the image upside down
                                        False: do not flip
        :return:    RAWImage object
        """
        frame_data = GxFrameData()
        frame_data.status = raw8_image.frame_data.status
        frame_data.width = raw8_image.frame_data.width
        frame_data.height = raw8_image.frame_data.height
        frame_data.pixel_format = GxPixelFormatEntry.RGB8_PLANAR
        frame_data.image_size = raw8_image.frame_data.width * raw8_image.frame_data.height * 3
        frame_data.frame_id = raw8_image.frame_data.frame_id
        frame_data.timestamp = raw8_image.frame_data.timestamp
        # frame_data.buf_id = self.frame_data.buf_id
        frame_data.image_buf = None
        image_rgb = RGBImage(frame_data)

        status = dx_raw8_to_rgb24(raw8_image.frame_data.image_buf, image_rgb.frame_data.image_buf,
                                  raw8_image.frame_data.width, raw8_image.frame_data.height,
                                  convert_type, pixel_color_filter, flip)

        if status != DxStatus.OK:
            raise UnexpectedError("RawImage.convert: failed, error code:%s" % hex(status).__str__())

        return image_rgb

    def convert(self, mode, flip=False, valid_bits=DxValidBit.BIT4_11,
                convert_type=DxBayerConvertType.NEIGHBOUR):
        """
        :brief      Image format convert
        :param      mode:           "RAW8":     convert raw16 RAWImage object to raw8 RAWImage object
                                    "RGB":   convert raw8 RAWImage object to RGBImage object
        :param      flip:           Output image flip flag
                                    True: turn the image upside down
                                    False: do not flip
        :param      valid_bits:     Data valid digit, See detail in DxValidBit, raw8 don't this param
        :param      convert_type:   Bayer convert type, See detail in DxBayerConvertType
        :return:    return image object according to mode parameter
        """
        if self.frame_data.status != GxFrameStatusList.SUCCESS:
            print("RawImage.convert: This is a incomplete image")
            return None

        if not isinstance(flip, bool):
            raise ParameterTypeError("RawImage.convert: "
                                     "Expected flip type is bool, not %s" % type(flip))

        if not isinstance(convert_type, INT_TYPE):
            raise ParameterTypeError("RawImage.convert: "
                                     "Expected convert_type type is int, not %s" % type(convert_type))

        if not isinstance(valid_bits, INT_TYPE):
            raise ParameterTypeError("RawImage.convert: "
                                     "Expected valid_bits type is int, not %s" % type(valid_bits))

        if not isinstance(mode, str):
            raise ParameterTypeError("RawImage.convert: "
                                     "Expected mode type is str, not %s" % type(mode))

        convert_type_dict = dict((name, getattr(DxBayerConvertType, name))
                                 for name in dir(DxBayerConvertType) if not name.startswith('__'))
        if convert_type not in convert_type_dict.values():
            print("RawImage.convert: convert_type out of bounds, %s" % convert_type_dict.__str__())
            return None

        valid_bits_dict = dict((name, getattr(DxValidBit, name))
                               for name in dir(DxValidBit) if not name.startswith('__'))
        if valid_bits not in valid_bits_dict.values():
            print("RawImage.convert: valid_bits out of bounds, %s" % valid_bits_dict.__str__())
            return None

        pixel_bit_depth = self.__get_bit_depth(self.frame_data.pixel_format)
        pixel_color_filter = self.__get_pixel_color_filter(self.frame_data.pixel_format)

        if pixel_bit_depth < GxPixelSizeEntry.BPP8 or \
           pixel_bit_depth > GxPixelSizeEntry.BPP12:
            print("RawImage.convert: This pixel format is not support")
            return None

        if mode == "RAW8":
            if flip is True:
                print('''RawImage.convert: mode="RAW8" don't support flip=True''')
                return None

            if pixel_bit_depth in (GxPixelSizeEntry.BPP10, GxPixelSizeEntry.BPP12):
                image_raw8 = self.__raw16_to_raw8(pixel_bit_depth, valid_bits)
                return image_raw8
            else:
                print('RawImage.convert: mode="RAW8" only support 10bit and 12bit')
        elif mode == "RGB":
            if pixel_bit_depth in (GxPixelSizeEntry.BPP10, GxPixelSizeEntry.BPP12):
                image_raw8 = self.__raw16_to_raw8(pixel_bit_depth, valid_bits)
            else:
                image_raw8 = self

            return self.__raw8_to_rgb(image_raw8, convert_type, pixel_color_filter, flip)
        else:
            print('''RawImage.convert: mode="%s", isn't support''' % mode)
            return None

    def get_numpy_array(self):
        """
        :brief      Return data as a numpy.Array type with dimension Image.height * Image.width
        :return:    numpy.Array objects
        """
        if self.frame_data.status != GxFrameStatusList.SUCCESS:
            print("RawImage.get_numpy_array: This is a incomplete image")
            return None

        image_size = self.frame_data.width * self.frame_data.height

        if self.frame_data.pixel_format & PIXEL_BIT_MASK == GX_PIXEL_8BIT:
            image_np = numpy.frombuffer(self.__image_array, dtype=numpy.ubyte, count=image_size).\
                reshape(self.frame_data.height, self.frame_data.width)
        elif self.frame_data.pixel_format & PIXEL_BIT_MASK == GX_PIXEL_16BIT:
            image_np = numpy.frombuffer(self.__image_array, dtype=numpy.uint16, count=image_size).\
                reshape(self.frame_data.height, self.frame_data.width)
        else:
            image_np = None

        return image_np

    def get_data(self):
        """
        :brief      get Raw data
        :return:    raw data[string]
        """
        image_str = string_at(self.__image_array, self.frame_data.image_size)
        return image_str

    def save_raw(self, file_path):
        """
        :brief      save raw data
        :param      file_path:      file path
        :return:    None
        """
        if not isinstance(file_path, str):
            raise ParameterTypeError("RawImage.save_raw: "
                                     "Expected file_path type is str, not %s" % type(file_path))

        try:
            fp = open(file_path, "wb")
            fp.write(self.__image_array)
            fp.close()
        except Exception as error:
            raise UnexpectedError("RawImage.save_raw:%s" % error)

    def get_status(self):
        """
        :brief      get raw data status
        :return:    status
        """
        return self.frame_data.status

    def get_width(self):
        """
        :brief      get width of raw data
        :return:    width
        """
        return self.frame_data.width

    def get_height(self):
        """
        :brief     get height of raw data
        :return:
        """
        return self.frame_data.height

    def get_pixel_format(self):
        """
        :brief      Get image pixel format
        :return:    pixel format
        """
        return self.frame_data.pixel_format

    def get_image_size(self):
        """
        :brief      Get raw data size
        :return:    size
        """
        return self.frame_data.image_size

    def get_frame_id(self):
        """
        :brief      Get  frame id of raw data
        :return:    frame id
        """
        return self.frame_data.frame_id

    def get_timestamp(self):
        """
        :brief      Get timestamp of raw data
        :return:    timestamp
        """
        return self.frame_data.timestamp



class Utility:
    def __init__(self):
        pass

    @staticmethod
    def get_gamma_lut(gamma=1):
        if not (isinstance(gamma, (INT_TYPE, float))):
            raise ParameterTypeError("Utility.get_gamma_lut: "
                                     "Expected gamma type is float, not %s" % type(gamma))

        if (gamma < GAMMA_MIN) or (gamma > GAMMA_MAX):
            print("Utility.get_gamma_lut: gamma out of bounds, range:[0.1, 10.0]")
            return None

        status, gamma_lut, gamma_lut_len = dx_get_gamma_lut(gamma)
        if status != DxStatus.OK:
            print("Utility.get_gamma_lut: get gamma lut failure, Error code:%s" % hex(status).__str__())
            return None

        return Buffer(gamma_lut)

    @staticmethod
    def get_contrast_lut(contrast=0):
        if not (isinstance(contrast, INT_TYPE)):
            raise ParameterTypeError("Utility.get_contrast_lut: "
                                     "Expected contrast type is int, not %s" % type(contrast))

        if (contrast < CONTRAST_MIN) or (contrast > CONTRAST_MAX):
            print("Utility.get_contrast_lut: contrast out of bounds, range:[-50, 100]")
            return None

        status, contrast_lut, contrast_lut_len = dx_get_contrast_lut(contrast)
        if status != DxStatus.OK:
            print("Utility.get_contrast_lut: get contrast lut failure, Error code:%s" % hex(status).__str__())
            return None

        return Buffer(contrast_lut)




